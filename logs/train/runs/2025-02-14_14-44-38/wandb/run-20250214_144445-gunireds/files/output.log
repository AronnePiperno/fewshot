[[36m2025-02-14 14:44:46,992[0m][[34m__main__[0m][[32mINFO[0m] - Starting training![0m
You are using a CUDA device ('NVIDIA GeForce RTX 4070 SUPER') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision
No of videos in train is 214
Loading train Video Information ...
No of class 10
No of videos in validation is 203
Loading validation Video Information ...
No of class 10
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”“
â”ƒ[1;35m [0m[1;35m   [0m[1;35m [0mâ”ƒ[1;35m [0m[1;35mName                                                   [0m[1;35m [0mâ”ƒ[1;35m [0m[1;35mType                           [0m[1;35m [0mâ”ƒ[1;35m [0m[1;35mParams[0m[1;35m [0mâ”ƒ[1;35m [0m[1;35mMode [0m[1;35m [0mâ”ƒ
â”¡â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”©
â”‚[2m [0m[2m0  [0m[2m [0mâ”‚ net                                                     â”‚ T3ALNet                         â”‚  638 M â”‚ train â”‚
â”‚[2m [0m[2m1  [0m[2m [0mâ”‚ net.model                                               â”‚ CoCa                            â”‚  638 M â”‚ train â”‚
â”‚[2m [0m[2m2  [0m[2m [0mâ”‚ net.model.text                                          â”‚ TextTransformer                 â”‚  123 M â”‚ train â”‚
â”‚[2m [0m[2m3  [0m[2m [0mâ”‚ net.model.text.token_embedding                          â”‚ Embedding                       â”‚ 37.9 M â”‚ train â”‚
â”‚[2m [0m[2m4  [0m[2m [0mâ”‚ net.model.text.transformer                              â”‚ Transformer                     â”‚ 85.1 M â”‚ train â”‚
â”‚[2m [0m[2m5  [0m[2m [0mâ”‚ net.model.text.transformer.resblocks                    â”‚ ModuleList                      â”‚ 85.1 M â”‚ train â”‚
â”‚[2m [0m[2m6  [0m[2m [0mâ”‚ net.model.text.transformer.resblocks.0                  â”‚ ResidualAttentionBlock          â”‚  7.1 M â”‚ train â”‚
â”‚[2m [0m[2m7  [0m[2m [0mâ”‚ net.model.text.transformer.resblocks.0.ln_1             â”‚ LayerNorm                       â”‚  1.5 K â”‚ train â”‚
â”‚[2m [0m[2m8  [0m[2m [0mâ”‚ net.model.text.transformer.resblocks.0.attn             â”‚ MultiheadAttention              â”‚  2.4 M â”‚ train â”‚
â”‚[2m [0m[2m9  [0m[2m [0mâ”‚ net.model.text.transformer.resblocks.0.attn.out_proj    â”‚ NonDynamicallyQuantizableLinear â”‚  590 K â”‚ train â”‚
â”‚[2m [0m[2m10 [0m[2m [0mâ”‚ net.model.text.transformer.resblocks.0.ls_1             â”‚ Identity                        â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m11 [0m[2m [0mâ”‚ net.model.text.transformer.resblocks.0.ln_2             â”‚ LayerNorm                       â”‚  1.5 K â”‚ train â”‚
â”‚[2m [0m[2m12 [0m[2m [0mâ”‚ net.model.text.transformer.resblocks.0.mlp              â”‚ Sequential                      â”‚  4.7 M â”‚ train â”‚
â”‚[2m [0m[2m13 [0m[2m [0mâ”‚ net.model.text.transformer.resblocks.0.mlp.c_fc         â”‚ Linear                          â”‚  2.4 M â”‚ train â”‚
â”‚[2m [0m[2m14 [0m[2m [0mâ”‚ net.model.text.transformer.resblocks.0.mlp.gelu         â”‚ GELU                            â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m15 [0m[2m [0mâ”‚ net.model.text.transformer.resblocks.0.mlp.c_proj       â”‚ Linear                          â”‚  2.4 M â”‚ train â”‚
â”‚[2m [0m[2m16 [0m[2m [0mâ”‚ net.model.text.transformer.resblocks.0.ls_2             â”‚ Identity                        â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m17 [0m[2m [0mâ”‚ net.model.text.transformer.resblocks.1                  â”‚ ResidualAttentionBlock          â”‚  7.1 M â”‚ train â”‚
â”‚[2m [0m[2m18 [0m[2m [0mâ”‚ net.model.text.transformer.resblocks.1.ln_1             â”‚ LayerNorm                       â”‚  1.5 K â”‚ train â”‚
â”‚[2m [0m[2m19 [0m[2m [0mâ”‚ net.model.text.transformer.resblocks.1.attn             â”‚ MultiheadAttention              â”‚  2.4 M â”‚ train â”‚
â”‚[2m [0m[2m20 [0m[2m [0mâ”‚ net.model.text.transformer.resblocks.1.attn.out_proj    â”‚ NonDynamicallyQuantizableLinear â”‚  590 K â”‚ train â”‚
â”‚[2m [0m[2m21 [0m[2m [0mâ”‚ net.model.text.transformer.resblocks.1.ls_1             â”‚ Identity                        â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m22 [0m[2m [0mâ”‚ net.model.text.transformer.resblocks.1.ln_2             â”‚ LayerNorm                       â”‚  1.5 K â”‚ train â”‚
â”‚[2m [0m[2m23 [0m[2m [0mâ”‚ net.model.text.transformer.resblocks.1.mlp              â”‚ Sequential                      â”‚  4.7 M â”‚ train â”‚
â”‚[2m [0m[2m24 [0m[2m [0mâ”‚ net.model.text.transformer.resblocks.1.mlp.c_fc         â”‚ Linear                          â”‚  2.4 M â”‚ train â”‚
â”‚[2m [0m[2m25 [0m[2m [0mâ”‚ net.model.text.transformer.resblocks.1.mlp.gelu         â”‚ GELU                            â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m26 [0m[2m [0mâ”‚ net.model.text.transformer.resblocks.1.mlp.c_proj       â”‚ Linear                          â”‚  2.4 M â”‚ train â”‚
â”‚[2m [0m[2m27 [0m[2m [0mâ”‚ net.model.text.transformer.resblocks.1.ls_2             â”‚ Identity                        â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m28 [0m[2m [0mâ”‚ net.model.text.transformer.resblocks.2                  â”‚ ResidualAttentionBlock          â”‚  7.1 M â”‚ train â”‚
â”‚[2m [0m[2m29 [0m[2m [0mâ”‚ net.model.text.transformer.resblocks.2.ln_1             â”‚ LayerNorm                       â”‚  1.5 K â”‚ train â”‚
â”‚[2m [0m[2m30 [0m[2m [0mâ”‚ net.model.text.transformer.resblocks.2.attn             â”‚ MultiheadAttention              â”‚  2.4 M â”‚ train â”‚
â”‚[2m [0m[2m31 [0m[2m [0mâ”‚ net.model.text.transformer.resblocks.2.attn.out_proj    â”‚ NonDynamicallyQuantizableLinear â”‚  590 K â”‚ train â”‚
â”‚[2m [0m[2m32 [0m[2m [0mâ”‚ net.model.text.transformer.resblocks.2.ls_1             â”‚ Identity                        â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m33 [0m[2m [0mâ”‚ net.model.text.transformer.resblocks.2.ln_2             â”‚ LayerNorm                       â”‚  1.5 K â”‚ train â”‚
â”‚[2m [0m[2m34 [0m[2m [0mâ”‚ net.model.text.transformer.resblocks.2.mlp              â”‚ Sequential                      â”‚  4.7 M â”‚ train â”‚
â”‚[2m [0m[2m35 [0m[2m [0mâ”‚ net.model.text.transformer.resblocks.2.mlp.c_fc         â”‚ Linear                          â”‚  2.4 M â”‚ train â”‚
â”‚[2m [0m[2m36 [0m[2m [0mâ”‚ net.model.text.transformer.resblocks.2.mlp.gelu         â”‚ GELU                            â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m37 [0m[2m [0mâ”‚ net.model.text.transformer.resblocks.2.mlp.c_proj       â”‚ Linear                          â”‚  2.4 M â”‚ train â”‚
â”‚[2m [0m[2m38 [0m[2m [0mâ”‚ net.model.text.transformer.resblocks.2.ls_2             â”‚ Identity                        â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m39 [0m[2m [0mâ”‚ net.model.text.transformer.resblocks.3                  â”‚ ResidualAttentionBlock          â”‚  7.1 M â”‚ train â”‚
â”‚[2m [0m[2m40 [0m[2m [0mâ”‚ net.model.text.transformer.resblocks.3.ln_1             â”‚ LayerNorm                       â”‚  1.5 K â”‚ train â”‚
â”‚[2m [0m[2m41 [0m[2m [0mâ”‚ net.model.text.transformer.resblocks.3.attn             â”‚ MultiheadAttention              â”‚  2.4 M â”‚ train â”‚
â”‚[2m [0m[2m42 [0m[2m [0mâ”‚ net.model.text.transformer.resblocks.3.attn.out_proj    â”‚ NonDynamicallyQuantizableLinear â”‚  590 K â”‚ train â”‚
â”‚[2m [0m[2m43 [0m[2m [0mâ”‚ net.model.text.transformer.resblocks.3.ls_1             â”‚ Identity                        â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m44 [0m[2m [0mâ”‚ net.model.text.transformer.resblocks.3.ln_2             â”‚ LayerNorm                       â”‚  1.5 K â”‚ train â”‚
â”‚[2m [0m[2m45 [0m[2m [0mâ”‚ net.model.text.transformer.resblocks.3.mlp              â”‚ Sequential                      â”‚  4.7 M â”‚ train â”‚
â”‚[2m [0m[2m46 [0m[2m [0mâ”‚ net.model.text.transformer.resblocks.3.mlp.c_fc         â”‚ Linear                          â”‚  2.4 M â”‚ train â”‚
â”‚[2m [0m[2m47 [0m[2m [0mâ”‚ net.model.text.transformer.resblocks.3.mlp.gelu         â”‚ GELU                            â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m48 [0m[2m [0mâ”‚ net.model.text.transformer.resblocks.3.mlp.c_proj       â”‚ Linear                          â”‚  2.4 M â”‚ train â”‚
â”‚[2m [0m[2m49 [0m[2m [0mâ”‚ net.model.text.transformer.resblocks.3.ls_2             â”‚ Identity                        â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m50 [0m[2m [0mâ”‚ net.model.text.transformer.resblocks.4                  â”‚ ResidualAttentionBlock          â”‚  7.1 M â”‚ train â”‚
â”‚[2m [0m[2m51 [0m[2m [0mâ”‚ net.model.text.transformer.resblocks.4.ln_1             â”‚ LayerNorm                       â”‚  1.5 K â”‚ train â”‚
â”‚[2m [0m[2m52 [0m[2m [0mâ”‚ net.model.text.transformer.resblocks.4.attn             â”‚ MultiheadAttention              â”‚  2.4 M â”‚ train â”‚
â”‚[2m [0m[2m53 [0m[2m [0mâ”‚ net.model.text.transformer.resblocks.4.attn.out_proj    â”‚ NonDynamicallyQuantizableLinear â”‚  590 K â”‚ train â”‚
â”‚[2m [0m[2m54 [0m[2m [0mâ”‚ net.model.text.transformer.resblocks.4.ls_1             â”‚ Identity                        â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m55 [0m[2m [0mâ”‚ net.model.text.transformer.resblocks.4.ln_2             â”‚ LayerNorm                       â”‚  1.5 K â”‚ train â”‚
â”‚[2m [0m[2m56 [0m[2m [0mâ”‚ net.model.text.transformer.resblocks.4.mlp              â”‚ Sequential                      â”‚  4.7 M â”‚ train â”‚
â”‚[2m [0m[2m57 [0m[2m [0mâ”‚ net.model.text.transformer.resblocks.4.mlp.c_fc         â”‚ Linear                          â”‚  2.4 M â”‚ train â”‚
â”‚[2m [0m[2m58 [0m[2m [0mâ”‚ net.model.text.transformer.resblocks.4.mlp.gelu         â”‚ GELU                            â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m59 [0m[2m [0mâ”‚ net.model.text.transformer.resblocks.4.mlp.c_proj       â”‚ Linear                          â”‚  2.4 M â”‚ train â”‚
â”‚[2m [0m[2m60 [0m[2m [0mâ”‚ net.model.text.transformer.resblocks.4.ls_2             â”‚ Identity                        â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m61 [0m[2m [0mâ”‚ net.model.text.transformer.resblocks.5                  â”‚ ResidualAttentionBlock          â”‚  7.1 M â”‚ train â”‚
â”‚[2m [0m[2m62 [0m[2m [0mâ”‚ net.model.text.transformer.resblocks.5.ln_1             â”‚ LayerNorm                       â”‚  1.5 K â”‚ train â”‚
â”‚[2m [0m[2m63 [0m[2m [0mâ”‚ net.model.text.transformer.resblocks.5.attn             â”‚ MultiheadAttention              â”‚  2.4 M â”‚ train â”‚
â”‚[2m [0m[2m64 [0m[2m [0mâ”‚ net.model.text.transformer.resblocks.5.attn.out_proj    â”‚ NonDynamicallyQuantizableLinear â”‚  590 K â”‚ train â”‚
â”‚[2m [0m[2m65 [0m[2m [0mâ”‚ net.model.text.transformer.resblocks.5.ls_1             â”‚ Identity                        â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m66 [0m[2m [0mâ”‚ net.model.text.transformer.resblocks.5.ln_2             â”‚ LayerNorm                       â”‚  1.5 K â”‚ train â”‚
â”‚[2m [0m[2m67 [0m[2m [0mâ”‚ net.model.text.transformer.resblocks.5.mlp              â”‚ Sequential                      â”‚  4.7 M â”‚ train â”‚
â”‚[2m [0m[2m68 [0m[2m [0mâ”‚ net.model.text.transformer.resblocks.5.mlp.c_fc         â”‚ Linear                          â”‚  2.4 M â”‚ train â”‚
â”‚[2m [0m[2m69 [0m[2m [0mâ”‚ net.model.text.transformer.resblocks.5.mlp.gelu         â”‚ GELU                            â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m70 [0m[2m [0mâ”‚ net.model.text.transformer.resblocks.5.mlp.c_proj       â”‚ Linear                          â”‚  2.4 M â”‚ train â”‚
â”‚[2m [0m[2m71 [0m[2m [0mâ”‚ net.model.text.transformer.resblocks.5.ls_2             â”‚ Identity                        â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m72 [0m[2m [0mâ”‚ net.model.text.transformer.resblocks.6                  â”‚ ResidualAttentionBlock          â”‚  7.1 M â”‚ train â”‚
â”‚[2m [0m[2m73 [0m[2m [0mâ”‚ net.model.text.transformer.resblocks.6.ln_1             â”‚ LayerNorm                       â”‚  1.5 K â”‚ train â”‚
â”‚[2m [0m[2m74 [0m[2m [0mâ”‚ net.model.text.transformer.resblocks.6.attn             â”‚ MultiheadAttention              â”‚  2.4 M â”‚ train â”‚
â”‚[2m [0m[2m75 [0m[2m [0mâ”‚ net.model.text.transformer.resblocks.6.attn.out_proj    â”‚ NonDynamicallyQuantizableLinear â”‚  590 K â”‚ train â”‚
â”‚[2m [0m[2m76 [0m[2m [0mâ”‚ net.model.text.transformer.resblocks.6.ls_1             â”‚ Identity                        â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m77 [0m[2m [0mâ”‚ net.model.text.transformer.resblocks.6.ln_2             â”‚ LayerNorm                       â”‚  1.5 K â”‚ train â”‚
â”‚[2m [0m[2m78 [0m[2m [0mâ”‚ net.model.text.transformer.resblocks.6.mlp              â”‚ Sequential                      â”‚  4.7 M â”‚ train â”‚
â”‚[2m [0m[2m79 [0m[2m [0mâ”‚ net.model.text.transformer.resblocks.6.mlp.c_fc         â”‚ Linear                          â”‚  2.4 M â”‚ train â”‚
â”‚[2m [0m[2m80 [0m[2m [0mâ”‚ net.model.text.transformer.resblocks.6.mlp.gelu         â”‚ GELU                            â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m81 [0m[2m [0mâ”‚ net.model.text.transformer.resblocks.6.mlp.c_proj       â”‚ Linear                          â”‚  2.4 M â”‚ train â”‚
â”‚[2m [0m[2m82 [0m[2m [0mâ”‚ net.model.text.transformer.resblocks.6.ls_2             â”‚ Identity                        â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m83 [0m[2m [0mâ”‚ net.model.text.transformer.resblocks.7                  â”‚ ResidualAttentionBlock          â”‚  7.1 M â”‚ train â”‚
â”‚[2m [0m[2m84 [0m[2m [0mâ”‚ net.model.text.transformer.resblocks.7.ln_1             â”‚ LayerNorm                       â”‚  1.5 K â”‚ train â”‚
â”‚[2m [0m[2m85 [0m[2m [0mâ”‚ net.model.text.transformer.resblocks.7.attn             â”‚ MultiheadAttention              â”‚  2.4 M â”‚ train â”‚
â”‚[2m [0m[2m86 [0m[2m [0mâ”‚ net.model.text.transformer.resblocks.7.attn.out_proj    â”‚ NonDynamicallyQuantizableLinear â”‚  590 K â”‚ train â”‚
â”‚[2m [0m[2m87 [0m[2m [0mâ”‚ net.model.text.transformer.resblocks.7.ls_1             â”‚ Identity                        â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m88 [0m[2m [0mâ”‚ net.model.text.transformer.resblocks.7.ln_2             â”‚ LayerNorm                       â”‚  1.5 K â”‚ train â”‚
â”‚[2m [0m[2m89 [0m[2m [0mâ”‚ net.model.text.transformer.resblocks.7.mlp              â”‚ Sequential                      â”‚  4.7 M â”‚ train â”‚
â”‚[2m [0m[2m90 [0m[2m [0mâ”‚ net.model.text.transformer.resblocks.7.mlp.c_fc         â”‚ Linear                          â”‚  2.4 M â”‚ train â”‚
â”‚[2m [0m[2m91 [0m[2m [0mâ”‚ net.model.text.transformer.resblocks.7.mlp.gelu         â”‚ GELU                            â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m92 [0m[2m [0mâ”‚ net.model.text.transformer.resblocks.7.mlp.c_proj       â”‚ Linear                          â”‚  2.4 M â”‚ train â”‚
â”‚[2m [0m[2m93 [0m[2m [0mâ”‚ net.model.text.transformer.resblocks.7.ls_2             â”‚ Identity                        â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m94 [0m[2m [0mâ”‚ net.model.text.transformer.resblocks.8                  â”‚ ResidualAttentionBlock          â”‚  7.1 M â”‚ train â”‚
â”‚[2m [0m[2m95 [0m[2m [0mâ”‚ net.model.text.transformer.resblocks.8.ln_1             â”‚ LayerNorm                       â”‚  1.5 K â”‚ train â”‚
â”‚[2m [0m[2m96 [0m[2m [0mâ”‚ net.model.text.transformer.resblocks.8.attn             â”‚ MultiheadAttention              â”‚  2.4 M â”‚ train â”‚
â”‚[2m [0m[2m97 [0m[2m [0mâ”‚ net.model.text.transformer.resblocks.8.attn.out_proj    â”‚ NonDynamicallyQuantizableLinear â”‚  590 K â”‚ train â”‚
â”‚[2m [0m[2m98 [0m[2m [0mâ”‚ net.model.text.transformer.resblocks.8.ls_1             â”‚ Identity                        â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m99 [0m[2m [0mâ”‚ net.model.text.transformer.resblocks.8.ln_2             â”‚ LayerNorm                       â”‚  1.5 K â”‚ train â”‚
â”‚[2m [0m[2m100[0m[2m [0mâ”‚ net.model.text.transformer.resblocks.8.mlp              â”‚ Sequential                      â”‚  4.7 M â”‚ train â”‚
â”‚[2m [0m[2m101[0m[2m [0mâ”‚ net.model.text.transformer.resblocks.8.mlp.c_fc         â”‚ Linear                          â”‚  2.4 M â”‚ train â”‚
â”‚[2m [0m[2m102[0m[2m [0mâ”‚ net.model.text.transformer.resblocks.8.mlp.gelu         â”‚ GELU                            â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m103[0m[2m [0mâ”‚ net.model.text.transformer.resblocks.8.mlp.c_proj       â”‚ Linear                          â”‚  2.4 M â”‚ train â”‚
â”‚[2m [0m[2m104[0m[2m [0mâ”‚ net.model.text.transformer.resblocks.8.ls_2             â”‚ Identity                        â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m105[0m[2m [0mâ”‚ net.model.text.transformer.resblocks.9                  â”‚ ResidualAttentionBlock          â”‚  7.1 M â”‚ train â”‚
â”‚[2m [0m[2m106[0m[2m [0mâ”‚ net.model.text.transformer.resblocks.9.ln_1             â”‚ LayerNorm                       â”‚  1.5 K â”‚ train â”‚
â”‚[2m [0m[2m107[0m[2m [0mâ”‚ net.model.text.transformer.resblocks.9.attn             â”‚ MultiheadAttention              â”‚  2.4 M â”‚ train â”‚
â”‚[2m [0m[2m108[0m[2m [0mâ”‚ net.model.text.transformer.resblocks.9.attn.out_proj    â”‚ NonDynamicallyQuantizableLinear â”‚  590 K â”‚ train â”‚
â”‚[2m [0m[2m109[0m[2m [0mâ”‚ net.model.text.transformer.resblocks.9.ls_1             â”‚ Identity                        â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m110[0m[2m [0mâ”‚ net.model.text.transformer.resblocks.9.ln_2             â”‚ LayerNorm                       â”‚  1.5 K â”‚ train â”‚
â”‚[2m [0m[2m111[0m[2m [0mâ”‚ net.model.text.transformer.resblocks.9.mlp              â”‚ Sequential                      â”‚  4.7 M â”‚ train â”‚
â”‚[2m [0m[2m112[0m[2m [0mâ”‚ net.model.text.transformer.resblocks.9.mlp.c_fc         â”‚ Linear                          â”‚  2.4 M â”‚ train â”‚
â”‚[2m [0m[2m113[0m[2m [0mâ”‚ net.model.text.transformer.resblocks.9.mlp.gelu         â”‚ GELU                            â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m114[0m[2m [0mâ”‚ net.model.text.transformer.resblocks.9.mlp.c_proj       â”‚ Linear                          â”‚  2.4 M â”‚ train â”‚
â”‚[2m [0m[2m115[0m[2m [0mâ”‚ net.model.text.transformer.resblocks.9.ls_2             â”‚ Identity                        â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m116[0m[2m [0mâ”‚ net.model.text.transformer.resblocks.10                 â”‚ ResidualAttentionBlock          â”‚  7.1 M â”‚ train â”‚
â”‚[2m [0m[2m117[0m[2m [0mâ”‚ net.model.text.transformer.resblocks.10.ln_1            â”‚ LayerNorm                       â”‚  1.5 K â”‚ train â”‚
â”‚[2m [0m[2m118[0m[2m [0mâ”‚ net.model.text.transformer.resblocks.10.attn            â”‚ MultiheadAttention              â”‚  2.4 M â”‚ train â”‚
â”‚[2m [0m[2m119[0m[2m [0mâ”‚ net.model.text.transformer.resblocks.10.attn.out_proj   â”‚ NonDynamicallyQuantizableLinear â”‚  590 K â”‚ train â”‚
â”‚[2m [0m[2m120[0m[2m [0mâ”‚ net.model.text.transformer.resblocks.10.ls_1            â”‚ Identity                        â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m121[0m[2m [0mâ”‚ net.model.text.transformer.resblocks.10.ln_2            â”‚ LayerNorm                       â”‚  1.5 K â”‚ train â”‚
â”‚[2m [0m[2m122[0m[2m [0mâ”‚ net.model.text.transformer.resblocks.10.mlp             â”‚ Sequential                      â”‚  4.7 M â”‚ train â”‚
â”‚[2m [0m[2m123[0m[2m [0mâ”‚ net.model.text.transformer.resblocks.10.mlp.c_fc        â”‚ Linear                          â”‚  2.4 M â”‚ train â”‚
â”‚[2m [0m[2m124[0m[2m [0mâ”‚ net.model.text.transformer.resblocks.10.mlp.gelu        â”‚ GELU                            â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m125[0m[2m [0mâ”‚ net.model.text.transformer.resblocks.10.mlp.c_proj      â”‚ Linear                          â”‚  2.4 M â”‚ train â”‚
â”‚[2m [0m[2m126[0m[2m [0mâ”‚ net.model.text.transformer.resblocks.10.ls_2            â”‚ Identity                        â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m127[0m[2m [0mâ”‚ net.model.text.transformer.resblocks.11                 â”‚ ResidualAttentionBlock          â”‚  7.1 M â”‚ train â”‚
â”‚[2m [0m[2m128[0m[2m [0mâ”‚ net.model.text.transformer.resblocks.11.ln_1            â”‚ LayerNorm                       â”‚  1.5 K â”‚ train â”‚
â”‚[2m [0m[2m129[0m[2m [0mâ”‚ net.model.text.transformer.resblocks.11.attn            â”‚ MultiheadAttention              â”‚  2.4 M â”‚ train â”‚
â”‚[2m [0m[2m130[0m[2m [0mâ”‚ net.model.text.transformer.resblocks.11.attn.out_proj   â”‚ NonDynamicallyQuantizableLinear â”‚  590 K â”‚ train â”‚
â”‚[2m [0m[2m131[0m[2m [0mâ”‚ net.model.text.transformer.resblocks.11.ls_1            â”‚ Identity                        â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m132[0m[2m [0mâ”‚ net.model.text.transformer.resblocks.11.ln_2            â”‚ LayerNorm                       â”‚  1.5 K â”‚ train â”‚
â”‚[2m [0m[2m133[0m[2m [0mâ”‚ net.model.text.transformer.resblocks.11.mlp             â”‚ Sequential                      â”‚  4.7 M â”‚ train â”‚
â”‚[2m [0m[2m134[0m[2m [0mâ”‚ net.model.text.transformer.resblocks.11.mlp.c_fc        â”‚ Linear                          â”‚  2.4 M â”‚ train â”‚
â”‚[2m [0m[2m135[0m[2m [0mâ”‚ net.model.text.transformer.resblocks.11.mlp.gelu        â”‚ GELU                            â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m136[0m[2m [0mâ”‚ net.model.text.transformer.resblocks.11.mlp.c_proj      â”‚ Linear                          â”‚  2.4 M â”‚ train â”‚
â”‚[2m [0m[2m137[0m[2m [0mâ”‚ net.model.text.transformer.resblocks.11.ls_2            â”‚ Identity                        â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m138[0m[2m [0mâ”‚ net.model.text.ln_final                                 â”‚ LayerNorm                       â”‚  1.5 K â”‚ train â”‚
â”‚[2m [0m[2m139[0m[2m [0mâ”‚ net.model.visual                                        â”‚ VisionTransformer               â”‚  306 M â”‚ train â”‚
â”‚[2m [0m[2m140[0m[2m [0mâ”‚ net.model.visual.conv1                                  â”‚ Conv2d                          â”‚  602 K â”‚ train â”‚
â”‚[2m [0m[2m141[0m[2m [0mâ”‚ net.model.visual.patch_dropout                          â”‚ Identity                        â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m142[0m[2m [0mâ”‚ net.model.visual.ln_pre                                 â”‚ LayerNorm                       â”‚  2.0 K â”‚ train â”‚
â”‚[2m [0m[2m143[0m[2m [0mâ”‚ net.model.visual.transformer                            â”‚ Transformer                     â”‚  302 M â”‚ train â”‚
â”‚[2m [0m[2m144[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks                  â”‚ ModuleList                      â”‚  302 M â”‚ train â”‚
â”‚[2m [0m[2m145[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.0                â”‚ ResidualAttentionBlock          â”‚ 12.6 M â”‚ train â”‚
â”‚[2m [0m[2m146[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.0.ln_1           â”‚ LayerNorm                       â”‚  2.0 K â”‚ train â”‚
â”‚[2m [0m[2m147[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.0.attn           â”‚ MultiheadAttention              â”‚  4.2 M â”‚ train â”‚
â”‚[2m [0m[2m148[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.0.attn.out_proj  â”‚ NonDynamicallyQuantizableLinear â”‚  1.0 M â”‚ train â”‚
â”‚[2m [0m[2m149[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.0.ls_1           â”‚ Identity                        â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m150[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.0.ln_2           â”‚ LayerNorm                       â”‚  2.0 K â”‚ train â”‚
â”‚[2m [0m[2m151[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.0.mlp            â”‚ Sequential                      â”‚  8.4 M â”‚ train â”‚
â”‚[2m [0m[2m152[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.0.mlp.c_fc       â”‚ Linear                          â”‚  4.2 M â”‚ train â”‚
â”‚[2m [0m[2m153[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.0.mlp.gelu       â”‚ GELU                            â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m154[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.0.mlp.c_proj     â”‚ Linear                          â”‚  4.2 M â”‚ train â”‚
â”‚[2m [0m[2m155[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.0.ls_2           â”‚ Identity                        â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m156[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.1                â”‚ ResidualAttentionBlock          â”‚ 12.6 M â”‚ train â”‚
â”‚[2m [0m[2m157[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.1.ln_1           â”‚ LayerNorm                       â”‚  2.0 K â”‚ train â”‚
â”‚[2m [0m[2m158[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.1.attn           â”‚ MultiheadAttention              â”‚  4.2 M â”‚ train â”‚
â”‚[2m [0m[2m159[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.1.attn.out_proj  â”‚ NonDynamicallyQuantizableLinear â”‚  1.0 M â”‚ train â”‚
â”‚[2m [0m[2m160[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.1.ls_1           â”‚ Identity                        â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m161[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.1.ln_2           â”‚ LayerNorm                       â”‚  2.0 K â”‚ train â”‚
â”‚[2m [0m[2m162[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.1.mlp            â”‚ Sequential                      â”‚  8.4 M â”‚ train â”‚
â”‚[2m [0m[2m163[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.1.mlp.c_fc       â”‚ Linear                          â”‚  4.2 M â”‚ train â”‚
â”‚[2m [0m[2m164[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.1.mlp.gelu       â”‚ GELU                            â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m165[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.1.mlp.c_proj     â”‚ Linear                          â”‚  4.2 M â”‚ train â”‚
â”‚[2m [0m[2m166[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.1.ls_2           â”‚ Identity                        â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m167[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.2                â”‚ ResidualAttentionBlock          â”‚ 12.6 M â”‚ train â”‚
â”‚[2m [0m[2m168[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.2.ln_1           â”‚ LayerNorm                       â”‚  2.0 K â”‚ train â”‚
â”‚[2m [0m[2m169[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.2.attn           â”‚ MultiheadAttention              â”‚  4.2 M â”‚ train â”‚
â”‚[2m [0m[2m170[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.2.attn.out_proj  â”‚ NonDynamicallyQuantizableLinear â”‚  1.0 M â”‚ train â”‚
â”‚[2m [0m[2m171[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.2.ls_1           â”‚ Identity                        â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m172[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.2.ln_2           â”‚ LayerNorm                       â”‚  2.0 K â”‚ train â”‚
â”‚[2m [0m[2m173[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.2.mlp            â”‚ Sequential                      â”‚  8.4 M â”‚ train â”‚
â”‚[2m [0m[2m174[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.2.mlp.c_fc       â”‚ Linear                          â”‚  4.2 M â”‚ train â”‚
â”‚[2m [0m[2m175[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.2.mlp.gelu       â”‚ GELU                            â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m176[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.2.mlp.c_proj     â”‚ Linear                          â”‚  4.2 M â”‚ train â”‚
â”‚[2m [0m[2m177[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.2.ls_2           â”‚ Identity                        â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m178[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.3                â”‚ ResidualAttentionBlock          â”‚ 12.6 M â”‚ train â”‚
â”‚[2m [0m[2m179[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.3.ln_1           â”‚ LayerNorm                       â”‚  2.0 K â”‚ train â”‚
â”‚[2m [0m[2m180[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.3.attn           â”‚ MultiheadAttention              â”‚  4.2 M â”‚ train â”‚
â”‚[2m [0m[2m181[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.3.attn.out_proj  â”‚ NonDynamicallyQuantizableLinear â”‚  1.0 M â”‚ train â”‚
â”‚[2m [0m[2m182[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.3.ls_1           â”‚ Identity                        â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m183[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.3.ln_2           â”‚ LayerNorm                       â”‚  2.0 K â”‚ train â”‚
â”‚[2m [0m[2m184[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.3.mlp            â”‚ Sequential                      â”‚  8.4 M â”‚ train â”‚
â”‚[2m [0m[2m185[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.3.mlp.c_fc       â”‚ Linear                          â”‚  4.2 M â”‚ train â”‚
â”‚[2m [0m[2m186[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.3.mlp.gelu       â”‚ GELU                            â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m187[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.3.mlp.c_proj     â”‚ Linear                          â”‚  4.2 M â”‚ train â”‚
â”‚[2m [0m[2m188[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.3.ls_2           â”‚ Identity                        â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m189[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.4                â”‚ ResidualAttentionBlock          â”‚ 12.6 M â”‚ train â”‚
â”‚[2m [0m[2m190[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.4.ln_1           â”‚ LayerNorm                       â”‚  2.0 K â”‚ train â”‚
â”‚[2m [0m[2m191[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.4.attn           â”‚ MultiheadAttention              â”‚  4.2 M â”‚ train â”‚
â”‚[2m [0m[2m192[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.4.attn.out_proj  â”‚ NonDynamicallyQuantizableLinear â”‚  1.0 M â”‚ train â”‚
â”‚[2m [0m[2m193[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.4.ls_1           â”‚ Identity                        â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m194[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.4.ln_2           â”‚ LayerNorm                       â”‚  2.0 K â”‚ train â”‚
â”‚[2m [0m[2m195[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.4.mlp            â”‚ Sequential                      â”‚  8.4 M â”‚ train â”‚
â”‚[2m [0m[2m196[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.4.mlp.c_fc       â”‚ Linear                          â”‚  4.2 M â”‚ train â”‚
â”‚[2m [0m[2m197[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.4.mlp.gelu       â”‚ GELU                            â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m198[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.4.mlp.c_proj     â”‚ Linear                          â”‚  4.2 M â”‚ train â”‚
â”‚[2m [0m[2m199[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.4.ls_2           â”‚ Identity                        â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m200[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.5                â”‚ ResidualAttentionBlock          â”‚ 12.6 M â”‚ train â”‚
â”‚[2m [0m[2m201[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.5.ln_1           â”‚ LayerNorm                       â”‚  2.0 K â”‚ train â”‚
â”‚[2m [0m[2m202[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.5.attn           â”‚ MultiheadAttention              â”‚  4.2 M â”‚ train â”‚
â”‚[2m [0m[2m203[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.5.attn.out_proj  â”‚ NonDynamicallyQuantizableLinear â”‚  1.0 M â”‚ train â”‚
â”‚[2m [0m[2m204[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.5.ls_1           â”‚ Identity                        â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m205[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.5.ln_2           â”‚ LayerNorm                       â”‚  2.0 K â”‚ train â”‚
â”‚[2m [0m[2m206[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.5.mlp            â”‚ Sequential                      â”‚  8.4 M â”‚ train â”‚
â”‚[2m [0m[2m207[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.5.mlp.c_fc       â”‚ Linear                          â”‚  4.2 M â”‚ train â”‚
â”‚[2m [0m[2m208[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.5.mlp.gelu       â”‚ GELU                            â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m209[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.5.mlp.c_proj     â”‚ Linear                          â”‚  4.2 M â”‚ train â”‚
â”‚[2m [0m[2m210[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.5.ls_2           â”‚ Identity                        â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m211[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.6                â”‚ ResidualAttentionBlock          â”‚ 12.6 M â”‚ train â”‚
â”‚[2m [0m[2m212[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.6.ln_1           â”‚ LayerNorm                       â”‚  2.0 K â”‚ train â”‚
â”‚[2m [0m[2m213[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.6.attn           â”‚ MultiheadAttention              â”‚  4.2 M â”‚ train â”‚
â”‚[2m [0m[2m214[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.6.attn.out_proj  â”‚ NonDynamicallyQuantizableLinear â”‚  1.0 M â”‚ train â”‚
â”‚[2m [0m[2m215[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.6.ls_1           â”‚ Identity                        â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m216[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.6.ln_2           â”‚ LayerNorm                       â”‚  2.0 K â”‚ train â”‚
â”‚[2m [0m[2m217[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.6.mlp            â”‚ Sequential                      â”‚  8.4 M â”‚ train â”‚
â”‚[2m [0m[2m218[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.6.mlp.c_fc       â”‚ Linear                          â”‚  4.2 M â”‚ train â”‚
â”‚[2m [0m[2m219[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.6.mlp.gelu       â”‚ GELU                            â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m220[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.6.mlp.c_proj     â”‚ Linear                          â”‚  4.2 M â”‚ train â”‚
â”‚[2m [0m[2m221[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.6.ls_2           â”‚ Identity                        â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m222[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.7                â”‚ ResidualAttentionBlock          â”‚ 12.6 M â”‚ train â”‚
â”‚[2m [0m[2m223[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.7.ln_1           â”‚ LayerNorm                       â”‚  2.0 K â”‚ train â”‚
â”‚[2m [0m[2m224[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.7.attn           â”‚ MultiheadAttention              â”‚  4.2 M â”‚ train â”‚
â”‚[2m [0m[2m225[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.7.attn.out_proj  â”‚ NonDynamicallyQuantizableLinear â”‚  1.0 M â”‚ train â”‚
â”‚[2m [0m[2m226[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.7.ls_1           â”‚ Identity                        â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m227[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.7.ln_2           â”‚ LayerNorm                       â”‚  2.0 K â”‚ train â”‚
â”‚[2m [0m[2m228[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.7.mlp            â”‚ Sequential                      â”‚  8.4 M â”‚ train â”‚
â”‚[2m [0m[2m229[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.7.mlp.c_fc       â”‚ Linear                          â”‚  4.2 M â”‚ train â”‚
â”‚[2m [0m[2m230[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.7.mlp.gelu       â”‚ GELU                            â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m231[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.7.mlp.c_proj     â”‚ Linear                          â”‚  4.2 M â”‚ train â”‚
â”‚[2m [0m[2m232[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.7.ls_2           â”‚ Identity                        â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m233[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.8                â”‚ ResidualAttentionBlock          â”‚ 12.6 M â”‚ train â”‚
â”‚[2m [0m[2m234[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.8.ln_1           â”‚ LayerNorm                       â”‚  2.0 K â”‚ train â”‚
â”‚[2m [0m[2m235[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.8.attn           â”‚ MultiheadAttention              â”‚  4.2 M â”‚ train â”‚
â”‚[2m [0m[2m236[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.8.attn.out_proj  â”‚ NonDynamicallyQuantizableLinear â”‚  1.0 M â”‚ train â”‚
â”‚[2m [0m[2m237[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.8.ls_1           â”‚ Identity                        â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m238[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.8.ln_2           â”‚ LayerNorm                       â”‚  2.0 K â”‚ train â”‚
â”‚[2m [0m[2m239[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.8.mlp            â”‚ Sequential                      â”‚  8.4 M â”‚ train â”‚
â”‚[2m [0m[2m240[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.8.mlp.c_fc       â”‚ Linear                          â”‚  4.2 M â”‚ train â”‚
â”‚[2m [0m[2m241[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.8.mlp.gelu       â”‚ GELU                            â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m242[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.8.mlp.c_proj     â”‚ Linear                          â”‚  4.2 M â”‚ train â”‚
â”‚[2m [0m[2m243[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.8.ls_2           â”‚ Identity                        â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m244[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.9                â”‚ ResidualAttentionBlock          â”‚ 12.6 M â”‚ train â”‚
â”‚[2m [0m[2m245[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.9.ln_1           â”‚ LayerNorm                       â”‚  2.0 K â”‚ train â”‚
â”‚[2m [0m[2m246[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.9.attn           â”‚ MultiheadAttention              â”‚  4.2 M â”‚ train â”‚
â”‚[2m [0m[2m247[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.9.attn.out_proj  â”‚ NonDynamicallyQuantizableLinear â”‚  1.0 M â”‚ train â”‚
â”‚[2m [0m[2m248[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.9.ls_1           â”‚ Identity                        â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m249[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.9.ln_2           â”‚ LayerNorm                       â”‚  2.0 K â”‚ train â”‚
â”‚[2m [0m[2m250[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.9.mlp            â”‚ Sequential                      â”‚  8.4 M â”‚ train â”‚
â”‚[2m [0m[2m251[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.9.mlp.c_fc       â”‚ Linear                          â”‚  4.2 M â”‚ train â”‚
â”‚[2m [0m[2m252[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.9.mlp.gelu       â”‚ GELU                            â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m253[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.9.mlp.c_proj     â”‚ Linear                          â”‚  4.2 M â”‚ train â”‚
â”‚[2m [0m[2m254[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.9.ls_2           â”‚ Identity                        â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m255[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.10               â”‚ ResidualAttentionBlock          â”‚ 12.6 M â”‚ train â”‚
â”‚[2m [0m[2m256[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.10.ln_1          â”‚ LayerNorm                       â”‚  2.0 K â”‚ train â”‚
â”‚[2m [0m[2m257[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.10.attn          â”‚ MultiheadAttention              â”‚  4.2 M â”‚ train â”‚
â”‚[2m [0m[2m258[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.10.attn.out_proj â”‚ NonDynamicallyQuantizableLinear â”‚  1.0 M â”‚ train â”‚
â”‚[2m [0m[2m259[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.10.ls_1          â”‚ Identity                        â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m260[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.10.ln_2          â”‚ LayerNorm                       â”‚  2.0 K â”‚ train â”‚
â”‚[2m [0m[2m261[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.10.mlp           â”‚ Sequential                      â”‚  8.4 M â”‚ train â”‚
â”‚[2m [0m[2m262[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.10.mlp.c_fc      â”‚ Linear                          â”‚  4.2 M â”‚ train â”‚
â”‚[2m [0m[2m263[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.10.mlp.gelu      â”‚ GELU                            â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m264[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.10.mlp.c_proj    â”‚ Linear                          â”‚  4.2 M â”‚ train â”‚
â”‚[2m [0m[2m265[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.10.ls_2          â”‚ Identity                        â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m266[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.11               â”‚ ResidualAttentionBlock          â”‚ 12.6 M â”‚ train â”‚
â”‚[2m [0m[2m267[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.11.ln_1          â”‚ LayerNorm                       â”‚  2.0 K â”‚ train â”‚
â”‚[2m [0m[2m268[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.11.attn          â”‚ MultiheadAttention              â”‚  4.2 M â”‚ train â”‚
â”‚[2m [0m[2m269[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.11.attn.out_proj â”‚ NonDynamicallyQuantizableLinear â”‚  1.0 M â”‚ train â”‚
â”‚[2m [0m[2m270[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.11.ls_1          â”‚ Identity                        â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m271[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.11.ln_2          â”‚ LayerNorm                       â”‚  2.0 K â”‚ train â”‚
â”‚[2m [0m[2m272[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.11.mlp           â”‚ Sequential                      â”‚  8.4 M â”‚ train â”‚
â”‚[2m [0m[2m273[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.11.mlp.c_fc      â”‚ Linear                          â”‚  4.2 M â”‚ train â”‚
â”‚[2m [0m[2m274[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.11.mlp.gelu      â”‚ GELU                            â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m275[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.11.mlp.c_proj    â”‚ Linear                          â”‚  4.2 M â”‚ train â”‚
â”‚[2m [0m[2m276[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.11.ls_2          â”‚ Identity                        â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m277[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.12               â”‚ ResidualAttentionBlock          â”‚ 12.6 M â”‚ train â”‚
â”‚[2m [0m[2m278[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.12.ln_1          â”‚ LayerNorm                       â”‚  2.0 K â”‚ train â”‚
â”‚[2m [0m[2m279[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.12.attn          â”‚ MultiheadAttention              â”‚  4.2 M â”‚ train â”‚
â”‚[2m [0m[2m280[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.12.attn.out_proj â”‚ NonDynamicallyQuantizableLinear â”‚  1.0 M â”‚ train â”‚
â”‚[2m [0m[2m281[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.12.ls_1          â”‚ Identity                        â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m282[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.12.ln_2          â”‚ LayerNorm                       â”‚  2.0 K â”‚ train â”‚
â”‚[2m [0m[2m283[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.12.mlp           â”‚ Sequential                      â”‚  8.4 M â”‚ train â”‚
â”‚[2m [0m[2m284[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.12.mlp.c_fc      â”‚ Linear                          â”‚  4.2 M â”‚ train â”‚
â”‚[2m [0m[2m285[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.12.mlp.gelu      â”‚ GELU                            â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m286[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.12.mlp.c_proj    â”‚ Linear                          â”‚  4.2 M â”‚ train â”‚
â”‚[2m [0m[2m287[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.12.ls_2          â”‚ Identity                        â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m288[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.13               â”‚ ResidualAttentionBlock          â”‚ 12.6 M â”‚ train â”‚
â”‚[2m [0m[2m289[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.13.ln_1          â”‚ LayerNorm                       â”‚  2.0 K â”‚ train â”‚
â”‚[2m [0m[2m290[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.13.attn          â”‚ MultiheadAttention              â”‚  4.2 M â”‚ train â”‚
â”‚[2m [0m[2m291[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.13.attn.out_proj â”‚ NonDynamicallyQuantizableLinear â”‚  1.0 M â”‚ train â”‚
â”‚[2m [0m[2m292[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.13.ls_1          â”‚ Identity                        â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m293[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.13.ln_2          â”‚ LayerNorm                       â”‚  2.0 K â”‚ train â”‚
â”‚[2m [0m[2m294[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.13.mlp           â”‚ Sequential                      â”‚  8.4 M â”‚ train â”‚
â”‚[2m [0m[2m295[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.13.mlp.c_fc      â”‚ Linear                          â”‚  4.2 M â”‚ train â”‚
â”‚[2m [0m[2m296[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.13.mlp.gelu      â”‚ GELU                            â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m297[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.13.mlp.c_proj    â”‚ Linear                          â”‚  4.2 M â”‚ train â”‚
â”‚[2m [0m[2m298[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.13.ls_2          â”‚ Identity                        â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m299[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.14               â”‚ ResidualAttentionBlock          â”‚ 12.6 M â”‚ train â”‚
â”‚[2m [0m[2m300[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.14.ln_1          â”‚ LayerNorm                       â”‚  2.0 K â”‚ train â”‚
â”‚[2m [0m[2m301[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.14.attn          â”‚ MultiheadAttention              â”‚  4.2 M â”‚ train â”‚
â”‚[2m [0m[2m302[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.14.attn.out_proj â”‚ NonDynamicallyQuantizableLinear â”‚  1.0 M â”‚ train â”‚
â”‚[2m [0m[2m303[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.14.ls_1          â”‚ Identity                        â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m304[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.14.ln_2          â”‚ LayerNorm                       â”‚  2.0 K â”‚ train â”‚
â”‚[2m [0m[2m305[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.14.mlp           â”‚ Sequential                      â”‚  8.4 M â”‚ train â”‚
â”‚[2m [0m[2m306[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.14.mlp.c_fc      â”‚ Linear                          â”‚  4.2 M â”‚ train â”‚
â”‚[2m [0m[2m307[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.14.mlp.gelu      â”‚ GELU                            â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m308[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.14.mlp.c_proj    â”‚ Linear                          â”‚  4.2 M â”‚ train â”‚
â”‚[2m [0m[2m309[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.14.ls_2          â”‚ Identity                        â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m310[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.15               â”‚ ResidualAttentionBlock          â”‚ 12.6 M â”‚ train â”‚
â”‚[2m [0m[2m311[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.15.ln_1          â”‚ LayerNorm                       â”‚  2.0 K â”‚ train â”‚
â”‚[2m [0m[2m312[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.15.attn          â”‚ MultiheadAttention              â”‚  4.2 M â”‚ train â”‚
â”‚[2m [0m[2m313[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.15.attn.out_proj â”‚ NonDynamicallyQuantizableLinear â”‚  1.0 M â”‚ train â”‚
â”‚[2m [0m[2m314[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.15.ls_1          â”‚ Identity                        â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m315[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.15.ln_2          â”‚ LayerNorm                       â”‚  2.0 K â”‚ train â”‚
â”‚[2m [0m[2m316[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.15.mlp           â”‚ Sequential                      â”‚  8.4 M â”‚ train â”‚
â”‚[2m [0m[2m317[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.15.mlp.c_fc      â”‚ Linear                          â”‚  4.2 M â”‚ train â”‚
â”‚[2m [0m[2m318[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.15.mlp.gelu      â”‚ GELU                            â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m319[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.15.mlp.c_proj    â”‚ Linear                          â”‚  4.2 M â”‚ train â”‚
â”‚[2m [0m[2m320[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.15.ls_2          â”‚ Identity                        â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m321[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.16               â”‚ ResidualAttentionBlock          â”‚ 12.6 M â”‚ train â”‚
â”‚[2m [0m[2m322[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.16.ln_1          â”‚ LayerNorm                       â”‚  2.0 K â”‚ train â”‚
â”‚[2m [0m[2m323[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.16.attn          â”‚ MultiheadAttention              â”‚  4.2 M â”‚ train â”‚
â”‚[2m [0m[2m324[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.16.attn.out_proj â”‚ NonDynamicallyQuantizableLinear â”‚  1.0 M â”‚ train â”‚
â”‚[2m [0m[2m325[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.16.ls_1          â”‚ Identity                        â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m326[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.16.ln_2          â”‚ LayerNorm                       â”‚  2.0 K â”‚ train â”‚
â”‚[2m [0m[2m327[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.16.mlp           â”‚ Sequential                      â”‚  8.4 M â”‚ train â”‚
â”‚[2m [0m[2m328[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.16.mlp.c_fc      â”‚ Linear                          â”‚  4.2 M â”‚ train â”‚
â”‚[2m [0m[2m329[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.16.mlp.gelu      â”‚ GELU                            â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m330[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.16.mlp.c_proj    â”‚ Linear                          â”‚  4.2 M â”‚ train â”‚
â”‚[2m [0m[2m331[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.16.ls_2          â”‚ Identity                        â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m332[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.17               â”‚ ResidualAttentionBlock          â”‚ 12.6 M â”‚ train â”‚
â”‚[2m [0m[2m333[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.17.ln_1          â”‚ LayerNorm                       â”‚  2.0 K â”‚ train â”‚
â”‚[2m [0m[2m334[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.17.attn          â”‚ MultiheadAttention              â”‚  4.2 M â”‚ train â”‚
â”‚[2m [0m[2m335[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.17.attn.out_proj â”‚ NonDynamicallyQuantizableLinear â”‚  1.0 M â”‚ train â”‚
â”‚[2m [0m[2m336[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.17.ls_1          â”‚ Identity                        â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m337[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.17.ln_2          â”‚ LayerNorm                       â”‚  2.0 K â”‚ train â”‚
â”‚[2m [0m[2m338[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.17.mlp           â”‚ Sequential                      â”‚  8.4 M â”‚ train â”‚
â”‚[2m [0m[2m339[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.17.mlp.c_fc      â”‚ Linear                          â”‚  4.2 M â”‚ train â”‚
â”‚[2m [0m[2m340[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.17.mlp.gelu      â”‚ GELU                            â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m341[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.17.mlp.c_proj    â”‚ Linear                          â”‚  4.2 M â”‚ train â”‚
â”‚[2m [0m[2m342[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.17.ls_2          â”‚ Identity                        â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m343[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.18               â”‚ ResidualAttentionBlock          â”‚ 12.6 M â”‚ train â”‚
â”‚[2m [0m[2m344[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.18.ln_1          â”‚ LayerNorm                       â”‚  2.0 K â”‚ train â”‚
â”‚[2m [0m[2m345[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.18.attn          â”‚ MultiheadAttention              â”‚  4.2 M â”‚ train â”‚
â”‚[2m [0m[2m346[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.18.attn.out_proj â”‚ NonDynamicallyQuantizableLinear â”‚  1.0 M â”‚ train â”‚
â”‚[2m [0m[2m347[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.18.ls_1          â”‚ Identity                        â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m348[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.18.ln_2          â”‚ LayerNorm                       â”‚  2.0 K â”‚ train â”‚
â”‚[2m [0m[2m349[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.18.mlp           â”‚ Sequential                      â”‚  8.4 M â”‚ train â”‚
â”‚[2m [0m[2m350[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.18.mlp.c_fc      â”‚ Linear                          â”‚  4.2 M â”‚ train â”‚
â”‚[2m [0m[2m351[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.18.mlp.gelu      â”‚ GELU                            â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m352[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.18.mlp.c_proj    â”‚ Linear                          â”‚  4.2 M â”‚ train â”‚
â”‚[2m [0m[2m353[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.18.ls_2          â”‚ Identity                        â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m354[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.19               â”‚ ResidualAttentionBlock          â”‚ 12.6 M â”‚ train â”‚
â”‚[2m [0m[2m355[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.19.ln_1          â”‚ LayerNorm                       â”‚  2.0 K â”‚ train â”‚
â”‚[2m [0m[2m356[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.19.attn          â”‚ MultiheadAttention              â”‚  4.2 M â”‚ train â”‚
â”‚[2m [0m[2m357[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.19.attn.out_proj â”‚ NonDynamicallyQuantizableLinear â”‚  1.0 M â”‚ train â”‚
â”‚[2m [0m[2m358[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.19.ls_1          â”‚ Identity                        â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m359[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.19.ln_2          â”‚ LayerNorm                       â”‚  2.0 K â”‚ train â”‚
â”‚[2m [0m[2m360[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.19.mlp           â”‚ Sequential                      â”‚  8.4 M â”‚ train â”‚
â”‚[2m [0m[2m361[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.19.mlp.c_fc      â”‚ Linear                          â”‚  4.2 M â”‚ train â”‚
â”‚[2m [0m[2m362[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.19.mlp.gelu      â”‚ GELU                            â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m363[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.19.mlp.c_proj    â”‚ Linear                          â”‚  4.2 M â”‚ train â”‚
â”‚[2m [0m[2m364[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.19.ls_2          â”‚ Identity                        â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m365[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.20               â”‚ ResidualAttentionBlock          â”‚ 12.6 M â”‚ train â”‚
â”‚[2m [0m[2m366[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.20.ln_1          â”‚ LayerNorm                       â”‚  2.0 K â”‚ train â”‚
â”‚[2m [0m[2m367[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.20.attn          â”‚ MultiheadAttention              â”‚  4.2 M â”‚ train â”‚
â”‚[2m [0m[2m368[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.20.attn.out_proj â”‚ NonDynamicallyQuantizableLinear â”‚  1.0 M â”‚ train â”‚
â”‚[2m [0m[2m369[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.20.ls_1          â”‚ Identity                        â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m370[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.20.ln_2          â”‚ LayerNorm                       â”‚  2.0 K â”‚ train â”‚
â”‚[2m [0m[2m371[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.20.mlp           â”‚ Sequential                      â”‚  8.4 M â”‚ train â”‚
â”‚[2m [0m[2m372[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.20.mlp.c_fc      â”‚ Linear                          â”‚  4.2 M â”‚ train â”‚
â”‚[2m [0m[2m373[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.20.mlp.gelu      â”‚ GELU                            â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m374[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.20.mlp.c_proj    â”‚ Linear                          â”‚  4.2 M â”‚ train â”‚
â”‚[2m [0m[2m375[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.20.ls_2          â”‚ Identity                        â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m376[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.21               â”‚ ResidualAttentionBlock          â”‚ 12.6 M â”‚ train â”‚
â”‚[2m [0m[2m377[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.21.ln_1          â”‚ LayerNorm                       â”‚  2.0 K â”‚ train â”‚
â”‚[2m [0m[2m378[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.21.attn          â”‚ MultiheadAttention              â”‚  4.2 M â”‚ train â”‚
â”‚[2m [0m[2m379[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.21.attn.out_proj â”‚ NonDynamicallyQuantizableLinear â”‚  1.0 M â”‚ train â”‚
â”‚[2m [0m[2m380[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.21.ls_1          â”‚ Identity                        â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m381[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.21.ln_2          â”‚ LayerNorm                       â”‚  2.0 K â”‚ train â”‚
â”‚[2m [0m[2m382[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.21.mlp           â”‚ Sequential                      â”‚  8.4 M â”‚ train â”‚
â”‚[2m [0m[2m383[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.21.mlp.c_fc      â”‚ Linear                          â”‚  4.2 M â”‚ train â”‚
â”‚[2m [0m[2m384[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.21.mlp.gelu      â”‚ GELU                            â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m385[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.21.mlp.c_proj    â”‚ Linear                          â”‚  4.2 M â”‚ train â”‚
â”‚[2m [0m[2m386[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.21.ls_2          â”‚ Identity                        â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m387[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.22               â”‚ ResidualAttentionBlock          â”‚ 12.6 M â”‚ train â”‚
â”‚[2m [0m[2m388[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.22.ln_1          â”‚ LayerNorm                       â”‚  2.0 K â”‚ train â”‚
â”‚[2m [0m[2m389[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.22.attn          â”‚ MultiheadAttention              â”‚  4.2 M â”‚ train â”‚
â”‚[2m [0m[2m390[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.22.attn.out_proj â”‚ NonDynamicallyQuantizableLinear â”‚  1.0 M â”‚ train â”‚
â”‚[2m [0m[2m391[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.22.ls_1          â”‚ Identity                        â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m392[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.22.ln_2          â”‚ LayerNorm                       â”‚  2.0 K â”‚ train â”‚
â”‚[2m [0m[2m393[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.22.mlp           â”‚ Sequential                      â”‚  8.4 M â”‚ train â”‚
â”‚[2m [0m[2m394[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.22.mlp.c_fc      â”‚ Linear                          â”‚  4.2 M â”‚ train â”‚
â”‚[2m [0m[2m395[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.22.mlp.gelu      â”‚ GELU                            â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m396[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.22.mlp.c_proj    â”‚ Linear                          â”‚  4.2 M â”‚ train â”‚
â”‚[2m [0m[2m397[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.22.ls_2          â”‚ Identity                        â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m398[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.23               â”‚ ResidualAttentionBlock          â”‚ 12.6 M â”‚ train â”‚
â”‚[2m [0m[2m399[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.23.ln_1          â”‚ LayerNorm                       â”‚  2.0 K â”‚ train â”‚
â”‚[2m [0m[2m400[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.23.attn          â”‚ MultiheadAttention              â”‚  4.2 M â”‚ train â”‚
â”‚[2m [0m[2m401[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.23.attn.out_proj â”‚ NonDynamicallyQuantizableLinear â”‚  1.0 M â”‚ train â”‚
â”‚[2m [0m[2m402[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.23.ls_1          â”‚ Identity                        â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m403[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.23.ln_2          â”‚ LayerNorm                       â”‚  2.0 K â”‚ train â”‚
â”‚[2m [0m[2m404[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.23.mlp           â”‚ Sequential                      â”‚  8.4 M â”‚ train â”‚
â”‚[2m [0m[2m405[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.23.mlp.c_fc      â”‚ Linear                          â”‚  4.2 M â”‚ train â”‚
â”‚[2m [0m[2m406[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.23.mlp.gelu      â”‚ GELU                            â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m407[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.23.mlp.c_proj    â”‚ Linear                          â”‚  4.2 M â”‚ train â”‚
â”‚[2m [0m[2m408[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.23.ls_2          â”‚ Identity                        â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m409[0m[2m [0mâ”‚ net.model.visual.attn_pool                              â”‚ AttentionalPooler               â”‚  3.0 M â”‚ train â”‚
â”‚[2m [0m[2m410[0m[2m [0mâ”‚ net.model.visual.attn_pool.attn                         â”‚ MultiheadAttention              â”‚  2.8 M â”‚ train â”‚
â”‚[2m [0m[2m411[0m[2m [0mâ”‚ net.model.visual.attn_pool.attn.out_proj                â”‚ NonDynamicallyQuantizableLinear â”‚  590 K â”‚ train â”‚
â”‚[2m [0m[2m412[0m[2m [0mâ”‚ net.model.visual.attn_pool.ln_q                         â”‚ LayerNorm                       â”‚  1.5 K â”‚ train â”‚
â”‚[2m [0m[2m413[0m[2m [0mâ”‚ net.model.visual.attn_pool.ln_k                         â”‚ LayerNorm                       â”‚  2.0 K â”‚ train â”‚
â”‚[2m [0m[2m414[0m[2m [0mâ”‚ net.model.visual.ln_post                                â”‚ LayerNorm                       â”‚  1.5 K â”‚ train â”‚
â”‚[2m [0m[2m415[0m[2m [0mâ”‚ net.model.text_decoder                                  â”‚ MultimodalTransformer           â”‚  208 M â”‚ train â”‚
â”‚[2m [0m[2m416[0m[2m [0mâ”‚ net.model.text_decoder.resblocks                        â”‚ ModuleList                      â”‚ 85.1 M â”‚ train â”‚
â”‚[2m [0m[2m417[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.0                      â”‚ ResidualAttentionBlock          â”‚  7.1 M â”‚ train â”‚
â”‚[2m [0m[2m418[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.0.ln_1                 â”‚ LayerNorm                       â”‚  1.5 K â”‚ train â”‚
â”‚[2m [0m[2m419[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.0.attn                 â”‚ MultiheadAttention              â”‚  2.4 M â”‚ train â”‚
â”‚[2m [0m[2m420[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.0.attn.out_proj        â”‚ NonDynamicallyQuantizableLinear â”‚  590 K â”‚ train â”‚
â”‚[2m [0m[2m421[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.0.ls_1                 â”‚ Identity                        â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m422[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.0.ln_2                 â”‚ LayerNorm                       â”‚  1.5 K â”‚ train â”‚
â”‚[2m [0m[2m423[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.0.mlp                  â”‚ Sequential                      â”‚  4.7 M â”‚ train â”‚
â”‚[2m [0m[2m424[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.0.mlp.c_fc             â”‚ Linear                          â”‚  2.4 M â”‚ train â”‚
â”‚[2m [0m[2m425[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.0.mlp.gelu             â”‚ GELU                            â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m426[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.0.mlp.c_proj           â”‚ Linear                          â”‚  2.4 M â”‚ train â”‚
â”‚[2m [0m[2m427[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.0.ls_2                 â”‚ Identity                        â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m428[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.1                      â”‚ ResidualAttentionBlock          â”‚  7.1 M â”‚ train â”‚
â”‚[2m [0m[2m429[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.1.ln_1                 â”‚ LayerNorm                       â”‚  1.5 K â”‚ train â”‚
â”‚[2m [0m[2m430[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.1.attn                 â”‚ MultiheadAttention              â”‚  2.4 M â”‚ train â”‚
â”‚[2m [0m[2m431[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.1.attn.out_proj        â”‚ NonDynamicallyQuantizableLinear â”‚  590 K â”‚ train â”‚
â”‚[2m [0m[2m432[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.1.ls_1                 â”‚ Identity                        â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m433[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.1.ln_2                 â”‚ LayerNorm                       â”‚  1.5 K â”‚ train â”‚
â”‚[2m [0m[2m434[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.1.mlp                  â”‚ Sequential                      â”‚  4.7 M â”‚ train â”‚
â”‚[2m [0m[2m435[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.1.mlp.c_fc             â”‚ Linear                          â”‚  2.4 M â”‚ train â”‚
â”‚[2m [0m[2m436[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.1.mlp.gelu             â”‚ GELU                            â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m437[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.1.mlp.c_proj           â”‚ Linear                          â”‚  2.4 M â”‚ train â”‚
â”‚[2m [0m[2m438[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.1.ls_2                 â”‚ Identity                        â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m439[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.2                      â”‚ ResidualAttentionBlock          â”‚  7.1 M â”‚ train â”‚
â”‚[2m [0m[2m440[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.2.ln_1                 â”‚ LayerNorm                       â”‚  1.5 K â”‚ train â”‚
â”‚[2m [0m[2m441[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.2.attn                 â”‚ MultiheadAttention              â”‚  2.4 M â”‚ train â”‚
â”‚[2m [0m[2m442[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.2.attn.out_proj        â”‚ NonDynamicallyQuantizableLinear â”‚  590 K â”‚ train â”‚
â”‚[2m [0m[2m443[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.2.ls_1                 â”‚ Identity                        â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m444[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.2.ln_2                 â”‚ LayerNorm                       â”‚  1.5 K â”‚ train â”‚
â”‚[2m [0m[2m445[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.2.mlp                  â”‚ Sequential                      â”‚  4.7 M â”‚ train â”‚
â”‚[2m [0m[2m446[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.2.mlp.c_fc             â”‚ Linear                          â”‚  2.4 M â”‚ train â”‚
â”‚[2m [0m[2m447[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.2.mlp.gelu             â”‚ GELU                            â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m448[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.2.mlp.c_proj           â”‚ Linear                          â”‚  2.4 M â”‚ train â”‚
â”‚[2m [0m[2m449[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.2.ls_2                 â”‚ Identity                        â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m450[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.3                      â”‚ ResidualAttentionBlock          â”‚  7.1 M â”‚ train â”‚
â”‚[2m [0m[2m451[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.3.ln_1                 â”‚ LayerNorm                       â”‚  1.5 K â”‚ train â”‚
â”‚[2m [0m[2m452[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.3.attn                 â”‚ MultiheadAttention              â”‚  2.4 M â”‚ train â”‚
â”‚[2m [0m[2m453[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.3.attn.out_proj        â”‚ NonDynamicallyQuantizableLinear â”‚  590 K â”‚ train â”‚
â”‚[2m [0m[2m454[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.3.ls_1                 â”‚ Identity                        â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m455[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.3.ln_2                 â”‚ LayerNorm                       â”‚  1.5 K â”‚ train â”‚
â”‚[2m [0m[2m456[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.3.mlp                  â”‚ Sequential                      â”‚  4.7 M â”‚ train â”‚
â”‚[2m [0m[2m457[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.3.mlp.c_fc             â”‚ Linear                          â”‚  2.4 M â”‚ train â”‚
â”‚[2m [0m[2m458[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.3.mlp.gelu             â”‚ GELU                            â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m459[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.3.mlp.c_proj           â”‚ Linear                          â”‚  2.4 M â”‚ train â”‚
â”‚[2m [0m[2m460[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.3.ls_2                 â”‚ Identity                        â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m461[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.4                      â”‚ ResidualAttentionBlock          â”‚  7.1 M â”‚ train â”‚
â”‚[2m [0m[2m462[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.4.ln_1                 â”‚ LayerNorm                       â”‚  1.5 K â”‚ train â”‚
â”‚[2m [0m[2m463[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.4.attn                 â”‚ MultiheadAttention              â”‚  2.4 M â”‚ train â”‚
â”‚[2m [0m[2m464[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.4.attn.out_proj        â”‚ NonDynamicallyQuantizableLinear â”‚  590 K â”‚ train â”‚
â”‚[2m [0m[2m465[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.4.ls_1                 â”‚ Identity                        â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m466[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.4.ln_2                 â”‚ LayerNorm                       â”‚  1.5 K â”‚ train â”‚
â”‚[2m [0m[2m467[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.4.mlp                  â”‚ Sequential                      â”‚  4.7 M â”‚ train â”‚
â”‚[2m [0m[2m468[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.4.mlp.c_fc             â”‚ Linear                          â”‚  2.4 M â”‚ train â”‚
â”‚[2m [0m[2m469[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.4.mlp.gelu             â”‚ GELU                            â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m470[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.4.mlp.c_proj           â”‚ Linear                          â”‚  2.4 M â”‚ train â”‚
â”‚[2m [0m[2m471[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.4.ls_2                 â”‚ Identity                        â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m472[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.5                      â”‚ ResidualAttentionBlock          â”‚  7.1 M â”‚ train â”‚
â”‚[2m [0m[2m473[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.5.ln_1                 â”‚ LayerNorm                       â”‚  1.5 K â”‚ train â”‚
â”‚[2m [0m[2m474[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.5.attn                 â”‚ MultiheadAttention              â”‚  2.4 M â”‚ train â”‚
â”‚[2m [0m[2m475[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.5.attn.out_proj        â”‚ NonDynamicallyQuantizableLinear â”‚  590 K â”‚ train â”‚
â”‚[2m [0m[2m476[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.5.ls_1                 â”‚ Identity                        â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m477[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.5.ln_2                 â”‚ LayerNorm                       â”‚  1.5 K â”‚ train â”‚
â”‚[2m [0m[2m478[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.5.mlp                  â”‚ Sequential                      â”‚  4.7 M â”‚ train â”‚
â”‚[2m [0m[2m479[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.5.mlp.c_fc             â”‚ Linear                          â”‚  2.4 M â”‚ train â”‚
â”‚[2m [0m[2m480[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.5.mlp.gelu             â”‚ GELU                            â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m481[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.5.mlp.c_proj           â”‚ Linear                          â”‚  2.4 M â”‚ train â”‚
â”‚[2m [0m[2m482[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.5.ls_2                 â”‚ Identity                        â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m483[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.6                      â”‚ ResidualAttentionBlock          â”‚  7.1 M â”‚ train â”‚
â”‚[2m [0m[2m484[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.6.ln_1                 â”‚ LayerNorm                       â”‚  1.5 K â”‚ train â”‚
â”‚[2m [0m[2m485[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.6.attn                 â”‚ MultiheadAttention              â”‚  2.4 M â”‚ train â”‚
â”‚[2m [0m[2m486[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.6.attn.out_proj        â”‚ NonDynamicallyQuantizableLinear â”‚  590 K â”‚ train â”‚
â”‚[2m [0m[2m487[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.6.ls_1                 â”‚ Identity                        â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m488[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.6.ln_2                 â”‚ LayerNorm                       â”‚  1.5 K â”‚ train â”‚
â”‚[2m [0m[2m489[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.6.mlp                  â”‚ Sequential                      â”‚  4.7 M â”‚ train â”‚
â”‚[2m [0m[2m490[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.6.mlp.c_fc             â”‚ Linear                          â”‚  2.4 M â”‚ train â”‚
â”‚[2m [0m[2m491[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.6.mlp.gelu             â”‚ GELU                            â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m492[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.6.mlp.c_proj           â”‚ Linear                          â”‚  2.4 M â”‚ train â”‚
â”‚[2m [0m[2m493[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.6.ls_2                 â”‚ Identity                        â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m494[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.7                      â”‚ ResidualAttentionBlock          â”‚  7.1 M â”‚ train â”‚
â”‚[2m [0m[2m495[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.7.ln_1                 â”‚ LayerNorm                       â”‚  1.5 K â”‚ train â”‚
â”‚[2m [0m[2m496[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.7.attn                 â”‚ MultiheadAttention              â”‚  2.4 M â”‚ train â”‚
â”‚[2m [0m[2m497[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.7.attn.out_proj        â”‚ NonDynamicallyQuantizableLinear â”‚  590 K â”‚ train â”‚
â”‚[2m [0m[2m498[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.7.ls_1                 â”‚ Identity                        â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m499[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.7.ln_2                 â”‚ LayerNorm                       â”‚  1.5 K â”‚ train â”‚
â”‚[2m [0m[2m500[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.7.mlp                  â”‚ Sequential                      â”‚  4.7 M â”‚ train â”‚
â”‚[2m [0m[2m501[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.7.mlp.c_fc             â”‚ Linear                          â”‚  2.4 M â”‚ train â”‚
â”‚[2m [0m[2m502[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.7.mlp.gelu             â”‚ GELU                            â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m503[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.7.mlp.c_proj           â”‚ Linear                          â”‚  2.4 M â”‚ train â”‚
â”‚[2m [0m[2m504[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.7.ls_2                 â”‚ Identity                        â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m505[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.8                      â”‚ ResidualAttentionBlock          â”‚  7.1 M â”‚ train â”‚
â”‚[2m [0m[2m506[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.8.ln_1                 â”‚ LayerNorm                       â”‚  1.5 K â”‚ train â”‚
â”‚[2m [0m[2m507[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.8.attn                 â”‚ MultiheadAttention              â”‚  2.4 M â”‚ train â”‚
â”‚[2m [0m[2m508[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.8.attn.out_proj        â”‚ NonDynamicallyQuantizableLinear â”‚  590 K â”‚ train â”‚
â”‚[2m [0m[2m509[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.8.ls_1                 â”‚ Identity                        â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m510[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.8.ln_2                 â”‚ LayerNorm                       â”‚  1.5 K â”‚ train â”‚
â”‚[2m [0m[2m511[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.8.mlp                  â”‚ Sequential                      â”‚  4.7 M â”‚ train â”‚
â”‚[2m [0m[2m512[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.8.mlp.c_fc             â”‚ Linear                          â”‚  2.4 M â”‚ train â”‚
â”‚[2m [0m[2m513[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.8.mlp.gelu             â”‚ GELU                            â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m514[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.8.mlp.c_proj           â”‚ Linear                          â”‚  2.4 M â”‚ train â”‚
â”‚[2m [0m[2m515[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.8.ls_2                 â”‚ Identity                        â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m516[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.9                      â”‚ ResidualAttentionBlock          â”‚  7.1 M â”‚ train â”‚
â”‚[2m [0m[2m517[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.9.ln_1                 â”‚ LayerNorm                       â”‚  1.5 K â”‚ train â”‚
â”‚[2m [0m[2m518[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.9.attn                 â”‚ MultiheadAttention              â”‚  2.4 M â”‚ train â”‚
â”‚[2m [0m[2m519[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.9.attn.out_proj        â”‚ NonDynamicallyQuantizableLinear â”‚  590 K â”‚ train â”‚
â”‚[2m [0m[2m520[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.9.ls_1                 â”‚ Identity                        â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m521[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.9.ln_2                 â”‚ LayerNorm                       â”‚  1.5 K â”‚ train â”‚
â”‚[2m [0m[2m522[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.9.mlp                  â”‚ Sequential                      â”‚  4.7 M â”‚ train â”‚
â”‚[2m [0m[2m523[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.9.mlp.c_fc             â”‚ Linear                          â”‚  2.4 M â”‚ train â”‚
â”‚[2m [0m[2m524[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.9.mlp.gelu             â”‚ GELU                            â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m525[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.9.mlp.c_proj           â”‚ Linear                          â”‚  2.4 M â”‚ train â”‚
â”‚[2m [0m[2m526[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.9.ls_2                 â”‚ Identity                        â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m527[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.10                     â”‚ ResidualAttentionBlock          â”‚  7.1 M â”‚ train â”‚
â”‚[2m [0m[2m528[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.10.ln_1                â”‚ LayerNorm                       â”‚  1.5 K â”‚ train â”‚
â”‚[2m [0m[2m529[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.10.attn                â”‚ MultiheadAttention              â”‚  2.4 M â”‚ train â”‚
â”‚[2m [0m[2m530[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.10.attn.out_proj       â”‚ NonDynamicallyQuantizableLinear â”‚  590 K â”‚ train â”‚
â”‚[2m [0m[2m531[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.10.ls_1                â”‚ Identity                        â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m532[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.10.ln_2                â”‚ LayerNorm                       â”‚  1.5 K â”‚ train â”‚
â”‚[2m [0m[2m533[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.10.mlp                 â”‚ Sequential                      â”‚  4.7 M â”‚ train â”‚
â”‚[2m [0m[2m534[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.10.mlp.c_fc            â”‚ Linear                          â”‚  2.4 M â”‚ train â”‚
â”‚[2m [0m[2m535[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.10.mlp.gelu            â”‚ GELU                            â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m536[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.10.mlp.c_proj          â”‚ Linear                          â”‚  2.4 M â”‚ train â”‚
â”‚[2m [0m[2m537[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.10.ls_2                â”‚ Identity                        â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m538[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.11                     â”‚ ResidualAttentionBlock          â”‚  7.1 M â”‚ train â”‚
â”‚[2m [0m[2m539[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.11.ln_1                â”‚ LayerNorm                       â”‚  1.5 K â”‚ train â”‚
â”‚[2m [0m[2m540[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.11.attn                â”‚ MultiheadAttention              â”‚  2.4 M â”‚ train â”‚
â”‚[2m [0m[2m541[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.11.attn.out_proj       â”‚ NonDynamicallyQuantizableLinear â”‚  590 K â”‚ train â”‚
â”‚[2m [0m[2m542[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.11.ls_1                â”‚ Identity                        â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m543[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.11.ln_2                â”‚ LayerNorm                       â”‚  1.5 K â”‚ train â”‚
â”‚[2m [0m[2m544[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.11.mlp                 â”‚ Sequential                      â”‚  4.7 M â”‚ train â”‚
â”‚[2m [0m[2m545[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.11.mlp.c_fc            â”‚ Linear                          â”‚  2.4 M â”‚ train â”‚
â”‚[2m [0m[2m546[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.11.mlp.gelu            â”‚ GELU                            â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m547[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.11.mlp.c_proj          â”‚ Linear                          â”‚  2.4 M â”‚ train â”‚
â”‚[2m [0m[2m548[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.11.ls_2                â”‚ Identity                        â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m549[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn                       â”‚ ModuleList                      â”‚ 85.1 M â”‚ train â”‚
â”‚[2m [0m[2m550[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.0                     â”‚ ResidualAttentionBlock          â”‚  7.1 M â”‚ train â”‚
â”‚[2m [0m[2m551[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.0.ln_1                â”‚ LayerNorm                       â”‚  1.5 K â”‚ train â”‚
â”‚[2m [0m[2m552[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.0.attn                â”‚ MultiheadAttention              â”‚  2.4 M â”‚ train â”‚
â”‚[2m [0m[2m553[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.0.attn.out_proj       â”‚ NonDynamicallyQuantizableLinear â”‚  590 K â”‚ train â”‚
â”‚[2m [0m[2m554[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.0.ls_1                â”‚ Identity                        â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m555[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.0.ln_1_kv             â”‚ LayerNorm                       â”‚  1.5 K â”‚ train â”‚
â”‚[2m [0m[2m556[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.0.ln_2                â”‚ LayerNorm                       â”‚  1.5 K â”‚ train â”‚
â”‚[2m [0m[2m557[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.0.mlp                 â”‚ Sequential                      â”‚  4.7 M â”‚ train â”‚
â”‚[2m [0m[2m558[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.0.mlp.c_fc            â”‚ Linear                          â”‚  2.4 M â”‚ train â”‚
â”‚[2m [0m[2m559[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.0.mlp.gelu            â”‚ GELU                            â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m560[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.0.mlp.c_proj          â”‚ Linear                          â”‚  2.4 M â”‚ train â”‚
â”‚[2m [0m[2m561[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.0.ls_2                â”‚ Identity                        â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m562[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.1                     â”‚ ResidualAttentionBlock          â”‚  7.1 M â”‚ train â”‚
â”‚[2m [0m[2m563[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.1.ln_1                â”‚ LayerNorm                       â”‚  1.5 K â”‚ train â”‚
â”‚[2m [0m[2m564[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.1.attn                â”‚ MultiheadAttention              â”‚  2.4 M â”‚ train â”‚
â”‚[2m [0m[2m565[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.1.attn.out_proj       â”‚ NonDynamicallyQuantizableLinear â”‚  590 K â”‚ train â”‚
â”‚[2m [0m[2m566[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.1.ls_1                â”‚ Identity                        â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m567[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.1.ln_1_kv             â”‚ LayerNorm                       â”‚  1.5 K â”‚ train â”‚
â”‚[2m [0m[2m568[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.1.ln_2                â”‚ LayerNorm                       â”‚  1.5 K â”‚ train â”‚
â”‚[2m [0m[2m569[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.1.mlp                 â”‚ Sequential                      â”‚  4.7 M â”‚ train â”‚
â”‚[2m [0m[2m570[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.1.mlp.c_fc            â”‚ Linear                          â”‚  2.4 M â”‚ train â”‚
â”‚[2m [0m[2m571[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.1.mlp.gelu            â”‚ GELU                            â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m572[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.1.mlp.c_proj          â”‚ Linear                          â”‚  2.4 M â”‚ train â”‚
â”‚[2m [0m[2m573[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.1.ls_2                â”‚ Identity                        â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m574[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.2                     â”‚ ResidualAttentionBlock          â”‚  7.1 M â”‚ train â”‚
â”‚[2m [0m[2m575[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.2.ln_1                â”‚ LayerNorm                       â”‚  1.5 K â”‚ train â”‚
â”‚[2m [0m[2m576[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.2.attn                â”‚ MultiheadAttention              â”‚  2.4 M â”‚ train â”‚
â”‚[2m [0m[2m577[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.2.attn.out_proj       â”‚ NonDynamicallyQuantizableLinear â”‚  590 K â”‚ train â”‚
â”‚[2m [0m[2m578[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.2.ls_1                â”‚ Identity                        â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m579[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.2.ln_1_kv             â”‚ LayerNorm                       â”‚  1.5 K â”‚ train â”‚
â”‚[2m [0m[2m580[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.2.ln_2                â”‚ LayerNorm                       â”‚  1.5 K â”‚ train â”‚
â”‚[2m [0m[2m581[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.2.mlp                 â”‚ Sequential                      â”‚  4.7 M â”‚ train â”‚
â”‚[2m [0m[2m582[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.2.mlp.c_fc            â”‚ Linear                          â”‚  2.4 M â”‚ train â”‚
â”‚[2m [0m[2m583[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.2.mlp.gelu            â”‚ GELU                            â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m584[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.2.mlp.c_proj          â”‚ Linear                          â”‚  2.4 M â”‚ train â”‚
â”‚[2m [0m[2m585[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.2.ls_2                â”‚ Identity                        â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m586[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.3                     â”‚ ResidualAttentionBlock          â”‚  7.1 M â”‚ train â”‚
â”‚[2m [0m[2m587[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.3.ln_1                â”‚ LayerNorm                       â”‚  1.5 K â”‚ train â”‚
â”‚[2m [0m[2m588[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.3.attn                â”‚ MultiheadAttention              â”‚  2.4 M â”‚ train â”‚
â”‚[2m [0m[2m589[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.3.attn.out_proj       â”‚ NonDynamicallyQuantizableLinear â”‚  590 K â”‚ train â”‚
â”‚[2m [0m[2m590[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.3.ls_1                â”‚ Identity                        â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m591[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.3.ln_1_kv             â”‚ LayerNorm                       â”‚  1.5 K â”‚ train â”‚
â”‚[2m [0m[2m592[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.3.ln_2                â”‚ LayerNorm                       â”‚  1.5 K â”‚ train â”‚
â”‚[2m [0m[2m593[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.3.mlp                 â”‚ Sequential                      â”‚  4.7 M â”‚ train â”‚
â”‚[2m [0m[2m594[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.3.mlp.c_fc            â”‚ Linear                          â”‚  2.4 M â”‚ train â”‚
â”‚[2m [0m[2m595[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.3.mlp.gelu            â”‚ GELU                            â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m596[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.3.mlp.c_proj          â”‚ Linear                          â”‚  2.4 M â”‚ train â”‚
â”‚[2m [0m[2m597[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.3.ls_2                â”‚ Identity                        â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m598[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.4                     â”‚ ResidualAttentionBlock          â”‚  7.1 M â”‚ train â”‚
â”‚[2m [0m[2m599[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.4.ln_1                â”‚ LayerNorm                       â”‚  1.5 K â”‚ train â”‚
â”‚[2m [0m[2m600[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.4.attn                â”‚ MultiheadAttention              â”‚  2.4 M â”‚ train â”‚
â”‚[2m [0m[2m601[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.4.attn.out_proj       â”‚ NonDynamicallyQuantizableLinear â”‚  590 K â”‚ train â”‚
â”‚[2m [0m[2m602[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.4.ls_1                â”‚ Identity                        â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m603[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.4.ln_1_kv             â”‚ LayerNorm                       â”‚  1.5 K â”‚ train â”‚
â”‚[2m [0m[2m604[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.4.ln_2                â”‚ LayerNorm                       â”‚  1.5 K â”‚ train â”‚
â”‚[2m [0m[2m605[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.4.mlp                 â”‚ Sequential                      â”‚  4.7 M â”‚ train â”‚
â”‚[2m [0m[2m606[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.4.mlp.c_fc            â”‚ Linear                          â”‚  2.4 M â”‚ train â”‚
â”‚[2m [0m[2m607[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.4.mlp.gelu            â”‚ GELU                            â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m608[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.4.mlp.c_proj          â”‚ Linear                          â”‚  2.4 M â”‚ train â”‚
â”‚[2m [0m[2m609[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.4.ls_2                â”‚ Identity                        â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m610[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.5                     â”‚ ResidualAttentionBlock          â”‚  7.1 M â”‚ train â”‚
â”‚[2m [0m[2m611[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.5.ln_1                â”‚ LayerNorm                       â”‚  1.5 K â”‚ train â”‚
â”‚[2m [0m[2m612[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.5.attn                â”‚ MultiheadAttention              â”‚  2.4 M â”‚ train â”‚
â”‚[2m [0m[2m613[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.5.attn.out_proj       â”‚ NonDynamicallyQuantizableLinear â”‚  590 K â”‚ train â”‚
â”‚[2m [0m[2m614[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.5.ls_1                â”‚ Identity                        â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m615[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.5.ln_1_kv             â”‚ LayerNorm                       â”‚  1.5 K â”‚ train â”‚
â”‚[2m [0m[2m616[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.5.ln_2                â”‚ LayerNorm                       â”‚  1.5 K â”‚ train â”‚
â”‚[2m [0m[2m617[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.5.mlp                 â”‚ Sequential                      â”‚  4.7 M â”‚ train â”‚
â”‚[2m [0m[2m618[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.5.mlp.c_fc            â”‚ Linear                          â”‚  2.4 M â”‚ train â”‚
â”‚[2m [0m[2m619[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.5.mlp.gelu            â”‚ GELU                            â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m620[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.5.mlp.c_proj          â”‚ Linear                          â”‚  2.4 M â”‚ train â”‚
â”‚[2m [0m[2m621[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.5.ls_2                â”‚ Identity                        â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m622[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.6                     â”‚ ResidualAttentionBlock          â”‚  7.1 M â”‚ train â”‚
â”‚[2m [0m[2m623[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.6.ln_1                â”‚ LayerNorm                       â”‚  1.5 K â”‚ train â”‚
â”‚[2m [0m[2m624[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.6.attn                â”‚ MultiheadAttention              â”‚  2.4 M â”‚ train â”‚
â”‚[2m [0m[2m625[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.6.attn.out_proj       â”‚ NonDynamicallyQuantizableLinear â”‚  590 K â”‚ train â”‚
â”‚[2m [0m[2m626[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.6.ls_1                â”‚ Identity                        â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m627[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.6.ln_1_kv             â”‚ LayerNorm                       â”‚  1.5 K â”‚ train â”‚
â”‚[2m [0m[2m628[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.6.ln_2                â”‚ LayerNorm                       â”‚  1.5 K â”‚ train â”‚
â”‚[2m [0m[2m629[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.6.mlp                 â”‚ Sequential                      â”‚  4.7 M â”‚ train â”‚
â”‚[2m [0m[2m630[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.6.mlp.c_fc            â”‚ Linear                          â”‚  2.4 M â”‚ train â”‚
â”‚[2m [0m[2m631[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.6.mlp.gelu            â”‚ GELU                            â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m632[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.6.mlp.c_proj          â”‚ Linear                          â”‚  2.4 M â”‚ train â”‚
â”‚[2m [0m[2m633[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.6.ls_2                â”‚ Identity                        â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m634[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.7                     â”‚ ResidualAttentionBlock          â”‚  7.1 M â”‚ train â”‚
â”‚[2m [0m[2m635[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.7.ln_1                â”‚ LayerNorm                       â”‚  1.5 K â”‚ train â”‚
â”‚[2m [0m[2m636[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.7.attn                â”‚ MultiheadAttention              â”‚  2.4 M â”‚ train â”‚
â”‚[2m [0m[2m637[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.7.attn.out_proj       â”‚ NonDynamicallyQuantizableLinear â”‚  590 K â”‚ train â”‚
â”‚[2m [0m[2m638[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.7.ls_1                â”‚ Identity                        â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m639[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.7.ln_1_kv             â”‚ LayerNorm                       â”‚  1.5 K â”‚ train â”‚
â”‚[2m [0m[2m640[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.7.ln_2                â”‚ LayerNorm                       â”‚  1.5 K â”‚ train â”‚
â”‚[2m [0m[2m641[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.7.mlp                 â”‚ Sequential                      â”‚  4.7 M â”‚ train â”‚
â”‚[2m [0m[2m642[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.7.mlp.c_fc            â”‚ Linear                          â”‚  2.4 M â”‚ train â”‚
â”‚[2m [0m[2m643[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.7.mlp.gelu            â”‚ GELU                            â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m644[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.7.mlp.c_proj          â”‚ Linear                          â”‚  2.4 M â”‚ train â”‚
â”‚[2m [0m[2m645[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.7.ls_2                â”‚ Identity                        â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m646[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.8                     â”‚ ResidualAttentionBlock          â”‚  7.1 M â”‚ train â”‚
â”‚[2m [0m[2m647[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.8.ln_1                â”‚ LayerNorm                       â”‚  1.5 K â”‚ train â”‚
â”‚[2m [0m[2m648[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.8.attn                â”‚ MultiheadAttention              â”‚  2.4 M â”‚ train â”‚
â”‚[2m [0m[2m649[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.8.attn.out_proj       â”‚ NonDynamicallyQuantizableLinear â”‚  590 K â”‚ train â”‚
â”‚[2m [0m[2m650[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.8.ls_1                â”‚ Identity                        â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m651[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.8.ln_1_kv             â”‚ LayerNorm                       â”‚  1.5 K â”‚ train â”‚
â”‚[2m [0m[2m652[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.8.ln_2                â”‚ LayerNorm                       â”‚  1.5 K â”‚ train â”‚
â”‚[2m [0m[2m653[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.8.mlp                 â”‚ Sequential                      â”‚  4.7 M â”‚ train â”‚
â”‚[2m [0m[2m654[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.8.mlp.c_fc            â”‚ Linear                          â”‚  2.4 M â”‚ train â”‚
â”‚[2m [0m[2m655[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.8.mlp.gelu            â”‚ GELU                            â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m656[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.8.mlp.c_proj          â”‚ Linear                          â”‚  2.4 M â”‚ train â”‚
â”‚[2m [0m[2m657[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.8.ls_2                â”‚ Identity                        â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m658[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.9                     â”‚ ResidualAttentionBlock          â”‚  7.1 M â”‚ train â”‚
â”‚[2m [0m[2m659[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.9.ln_1                â”‚ LayerNorm                       â”‚  1.5 K â”‚ train â”‚
â”‚[2m [0m[2m660[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.9.attn                â”‚ MultiheadAttention              â”‚  2.4 M â”‚ train â”‚
â”‚[2m [0m[2m661[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.9.attn.out_proj       â”‚ NonDynamicallyQuantizableLinear â”‚  590 K â”‚ train â”‚
â”‚[2m [0m[2m662[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.9.ls_1                â”‚ Identity                        â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m663[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.9.ln_1_kv             â”‚ LayerNorm                       â”‚  1.5 K â”‚ train â”‚
â”‚[2m [0m[2m664[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.9.ln_2                â”‚ LayerNorm                       â”‚  1.5 K â”‚ train â”‚
â”‚[2m [0m[2m665[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.9.mlp                 â”‚ Sequential                      â”‚  4.7 M â”‚ train â”‚
â”‚[2m [0m[2m666[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.9.mlp.c_fc            â”‚ Linear                          â”‚  2.4 M â”‚ train â”‚
â”‚[2m [0m[2m667[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.9.mlp.gelu            â”‚ GELU                            â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m668[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.9.mlp.c_proj          â”‚ Linear                          â”‚  2.4 M â”‚ train â”‚
â”‚[2m [0m[2m669[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.9.ls_2                â”‚ Identity                        â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m670[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.10                    â”‚ ResidualAttentionBlock          â”‚  7.1 M â”‚ train â”‚
â”‚[2m [0m[2m671[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.10.ln_1               â”‚ LayerNorm                       â”‚  1.5 K â”‚ train â”‚
â”‚[2m [0m[2m672[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.10.attn               â”‚ MultiheadAttention              â”‚  2.4 M â”‚ train â”‚
â”‚[2m [0m[2m673[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.10.attn.out_proj      â”‚ NonDynamicallyQuantizableLinear â”‚  590 K â”‚ train â”‚
â”‚[2m [0m[2m674[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.10.ls_1               â”‚ Identity                        â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m675[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.10.ln_1_kv            â”‚ LayerNorm                       â”‚  1.5 K â”‚ train â”‚
â”‚[2m [0m[2m676[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.10.ln_2               â”‚ LayerNorm                       â”‚  1.5 K â”‚ train â”‚
â”‚[2m [0m[2m677[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.10.mlp                â”‚ Sequential                      â”‚  4.7 M â”‚ train â”‚
â”‚[2m [0m[2m678[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.10.mlp.c_fc           â”‚ Linear                          â”‚  2.4 M â”‚ train â”‚
â”‚[2m [0m[2m679[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.10.mlp.gelu           â”‚ GELU                            â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m680[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.10.mlp.c_proj         â”‚ Linear                          â”‚  2.4 M â”‚ train â”‚
â”‚[2m [0m[2m681[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.10.ls_2               â”‚ Identity                        â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m682[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.11                    â”‚ ResidualAttentionBlock          â”‚  7.1 M â”‚ train â”‚
â”‚[2m [0m[2m683[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.11.ln_1               â”‚ LayerNorm                       â”‚  1.5 K â”‚ train â”‚
â”‚[2m [0m[2m684[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.11.attn               â”‚ MultiheadAttention              â”‚  2.4 M â”‚ train â”‚
â”‚[2m [0m[2m685[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.11.attn.out_proj      â”‚ NonDynamicallyQuantizableLinear â”‚  590 K â”‚ train â”‚
â”‚[2m [0m[2m686[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.11.ls_1               â”‚ Identity                        â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m687[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.11.ln_1_kv            â”‚ LayerNorm                       â”‚  1.5 K â”‚ train â”‚
â”‚[2m [0m[2m688[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.11.ln_2               â”‚ LayerNorm                       â”‚  1.5 K â”‚ train â”‚
â”‚[2m [0m[2m689[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.11.mlp                â”‚ Sequential                      â”‚  4.7 M â”‚ train â”‚
â”‚[2m [0m[2m690[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.11.mlp.c_fc           â”‚ Linear                          â”‚  2.4 M â”‚ train â”‚
â”‚[2m [0m[2m691[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.11.mlp.gelu           â”‚ GELU                            â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m692[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.11.mlp.c_proj         â”‚ Linear                          â”‚  2.4 M â”‚ train â”‚
â”‚[2m [0m[2m693[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.11.ls_2               â”‚ Identity                        â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m694[0m[2m [0mâ”‚ net.model.text_decoder.ln_final                         â”‚ LayerNorm                       â”‚  1.5 K â”‚ train â”‚
â”‚[2m [0m[2m695[0m[2m [0mâ”‚ net.tta_loss                                            â”‚ ByolLoss                        â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m696[0m[2m [0mâ”‚ binary_acc                                              â”‚ BinaryAccuracy                  â”‚      0 â”‚ train â”‚
â””â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”˜
[1mTrainable params[0m: 1.2 M
[1mNon-trainable params[0m: 637 M
[1mTotal params[0m: 638 M
[1mTotal estimated model params size (MB)[0m: 2.6 K
[1mModules in train mode[0m: 697
[1mModules in eval mode[0m: 0
/home/def/miniforge3/envs/fewshot/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:425: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.
`Trainer.fit` stopped: `max_epochs=0` reached.
[[36m2025-02-14 14:44:48,630[0m][[34m__main__[0m][[32mINFO[0m] - Starting testing![0m
[[36m2025-02-14 14:44:48,630[0m][[34m__main__[0m][[33mWARNING[0m] - Best ckpt not found! Using current weights for testing...[0m
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
/home/def/miniforge3/envs/fewshot/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:425: The 'test_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.
[2KStart testing...
[2Kself.avg_features.shape torch.Size([5, 768])â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 0/203 [2m0:00:00 â€¢ -:--:--[0m [2;4m0.00it/s[0m  
[2K/home/def/fewshot/src/models/components/tt_method.py:234: UserWarning: The use of `x.T` on tensors of dimension other than 2 to reverse their shape is deprecated and it will throw an error in a future release. Consider `x.mT` to transpose batches of matrices or
`x.permute(*torch.arange(x.ndim - 1, -1, -1))` to reverse the dimensions of a tensor. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3683.)
  dot_product = (x @ y.T)
[2Kindexes: 2;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 0/203 [2m0:00:00 â€¢ -:--:--[0m [2;4m0.00it/s[0m  
[2Kself.avg_features.shape torch.Size([5, 768])â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 1/203 [2m0:00:00 â€¢ -:--:--[0m [2;4m0.00it/s[0m  
[2Kindexes: 1;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 1/203 [2m0:00:00 â€¢ -:--:--[0m [2;4m0.00it/s[0m  
[2Kself.avg_features.shape torch.Size([5, 768])â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 2/203 [2m0:00:01 â€¢ 0:01:17[0m [2;4m2.62it/s[0m  
[2Kindexes: 4;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 2/203 [2m0:00:01 â€¢ 0:01:17[0m [2;4m2.62it/s[0m  
[2Kself.avg_features.shape torch.Size([5, 768])â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 3/203 [2m0:00:01 â€¢ 0:00:52[0m [2;4m3.87it/s[0m  
[2Kindexes: 1;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 3/203 [2m0:00:01 â€¢ 0:00:52[0m [2;4m3.87it/s[0m  
[2Kself.avg_features.shape torch.Size([5, 768])â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 4/203 [2m0:00:02 â€¢ 0:01:41[0m [2;4m1.98it/s[0m  
[2Kindexes: 0;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 4/203 [2m0:00:02 â€¢ 0:01:41[0m [2;4m1.98it/s[0m  
[2Kself.avg_features.shape torch.Size([5, 768])â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 5/203 [2m0:00:02 â€¢ 0:01:21[0m [2;4m2.46it/s[0m  
[2Kindexes: 4;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 5/203 [2m0:00:02 â€¢ 0:01:21[0m [2;4m2.46it/s[0m  
[2Kself.avg_features.shape torch.Size([5, 768])m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 6/203 [2m0:00:02 â€¢ 0:01:14[0m [2;4m2.67it/s[0m  
[2Kindexes: 1;98;6;224mâ”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 6/203 [2m0:00:02 â€¢ 0:01:14[0m [2;4m2.67it/s[0m  
[2Kself.avg_features.shape torch.Size([5, 768])m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 7/203 [2m0:00:03 â€¢ 0:01:31[0m [2;4m2.17it/s[0m  
[2Kindexes: 4;98;6;224mâ”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 7/203 [2m0:00:03 â€¢ 0:01:31[0m [2;4m2.17it/s[0m  
[2Kself.avg_features.shape torch.Size([5, 768])mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 8/203 [2m0:00:03 â€¢ 0:01:23[0m [2;4m2.35it/s[0m  
[2Kindexes: 0;98;6;224mâ”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 8/203 [2m0:00:03 â€¢ 0:01:23[0m [2;4m2.35it/s[0m  
[2Kself.avg_features.shape torch.Size([5, 768])mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 9/203 [2m0:00:03 â€¢ 0:01:18[0m [2;4m2.52it/s[0m  
[2Kindexes: 0;98;6;224mâ”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 9/203 [2m0:00:03 â€¢ 0:01:18[0m [2;4m2.52it/s[0m  
[2Kself.avg_features.shape torch.Size([5, 768])mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 10/203 [2m0:00:04 â€¢ 0:01:11[0m [2;4m2.72it/s[0m  
[2Kindexes: 4;98;6;224mâ”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 10/203 [2m0:00:04 â€¢ 0:01:11[0m [2;4m2.72it/s[0m  
[2Kself.avg_features.shape torch.Size([5, 768])0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 11/203 [2m0:00:04 â€¢ 0:01:06[0m [2;4m2.93it/s[0m   
[2Kindexes: 1;98;6;224mâ”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 11/203 [2m0:00:04 â€¢ 0:01:06[0m [2;4m2.93it/s[0m  
[2Kself.avg_features.shape torch.Size([5, 768])0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 12/203 [2m0:00:04 â€¢ 0:01:03[0m [2;4m3.04it/s[0m  
[2Kindexes: 1;98;6;224mâ”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 12/203 [2m0:00:04 â€¢ 0:01:03[0m [2;4m3.04it/s[0m  
[2Kself.avg_features.shape torch.Size([5, 768])4mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 13/203 [2m0:00:04 â€¢ 0:01:00[0m [2;4m3.22it/s[0m  
[2Kindexes: 0;98;6;224mâ”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 13/203 [2m0:00:04 â€¢ 0:01:00[0m [2;4m3.22it/s[0m  
[2Kself.avg_features.shape torch.Size([5, 768])4mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 14/203 [2m0:00:04 â€¢ 0:00:58[0m [2;4m3.31it/s[0m  
[2Kindexes: 4;98;6;224mâ”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 14/203 [2m0:00:04 â€¢ 0:00:58[0m [2;4m3.31it/s[0m  
[2Kself.avg_features.shape torch.Size([5, 768])4mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 15/203 [2m0:00:04 â€¢ 0:00:55[0m [2;4m3.45it/s[0m  
[2Kindexes: 2;98;6;224mâ”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 15/203 [2m0:00:04 â€¢ 0:00:55[0m [2;4m3.45it/s[0m  
[2Kself.avg_features.shape torch.Size([5, 768])[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 16/203 [2m0:00:04 â€¢ 0:00:52[0m [2;4m3.60it/s[0m   
[2Kindexes: 4;98;6;224mâ”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 16/203 [2m0:00:04 â€¢ 0:00:52[0m [2;4m3.60it/s[0m  
[2Kself.avg_features.shape torch.Size([5, 768])[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 17/203 [2m0:00:05 â€¢ 0:00:51[0m [2;4m3.68it/s[0m  
[2Kindexes: 4;98;6;224mâ”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 17/203 [2m0:00:05 â€¢ 0:00:51[0m [2;4m3.68it/s[0m  
[2Kself.avg_features.shape torch.Size([5, 768])24mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 18/203 [2m0:00:05 â€¢ 0:00:50[0m [2;4m3.77it/s[0m  
[2Kindexes: 4;98;6;224mâ”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 18/203 [2m0:00:05 â€¢ 0:00:50[0m [2;4m3.77it/s[0m  
[2Kself.avg_features.shape torch.Size([5, 768])24mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 19/203 [2m0:00:05 â€¢ 0:00:48[0m [2;4m3.86it/s[0m  
[2Kindexes: 3;98;6;224mâ”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 19/203 [2m0:00:05 â€¢ 0:00:48[0m [2;4m3.86it/s[0m  
[2Kself.avg_features.shape torch.Size([5, 768])24mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 20/203 [2m0:00:05 â€¢ 0:00:46[0m [2;4m4.00it/s[0m  
[2Kindexes: 2;98;6;224mâ”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 20/203 [2m0:00:05 â€¢ 0:00:46[0m [2;4m4.00it/s[0m  
[2Kself.avg_features.shape torch.Size([5, 768])[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 21/203 [2m0:00:06 â€¢ 0:00:49[0m [2;4m3.78it/s[0m   
[2Kindexes: 0;98;6;224mâ”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 21/203 [2m0:00:06 â€¢ 0:00:49[0m [2;4m3.78it/s[0m  
[2Kself.avg_features.shape torch.Size([5, 768])[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 22/203 [2m0:00:06 â€¢ 0:00:47[0m [2;4m3.87it/s[0m  
[2Kindexes: 1;98;6;224mâ”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 22/203 [2m0:00:06 â€¢ 0:00:47[0m [2;4m3.87it/s[0m  
[2Kself.avg_features.shape torch.Size([5, 768])224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 23/203 [2m0:00:06 â€¢ 0:00:46[0m [2;4m3.97it/s[0m  
[2Kindexes: 1;98;6;224mâ”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 23/203 [2m0:00:06 â€¢ 0:00:46[0m [2;4m3.97it/s[0m  
[2Kself.avg_features.shape torch.Size([5, 768])224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 24/203 [2m0:00:06 â€¢ 0:00:45[0m [2;4m4.05it/s[0m  
[2Kindexes: 4;98;6;224mâ”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 24/203 [2m0:00:06 â€¢ 0:00:45[0m [2;4m4.05it/s[0m  
[2Kself.avg_features.shape torch.Size([5, 768])224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 25/203 [2m0:00:06 â€¢ 0:00:44[0m [2;4m4.05it/s[0m  
[2Kindexes: 4;98;6;224mâ”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 25/203 [2m0:00:06 â€¢ 0:00:44[0m [2;4m4.05it/s[0m  
[2Kself.avg_features.shape torch.Size([5, 768])â•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 26/203 [2m0:00:06 â€¢ 0:00:44[0m [2;4m4.11it/s[0m   
[2Kindexes: 4;98;6;224mâ”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 26/203 [2m0:00:06 â€¢ 0:00:44[0m [2;4m4.11it/s[0m  
[2Kself.avg_features.shape torch.Size([5, 768])â•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 27/203 [2m0:00:07 â€¢ 0:00:46[0m [2;4m3.83it/s[0m  
[2Kindexes: 0;98;6;224mâ”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 27/203 [2m0:00:07 â€¢ 0:00:46[0m [2;4m3.83it/s[0m  
[2Kself.avg_features.shape torch.Size([5, 768]);224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 28/203 [2m0:00:07 â€¢ 0:00:46[0m [2;4m3.81it/s[0m  
[2Kindexes: 1;98;6;224mâ”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 28/203 [2m0:00:07 â€¢ 0:00:46[0m [2;4m3.81it/s[0m  
[2Kself.avg_features.shape torch.Size([5, 768]);224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 29/203 [2m0:00:08 â€¢ 0:00:46[0m [2;4m3.82it/s[0m  
[2Kindexes: 4;98;6;224mâ”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 29/203 [2m0:00:08 â€¢ 0:00:46[0m [2;4m3.82it/s[0m  
[2Kself.avg_features.shape torch.Size([5, 768]);224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 30/203 [2m0:00:08 â€¢ 0:00:46[0m [2;4m3.84it/s[0m  
[2Kindexes: 4;98;6;224mâ”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 30/203 [2m0:00:08 â€¢ 0:00:46[0m [2;4m3.84it/s[0m  
[2Kself.avg_features.shape torch.Size([5, 768])mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 31/203 [2m0:00:08 â€¢ 0:00:45[0m [2;4m3.84it/s[0m   
[2Kindexes: 1;98;6;224mâ”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 31/203 [2m0:00:08 â€¢ 0:00:45[0m [2;4m3.84it/s[0m  
[2Kself.avg_features.shape torch.Size([5, 768])mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 32/203 [2m0:00:09 â€¢ 0:00:46[0m [2;4m3.78it/s[0m  
[2Kindexes: 4;98;6;224mâ”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 32/203 [2m0:00:09 â€¢ 0:00:46[0m [2;4m3.78it/s[0m  
[2Kself.avg_features.shape torch.Size([5, 768])6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 33/203 [2m0:00:09 â€¢ 0:00:45[0m [2;4m3.81it/s[0m  
[2Kindexes: 4;98;6;224mâ”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 33/203 [2m0:00:09 â€¢ 0:00:45[0m [2;4m3.81it/s[0m  
[2Kself.avg_features.shape torch.Size([5, 768])6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 34/203 [2m0:00:09 â€¢ 0:00:45[0m [2;4m3.83it/s[0m  
[2Kindexes: 1;98;6;224mâ”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 34/203 [2m0:00:09 â€¢ 0:00:45[0m [2;4m3.83it/s[0m  
[2Kself.avg_features.shape torch.Size([5, 768])6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 35/203 [2m0:00:09 â€¢ 0:00:44[0m [2;4m3.87it/s[0m  
[2Kindexes: 4;98;6;224mâ”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 35/203 [2m0:00:09 â€¢ 0:00:44[0m [2;4m3.87it/s[0m  
[2Kself.avg_features.shape torch.Size([5, 768])7mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 36/203 [2m0:00:09 â€¢ 0:00:43[0m [2;4m3.91it/s[0m   
[2Kindexes: 4;98;6;224mâ”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 36/203 [2m0:00:09 â€¢ 0:00:43[0m [2;4m3.91it/s[0m  
[2Kself.avg_features.shape torch.Size([5, 768])7mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 37/203 [2m0:00:09 â€¢ 0:00:42[0m [2;4m3.97it/s[0m  
[2Kindexes: 2;98;6;224mâ”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 37/203 [2m0:00:09 â€¢ 0:00:42[0m [2;4m3.97it/s[0m  
[2Kself.avg_features.shape torch.Size([5, 768])7mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 38/203 [2m0:00:10 â€¢ 0:00:42[0m [2;4m4.01it/s[0m  
[2Kindexes: 4;98;6;224mâ”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 38/203 [2m0:00:10 â€¢ 0:00:42[0m [2;4m4.01it/s[0m  
[2Kself.avg_features.shape torch.Size([5, 768]);6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 39/203 [2m0:00:10 â€¢ 0:00:42[0m [2;4m3.94it/s[0m  
[2Kindexes: 4;98;6;224mâ”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 39/203 [2m0:00:10 â€¢ 0:00:42[0m [2;4m3.94it/s[0m  
[2Kself.avg_features.shape torch.Size([5, 768]);6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 40/203 [2m0:00:10 â€¢ 0:00:42[0m [2;4m3.95it/s[0m  
[2Kindexes: 2;98;6;224mâ”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 40/203 [2m0:00:10 â€¢ 0:00:42[0m [2;4m3.95it/s[0m  
[2Kself.avg_features.shape torch.Size([5, 768])37mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 41/203 [2m0:00:11 â€¢ 0:00:42[0m [2;4m3.90it/s[0m   
[2Kindexes: 1;98;6;224mâ”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 41/203 [2m0:00:11 â€¢ 0:00:42[0m [2;4m3.90it/s[0m  
[2Kself.avg_features.shape torch.Size([5, 768])37mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 42/203 [2m0:00:11 â€¢ 0:00:42[0m [2;4m3.90it/s[0m  
[2Kindexes: 4;98;6;224mâ”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 42/203 [2m0:00:11 â€¢ 0:00:42[0m [2;4m3.90it/s[0m  
[2Kself.avg_features.shape torch.Size([5, 768])37mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 43/203 [2m0:00:11 â€¢ 0:00:41[0m [2;4m3.97it/s[0m  
[2Kindexes: 4;98;6;224mâ”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 43/203 [2m0:00:11 â€¢ 0:00:41[0m [2;4m3.97it/s[0m  
[2Kself.avg_features.shape torch.Size([5, 768])8;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 44/203 [2m0:00:11 â€¢ 0:00:40[0m [2;4m3.98it/s[0m  
[2Kindexes: 1;98;6;224mâ”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 44/203 [2m0:00:11 â€¢ 0:00:40[0m [2;4m3.98it/s[0m  
[2Kself.avg_features.shape torch.Size([5, 768])8;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 45/203 [2m0:00:12 â€¢ 0:00:42[0m [2;4m3.85it/s[0m  
[2Kindexes: 0;98;6;224mâ”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 45/203 [2m0:00:12 â€¢ 0:00:42[0m [2;4m3.85it/s[0m  
[2Kself.avg_features.shape torch.Size([5, 768])237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 46/203 [2m0:00:12 â€¢ 0:00:41[0m [2;4m3.85it/s[0m   
[2Kindexes: 4;98;6;224mâ”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 46/203 [2m0:00:12 â€¢ 0:00:41[0m [2;4m3.85it/s[0m  
[2Kself.avg_features.shape torch.Size([5, 768])237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 47/203 [2m0:00:12 â€¢ 0:00:41[0m [2;4m3.85it/s[0m  
[2Kindexes: 4;98;6;224mâ”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 47/203 [2m0:00:12 â€¢ 0:00:41[0m [2;4m3.85it/s[0m  
[2Kself.avg_features.shape torch.Size([5, 768])237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 48/203 [2m0:00:13 â€¢ 0:00:42[0m [2;4m3.74it/s[0m  
[2Kindexes: 4;98;6;224mâ”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 48/203 [2m0:00:13 â€¢ 0:00:42[0m [2;4m3.74it/s[0m  
[2Kself.avg_features.shape torch.Size([5, 768])98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 49/203 [2m0:00:13 â€¢ 0:00:41[0m [2;4m3.79it/s[0m  
[2Kindexes: 1;98;6;224mâ”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 49/203 [2m0:00:13 â€¢ 0:00:41[0m [2;4m3.79it/s[0m  
[2Kself.avg_features.shape torch.Size([5, 768])98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 50/203 [2m0:00:13 â€¢ 0:00:41[0m [2;4m3.80it/s[0m  
[2Kindexes: 4;98;6;224mâ”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 50/203 [2m0:00:13 â€¢ 0:00:41[0m [2;4m3.80it/s[0m  
[2Kself.avg_features.shape torch.Size([5, 768]);237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 51/203 [2m0:00:13 â€¢ 0:00:40[0m [2;4m3.81it/s[0m   
[2Kindexes: 0;98;6;224mâ”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 51/203 [2m0:00:13 â€¢ 0:00:40[0m [2;4m3.81it/s[0m  
[2Kself.avg_features.shape torch.Size([5, 768]);237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 52/203 [2m0:00:14 â€¢ 0:00:40[0m [2;4m3.85it/s[0m  
[2Kindexes: 4;98;6;224mâ”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 52/203 [2m0:00:14 â€¢ 0:00:40[0m [2;4m3.85it/s[0m  
[2Kself.avg_features.shape torch.Size([5, 768]);237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 53/203 [2m0:00:14 â€¢ 0:00:39[0m [2;4m3.90it/s[0m  
[2Kindexes: 4;98;6;224mâ”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 53/203 [2m0:00:14 â€¢ 0:00:39[0m [2;4m3.90it/s[0m  
[2Kself.avg_features.shape torch.Size([5, 768]);98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 54/203 [2m0:00:14 â€¢ 0:00:39[0m [2;4m3.90it/s[0m  
[2Kindexes: 3;98;6;224mâ”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 54/203 [2m0:00:14 â€¢ 0:00:39[0m [2;4m3.90it/s[0m  
[2Kself.avg_features.shape torch.Size([5, 768]);98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 55/203 [2m0:00:14 â€¢ 0:00:39[0m [2;4m3.89it/s[0m  
[2Kindexes: 4;98;6;224mâ”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 55/203 [2m0:00:14 â€¢ 0:00:39[0m [2;4m3.89it/s[0m  
[2Kself.avg_features.shape torch.Size([5, 768])5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 56/203 [2m0:00:14 â€¢ 0:00:38[0m [2;4m3.93it/s[0m   
[2Kindexes: 1;98;6;224mâ”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 56/203 [2m0:00:14 â€¢ 0:00:38[0m [2;4m3.93it/s[0m  
[2Kself.avg_features.shape torch.Size([5, 768])5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 57/203 [2m0:00:14 â€¢ 0:00:37[0m [2;4m3.98it/s[0m  
[2Kindexes: 4;98;6;224mâ”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 57/203 [2m0:00:14 â€¢ 0:00:37[0m [2;4m3.98it/s[0m  
[2Kself.avg_features.shape torch.Size([5, 768])5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 58/203 [2m0:00:15 â€¢ 0:00:37[0m [2;4m3.99it/s[0m  
[2Kindexes: 4;98;6;224mâ”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 58/203 [2m0:00:15 â€¢ 0:00:37[0m [2;4m3.99it/s[0m  
[2Kself.avg_features.shape torch.Size([5, 768])2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 59/203 [2m0:00:15 â€¢ 0:00:36[0m [2;4m4.01it/s[0m  
[2Kindexes: 4;98;6;224mâ”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 59/203 [2m0:00:15 â€¢ 0:00:36[0m [2;4m4.01it/s[0m  
[2Kself.avg_features.shape torch.Size([5, 768])2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 60/203 [2m0:00:15 â€¢ 0:00:36[0m [2;4m4.03it/s[0m  
[2Kindexes: 1;98;6;224mâ”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 60/203 [2m0:00:15 â€¢ 0:00:36[0m [2;4m4.03it/s[0m  
[2Kself.avg_features.shape torch.Size([5, 768]);5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 61/203 [2m0:00:15 â€¢ 0:00:36[0m [2;4m4.00it/s[0m   
[2Kindexes: 4;98;6;224mâ”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 61/203 [2m0:00:15 â€¢ 0:00:36[0m [2;4m4.00it/s[0m  
[2Kself.avg_features.shape torch.Size([5, 768]);5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 62/203 [2m0:00:16 â€¢ 0:00:36[0m [2;4m4.01it/s[0m  
[2Kindexes: 4;98;6;224mâ”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 62/203 [2m0:00:16 â€¢ 0:00:36[0m [2;4m4.01it/s[0m  
[2Kself.avg_features.shape torch.Size([5, 768]);5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 63/203 [2m0:00:16 â€¢ 0:00:35[0m [2;4m4.02it/s[0m  
[2Kindexes: 1;98;6;224mâ”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 63/203 [2m0:00:16 â€¢ 0:00:35[0m [2;4m4.02it/s[0m  
[2Kself.avg_features.shape torch.Size([5, 768]);2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 64/203 [2m0:00:16 â€¢ 0:00:36[0m [2;4m3.94it/s[0m  
[2Kindexes: 0;98;6;224mâ”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 64/203 [2m0:00:16 â€¢ 0:00:36[0m [2;4m3.94it/s[0m  
[2Kself.avg_features.shape torch.Size([5, 768]);2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 65/203 [2m0:00:17 â€¢ 0:00:36[0m [2;4m3.93it/s[0m  
[2Kindexes: 0;98;6;224mâ”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 65/203 [2m0:00:17 â€¢ 0:00:36[0m [2;4m3.93it/s[0m  
[2Kself.avg_features.shape torch.Size([5, 768])8;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 66/203 [2m0:00:17 â€¢ 0:00:35[0m [2;4m3.97it/s[0m   
[2Kindexes: 3;98;6;224mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 66/203 [2m0:00:17 â€¢ 0:00:35[0m [2;4m3.97it/s[0m  
[2Kself.avg_features.shape torch.Size([5, 768])8;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 67/203 [2m0:00:17 â€¢ 0:00:35[0m [2;4m4.00it/s[0m  
[2Kindexes: 1;98;6;224mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 67/203 [2m0:00:17 â€¢ 0:00:35[0m [2;4m4.00it/s[0m  
[2Kself.avg_features.shape torch.Size([5, 768])8;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 68/203 [2m0:00:18 â€¢ 0:00:36[0m [2;4m3.76it/s[0m  
[2Kindexes: 4;98;6;224mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 68/203 [2m0:00:18 â€¢ 0:00:36[0m [2;4m3.76it/s[0m  
[2Kself.avg_features.shape torch.Size([5, 768])8;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 69/203 [2m0:00:18 â€¢ 0:00:36[0m [2;4m3.78it/s[0m  
[2Kindexes: 4;98;6;224mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 69/203 [2m0:00:18 â€¢ 0:00:36[0m [2;4m3.78it/s[0m  
[2Kself.avg_features.shape torch.Size([5, 768])8;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 70/203 [2m0:00:19 â€¢ 0:00:36[0m [2;4m3.79it/s[0m  
[2Kindexes: 4;98;6;224mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 70/203 [2m0:00:19 â€¢ 0:00:36[0m [2;4m3.79it/s[0m  
[2Kself.avg_features.shape torch.Size([5, 768])8;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 71/203 [2m0:00:19 â€¢ 0:00:35[0m [2;4m3.79it/s[0m  
[2Kindexes: 2;98;6;224mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 71/203 [2m0:00:19 â€¢ 0:00:35[0m [2;4m3.79it/s[0m  
[2Kself.avg_features.shape torch.Size([5, 768])38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 72/203 [2m0:00:19 â€¢ 0:00:35[0m [2;4m3.77it/s[0m   
[2Kindexes: 4;98;6;224mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 72/203 [2m0:00:19 â€¢ 0:00:35[0m [2;4m3.77it/s[0m  
[2Kself.avg_features.shape torch.Size([5, 768])38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 73/203 [2m0:00:20 â€¢ 0:00:36[0m [2;4m3.70it/s[0m  
[2Kindexes: 4;98;6;224mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 73/203 [2m0:00:20 â€¢ 0:00:36[0m [2;4m3.70it/s[0m  
[2Kself.avg_features.shape torch.Size([5, 768])38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 74/203 [2m0:00:20 â€¢ 0:00:35[0m [2;4m3.73it/s[0m  
[2Kindexes: 4;98;6;224mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 74/203 [2m0:00:20 â€¢ 0:00:35[0m [2;4m3.73it/s[0m  
[2Kself.avg_features.shape torch.Size([5, 768])38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 75/203 [2m0:00:20 â€¢ 0:00:35[0m [2;4m3.75it/s[0m  
[2Kindexes: 0;98;6;224mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 75/203 [2m0:00:20 â€¢ 0:00:35[0m [2;4m3.75it/s[0m  
[2Kself.avg_features.shape torch.Size([5, 768])38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 76/203 [2m0:00:20 â€¢ 0:00:34[0m [2;4m3.77it/s[0m  
[2Kindexes: 4;98;6;224mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 76/203 [2m0:00:20 â€¢ 0:00:34[0m [2;4m3.77it/s[0m  
[2Kself.avg_features.shape torch.Size([5, 768])[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 77/203 [2m0:00:20 â€¢ 0:00:34[0m [2;4m3.78it/s[0m   
[2Kindexes: 3;98;6;224mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 77/203 [2m0:00:20 â€¢ 0:00:34[0m [2;4m3.78it/s[0m  
[2Kself.avg_features.shape torch.Size([5, 768])[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 78/203 [2m0:00:21 â€¢ 0:00:33[0m [2;4m3.80it/s[0m  
[2Kindexes: 2;98;6;224mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 78/203 [2m0:00:21 â€¢ 0:00:33[0m [2;4m3.80it/s[0m  
[2Kself.avg_features.shape torch.Size([5, 768])[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 79/203 [2m0:00:21 â€¢ 0:00:33[0m [2;4m3.77it/s[0m  
[2Kindexes: 4;98;6;224mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 79/203 [2m0:00:21 â€¢ 0:00:33[0m [2;4m3.77it/s[0m  
[2Kself.avg_features.shape torch.Size([5, 768])[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 80/203 [2m0:00:21 â€¢ 0:00:33[0m [2;4m3.78it/s[0m  
[2Kindexes: 0;98;6;224mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 80/203 [2m0:00:21 â€¢ 0:00:33[0m [2;4m3.78it/s[0m  
[2Kself.avg_features.shape torch.Size([5, 768])[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 81/203 [2m0:00:21 â€¢ 0:00:32[0m [2;4m3.81it/s[0m  
[2Kindexes: 4;98;6;224mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 81/203 [2m0:00:21 â€¢ 0:00:32[0m [2;4m3.81it/s[0m  
[2Kself.avg_features.shape torch.Size([5, 768])[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 82/203 [2m0:00:21 â€¢ 0:00:32[0m [2;4m3.85it/s[0m   
[2Kindexes: 3;98;6;224mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 82/203 [2m0:00:21 â€¢ 0:00:32[0m [2;4m3.85it/s[0m  
[2Kself.avg_features.shape torch.Size([5, 768])[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 83/203 [2m0:00:21 â€¢ 0:00:31[0m [2;4m3.87it/s[0m  
[2Kindexes: 1;98;6;224mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 83/203 [2m0:00:21 â€¢ 0:00:31[0m [2;4m3.87it/s[0m  
[2Kself.avg_features.shape torch.Size([5, 768])[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 84/203 [2m0:00:22 â€¢ 0:00:31[0m [2;4m3.89it/s[0m  
[2Kindexes: 1;98;6;224mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 84/203 [2m0:00:22 â€¢ 0:00:31[0m [2;4m3.89it/s[0m  
[2Kself.avg_features.shape torch.Size([5, 768])[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 85/203 [2m0:00:22 â€¢ 0:00:31[0m [2;4m3.90it/s[0m  
[2Kindexes: 4;98;6;224mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 85/203 [2m0:00:22 â€¢ 0:00:31[0m [2;4m3.90it/s[0m  
[2Kself.avg_features.shape torch.Size([5, 768])[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 86/203 [2m0:00:22 â€¢ 0:00:30[0m [2;4m3.91it/s[0m  
[2Kindexes: 1;98;6;224mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 86/203 [2m0:00:22 â€¢ 0:00:30[0m [2;4m3.91it/s[0m  
[2Kself.avg_features.shape torch.Size([5, 768])m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 87/203 [2m0:00:22 â€¢ 0:00:30[0m [2;4m3.92it/s[0m   
[2Kindexes: 1;98;6;224mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 87/203 [2m0:00:22 â€¢ 0:00:30[0m [2;4m3.92it/s[0m  
[2Kself.avg_features.shape torch.Size([5, 768])m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 88/203 [2m0:00:23 â€¢ 0:00:30[0m [2;4m3.90it/s[0m  
[2Kindexes: 4;98;6;224mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 88/203 [2m0:00:23 â€¢ 0:00:30[0m [2;4m3.90it/s[0m  
[2Kself.avg_features.shape torch.Size([5, 768])m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 89/203 [2m0:00:23 â€¢ 0:00:30[0m [2;4m3.85it/s[0m  
[2Kindexes: 4;98;6;224mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 89/203 [2m0:00:23 â€¢ 0:00:30[0m [2;4m3.85it/s[0m  
[2Kself.avg_features.shape torch.Size([5, 768])m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 90/203 [2m0:00:24 â€¢ 0:00:30[0m [2;4m3.81it/s[0m  
[2Kindexes: 1;98;6;224mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 90/203 [2m0:00:24 â€¢ 0:00:30[0m [2;4m3.81it/s[0m  
[2Kself.avg_features.shape torch.Size([5, 768])m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 91/203 [2m0:00:24 â€¢ 0:00:30[0m [2;4m3.83it/s[0m  
[2Kindexes: 3;98;6;224mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 91/203 [2m0:00:24 â€¢ 0:00:30[0m [2;4m3.83it/s[0m  
[2Kself.avg_features.shape torch.Size([5, 768])0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 92/203 [2m0:00:24 â€¢ 0:00:29[0m [2;4m3.85it/s[0m   
[2Kindexes: 0;98;6;224mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 92/203 [2m0:00:24 â€¢ 0:00:29[0m [2;4m3.85it/s[0m  
[2Kself.avg_features.shape torch.Size([5, 768])0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 93/203 [2m0:00:24 â€¢ 0:00:29[0m [2;4m3.88it/s[0m  
[2Kindexes: 3;98;6;224mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 93/203 [2m0:00:24 â€¢ 0:00:29[0m [2;4m3.88it/s[0m  
[2Kself.avg_features.shape torch.Size([5, 768])0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 94/203 [2m0:00:24 â€¢ 0:00:28[0m [2;4m3.90it/s[0m  
[2Kindexes: 3;98;6;224mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 94/203 [2m0:00:24 â€¢ 0:00:28[0m [2;4m3.90it/s[0m  
[2Kself.avg_features.shape torch.Size([5, 768])0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 95/203 [2m0:00:24 â€¢ 0:00:28[0m [2;4m3.92it/s[0m  
[2Kindexes: 4;98;6;224mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 95/203 [2m0:00:24 â€¢ 0:00:28[0m [2;4m3.92it/s[0m  
[2Kself.avg_features.shape torch.Size([5, 768])0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 96/203 [2m0:00:25 â€¢ 0:00:28[0m [2;4m3.93it/s[0m  
[2Kindexes: 2;98;6;224mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 96/203 [2m0:00:25 â€¢ 0:00:28[0m [2;4m3.93it/s[0m  
[2Kself.avg_features.shape torch.Size([5, 768])[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 97/203 [2m0:00:25 â€¢ 0:00:27[0m [2;4m3.95it/s[0m   
[2Kindexes: 4;98;6;224mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 97/203 [2m0:00:25 â€¢ 0:00:27[0m [2;4m3.95it/s[0m  
[2Kself.avg_features.shape torch.Size([5, 768])[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 98/203 [2m0:00:25 â€¢ 0:00:27[0m [2;4m3.96it/s[0m  
[2Kindexes: 2;98;6;224mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 98/203 [2m0:00:25 â€¢ 0:00:27[0m [2;4m3.96it/s[0m  
[2Kself.avg_features.shape torch.Size([5, 768])[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 99/203 [2m0:00:25 â€¢ 0:00:27[0m [2;4m3.99it/s[0m  
[2Kindexes: 1;98;6;224mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 99/203 [2m0:00:25 â€¢ 0:00:27[0m [2;4m3.99it/s[0m  
[2Kself.avg_features.shape torch.Size([5, 768])[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 100/203 [2m0:00:25 â€¢ 0:00:26[0m [2;4m4.00it/s[0m  
[2Kindexes: 2;98;6;224mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 100/203 [2m0:00:25 â€¢ 0:00:26[0m [2;4m4.00it/s[0m  
[2Kself.avg_features.shape torch.Size([5, 768])[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 101/203 [2m0:00:25 â€¢ 0:00:26[0m [2;4m3.99it/s[0m  
[2Kindexes: 4;98;6;224mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 101/203 [2m0:00:25 â€¢ 0:00:26[0m [2;4m3.99it/s[0m  
[2Kself.avg_features.shape torch.Size([5, 768])[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 102/203 [2m0:00:26 â€¢ 0:00:26[0m [2;4m4.01it/s[0m   
[2Kindexes: 1;98;6;224mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 102/203 [2m0:00:26 â€¢ 0:00:26[0m [2;4m4.01it/s[0m  
[2Kself.avg_features.shape torch.Size([5, 768])[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 103/203 [2m0:00:26 â€¢ 0:00:25[0m [2;4m4.03it/s[0m  
[2Kindexes: 4;98;6;224mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 103/203 [2m0:00:26 â€¢ 0:00:25[0m [2;4m4.03it/s[0m  
[2Kself.avg_features.shape torch.Size([5, 768])[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 104/203 [2m0:00:26 â€¢ 0:00:25[0m [2;4m4.05it/s[0m  
[2Kindexes: 4;98;6;224mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 104/203 [2m0:00:26 â€¢ 0:00:25[0m [2;4m4.05it/s[0m  
[2Kself.avg_features.shape torch.Size([5, 768])[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 105/203 [2m0:00:26 â€¢ 0:00:25[0m [2;4m4.04it/s[0m  
[2Kindexes: 1;98;6;224mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 105/203 [2m0:00:26 â€¢ 0:00:25[0m [2;4m4.04it/s[0m  
[2Kself.avg_features.shape torch.Size([5, 768])[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 106/203 [2m0:00:26 â€¢ 0:00:25[0m [2;4m4.04it/s[0m  
[2Kindexes: 4;98;6;224mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 106/203 [2m0:00:26 â€¢ 0:00:25[0m [2;4m4.04it/s[0m  
[2Kself.avg_features.shape torch.Size([5, 768])â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 107/203 [2m0:00:27 â€¢ 0:00:24[0m [2;4m4.04it/s[0m   
[2Kindexes: 4;98;6;224mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 107/203 [2m0:00:27 â€¢ 0:00:24[0m [2;4m4.04it/s[0m  
[2Kself.avg_features.shape torch.Size([5, 768])â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 108/203 [2m0:00:27 â€¢ 0:00:24[0m [2;4m4.03it/s[0m  
[2Kindexes: 1;98;6;224mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 108/203 [2m0:00:27 â€¢ 0:00:24[0m [2;4m4.03it/s[0m  
[2Kself.avg_features.shape torch.Size([5, 768])â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 109/203 [2m0:00:27 â€¢ 0:00:24[0m [2;4m4.03it/s[0m  
[2Kindexes: 4;98;6;224mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 109/203 [2m0:00:27 â€¢ 0:00:24[0m [2;4m4.03it/s[0m  
[2Kself.avg_features.shape torch.Size([5, 768])â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 110/203 [2m0:00:27 â€¢ 0:00:24[0m [2;4m4.03it/s[0m  
[2Kindexes: 1;98;6;224mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 110/203 [2m0:00:27 â€¢ 0:00:24[0m [2;4m4.03it/s[0m  
[2Kself.avg_features.shape torch.Size([5, 768])â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 111/203 [2m0:00:28 â€¢ 0:00:23[0m [2;4m4.04it/s[0m  
[2Kindexes: 4;98;6;224mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 111/203 [2m0:00:28 â€¢ 0:00:23[0m [2;4m4.04it/s[0m  
[2Kself.avg_features.shape torch.Size([5, 768])â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 112/203 [2m0:00:28 â€¢ 0:00:23[0m [2;4m4.04it/s[0m   
[2Kindexes: 1;98;6;224mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 112/203 [2m0:00:28 â€¢ 0:00:23[0m [2;4m4.04it/s[0m  
[2Kself.avg_features.shape torch.Size([5, 768])â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 113/203 [2m0:00:28 â€¢ 0:00:23[0m [2;4m4.04it/s[0m  
[2Kindexes: 4;98;6;224mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 113/203 [2m0:00:28 â€¢ 0:00:23[0m [2;4m4.04it/s[0m  
[2Kself.avg_features.shape torch.Size([5, 768])â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 114/203 [2m0:00:29 â€¢ 0:00:23[0m [2;4m4.01it/s[0m  
[2Kindexes: 4;98;6;224mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 114/203 [2m0:00:29 â€¢ 0:00:23[0m [2;4m4.01it/s[0m  
[2Kself.avg_features.shape torch.Size([5, 768])â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 115/203 [2m0:00:30 â€¢ 0:00:23[0m [2;4m3.90it/s[0m  
[2Kindexes: 1;98;6;224mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 115/203 [2m0:00:30 â€¢ 0:00:23[0m [2;4m3.90it/s[0m  
[2Kself.avg_features.shape torch.Size([5, 768])â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 116/203 [2m0:00:30 â€¢ 0:00:23[0m [2;4m3.92it/s[0m  
[2Kindexes: 1;98;6;224mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 116/203 [2m0:00:30 â€¢ 0:00:23[0m [2;4m3.92it/s[0m  
[2Kself.avg_features.shape torch.Size([5, 768])â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 117/203 [2m0:00:30 â€¢ 0:00:22[0m [2;4m3.93it/s[0m   
[2Kindexes: 1;98;6;224mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 117/203 [2m0:00:30 â€¢ 0:00:22[0m [2;4m3.93it/s[0m  
[2Kself.avg_features.shape torch.Size([5, 768])â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 118/203 [2m0:00:30 â€¢ 0:00:22[0m [2;4m3.94it/s[0m  
[2Kindexes: 4;98;6;224mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 118/203 [2m0:00:30 â€¢ 0:00:22[0m [2;4m3.94it/s[0m  
[2Kself.avg_features.shape torch.Size([5, 768])â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 119/203 [2m0:00:30 â€¢ 0:00:22[0m [2;4m3.95it/s[0m  
[2Kindexes: 4;98;6;224mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 119/203 [2m0:00:30 â€¢ 0:00:22[0m [2;4m3.95it/s[0m  
[2Kself.avg_features.shape torch.Size([5, 768])â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 120/203 [2m0:00:31 â€¢ 0:00:22[0m [2;4m3.94it/s[0m  
[2Kindexes: 3;98;6;224mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 120/203 [2m0:00:31 â€¢ 0:00:22[0m [2;4m3.94it/s[0m  
[2Kself.avg_features.shape torch.Size([5, 768])â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 121/203 [2m0:00:31 â€¢ 0:00:21[0m [2;4m3.95it/s[0m  
[2Kindexes: 3;98;6;224mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 121/203 [2m0:00:31 â€¢ 0:00:21[0m [2;4m3.95it/s[0m  
[2Kself.avg_features.shape torch.Size([5, 768])â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 122/203 [2m0:00:31 â€¢ 0:00:21[0m [2;4m3.97it/s[0m   
[2Kindexes: 3;98;6;224mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 122/203 [2m0:00:31 â€¢ 0:00:21[0m [2;4m3.97it/s[0m  
[2Kself.avg_features.shape torch.Size([5, 768])â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 123/203 [2m0:00:31 â€¢ 0:00:20[0m [2;4m4.09it/s[0m  
[2Kindexes: 4;98;6;224mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 123/203 [2m0:00:31 â€¢ 0:00:20[0m [2;4m4.09it/s[0m  
[2Kself.avg_features.shape torch.Size([5, 768])â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 124/203 [2m0:00:31 â€¢ 0:00:20[0m [2;4m4.09it/s[0m  
[2Kindexes: 3;98;6;224mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 124/203 [2m0:00:31 â€¢ 0:00:20[0m [2;4m4.09it/s[0m  
[2Kself.avg_features.shape torch.Size([5, 768])â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 125/203 [2m0:00:31 â€¢ 0:00:20[0m [2;4m4.08it/s[0m  
[2Kindexes: 4;98;6;224mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 125/203 [2m0:00:31 â€¢ 0:00:20[0m [2;4m4.08it/s[0m  
[2Kself.avg_features.shape torch.Size([5, 768])â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 126/203 [2m0:00:32 â€¢ 0:00:19[0m [2;4m4.08it/s[0m  
[2Kindexes: 0;98;6;224mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 126/203 [2m0:00:32 â€¢ 0:00:19[0m [2;4m4.08it/s[0m  
[2Kself.avg_features.shape torch.Size([5, 768])â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 127/203 [2m0:00:32 â€¢ 0:00:19[0m [2;4m4.07it/s[0m   
[2Kindexes: 4;98;6;224mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 127/203 [2m0:00:32 â€¢ 0:00:19[0m [2;4m4.07it/s[0m  
[2Kself.avg_features.shape torch.Size([5, 768])â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 128/203 [2m0:00:32 â€¢ 0:00:19[0m [2;4m4.15it/s[0m  
[2Kindexes: 3;98;6;224mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 128/203 [2m0:00:32 â€¢ 0:00:19[0m [2;4m4.15it/s[0m  
[2Kself.avg_features.shape torch.Size([5, 768])â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 129/203 [2m0:00:32 â€¢ 0:00:18[0m [2;4m4.15it/s[0m  
[2Kindexes: 4;98;6;224mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 129/203 [2m0:00:32 â€¢ 0:00:18[0m [2;4m4.15it/s[0m  
[2Kself.avg_features.shape torch.Size([5, 768])â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 130/203 [2m0:00:33 â€¢ 0:00:18[0m [2;4m4.15it/s[0m  
[2Kindexes: 2;98;6;224mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 130/203 [2m0:00:33 â€¢ 0:00:18[0m [2;4m4.15it/s[0m  
[2Kself.avg_features.shape torch.Size([5, 768])â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 131/203 [2m0:00:33 â€¢ 0:00:18[0m [2;4m4.15it/s[0m  
[2Kindexes: 1;98;6;224mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 131/203 [2m0:00:33 â€¢ 0:00:18[0m [2;4m4.15it/s[0m  
[2Kself.avg_features.shape torch.Size([5, 768])â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m 132/203 [2m0:00:33 â€¢ 0:00:18[0m [2;4m4.16it/s[0m   
[2Kindexes: 4;98;6;224mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m 132/203 [2m0:00:33 â€¢ 0:00:18[0m [2;4m4.16it/s[0m  
[2Kself.avg_features.shape torch.Size([5, 768])â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m 133/203 [2m0:00:33 â€¢ 0:00:17[0m [2;4m4.15it/s[0m  
[2Kindexes: 4;98;6;224mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m 133/203 [2m0:00:33 â€¢ 0:00:17[0m [2;4m4.15it/s[0m  
[2Kself.avg_features.shape torch.Size([5, 768])â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m 134/203 [2m0:00:34 â€¢ 0:00:17[0m [2;4m4.11it/s[0m  
[2Kindexes: 4;98;6;224mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m 134/203 [2m0:00:34 â€¢ 0:00:17[0m [2;4m4.11it/s[0m  
[2Kself.avg_features.shape torch.Size([5, 768])â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m 135/203 [2m0:00:34 â€¢ 0:00:17[0m [2;4m4.10it/s[0m  
[2Kindexes: 1;98;6;224mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m 135/203 [2m0:00:34 â€¢ 0:00:17[0m [2;4m4.10it/s[0m  
[2Kself.avg_features.shape torch.Size([5, 768])â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m 136/203 [2m0:00:34 â€¢ 0:00:17[0m [2;4m4.05it/s[0m  
[2Kindexes: 4;98;6;224mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m 136/203 [2m0:00:34 â€¢ 0:00:17[0m [2;4m4.05it/s[0m  
[2Kself.avg_features.shape torch.Size([5, 768])â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m 137/203 [2m0:00:35 â€¢ 0:00:17[0m [2;4m4.02it/s[0m  
[2Kindexes: 3;98;6;224mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m 137/203 [2m0:00:35 â€¢ 0:00:17[0m [2;4m4.02it/s[0m  
[2Kself.avg_features.shape torch.Size([5, 768])â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”[0m 138/203 [2m0:00:35 â€¢ 0:00:17[0m [2;4m4.02it/s[0m   
[2Kindexes: 4;98;6;224mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”[0m 138/203 [2m0:00:35 â€¢ 0:00:17[0m [2;4m4.02it/s[0m  
[2Kself.avg_features.shape torch.Size([5, 768])â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”[0m 139/203 [2m0:00:35 â€¢ 0:00:16[0m [2;4m4.00it/s[0m  
[2Kindexes: 2;98;6;224mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”[0m 139/203 [2m0:00:35 â€¢ 0:00:16[0m [2;4m4.00it/s[0m  
[2Kself.avg_features.shape torch.Size([5, 768])â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”[0m 140/203 [2m0:00:35 â€¢ 0:00:16[0m [2;4m4.01it/s[0m  
[2Kindexes: 1;98;6;224mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”[0m 140/203 [2m0:00:35 â€¢ 0:00:16[0m [2;4m4.01it/s[0m  
[2Kself.avg_features.shape torch.Size([5, 768])â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”[0m 141/203 [2m0:00:35 â€¢ 0:00:16[0m [2;4m4.02it/s[0m  
[2Kindexes: 4;98;6;224mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”[0m 141/203 [2m0:00:35 â€¢ 0:00:16[0m [2;4m4.02it/s[0m  
[2Kself.avg_features.shape torch.Size([5, 768])â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”[0m 142/203 [2m0:00:36 â€¢ 0:00:16[0m [2;4m4.04it/s[0m  
[2Kindexes: 1;98;6;224mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”[0m 142/203 [2m0:00:36 â€¢ 0:00:16[0m [2;4m4.04it/s[0m  
[2Kself.avg_features.shape torch.Size([5, 768])â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”[0m 143/203 [2m0:00:36 â€¢ 0:00:15[0m [2;4m4.01it/s[0m   
[2Kindexes: 1;98;6;224mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”[0m 143/203 [2m0:00:36 â€¢ 0:00:15[0m [2;4m4.01it/s[0m  
[2Kself.avg_features.shape torch.Size([5, 768])â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”[0m 144/203 [2m0:00:36 â€¢ 0:00:15[0m [2;4m3.98it/s[0m  
[2Kindexes: 2;98;6;224mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”[0m 144/203 [2m0:00:36 â€¢ 0:00:15[0m [2;4m3.98it/s[0m  
[2Kself.avg_features.shape torch.Size([5, 768])â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”[0m 145/203 [2m0:00:37 â€¢ 0:00:15[0m [2;4m3.93it/s[0m  
[2Kindexes: 4;98;6;224mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”[0m 145/203 [2m0:00:37 â€¢ 0:00:15[0m [2;4m3.93it/s[0m  
[2Kself.avg_features.shape torch.Size([5, 768])â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”[0m 146/203 [2m0:00:37 â€¢ 0:00:15[0m [2;4m3.95it/s[0m  
[2Kindexes: 1;98;6;224mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”[0m 146/203 [2m0:00:37 â€¢ 0:00:15[0m [2;4m3.95it/s[0m  
[2Kself.avg_features.shape torch.Size([5, 768])â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”[0m 147/203 [2m0:00:38 â€¢ 0:00:15[0m [2;4m3.95it/s[0m  
[2Kindexes: 4;98;6;224mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”[0m 147/203 [2m0:00:38 â€¢ 0:00:15[0m [2;4m3.95it/s[0m  
[2Kself.avg_features.shape torch.Size([5, 768])â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”[0m 148/203 [2m0:00:38 â€¢ 0:00:14[0m [2;4m3.95it/s[0m   
[2Kindexes: 3;98;6;224mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”[0m 148/203 [2m0:00:38 â€¢ 0:00:14[0m [2;4m3.95it/s[0m  
[2Kself.avg_features.shape torch.Size([5, 768])â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”[0m 149/203 [2m0:00:38 â€¢ 0:00:14[0m [2;4m3.94it/s[0m  
[2Kindexes: 4;98;6;224mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”[0m 149/203 [2m0:00:38 â€¢ 0:00:14[0m [2;4m3.94it/s[0m  
[2Kself.avg_features.shape torch.Size([5, 768])â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”[0m 150/203 [2m0:00:38 â€¢ 0:00:14[0m [2;4m3.94it/s[0m  
[2Kindexes: 0;98;6;224mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”[0m 150/203 [2m0:00:38 â€¢ 0:00:14[0m [2;4m3.94it/s[0m  
[2Kself.avg_features.shape torch.Size([5, 768])â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”[0m 151/203 [2m0:00:39 â€¢ 0:00:14[0m [2;4m3.95it/s[0m  
[2Kindexes: 0;98;6;224mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”[0m 151/203 [2m0:00:39 â€¢ 0:00:14[0m [2;4m3.95it/s[0m  
[2Kself.avg_features.shape torch.Size([5, 768])â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”[0m 152/203 [2m0:00:39 â€¢ 0:00:13[0m [2;4m3.95it/s[0m  
[2Kindexes: 2;98;6;224mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”[0m 152/203 [2m0:00:39 â€¢ 0:00:13[0m [2;4m3.95it/s[0m  
[2Kself.avg_features.shape torch.Size([5, 768])â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”[0m 153/203 [2m0:00:40 â€¢ 0:00:14[0m [2;4m3.76it/s[0m   
[2Kindexes: 4;98;6;224mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”[0m 153/203 [2m0:00:40 â€¢ 0:00:14[0m [2;4m3.76it/s[0m  
[2Kself.avg_features.shape torch.Size([5, 768])â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”[0m 154/203 [2m0:00:41 â€¢ 0:00:14[0m [2;4m3.76it/s[0m  
[2Kindexes: 4;98;6;224mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”[0m 154/203 [2m0:00:41 â€¢ 0:00:14[0m [2;4m3.76it/s[0m  
[2Kself.avg_features.shape torch.Size([5, 768])â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”[0m 155/203 [2m0:00:41 â€¢ 0:00:13[0m [2;4m3.74it/s[0m  
[2Kindexes: 4;98;6;224mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”[0m 155/203 [2m0:00:41 â€¢ 0:00:13[0m [2;4m3.74it/s[0m  
[2Kself.avg_features.shape torch.Size([5, 768])â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”[0m 156/203 [2m0:00:41 â€¢ 0:00:13[0m [2;4m3.73it/s[0m  
[2Kindexes: 1;98;6;224mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”[0m 156/203 [2m0:00:41 â€¢ 0:00:13[0m [2;4m3.73it/s[0m  
[2Kself.avg_features.shape torch.Size([5, 768])â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”[0m 157/203 [2m0:00:42 â€¢ 0:00:13[0m [2;4m3.71it/s[0m  
[2Kindexes: 0;98;6;224mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”[0m 157/203 [2m0:00:42 â€¢ 0:00:13[0m [2;4m3.71it/s[0m  
[2Kself.avg_features.shape torch.Size([5, 768])â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”[0m 158/203 [2m0:00:42 â€¢ 0:00:13[0m [2;4m3.71it/s[0m   
[2Kindexes: 0;98;6;224mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”[0m 158/203 [2m0:00:42 â€¢ 0:00:13[0m [2;4m3.71it/s[0m  
[2Kself.avg_features.shape torch.Size([5, 768])â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”[0m 159/203 [2m0:00:42 â€¢ 0:00:12[0m [2;4m3.77it/s[0m  
[2Kindexes: 3;98;6;224mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”[0m 159/203 [2m0:00:42 â€¢ 0:00:12[0m [2;4m3.77it/s[0m  
[2Kself.avg_features.shape torch.Size([5, 768])â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”[0m 160/203 [2m0:00:42 â€¢ 0:00:12[0m [2;4m3.79it/s[0m  
[2Kindexes: 4;98;6;224mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”[0m 160/203 [2m0:00:42 â€¢ 0:00:12[0m [2;4m3.79it/s[0m  
[2Kself.avg_features.shape torch.Size([5, 768])â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”[0m 161/203 [2m0:00:43 â€¢ 0:00:12[0m [2;4m3.80it/s[0m  
[2Kindexes: 4;98;6;224mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”[0m 161/203 [2m0:00:43 â€¢ 0:00:12[0m [2;4m3.80it/s[0m  
[2Kself.avg_features.shape torch.Size([5, 768])â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”[0m 162/203 [2m0:00:43 â€¢ 0:00:11[0m [2;4m3.81it/s[0m  
[2Kindexes: 2;98;6;224mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”[0m 162/203 [2m0:00:43 â€¢ 0:00:11[0m [2;4m3.81it/s[0m  
[2Kself.avg_features.shape torch.Size([5, 768])â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”[0m 163/203 [2m0:00:43 â€¢ 0:00:11[0m [2;4m3.76it/s[0m   
[2Kindexes: 0;98;6;224mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”[0m 163/203 [2m0:00:43 â€¢ 0:00:11[0m [2;4m3.76it/s[0m  
[2Kself.avg_features.shape torch.Size([5, 768])â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”[0m 164/203 [2m0:00:43 â€¢ 0:00:11[0m [2;4m3.77it/s[0m  
[2Kindexes: 4;98;6;224mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”[0m 164/203 [2m0:00:43 â€¢ 0:00:11[0m [2;4m3.77it/s[0m  
[2Kself.avg_features.shape torch.Size([5, 768])â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”[0m 165/203 [2m0:00:44 â€¢ 0:00:11[0m [2;4m3.73it/s[0m  
[2Kindexes: 4;98;6;224mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”[0m 165/203 [2m0:00:44 â€¢ 0:00:11[0m [2;4m3.73it/s[0m  
[2Kself.avg_features.shape torch.Size([5, 768])â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”[0m 166/203 [2m0:00:44 â€¢ 0:00:10[0m [2;4m3.74it/s[0m  
[2Kindexes: 4;98;6;224mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”[0m 166/203 [2m0:00:44 â€¢ 0:00:10[0m [2;4m3.74it/s[0m  
[2Kself.avg_features.shape torch.Size([5, 768])â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”[0m 167/203 [2m0:00:44 â€¢ 0:00:10[0m [2;4m3.75it/s[0m  
[2Kindexes: 0;98;6;224mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”[0m 167/203 [2m0:00:44 â€¢ 0:00:10[0m [2;4m3.75it/s[0m  
[2Kself.avg_features.shape torch.Size([5, 768])â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”[0m 168/203 [2m0:00:44 â€¢ 0:00:10[0m [2;4m3.74it/s[0m   
[2Kindexes: 3;98;6;224mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”[0m 168/203 [2m0:00:44 â€¢ 0:00:10[0m [2;4m3.74it/s[0m  
[2Kself.avg_features.shape torch.Size([5, 768])â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”[0m 169/203 [2m0:00:44 â€¢ 0:00:10[0m [2;4m3.73it/s[0m  
[2Kindexes: 4;98;6;224mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”[0m 169/203 [2m0:00:44 â€¢ 0:00:10[0m [2;4m3.73it/s[0m  
[2Kself.avg_features.shape torch.Size([5, 768])â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”[0m 170/203 [2m0:00:45 â€¢ 0:00:09[0m [2;4m3.72it/s[0m  
[2Kindexes: 1;98;6;224mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”[0m 170/203 [2m0:00:45 â€¢ 0:00:09[0m [2;4m3.72it/s[0m  
[2Kself.avg_features.shape torch.Size([5, 768])â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”[0m 171/203 [2m0:00:45 â€¢ 0:00:09[0m [2;4m3.68it/s[0m  
[2Kindexes: 0;98;6;224mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”[0m 171/203 [2m0:00:45 â€¢ 0:00:09[0m [2;4m3.68it/s[0m  
[2Kself.avg_features.shape torch.Size([5, 768])â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”[0m 172/203 [2m0:00:45 â€¢ 0:00:09[0m [2;4m3.68it/s[0m  
[2Kindexes: 2;98;6;224mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”[0m 172/203 [2m0:00:45 â€¢ 0:00:09[0m [2;4m3.68it/s[0m  
[2Kself.avg_features.shape torch.Size([5, 768])â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”[0m 173/203 [2m0:00:46 â€¢ 0:00:09[0m [2;4m3.67it/s[0m   
[2Kindexes: 1;98;6;224mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”[0m 173/203 [2m0:00:46 â€¢ 0:00:09[0m [2;4m3.67it/s[0m  
[2Kself.avg_features.shape torch.Size([5, 768])â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”[0m 174/203 [2m0:00:46 â€¢ 0:00:08[0m [2;4m3.69it/s[0m  
[2Kindexes: 4;98;6;224mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”[0m 174/203 [2m0:00:46 â€¢ 0:00:08[0m [2;4m3.69it/s[0m  
[2Kself.avg_features.shape torch.Size([5, 768])â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”[0m 175/203 [2m0:00:46 â€¢ 0:00:08[0m [2;4m3.69it/s[0m  
[2Kindexes: 4;98;6;224mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”[0m 175/203 [2m0:00:46 â€¢ 0:00:08[0m [2;4m3.69it/s[0m  
[2Kself.avg_features.shape torch.Size([5, 768])â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”[0m 176/203 [2m0:00:47 â€¢ 0:00:08[0m [2;4m3.70it/s[0m  
[2Kindexes: 0;98;6;224mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”[0m 176/203 [2m0:00:47 â€¢ 0:00:08[0m [2;4m3.70it/s[0m  
[2Kself.avg_features.shape torch.Size([5, 768])â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”[0m 177/203 [2m0:00:47 â€¢ 0:00:07[0m [2;4m3.79it/s[0m  
[2Kindexes: 2;98;6;224mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”[0m 177/203 [2m0:00:47 â€¢ 0:00:07[0m [2;4m3.79it/s[0m  
[2Kself.avg_features.shape torch.Size([5, 768])â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”[0m 178/203 [2m0:00:47 â€¢ 0:00:07[0m [2;4m3.79it/s[0m   
[2Kindexes: 4;98;6;224mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”[0m 178/203 [2m0:00:47 â€¢ 0:00:07[0m [2;4m3.79it/s[0m  
[2Kself.avg_features.shape torch.Size([5, 768])â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”[0m 179/203 [2m0:00:48 â€¢ 0:00:07[0m [2;4m3.64it/s[0m  
[2Kindexes: 2;98;6;224mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”[0m 179/203 [2m0:00:48 â€¢ 0:00:07[0m [2;4m3.64it/s[0m  
[2Kself.avg_features.shape torch.Size([5, 768])â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”[0m 180/203 [2m0:00:49 â€¢ 0:00:07[0m [2;4m3.62it/s[0m  
[2Kindexes: 1;98;6;224mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”[0m 180/203 [2m0:00:49 â€¢ 0:00:07[0m [2;4m3.62it/s[0m  
[2Kself.avg_features.shape torch.Size([5, 768])â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”[0m 181/203 [2m0:00:49 â€¢ 0:00:07[0m [2;4m3.66it/s[0m  
[2Kindexes: 4;98;6;224mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”[0m 181/203 [2m0:00:49 â€¢ 0:00:07[0m [2;4m3.66it/s[0m  
[2Kself.avg_features.shape torch.Size([5, 768])â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”[0m 182/203 [2m0:00:50 â€¢ 0:00:06[0m [2;4m3.66it/s[0m  
[2Kindexes: 4;98;6;224mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”[0m 182/203 [2m0:00:50 â€¢ 0:00:06[0m [2;4m3.66it/s[0m  
[2Kself.avg_features.shape torch.Size([5, 768])â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”[0m 183/203 [2m0:00:50 â€¢ 0:00:06[0m [2;4m3.67it/s[0m   
[2Kindexes: 0;98;6;224mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”[0m 183/203 [2m0:00:50 â€¢ 0:00:06[0m [2;4m3.67it/s[0m  
[2Kself.avg_features.shape torch.Size([5, 768])â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”[0m 184/203 [2m0:00:50 â€¢ 0:00:06[0m [2;4m3.65it/s[0m  
[2Kindexes: 3;98;6;224mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”[0m 184/203 [2m0:00:50 â€¢ 0:00:06[0m [2;4m3.65it/s[0m  
[2Kself.avg_features.shape torch.Size([5, 768])â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”[0m 185/203 [2m0:00:50 â€¢ 0:00:05[0m [2;4m3.65it/s[0m  
[2Kindexes: 4;98;6;224mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”[0m 185/203 [2m0:00:50 â€¢ 0:00:05[0m [2;4m3.65it/s[0m  
[2Kself.avg_features.shape torch.Size([5, 768])â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”[0m 186/203 [2m0:00:50 â€¢ 0:00:05[0m [2;4m3.64it/s[0m  
[2Kindexes: 3;98;6;224mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”[0m 186/203 [2m0:00:50 â€¢ 0:00:05[0m [2;4m3.64it/s[0m  
[2Kself.avg_features.shape torch.Size([5, 768])â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”[0m 187/203 [2m0:00:51 â€¢ 0:00:05[0m [2;4m3.64it/s[0m  
[2Kindexes: 1;98;6;224mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”[0m 187/203 [2m0:00:51 â€¢ 0:00:05[0m [2;4m3.64it/s[0m  
[2Kself.avg_features.shape torch.Size([5, 768])â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”[0m 188/203 [2m0:00:51 â€¢ 0:00:05[0m [2;4m3.68it/s[0m   
[2Kindexes: 4;98;6;224mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”[0m 188/203 [2m0:00:51 â€¢ 0:00:05[0m [2;4m3.68it/s[0m  
[2Kself.avg_features.shape torch.Size([5, 768])â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”[0m 189/203 [2m0:00:51 â€¢ 0:00:04[0m [2;4m3.69it/s[0m  
[2Kindexes: 4;98;6;224mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”[0m 189/203 [2m0:00:51 â€¢ 0:00:04[0m [2;4m3.69it/s[0m  
[2Kself.avg_features.shape torch.Size([5, 768])â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”[0m 190/203 [2m0:00:51 â€¢ 0:00:04[0m [2;4m3.70it/s[0m  
[2Kindexes: 2;98;6;224mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”[0m 190/203 [2m0:00:51 â€¢ 0:00:04[0m [2;4m3.70it/s[0m  
[2Kself.avg_features.shape torch.Size([5, 768])â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”[0m 191/203 [2m0:00:52 â€¢ 0:00:04[0m [2;4m3.48it/s[0m  
[2Kindexes: 1;98;6;224mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”[0m 191/203 [2m0:00:52 â€¢ 0:00:04[0m [2;4m3.48it/s[0m  
[2Kself.avg_features.shape torch.Size([5, 768])â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”[0m 192/203 [2m0:00:52 â€¢ 0:00:04[0m [2;4m3.50it/s[0m  
[2Kindexes: 1;98;6;224mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”[0m 192/203 [2m0:00:52 â€¢ 0:00:04[0m [2;4m3.50it/s[0m  
[2Kself.avg_features.shape torch.Size([5, 768])â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”[0m 193/203 [2m0:00:53 â€¢ 0:00:03[0m [2;4m3.51it/s[0m   
[2Kindexes: 0;98;6;224mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”[0m 193/203 [2m0:00:53 â€¢ 0:00:03[0m [2;4m3.51it/s[0m  
[2Kself.avg_features.shape torch.Size([5, 768])â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”[0m 194/203 [2m0:00:53 â€¢ 0:00:03[0m [2;4m3.56it/s[0m  
[2Kindexes: 4;98;6;224mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”[0m 194/203 [2m0:00:53 â€¢ 0:00:03[0m [2;4m3.56it/s[0m  
[2Kself.avg_features.shape torch.Size([5, 768])â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”[0m 195/203 [2m0:00:53 â€¢ 0:00:03[0m [2;4m3.52it/s[0m  
[2Kindexes: 4;98;6;224mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”[0m 195/203 [2m0:00:53 â€¢ 0:00:03[0m [2;4m3.52it/s[0m  
[2Kself.avg_features.shape torch.Size([5, 768])â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”[0m 196/203 [2m0:00:54 â€¢ 0:00:03[0m [2;4m3.47it/s[0m  
[2Kindexes: 4;98;6;224mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”[0m 196/203 [2m0:00:54 â€¢ 0:00:03[0m [2;4m3.47it/s[0m  
[2Kself.avg_features.shape torch.Size([5, 768])â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”[0m 197/203 [2m0:00:54 â€¢ 0:00:02[0m [2;4m3.44it/s[0m  
[2Kindexes: 4;98;6;224mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”[0m 197/203 [2m0:00:54 â€¢ 0:00:02[0m [2;4m3.44it/s[0m  
[2Kself.avg_features.shape torch.Size([5, 768])â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m 198/203 [2m0:00:54 â€¢ 0:00:02[0m [2;4m3.41it/s[0m  4m3.44it/s[0m  
[2Kindexes: 3;98;6;224mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m 198/203 [2m0:00:54 â€¢ 0:00:02[0m [2;4m3.41it/s[0m  
[2Kself.avg_features.shape torch.Size([5, 768])â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m 199/203 [2m0:00:55 â€¢ 0:00:02[0m [2;4m3.40it/s[0m  
[2Kindexes: 2;98;6;224mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m 199/203 [2m0:00:55 â€¢ 0:00:02[0m [2;4m3.40it/s[0m  
[2Kself.avg_features.shape torch.Size([5, 768])â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m 200/203 [2m0:00:56 â€¢ 0:00:01[0m [2;4m3.20it/s[0m  
[2Kindexes: 1;98;6;224mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m 200/203 [2m0:00:56 â€¢ 0:00:01[0m [2;4m3.20it/s[0m  
[2Kself.avg_features.shape torch.Size([5, 768])â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m 201/203 [2m0:00:56 â€¢ 0:00:01[0m [2;4m3.23it/s[0m  
[2Kindexes: 1;98;6;224mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m 201/203 [2m0:00:56 â€¢ 0:00:01[0m [2;4m3.23it/s[0m  
[2Kself.avg_features.shape torch.Size([5, 768])â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m 202/203 [2m0:00:56 â€¢ 0:00:01[0m [2;4m3.24it/s[0m  
[2Kindexes: 4;98;6;224mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m 202/203 [2m0:00:56 â€¢ 0:00:01[0m [2;4m3.24it/s[0m  
[2K                   video-id  t-start  t-end      labelâ”â”â”â”â”â”â”â”â”â”[0m 203/203 [2m0:00:56 â€¢ 0:00:00[0m [2;4m3.21it/s[0m  4m3.24it/s[0m  
0  video_validation_0000664     20.4   29.9  PoleVault
1  video_validation_0000664     33.8   37.8  PoleVault
2  video_validation_0000664     43.5   49.2  PoleVault
3  video_validation_0000664     53.0   59.3  PoleVault
[2K4  video_validation_0000664     63.9   68.6  PoleVaultâ”â”â”â”â”â”[0m 203/203 [2m0:00:56 â€¢ 0:00:00[0m [2;4m3.21it/s[0m  
[2K                   video-id    t-start      t-end       score      label [2m0:00:56 â€¢ 0:00:00[0m [2;4m3.21it/s[0m  
0  video_validation_0000365  19.833333  21.100000  0.08444041  PoleVault
1  video_validation_0000365  21.833333  28.700000   0.4928759  PoleVault
2  video_validation_0000365  30.333333  36.766667  0.67282814  PoleVault
3  video_validation_0000365  37.500000  37.866667  0.13837384  PoleVault
[2K4  video_validation_0000365  39.733333  40.100000  0.08027762  PoleVault [2m0:00:56 â€¢ 0:00:00[0m [2;4m3.21it/s[0m  
[2KGround truth labels:  ['PoleVault' 'HammerThrow' 'BaseballPitch' 'ThrowDiscus' 'SoccerPenalty'][0m [2;4m3.21it/s[0m  
[2KPredicted labels:  ['PoleVault' 'HammerThrow' 'ThrowDiscus' 'BaseballPitch' 'SoccerPenalty']00[0m [2;4m3.21it/s[0m  
[2King [38;2;98;6;224mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 203/203 [2m0:00:56 â€¢ 0:00:00[0m [2;4m3.21it/s[0m  
[2King [38;2;98;6;224mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 203/203 [2m0:00:56 â€¢ 0:00:00[0m [2;4m3.21it/s[0m  
[2KBaseballPitch [7.6, 4.3, 1.3, 0.8, 0.4]â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 203/203 [2m0:00:56 â€¢ 0:00:00[0m [2;4m3.21it/s[0m  
[2King [38;2;98;6;224mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 203/203 [2m0:00:56 â€¢ 0:00:00[0m [2;4m3.21it/s[0m  
[2King [38;2;98;6;224mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 203/203 [2m0:00:56 â€¢ 0:00:00[0m [2;4m3.21it/s[0m  
[2KHammerThrow [6.8, 4.4, 2.4, 1.6, 0.9]â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 203/203 [2m0:00:56 â€¢ 0:00:00[0m [2;4m3.21it/s[0m  
[2King [38;2;98;6;224mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 203/203 [2m0:00:56 â€¢ 0:00:00[0m [2;4m3.21it/s[0m  
[2King [38;2;98;6;224mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 203/203 [2m0:00:56 â€¢ 0:00:00[0m [2;4m3.21it/s[0m  
[2KPoleVault [29.6, 22.0, 13.9, 10.0, 5.7]â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 203/203 [2m0:00:56 â€¢ 0:00:00[0m [2;4m3.21it/s[0m  
[2King [38;2;98;6;224mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 203/203 [2m0:00:56 â€¢ 0:00:00[0m [2;4m3.21it/s[0m  
[2King [38;2;98;6;224mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 203/203 [2m0:00:56 â€¢ 0:00:00[0m [2;4m3.21it/s[0m  
[2KSoccerPenalty [18.7, 10.1, 4.4, 1.7, 0.5]â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 203/203 [2m0:00:56 â€¢ 0:00:00[0m [2;4m3.21it/s[0m  
[2King [38;2;98;6;224mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 203/203 [2m0:00:56 â€¢ 0:00:00[0m [2;4m3.21it/s[0m  
[2King [38;2;98;6;224mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 203/203 [2m0:00:56 â€¢ 0:00:00[0m [2;4m3.21it/s[0m  
[2KThrowDiscus [2.1, 1.5, 0.7, 0.5, 0.3]â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 203/203 [2m0:00:56 â€¢ 0:00:00[0m [2;4m3.21it/s[0m  
[2King [38;2;98;6;224mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 203/203 [2m0:00:56 â€¢ 0:00:00[0m [2;4m3.21it/s[0m  
[2King [38;2;98;6;224mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 203/203 [2m0:00:56 â€¢ 0:00:00[0m [2;4m3.21it/s[0m  
[2K\begin{tabular}{lrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr}
\hline
 Class         &     AP@0% &   AP@0% &   AP@0% &   AP@0% &   AP@0% \\
\hline
 BaseballPitch &  7.6      &     4.3 &     1.3 &     0.8 &     0.4 \\
 HammerThrow   &  6.8      &     4.4 &     2.4 &     1.6 &     0.9 \\
 PoleVault     & 29.6      &    22   &    13.9 &    10   &     5.7 \\
 SoccerPenalty & 18.7      &    10.1 &     4.4 &     1.7 &     0.5 \\
 ThrowDiscus   &  2.1      &     1.5 &     0.7 &     0.5 &     0.3 \\
 IoU           &  0.206381 &     0   &     0   &     0   &     0   \\
\hline
[2K\end{tabular};6;224mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 203/203 [2m0:00:56 â€¢ 0:00:00[0m [2;4m3.21it/s[0m  
[2K[12.96  8.46  4.54  2.92  1.56]â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 203/203 [2m0:00:56 â€¢ 0:00:00[0m [2;4m3.21it/s[0m  
[2KAverage TIOU:  0.006144053773369846â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 203/203 [2m0:00:56 â€¢ 0:00:00[0m [2;4m3.21it/s[0m  
[2Kpreds: [tensor([2.3815, 2.8015, 2.8031, 2.4195, 2.6857], device='cuda:0'), tensor([1.9312, 2.5343, 2.4210, 2.0713, 2.2920], device='cuda:0'), tensor([2.3682, 2.3451, 2.1229, 2.0196, 2.4155], device='cuda:0'), tensor([2.1864, 2.7121, 2.6312, 2.3602, 2.5662],
device='cuda:0'), tensor([2.5312, 2.4820, 2.2702, 1.9934, 2.4629], device='cuda:0'), tensor([2.5955, 3.0058, 2.6725, 2.4679, 3.0351], device='cuda:0'), tensor([2.7590, 2.9386, 2.6672, 2.1758, 2.8924], device='cuda:0'), tensor([2.1622, 2.3014, 2.2395, 2.2510, 2.3975],
device='cuda:0'), tensor([2.7900, 2.4720, 2.2862, 2.3428, 2.4991], device='cuda:0'), tensor([2.7579, 2.6321, 2.4103, 2.3087, 2.6571], device='cuda:0'), tensor([2.4536, 2.6209, 2.4577, 2.3296, 2.7144], device='cuda:0'), tensor([2.6868, 3.0140, 2.7946, 2.6318, 2.9391],
device='cuda:0'), tensor([2.0459, 2.5574, 2.3004, 2.1253, 2.5564], device='cuda:0'), tensor([2.5495, 2.3820, 2.3520, 2.2204, 2.3905], device='cuda:0'), tensor([2.4711, 2.4243, 2.2540, 1.9478, 2.5437], device='cuda:0'), tensor([2.0872, 2.4682, 2.5813, 2.2016, 2.4621],
device='cuda:0'), tensor([2.5568, 2.8127, 2.7882, 2.3552, 2.9610], device='cuda:0'), tensor([2.3893, 2.4034, 2.0642, 2.0268, 2.4333], device='cuda:0'), tensor([2.7009, 2.9370, 2.6451, 2.3073, 3.0410], device='cuda:0'), tensor([2.3380, 2.4703, 2.3830, 2.7267, 2.5427],
device='cuda:0'), tensor([2.3405, 2.6680, 2.6741, 2.1855, 2.6308], device='cuda:0'), tensor([2.6730, 2.4746, 2.2668, 1.9455, 2.5518], device='cuda:0'), tensor([1.6941, 2.2909, 2.0258, 1.8285, 2.1078], device='cuda:0'), tensor([2.2399, 2.3890, 1.9515, 2.0633, 2.3861],
device='cuda:0'), tensor([1.8077, 1.7545, 1.7860, 1.7448, 1.8419], device='cuda:0'), tensor([2.5748, 2.5382, 2.3837, 2.1700, 2.6030], device='cuda:0'), tensor([2.1139, 2.3434, 2.3350, 2.2167, 2.3550], device='cuda:0'), tensor([2.1702, 2.0598, 1.9221, 1.7995, 2.0702],
device='cuda:0'), tensor([1.9280, 2.4643, 2.4169, 2.0210, 2.3283], device='cuda:0'), tensor([1.9635, 1.9758, 1.9105, 1.7067, 2.0845], device='cuda:0'), tensor([2.3562, 2.6666, 2.3253, 1.9551, 2.6938], device='cuda:0'), tensor([2.0527, 2.3813, 2.2884, 1.7609, 2.3653],
device='cuda:0'), tensor([2.3532, 2.4856, 2.1194, 2.1718, 2.5521], device='cuda:0'), tensor([2.1724, 2.5382, 2.3974, 1.9834, 2.6228], device='cuda:0'), tensor([2.5790, 2.9515, 2.8941, 2.6768, 2.8474], device='cuda:0'), tensor([1.9339, 2.0697, 1.9534, 1.7183, 2.1663],
device='cuda:0'), tensor([2.2984, 2.5449, 2.2910, 2.2304, 2.6214], device='cuda:0'), tensor([2.2410, 2.2418, 2.5593, 2.3460, 2.2551], device='cuda:0'), tensor([2.2312, 2.4489, 2.5724, 2.1905, 2.6500], device='cuda:0'), tensor([2.4678, 2.4992, 2.0851, 2.0856, 2.6287],
device='cuda:0'), tensor([2.0222, 2.3991, 2.7162, 2.0411, 2.3444], device='cuda:0'), tensor([2.4856, 2.9276, 2.7705, 2.5634, 2.9169], device='cuda:0'), tensor([2.2346, 2.6046, 2.4031, 2.0437, 2.6984], device='cuda:0'), tensor([2.4345, 2.7430, 2.4984, 1.9854, 2.7755],
device='cuda:0'), tensor([2.3083, 2.8124, 2.7364, 2.5206, 2.7078], device='cuda:0'), tensor([2.1880, 2.1097, 1.8504, 1.7739, 2.1176], device='cuda:0'), tensor([2.4745, 2.5098, 2.3042, 2.1658, 2.5694], device='cuda:0'), tensor([2.4752, 2.8170, 2.8393, 2.4772, 2.9218],
device='cuda:0'), tensor([2.4339, 2.5154, 2.3038, 2.2021, 2.5951], device='cuda:0'), tensor([1.9957, 2.3727, 2.3217, 1.7117, 2.3268], device='cuda:0'), tensor([2.7976, 2.7961, 2.8757, 2.7953, 2.9304], device='cuda:0'), tensor([2.6286, 2.5342, 2.2817, 2.2576, 2.4734],
device='cuda:0'), tensor([2.2986, 2.6710, 2.5573, 2.1692, 2.6959], device='cuda:0'), tensor([1.9517, 1.9559, 1.9385, 1.8169, 2.0643], device='cuda:0'), tensor([2.5229, 2.6666, 2.5897, 3.0885, 2.7071], device='cuda:0'), tensor([2.6543, 2.8753, 2.8511, 2.6532, 2.9494],
device='cuda:0'), tensor([2.3796, 2.7146, 2.6959, 2.4654, 2.5863], device='cuda:0'), tensor([2.4181, 2.7833, 2.8059, 2.4045, 2.9318], device='cuda:0'), tensor([2.1212, 2.1534, 2.0714, 2.0764, 2.2501], device='cuda:0'), tensor([1.8986, 1.8199, 1.7756, 1.6022, 1.9233],
device='cuda:0'), tensor([2.0243, 2.5092, 2.3893, 2.1591, 2.4438], device='cuda:0'), tensor([1.9041, 1.8933, 1.8463, 1.7247, 1.9780], device='cuda:0'), tensor([2.1682, 2.1880, 2.1771, 2.1045, 2.3424], device='cuda:0'), tensor([2.0514, 2.5084, 2.2533, 1.8468, 2.4580],
device='cuda:0'), tensor([2.8619, 2.5362, 2.3638, 2.3200, 2.6225], device='cuda:0'), tensor([2.7192, 2.4395, 2.1734, 2.2619, 2.3759], device='cuda:0'), tensor([2.0814, 2.2062, 2.0771, 2.8011, 2.2096], device='cuda:0'), tensor([2.2694, 2.7850, 2.7080, 2.3908, 2.6035],
device='cuda:0'), tensor([2.3359, 2.5691, 2.2156, 2.2382, 2.6200], device='cuda:0'), tensor([1.5273, 1.8163, 1.8036, 1.6237, 1.8271], device='cuda:0'), tensor([2.6471, 2.9274, 2.8660, 2.6014, 2.9493], device='cuda:0'), tensor([2.3969, 2.8024, 2.9281, 2.2842, 2.7751],
device='cuda:0'), tensor([2.6379, 2.7999, 2.8079, 2.6064, 2.9011], device='cuda:0'), tensor([2.5638, 2.6013, 2.2097, 2.2721, 2.6637], device='cuda:0'), tensor([2.4917, 2.7151, 2.5305, 2.0214, 2.8035], device='cuda:0'), tensor([2.6981, 2.3971, 2.3272, 2.2035, 2.4340],
device='cuda:0'), tensor([2.1679, 2.1687, 2.2764, 2.0852, 2.3622], device='cuda:0'), tensor([2.5728, 2.6191, 2.5581, 2.8591, 2.6867], device='cuda:0'), tensor([2.4213, 2.7419, 2.8348, 2.5409, 2.8005], device='cuda:0'), tensor([2.6291, 2.8536, 2.7020, 2.4394, 3.0455],
device='cuda:0'), tensor([2.6505, 2.4136, 2.2547, 2.0769, 2.3849], device='cuda:0'), tensor([2.4238, 2.5273, 2.1946, 2.2685, 2.6472], device='cuda:0'), tensor([2.6091, 2.5686, 2.4729, 2.7881, 2.6775], device='cuda:0'), tensor([2.2631, 2.7508, 2.7391, 2.3884, 2.6943],
device='cuda:0'), tensor([2.3015, 2.7460, 2.7121, 2.3106, 2.7242], device='cuda:0'), tensor([2.6092, 2.7935, 2.4187, 2.3917, 2.8424], device='cuda:0'), tensor([2.5045, 2.9497, 2.7338, 2.6022, 2.8409], device='cuda:0'), tensor([1.9243, 2.4549, 2.3300, 2.1901, 2.2163],
device='cuda:0'), tensor([2.1825, 2.5995, 2.5310, 2.2327, 2.6328], device='cuda:0'), tensor([2.4171, 2.7395, 2.8171, 2.3121, 2.9345], device='cuda:0'), tensor([2.6297, 3.0320, 2.6330, 2.3732, 2.9206], device='cuda:0'), tensor([2.3172, 2.4365, 2.3826, 2.5911, 2.5655],
device='cuda:0'), tensor([2.6957, 2.4699, 2.1956, 2.1672, 2.4245], device='cuda:0'), tensor([2.5132, 2.7009, 2.5285, 3.0047, 2.7701], device='cuda:0'), tensor([2.4489, 2.5770, 2.4443, 3.0507, 2.6166], device='cuda:0'), tensor([2.7127, 3.0453, 2.9383, 2.5923, 3.0989],
device='cuda:0'), tensor([2.4011, 2.7708, 2.9912, 2.2993, 2.8817], device='cuda:0'), tensor([2.3992, 2.5757, 2.4412, 2.2163, 2.6807], device='cuda:0'), tensor([2.5038, 2.8128, 2.8537, 2.6405, 2.8069], device='cuda:0'), tensor([2.2158, 2.5745, 2.4503, 2.3331, 2.5358],
device='cuda:0'), tensor([2.2211, 2.5355, 2.6557, 2.0702, 2.5334], device='cuda:0'), tensor([2.0795, 2.2417, 2.2407, 2.1284, 2.3788], device='cuda:0'), tensor([1.9662, 2.2970, 2.0931, 1.5362, 2.2489], device='cuda:0'), tensor([2.5640, 2.6326, 2.3906, 2.3446, 2.7600],
device='cuda:0'), tensor([2.5012, 2.8558, 2.7819, 2.3395, 2.9253], device='cuda:0'), tensor([2.0695, 2.6162, 2.5891, 2.2321, 2.4470], device='cuda:0'), tensor([2.4353, 2.4709, 2.1844, 2.1206, 2.5323], device='cuda:0'), tensor([2.4994, 2.7850, 2.8143, 2.5315, 2.8603],
device='cuda:0'), tensor([1.9649, 2.3045, 2.1448, 1.6270, 2.2982], device='cuda:0'), tensor([2.3928, 2.7536, 2.4540, 1.9938, 2.7655], device='cuda:0'), tensor([2.4449, 2.9513, 2.8770, 2.6023, 2.8535], device='cuda:0'), tensor([2.7716, 2.8876, 2.8097, 2.4404, 2.9480],
device='cuda:0'), tensor([2.2543, 2.2637, 1.9939, 1.7667, 2.2185], device='cuda:0'), tensor([2.4861, 2.6049, 2.3250, 2.2264, 2.7237], device='cuda:0'), tensor([2.5416, 2.8612, 2.8029, 2.6286, 2.8873], device='cuda:0'), tensor([2.4758, 2.9366, 2.5392, 2.1630, 2.9280],
device='cuda:0'), tensor([2.5041, 2.9387, 2.8598, 2.6050, 2.8611], device='cuda:0'), tensor([2.4367, 2.8757, 2.8170, 2.5973, 2.8086], device='cuda:0'), tensor([1.9566, 2.0802, 2.0763, 2.0777, 2.0874], device='cuda:0'), tensor([2.6872, 2.9771, 2.8695, 2.6365, 3.0064],
device='cuda:0'), tensor([1.7392, 1.9111, 1.8297, 2.2703, 1.9491], device='cuda:0'), tensor([2.3707, 2.2533, 2.4552, 2.5341, 2.2573], device='cuda:0'), tensor([2.4477, 2.5704, 2.5860, 2.9785, 2.7008], device='cuda:0'), tensor([2.4378, 2.5896, 2.3890, 2.2266, 2.7269],
device='cuda:0'), tensor([2.3316, 2.2960, 2.1146, 2.5326, 2.3636], device='cuda:0'), tensor([2.0851, 2.1295, 2.0510, 1.9145, 2.2307], device='cuda:0'), tensor([2.6130, 2.4233, 2.2190, 2.3313, 2.4068], device='cuda:0'), tensor([2.6111, 2.9063, 2.8855, 2.6209, 2.9910],
device='cuda:0'), tensor([2.0451, 2.1983, 2.1007, 2.3559, 2.2364], device='cuda:0'), tensor([2.1378, 2.2575, 2.1903, 2.1321, 2.3961], device='cuda:0'), tensor([2.2088, 2.4038, 2.6054, 2.0010, 2.5378], device='cuda:0'), tensor([2.0897, 2.6673, 2.4952, 2.2336, 2.5889],
device='cuda:0'), tensor([2.0426, 2.0357, 1.9818, 1.7793, 2.1395], device='cuda:0'), tensor([2.3135, 2.4472, 2.0862, 2.0501, 2.4825], device='cuda:0'), tensor([2.8516, 3.0177, 2.9583, 2.4677, 3.0446], device='cuda:0'), tensor([2.0002, 2.4668, 2.3302, 1.8852, 2.4428],
device='cuda:0'), tensor([2.4378, 2.5047, 2.2914, 2.2391, 2.5807], device='cuda:0'), tensor([2.3456, 2.1430, 2.4159, 2.5975, 2.1254], device='cuda:0'), tensor([2.1574, 2.4685, 2.4237, 1.7989, 2.5062], device='cuda:0'), tensor([2.5311, 2.9721, 3.0113, 2.6504, 2.9790],
device='cuda:0'), tensor([2.6109, 2.9768, 2.8816, 2.5977, 2.9551], device='cuda:0'), tensor([2.3422, 2.4973, 2.2575, 2.0738, 2.5300], device='cuda:0'), tensor([2.4888, 2.8893, 2.8678, 2.5484, 2.7989], device='cuda:0'), tensor([2.6112, 2.9487, 2.8188, 2.6451, 2.8423],
device='cuda:0'), tensor([2.2722, 2.5792, 2.9049, 2.2606, 2.4497], device='cuda:0'), tensor([2.1225, 2.1614, 1.8422, 1.8937, 2.2664], device='cuda:0'), tensor([2.4983, 2.9668, 2.8236, 2.4652, 2.9042], device='cuda:0'), tensor([2.6046, 2.5376, 2.4281, 2.1367, 2.6497],
device='cuda:0'), tensor([2.1790, 2.2720, 2.2443, 2.6713, 2.1815], device='cuda:0'), tensor([2.5259, 2.8057, 2.7221, 2.3281, 2.9015], device='cuda:0'), tensor([2.5234, 2.3944, 2.3465, 2.2186, 2.4455], device='cuda:0'), tensor([2.2674, 2.2347, 1.9933, 1.8539, 2.2197],
device='cuda:0'), tensor([2.3060, 2.6542, 2.8929, 2.1897, 2.6012], device='cuda:0'), tensor([2.3799, 2.7294, 2.6412, 2.4414, 2.8251], device='cuda:0'), tensor([2.4391, 2.6558, 2.7413, 2.3773, 2.7792], device='cuda:0'), tensor([2.4580, 2.8067, 2.8129, 2.4348, 2.9471],
device='cuda:0'), tensor([1.9744, 2.4521, 2.3015, 1.8483, 2.4132], device='cuda:0'), tensor([2.3706, 2.1775, 2.0313, 1.7714, 2.2471], device='cuda:0'), tensor([2.8194, 2.5379, 2.2531, 2.3016, 2.5456], device='cuda:0'), tensor([2.0010, 2.2317, 2.0596, 2.3279, 2.2418],
device='cuda:0'), tensor([2.0721, 2.1181, 2.0311, 1.9329, 2.2685], device='cuda:0'), tensor([1.7064, 1.8646, 1.8997, 1.7440, 1.9672], device='cuda:0'), tensor([2.3557, 2.7567, 2.8851, 2.3947, 2.7039], device='cuda:0'), tensor([2.9213, 2.6698, 2.4510, 2.3895, 2.7320],
device='cuda:0'), tensor([1.9324, 2.0442, 2.0666, 1.9757, 2.2076], device='cuda:0'), tensor([2.7292, 2.7628, 2.6906, 2.5912, 2.8622], device='cuda:0'), tensor([2.3116, 2.3643, 2.1295, 2.1940, 2.4947], device='cuda:0'), tensor([2.6944, 2.5731, 2.3887, 2.2848, 2.5610],
device='cuda:0'), tensor([2.3651, 2.3199, 2.2668, 2.5531, 2.3854], device='cuda:0'), tensor([2.7839, 3.1095, 2.8888, 2.5236, 3.1236], device='cuda:0'), tensor([2.4924, 2.7731, 2.7016, 2.5236, 2.7363], device='cuda:0'), tensor([2.6634, 2.6008, 2.4152, 2.3505, 2.5328],
device='cuda:0'), tensor([2.4026, 2.8364, 2.9491, 2.3930, 2.8281], device='cuda:0'), tensor([2.5225, 2.9223, 2.7465, 2.6099, 2.8332], device='cuda:0'), tensor([2.5046, 2.5090, 2.1932, 2.1370, 2.5489], device='cuda:0'), tensor([2.5049, 2.4875, 2.4704, 2.4014, 2.5867],
device='cuda:0'), tensor([2.4755, 2.4105, 2.3818, 2.3306, 2.3522], device='cuda:0'), tensor([2.4315, 2.7333, 2.8712, 2.4572, 2.7375], device='cuda:0'), tensor([2.6612, 2.9287, 2.8903, 2.5607, 3.0076], device='cuda:0'), tensor([2.3275, 2.6382, 2.8295, 2.1619, 2.7513],
device='cuda:0'), tensor([2.0513, 2.4855, 2.3573, 1.9096, 2.4630], device='cuda:0'), tensor([2.5206, 2.4953, 2.2327, 2.1864, 2.5830], device='cuda:0'), tensor([1.9766, 2.4784, 2.4262, 1.9922, 2.5073], device='cuda:0'), tensor([2.7085, 2.3929, 2.2517, 2.2077, 2.4047],
device='cuda:0'), tensor([2.4033, 2.4376, 2.4843, 2.9969, 2.3984], device='cuda:0'), tensor([2.1155, 2.1816, 2.1422, 2.0533, 2.3359], device='cuda:0'), tensor([2.3528, 2.4680, 2.4315, 2.9504, 2.4871], device='cuda:0'), tensor([2.0749, 2.5161, 2.2856, 1.8685, 2.5054],
device='cuda:0'), tensor([2.3517, 2.5543, 2.2634, 2.3336, 2.6452], device='cuda:0'), tensor([2.3644, 2.4327, 2.0620, 2.1036, 2.5008], device='cuda:0'), tensor([2.3812, 2.6765, 2.7866, 2.1217, 2.6599], device='cuda:0'), tensor([1.8994, 2.3649, 2.2692, 1.6771, 2.2750],
device='cuda:0'), tensor([1.9173, 2.4739, 2.3620, 2.1013, 2.2257], device='cuda:0'), tensor([2.7943, 2.4804, 2.1909, 2.1614, 2.4275], device='cuda:0'), tensor([2.5780, 2.7009, 2.6036, 2.2836, 2.8014], device='cuda:0'), tensor([2.4667, 2.4214, 2.2221, 2.0827, 2.4951],
device='cuda:0'), tensor([1.7426, 1.7255, 1.7149, 1.5447, 1.8857], device='cuda:0'), tensor([2.1897, 2.4554, 2.5966, 2.1071, 2.6773], device='cuda:0'), tensor([2.4070, 2.5636, 2.4863, 2.9771, 2.6075], device='cuda:0'), tensor([2.1600, 2.5344, 2.7994, 2.1246, 2.5155],
device='cuda:0'), tensor([1.8536, 2.2347, 2.0742, 1.5214, 2.1979], device='cuda:0'), tensor([2.0118, 2.3490, 2.1729, 1.6588, 2.2932], device='cuda:0'), tensor([2.7276, 3.0320, 2.8726, 2.5964, 3.0974], device='cuda:0')]
[2Ktarget: [2, 1, 1, 0, 0, 1, 0, 4, 3, 0, 1, 4, 3, 1, 2, 1, 4, 4, 1, 0, 0, 3, 1, 4, 2, 3, 0, 0, 3, 2, 4, 1, 4, 0, 3, 4, 0, 3, 2, 1, 2, 2, 4, 3, 0, 3, 3, 4, 2, 4, 2, 2, 1, 1, 4, 1, 1, 4, 4, 4, 1, 3, 3, 3, 3, 0, 4, 2, 4, 3, 2, 4, 2, 1, 2, 4, 3, 0, 2, 4, 0, 0, 0, 3, 0, 3, 1,
0, 2, 4, 0, 0, 1, 2, 0, 3, 3, 2, 0, 1, 2, 3, 2, 1]
[2Kpreds_tensor: torch.Size([203, 5])â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 203/203 [2m0:00:56 â€¢ 0:00:00[0m [2;4m3.21it/s[0m  
[2KTesting [38;2;98;6;224mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 203/203 [2m0:00:56 â€¢ 0:00:00[0m [2;4m3.21it/s[0m
[?25h[[36m2025-02-14 14:45:49,762[0m][[34msrc.utils.utils[0m][[31mERROR[0m] - [0m
Traceback (most recent call last):
  File "/home/def/fewshot/src/utils/utils.py", line 65, in wrap
    metric_dict, object_dict = task_func(cfg=cfg)
  File "/home/def/fewshot/src/train.py", line 103, in train
    trainer.test(model=model, datamodule=datamodule, ckpt_path=ckpt_path)
  File "/home/def/miniforge3/envs/fewshot/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py", line 749, in test
    return call._call_and_handle_interrupt(
  File "/home/def/miniforge3/envs/fewshot/lib/python3.10/site-packages/lightning/pytorch/trainer/call.py", line 47, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
  File "/home/def/miniforge3/envs/fewshot/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py", line 789, in _test_impl
    results = self._run(model, ckpt_path=ckpt_path)
  File "/home/def/miniforge3/envs/fewshot/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py", line 982, in _run
    results = self._run_stage()
  File "/home/def/miniforge3/envs/fewshot/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py", line 1019, in _run_stage
    return self._evaluation_loop.run()
  File "/home/def/miniforge3/envs/fewshot/lib/python3.10/site-packages/lightning/pytorch/loops/utilities.py", line 179, in _decorator
    return loop_run(self, *args, **kwargs)
  File "/home/def/miniforge3/envs/fewshot/lib/python3.10/site-packages/lightning/pytorch/loops/evaluation_loop.py", line 151, in run
    return self.on_run_end()
  File "/home/def/miniforge3/envs/fewshot/lib/python3.10/site-packages/lightning/pytorch/loops/evaluation_loop.py", line 291, in on_run_end
    self._on_evaluation_epoch_end()
  File "/home/def/miniforge3/envs/fewshot/lib/python3.10/site-packages/lightning/pytorch/loops/evaluation_loop.py", line 371, in _on_evaluation_epoch_end
    call._call_lightning_module_hook(trainer, hook_name)
  File "/home/def/miniforge3/envs/fewshot/lib/python3.10/site-packages/lightning/pytorch/trainer/call.py", line 171, in _call_lightning_module_hook
    output = fn(*args, **kwargs)
  File "/home/def/fewshot/src/models/tt_method_module.py", line 151, in on_test_epoch_end
    self.log("label top-1 accuracy", top_k_accuracy(self.scores, self.label_gt, 1))
  File "/home/def/fewshot/src/models/tt_method_module.py", line 240, in top_k_accuracy
    target_expanded = target_tensor.view(-1, 1).expand_as(topk_indices)
RuntimeError: The expanded size of the tensor (203) must match the existing size (104) at non-singleton dimension 0.  Target sizes: [203, 1].  Tensor sizes: [104, 1]
[[36m2025-02-14 14:45:49,768[0m][[34msrc.utils.utils[0m][[32mINFO[0m] - Output dir: /home/def/fewshot/logs/train/runs/2025-02-14_14-44-38[0m
[[36m2025-02-14 14:45:49,768[0m][[34msrc.utils.utils[0m][[32mINFO[0m] - Closing wandb![0m
