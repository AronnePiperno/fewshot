[[36m2025-02-14 10:05:16,607[0m][[34m__main__[0m][[32mINFO[0m] - Starting training![0m
You are using a CUDA device ('NVIDIA GeForce RTX 4070 SUPER') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision
No of videos in train is 214
Loading train Video Information ...
No of class 10
No of videos in validation is 203
Loading validation Video Information ...
No of class 10
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”“
â”ƒ[1;35m [0m[1;35m   [0m[1;35m [0mâ”ƒ[1;35m [0m[1;35mName                                                   [0m[1;35m [0mâ”ƒ[1;35m [0m[1;35mType                           [0m[1;35m [0mâ”ƒ[1;35m [0m[1;35mParams[0m[1;35m [0mâ”ƒ[1;35m [0m[1;35mMode [0m[1;35m [0mâ”ƒ
â”¡â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”©
â”‚[2m [0m[2m0  [0m[2m [0mâ”‚ net                                                     â”‚ T3ALNet                         â”‚  639 M â”‚ train â”‚
â”‚[2m [0m[2m1  [0m[2m [0mâ”‚ net.model                                               â”‚ CoCa                            â”‚  638 M â”‚ train â”‚
â”‚[2m [0m[2m2  [0m[2m [0mâ”‚ net.model.text                                          â”‚ TextTransformer                 â”‚  123 M â”‚ train â”‚
â”‚[2m [0m[2m3  [0m[2m [0mâ”‚ net.model.text.token_embedding                          â”‚ Embedding                       â”‚ 37.9 M â”‚ train â”‚
â”‚[2m [0m[2m4  [0m[2m [0mâ”‚ net.model.text.transformer                              â”‚ Transformer                     â”‚ 85.1 M â”‚ train â”‚
â”‚[2m [0m[2m5  [0m[2m [0mâ”‚ net.model.text.transformer.resblocks                    â”‚ ModuleList                      â”‚ 85.1 M â”‚ train â”‚
â”‚[2m [0m[2m6  [0m[2m [0mâ”‚ net.model.text.transformer.resblocks.0                  â”‚ ResidualAttentionBlock          â”‚  7.1 M â”‚ train â”‚
â”‚[2m [0m[2m7  [0m[2m [0mâ”‚ net.model.text.transformer.resblocks.0.ln_1             â”‚ LayerNorm                       â”‚  1.5 K â”‚ train â”‚
â”‚[2m [0m[2m8  [0m[2m [0mâ”‚ net.model.text.transformer.resblocks.0.attn             â”‚ MultiheadAttention              â”‚  2.4 M â”‚ train â”‚
â”‚[2m [0m[2m9  [0m[2m [0mâ”‚ net.model.text.transformer.resblocks.0.attn.out_proj    â”‚ NonDynamicallyQuantizableLinear â”‚  590 K â”‚ train â”‚
â”‚[2m [0m[2m10 [0m[2m [0mâ”‚ net.model.text.transformer.resblocks.0.ls_1             â”‚ Identity                        â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m11 [0m[2m [0mâ”‚ net.model.text.transformer.resblocks.0.ln_2             â”‚ LayerNorm                       â”‚  1.5 K â”‚ train â”‚
â”‚[2m [0m[2m12 [0m[2m [0mâ”‚ net.model.text.transformer.resblocks.0.mlp              â”‚ Sequential                      â”‚  4.7 M â”‚ train â”‚
â”‚[2m [0m[2m13 [0m[2m [0mâ”‚ net.model.text.transformer.resblocks.0.mlp.c_fc         â”‚ Linear                          â”‚  2.4 M â”‚ train â”‚
â”‚[2m [0m[2m14 [0m[2m [0mâ”‚ net.model.text.transformer.resblocks.0.mlp.gelu         â”‚ GELU                            â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m15 [0m[2m [0mâ”‚ net.model.text.transformer.resblocks.0.mlp.c_proj       â”‚ Linear                          â”‚  2.4 M â”‚ train â”‚
â”‚[2m [0m[2m16 [0m[2m [0mâ”‚ net.model.text.transformer.resblocks.0.ls_2             â”‚ Identity                        â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m17 [0m[2m [0mâ”‚ net.model.text.transformer.resblocks.1                  â”‚ ResidualAttentionBlock          â”‚  7.1 M â”‚ train â”‚
â”‚[2m [0m[2m18 [0m[2m [0mâ”‚ net.model.text.transformer.resblocks.1.ln_1             â”‚ LayerNorm                       â”‚  1.5 K â”‚ train â”‚
â”‚[2m [0m[2m19 [0m[2m [0mâ”‚ net.model.text.transformer.resblocks.1.attn             â”‚ MultiheadAttention              â”‚  2.4 M â”‚ train â”‚
â”‚[2m [0m[2m20 [0m[2m [0mâ”‚ net.model.text.transformer.resblocks.1.attn.out_proj    â”‚ NonDynamicallyQuantizableLinear â”‚  590 K â”‚ train â”‚
â”‚[2m [0m[2m21 [0m[2m [0mâ”‚ net.model.text.transformer.resblocks.1.ls_1             â”‚ Identity                        â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m22 [0m[2m [0mâ”‚ net.model.text.transformer.resblocks.1.ln_2             â”‚ LayerNorm                       â”‚  1.5 K â”‚ train â”‚
â”‚[2m [0m[2m23 [0m[2m [0mâ”‚ net.model.text.transformer.resblocks.1.mlp              â”‚ Sequential                      â”‚  4.7 M â”‚ train â”‚
â”‚[2m [0m[2m24 [0m[2m [0mâ”‚ net.model.text.transformer.resblocks.1.mlp.c_fc         â”‚ Linear                          â”‚  2.4 M â”‚ train â”‚
â”‚[2m [0m[2m25 [0m[2m [0mâ”‚ net.model.text.transformer.resblocks.1.mlp.gelu         â”‚ GELU                            â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m26 [0m[2m [0mâ”‚ net.model.text.transformer.resblocks.1.mlp.c_proj       â”‚ Linear                          â”‚  2.4 M â”‚ train â”‚
â”‚[2m [0m[2m27 [0m[2m [0mâ”‚ net.model.text.transformer.resblocks.1.ls_2             â”‚ Identity                        â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m28 [0m[2m [0mâ”‚ net.model.text.transformer.resblocks.2                  â”‚ ResidualAttentionBlock          â”‚  7.1 M â”‚ train â”‚
â”‚[2m [0m[2m29 [0m[2m [0mâ”‚ net.model.text.transformer.resblocks.2.ln_1             â”‚ LayerNorm                       â”‚  1.5 K â”‚ train â”‚
â”‚[2m [0m[2m30 [0m[2m [0mâ”‚ net.model.text.transformer.resblocks.2.attn             â”‚ MultiheadAttention              â”‚  2.4 M â”‚ train â”‚
â”‚[2m [0m[2m31 [0m[2m [0mâ”‚ net.model.text.transformer.resblocks.2.attn.out_proj    â”‚ NonDynamicallyQuantizableLinear â”‚  590 K â”‚ train â”‚
â”‚[2m [0m[2m32 [0m[2m [0mâ”‚ net.model.text.transformer.resblocks.2.ls_1             â”‚ Identity                        â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m33 [0m[2m [0mâ”‚ net.model.text.transformer.resblocks.2.ln_2             â”‚ LayerNorm                       â”‚  1.5 K â”‚ train â”‚
â”‚[2m [0m[2m34 [0m[2m [0mâ”‚ net.model.text.transformer.resblocks.2.mlp              â”‚ Sequential                      â”‚  4.7 M â”‚ train â”‚
â”‚[2m [0m[2m35 [0m[2m [0mâ”‚ net.model.text.transformer.resblocks.2.mlp.c_fc         â”‚ Linear                          â”‚  2.4 M â”‚ train â”‚
â”‚[2m [0m[2m36 [0m[2m [0mâ”‚ net.model.text.transformer.resblocks.2.mlp.gelu         â”‚ GELU                            â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m37 [0m[2m [0mâ”‚ net.model.text.transformer.resblocks.2.mlp.c_proj       â”‚ Linear                          â”‚  2.4 M â”‚ train â”‚
â”‚[2m [0m[2m38 [0m[2m [0mâ”‚ net.model.text.transformer.resblocks.2.ls_2             â”‚ Identity                        â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m39 [0m[2m [0mâ”‚ net.model.text.transformer.resblocks.3                  â”‚ ResidualAttentionBlock          â”‚  7.1 M â”‚ train â”‚
â”‚[2m [0m[2m40 [0m[2m [0mâ”‚ net.model.text.transformer.resblocks.3.ln_1             â”‚ LayerNorm                       â”‚  1.5 K â”‚ train â”‚
â”‚[2m [0m[2m41 [0m[2m [0mâ”‚ net.model.text.transformer.resblocks.3.attn             â”‚ MultiheadAttention              â”‚  2.4 M â”‚ train â”‚
â”‚[2m [0m[2m42 [0m[2m [0mâ”‚ net.model.text.transformer.resblocks.3.attn.out_proj    â”‚ NonDynamicallyQuantizableLinear â”‚  590 K â”‚ train â”‚
â”‚[2m [0m[2m43 [0m[2m [0mâ”‚ net.model.text.transformer.resblocks.3.ls_1             â”‚ Identity                        â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m44 [0m[2m [0mâ”‚ net.model.text.transformer.resblocks.3.ln_2             â”‚ LayerNorm                       â”‚  1.5 K â”‚ train â”‚
â”‚[2m [0m[2m45 [0m[2m [0mâ”‚ net.model.text.transformer.resblocks.3.mlp              â”‚ Sequential                      â”‚  4.7 M â”‚ train â”‚
â”‚[2m [0m[2m46 [0m[2m [0mâ”‚ net.model.text.transformer.resblocks.3.mlp.c_fc         â”‚ Linear                          â”‚  2.4 M â”‚ train â”‚
â”‚[2m [0m[2m47 [0m[2m [0mâ”‚ net.model.text.transformer.resblocks.3.mlp.gelu         â”‚ GELU                            â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m48 [0m[2m [0mâ”‚ net.model.text.transformer.resblocks.3.mlp.c_proj       â”‚ Linear                          â”‚  2.4 M â”‚ train â”‚
â”‚[2m [0m[2m49 [0m[2m [0mâ”‚ net.model.text.transformer.resblocks.3.ls_2             â”‚ Identity                        â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m50 [0m[2m [0mâ”‚ net.model.text.transformer.resblocks.4                  â”‚ ResidualAttentionBlock          â”‚  7.1 M â”‚ train â”‚
â”‚[2m [0m[2m51 [0m[2m [0mâ”‚ net.model.text.transformer.resblocks.4.ln_1             â”‚ LayerNorm                       â”‚  1.5 K â”‚ train â”‚
â”‚[2m [0m[2m52 [0m[2m [0mâ”‚ net.model.text.transformer.resblocks.4.attn             â”‚ MultiheadAttention              â”‚  2.4 M â”‚ train â”‚
â”‚[2m [0m[2m53 [0m[2m [0mâ”‚ net.model.text.transformer.resblocks.4.attn.out_proj    â”‚ NonDynamicallyQuantizableLinear â”‚  590 K â”‚ train â”‚
â”‚[2m [0m[2m54 [0m[2m [0mâ”‚ net.model.text.transformer.resblocks.4.ls_1             â”‚ Identity                        â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m55 [0m[2m [0mâ”‚ net.model.text.transformer.resblocks.4.ln_2             â”‚ LayerNorm                       â”‚  1.5 K â”‚ train â”‚
â”‚[2m [0m[2m56 [0m[2m [0mâ”‚ net.model.text.transformer.resblocks.4.mlp              â”‚ Sequential                      â”‚  4.7 M â”‚ train â”‚
â”‚[2m [0m[2m57 [0m[2m [0mâ”‚ net.model.text.transformer.resblocks.4.mlp.c_fc         â”‚ Linear                          â”‚  2.4 M â”‚ train â”‚
â”‚[2m [0m[2m58 [0m[2m [0mâ”‚ net.model.text.transformer.resblocks.4.mlp.gelu         â”‚ GELU                            â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m59 [0m[2m [0mâ”‚ net.model.text.transformer.resblocks.4.mlp.c_proj       â”‚ Linear                          â”‚  2.4 M â”‚ train â”‚
â”‚[2m [0m[2m60 [0m[2m [0mâ”‚ net.model.text.transformer.resblocks.4.ls_2             â”‚ Identity                        â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m61 [0m[2m [0mâ”‚ net.model.text.transformer.resblocks.5                  â”‚ ResidualAttentionBlock          â”‚  7.1 M â”‚ train â”‚
â”‚[2m [0m[2m62 [0m[2m [0mâ”‚ net.model.text.transformer.resblocks.5.ln_1             â”‚ LayerNorm                       â”‚  1.5 K â”‚ train â”‚
â”‚[2m [0m[2m63 [0m[2m [0mâ”‚ net.model.text.transformer.resblocks.5.attn             â”‚ MultiheadAttention              â”‚  2.4 M â”‚ train â”‚
â”‚[2m [0m[2m64 [0m[2m [0mâ”‚ net.model.text.transformer.resblocks.5.attn.out_proj    â”‚ NonDynamicallyQuantizableLinear â”‚  590 K â”‚ train â”‚
â”‚[2m [0m[2m65 [0m[2m [0mâ”‚ net.model.text.transformer.resblocks.5.ls_1             â”‚ Identity                        â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m66 [0m[2m [0mâ”‚ net.model.text.transformer.resblocks.5.ln_2             â”‚ LayerNorm                       â”‚  1.5 K â”‚ train â”‚
â”‚[2m [0m[2m67 [0m[2m [0mâ”‚ net.model.text.transformer.resblocks.5.mlp              â”‚ Sequential                      â”‚  4.7 M â”‚ train â”‚
â”‚[2m [0m[2m68 [0m[2m [0mâ”‚ net.model.text.transformer.resblocks.5.mlp.c_fc         â”‚ Linear                          â”‚  2.4 M â”‚ train â”‚
â”‚[2m [0m[2m69 [0m[2m [0mâ”‚ net.model.text.transformer.resblocks.5.mlp.gelu         â”‚ GELU                            â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m70 [0m[2m [0mâ”‚ net.model.text.transformer.resblocks.5.mlp.c_proj       â”‚ Linear                          â”‚  2.4 M â”‚ train â”‚
â”‚[2m [0m[2m71 [0m[2m [0mâ”‚ net.model.text.transformer.resblocks.5.ls_2             â”‚ Identity                        â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m72 [0m[2m [0mâ”‚ net.model.text.transformer.resblocks.6                  â”‚ ResidualAttentionBlock          â”‚  7.1 M â”‚ train â”‚
â”‚[2m [0m[2m73 [0m[2m [0mâ”‚ net.model.text.transformer.resblocks.6.ln_1             â”‚ LayerNorm                       â”‚  1.5 K â”‚ train â”‚
â”‚[2m [0m[2m74 [0m[2m [0mâ”‚ net.model.text.transformer.resblocks.6.attn             â”‚ MultiheadAttention              â”‚  2.4 M â”‚ train â”‚
â”‚[2m [0m[2m75 [0m[2m [0mâ”‚ net.model.text.transformer.resblocks.6.attn.out_proj    â”‚ NonDynamicallyQuantizableLinear â”‚  590 K â”‚ train â”‚
â”‚[2m [0m[2m76 [0m[2m [0mâ”‚ net.model.text.transformer.resblocks.6.ls_1             â”‚ Identity                        â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m77 [0m[2m [0mâ”‚ net.model.text.transformer.resblocks.6.ln_2             â”‚ LayerNorm                       â”‚  1.5 K â”‚ train â”‚
â”‚[2m [0m[2m78 [0m[2m [0mâ”‚ net.model.text.transformer.resblocks.6.mlp              â”‚ Sequential                      â”‚  4.7 M â”‚ train â”‚
â”‚[2m [0m[2m79 [0m[2m [0mâ”‚ net.model.text.transformer.resblocks.6.mlp.c_fc         â”‚ Linear                          â”‚  2.4 M â”‚ train â”‚
â”‚[2m [0m[2m80 [0m[2m [0mâ”‚ net.model.text.transformer.resblocks.6.mlp.gelu         â”‚ GELU                            â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m81 [0m[2m [0mâ”‚ net.model.text.transformer.resblocks.6.mlp.c_proj       â”‚ Linear                          â”‚  2.4 M â”‚ train â”‚
â”‚[2m [0m[2m82 [0m[2m [0mâ”‚ net.model.text.transformer.resblocks.6.ls_2             â”‚ Identity                        â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m83 [0m[2m [0mâ”‚ net.model.text.transformer.resblocks.7                  â”‚ ResidualAttentionBlock          â”‚  7.1 M â”‚ train â”‚
â”‚[2m [0m[2m84 [0m[2m [0mâ”‚ net.model.text.transformer.resblocks.7.ln_1             â”‚ LayerNorm                       â”‚  1.5 K â”‚ train â”‚
â”‚[2m [0m[2m85 [0m[2m [0mâ”‚ net.model.text.transformer.resblocks.7.attn             â”‚ MultiheadAttention              â”‚  2.4 M â”‚ train â”‚
â”‚[2m [0m[2m86 [0m[2m [0mâ”‚ net.model.text.transformer.resblocks.7.attn.out_proj    â”‚ NonDynamicallyQuantizableLinear â”‚  590 K â”‚ train â”‚
â”‚[2m [0m[2m87 [0m[2m [0mâ”‚ net.model.text.transformer.resblocks.7.ls_1             â”‚ Identity                        â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m88 [0m[2m [0mâ”‚ net.model.text.transformer.resblocks.7.ln_2             â”‚ LayerNorm                       â”‚  1.5 K â”‚ train â”‚
â”‚[2m [0m[2m89 [0m[2m [0mâ”‚ net.model.text.transformer.resblocks.7.mlp              â”‚ Sequential                      â”‚  4.7 M â”‚ train â”‚
â”‚[2m [0m[2m90 [0m[2m [0mâ”‚ net.model.text.transformer.resblocks.7.mlp.c_fc         â”‚ Linear                          â”‚  2.4 M â”‚ train â”‚
â”‚[2m [0m[2m91 [0m[2m [0mâ”‚ net.model.text.transformer.resblocks.7.mlp.gelu         â”‚ GELU                            â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m92 [0m[2m [0mâ”‚ net.model.text.transformer.resblocks.7.mlp.c_proj       â”‚ Linear                          â”‚  2.4 M â”‚ train â”‚
â”‚[2m [0m[2m93 [0m[2m [0mâ”‚ net.model.text.transformer.resblocks.7.ls_2             â”‚ Identity                        â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m94 [0m[2m [0mâ”‚ net.model.text.transformer.resblocks.8                  â”‚ ResidualAttentionBlock          â”‚  7.1 M â”‚ train â”‚
â”‚[2m [0m[2m95 [0m[2m [0mâ”‚ net.model.text.transformer.resblocks.8.ln_1             â”‚ LayerNorm                       â”‚  1.5 K â”‚ train â”‚
â”‚[2m [0m[2m96 [0m[2m [0mâ”‚ net.model.text.transformer.resblocks.8.attn             â”‚ MultiheadAttention              â”‚  2.4 M â”‚ train â”‚
â”‚[2m [0m[2m97 [0m[2m [0mâ”‚ net.model.text.transformer.resblocks.8.attn.out_proj    â”‚ NonDynamicallyQuantizableLinear â”‚  590 K â”‚ train â”‚
â”‚[2m [0m[2m98 [0m[2m [0mâ”‚ net.model.text.transformer.resblocks.8.ls_1             â”‚ Identity                        â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m99 [0m[2m [0mâ”‚ net.model.text.transformer.resblocks.8.ln_2             â”‚ LayerNorm                       â”‚  1.5 K â”‚ train â”‚
â”‚[2m [0m[2m100[0m[2m [0mâ”‚ net.model.text.transformer.resblocks.8.mlp              â”‚ Sequential                      â”‚  4.7 M â”‚ train â”‚
â”‚[2m [0m[2m101[0m[2m [0mâ”‚ net.model.text.transformer.resblocks.8.mlp.c_fc         â”‚ Linear                          â”‚  2.4 M â”‚ train â”‚
â”‚[2m [0m[2m102[0m[2m [0mâ”‚ net.model.text.transformer.resblocks.8.mlp.gelu         â”‚ GELU                            â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m103[0m[2m [0mâ”‚ net.model.text.transformer.resblocks.8.mlp.c_proj       â”‚ Linear                          â”‚  2.4 M â”‚ train â”‚
â”‚[2m [0m[2m104[0m[2m [0mâ”‚ net.model.text.transformer.resblocks.8.ls_2             â”‚ Identity                        â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m105[0m[2m [0mâ”‚ net.model.text.transformer.resblocks.9                  â”‚ ResidualAttentionBlock          â”‚  7.1 M â”‚ train â”‚
â”‚[2m [0m[2m106[0m[2m [0mâ”‚ net.model.text.transformer.resblocks.9.ln_1             â”‚ LayerNorm                       â”‚  1.5 K â”‚ train â”‚
â”‚[2m [0m[2m107[0m[2m [0mâ”‚ net.model.text.transformer.resblocks.9.attn             â”‚ MultiheadAttention              â”‚  2.4 M â”‚ train â”‚
â”‚[2m [0m[2m108[0m[2m [0mâ”‚ net.model.text.transformer.resblocks.9.attn.out_proj    â”‚ NonDynamicallyQuantizableLinear â”‚  590 K â”‚ train â”‚
â”‚[2m [0m[2m109[0m[2m [0mâ”‚ net.model.text.transformer.resblocks.9.ls_1             â”‚ Identity                        â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m110[0m[2m [0mâ”‚ net.model.text.transformer.resblocks.9.ln_2             â”‚ LayerNorm                       â”‚  1.5 K â”‚ train â”‚
â”‚[2m [0m[2m111[0m[2m [0mâ”‚ net.model.text.transformer.resblocks.9.mlp              â”‚ Sequential                      â”‚  4.7 M â”‚ train â”‚
â”‚[2m [0m[2m112[0m[2m [0mâ”‚ net.model.text.transformer.resblocks.9.mlp.c_fc         â”‚ Linear                          â”‚  2.4 M â”‚ train â”‚
â”‚[2m [0m[2m113[0m[2m [0mâ”‚ net.model.text.transformer.resblocks.9.mlp.gelu         â”‚ GELU                            â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m114[0m[2m [0mâ”‚ net.model.text.transformer.resblocks.9.mlp.c_proj       â”‚ Linear                          â”‚  2.4 M â”‚ train â”‚
â”‚[2m [0m[2m115[0m[2m [0mâ”‚ net.model.text.transformer.resblocks.9.ls_2             â”‚ Identity                        â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m116[0m[2m [0mâ”‚ net.model.text.transformer.resblocks.10                 â”‚ ResidualAttentionBlock          â”‚  7.1 M â”‚ train â”‚
â”‚[2m [0m[2m117[0m[2m [0mâ”‚ net.model.text.transformer.resblocks.10.ln_1            â”‚ LayerNorm                       â”‚  1.5 K â”‚ train â”‚
â”‚[2m [0m[2m118[0m[2m [0mâ”‚ net.model.text.transformer.resblocks.10.attn            â”‚ MultiheadAttention              â”‚  2.4 M â”‚ train â”‚
â”‚[2m [0m[2m119[0m[2m [0mâ”‚ net.model.text.transformer.resblocks.10.attn.out_proj   â”‚ NonDynamicallyQuantizableLinear â”‚  590 K â”‚ train â”‚
â”‚[2m [0m[2m120[0m[2m [0mâ”‚ net.model.text.transformer.resblocks.10.ls_1            â”‚ Identity                        â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m121[0m[2m [0mâ”‚ net.model.text.transformer.resblocks.10.ln_2            â”‚ LayerNorm                       â”‚  1.5 K â”‚ train â”‚
â”‚[2m [0m[2m122[0m[2m [0mâ”‚ net.model.text.transformer.resblocks.10.mlp             â”‚ Sequential                      â”‚  4.7 M â”‚ train â”‚
â”‚[2m [0m[2m123[0m[2m [0mâ”‚ net.model.text.transformer.resblocks.10.mlp.c_fc        â”‚ Linear                          â”‚  2.4 M â”‚ train â”‚
â”‚[2m [0m[2m124[0m[2m [0mâ”‚ net.model.text.transformer.resblocks.10.mlp.gelu        â”‚ GELU                            â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m125[0m[2m [0mâ”‚ net.model.text.transformer.resblocks.10.mlp.c_proj      â”‚ Linear                          â”‚  2.4 M â”‚ train â”‚
â”‚[2m [0m[2m126[0m[2m [0mâ”‚ net.model.text.transformer.resblocks.10.ls_2            â”‚ Identity                        â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m127[0m[2m [0mâ”‚ net.model.text.transformer.resblocks.11                 â”‚ ResidualAttentionBlock          â”‚  7.1 M â”‚ train â”‚
â”‚[2m [0m[2m128[0m[2m [0mâ”‚ net.model.text.transformer.resblocks.11.ln_1            â”‚ LayerNorm                       â”‚  1.5 K â”‚ train â”‚
â”‚[2m [0m[2m129[0m[2m [0mâ”‚ net.model.text.transformer.resblocks.11.attn            â”‚ MultiheadAttention              â”‚  2.4 M â”‚ train â”‚
â”‚[2m [0m[2m130[0m[2m [0mâ”‚ net.model.text.transformer.resblocks.11.attn.out_proj   â”‚ NonDynamicallyQuantizableLinear â”‚  590 K â”‚ train â”‚
â”‚[2m [0m[2m131[0m[2m [0mâ”‚ net.model.text.transformer.resblocks.11.ls_1            â”‚ Identity                        â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m132[0m[2m [0mâ”‚ net.model.text.transformer.resblocks.11.ln_2            â”‚ LayerNorm                       â”‚  1.5 K â”‚ train â”‚
â”‚[2m [0m[2m133[0m[2m [0mâ”‚ net.model.text.transformer.resblocks.11.mlp             â”‚ Sequential                      â”‚  4.7 M â”‚ train â”‚
â”‚[2m [0m[2m134[0m[2m [0mâ”‚ net.model.text.transformer.resblocks.11.mlp.c_fc        â”‚ Linear                          â”‚  2.4 M â”‚ train â”‚
â”‚[2m [0m[2m135[0m[2m [0mâ”‚ net.model.text.transformer.resblocks.11.mlp.gelu        â”‚ GELU                            â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m136[0m[2m [0mâ”‚ net.model.text.transformer.resblocks.11.mlp.c_proj      â”‚ Linear                          â”‚  2.4 M â”‚ train â”‚
â”‚[2m [0m[2m137[0m[2m [0mâ”‚ net.model.text.transformer.resblocks.11.ls_2            â”‚ Identity                        â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m138[0m[2m [0mâ”‚ net.model.text.ln_final                                 â”‚ LayerNorm                       â”‚  1.5 K â”‚ train â”‚
â”‚[2m [0m[2m139[0m[2m [0mâ”‚ net.model.visual                                        â”‚ VisionTransformer               â”‚  306 M â”‚ train â”‚
â”‚[2m [0m[2m140[0m[2m [0mâ”‚ net.model.visual.conv1                                  â”‚ Conv2d                          â”‚  602 K â”‚ train â”‚
â”‚[2m [0m[2m141[0m[2m [0mâ”‚ net.model.visual.patch_dropout                          â”‚ Identity                        â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m142[0m[2m [0mâ”‚ net.model.visual.ln_pre                                 â”‚ LayerNorm                       â”‚  2.0 K â”‚ train â”‚
â”‚[2m [0m[2m143[0m[2m [0mâ”‚ net.model.visual.transformer                            â”‚ Transformer                     â”‚  302 M â”‚ train â”‚
â”‚[2m [0m[2m144[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks                  â”‚ ModuleList                      â”‚  302 M â”‚ train â”‚
â”‚[2m [0m[2m145[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.0                â”‚ ResidualAttentionBlock          â”‚ 12.6 M â”‚ train â”‚
â”‚[2m [0m[2m146[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.0.ln_1           â”‚ LayerNorm                       â”‚  2.0 K â”‚ train â”‚
â”‚[2m [0m[2m147[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.0.attn           â”‚ MultiheadAttention              â”‚  4.2 M â”‚ train â”‚
â”‚[2m [0m[2m148[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.0.attn.out_proj  â”‚ NonDynamicallyQuantizableLinear â”‚  1.0 M â”‚ train â”‚
â”‚[2m [0m[2m149[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.0.ls_1           â”‚ Identity                        â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m150[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.0.ln_2           â”‚ LayerNorm                       â”‚  2.0 K â”‚ train â”‚
â”‚[2m [0m[2m151[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.0.mlp            â”‚ Sequential                      â”‚  8.4 M â”‚ train â”‚
â”‚[2m [0m[2m152[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.0.mlp.c_fc       â”‚ Linear                          â”‚  4.2 M â”‚ train â”‚
â”‚[2m [0m[2m153[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.0.mlp.gelu       â”‚ GELU                            â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m154[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.0.mlp.c_proj     â”‚ Linear                          â”‚  4.2 M â”‚ train â”‚
â”‚[2m [0m[2m155[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.0.ls_2           â”‚ Identity                        â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m156[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.1                â”‚ ResidualAttentionBlock          â”‚ 12.6 M â”‚ train â”‚
â”‚[2m [0m[2m157[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.1.ln_1           â”‚ LayerNorm                       â”‚  2.0 K â”‚ train â”‚
â”‚[2m [0m[2m158[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.1.attn           â”‚ MultiheadAttention              â”‚  4.2 M â”‚ train â”‚
â”‚[2m [0m[2m159[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.1.attn.out_proj  â”‚ NonDynamicallyQuantizableLinear â”‚  1.0 M â”‚ train â”‚
â”‚[2m [0m[2m160[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.1.ls_1           â”‚ Identity                        â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m161[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.1.ln_2           â”‚ LayerNorm                       â”‚  2.0 K â”‚ train â”‚
â”‚[2m [0m[2m162[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.1.mlp            â”‚ Sequential                      â”‚  8.4 M â”‚ train â”‚
â”‚[2m [0m[2m163[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.1.mlp.c_fc       â”‚ Linear                          â”‚  4.2 M â”‚ train â”‚
â”‚[2m [0m[2m164[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.1.mlp.gelu       â”‚ GELU                            â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m165[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.1.mlp.c_proj     â”‚ Linear                          â”‚  4.2 M â”‚ train â”‚
â”‚[2m [0m[2m166[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.1.ls_2           â”‚ Identity                        â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m167[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.2                â”‚ ResidualAttentionBlock          â”‚ 12.6 M â”‚ train â”‚
â”‚[2m [0m[2m168[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.2.ln_1           â”‚ LayerNorm                       â”‚  2.0 K â”‚ train â”‚
â”‚[2m [0m[2m169[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.2.attn           â”‚ MultiheadAttention              â”‚  4.2 M â”‚ train â”‚
â”‚[2m [0m[2m170[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.2.attn.out_proj  â”‚ NonDynamicallyQuantizableLinear â”‚  1.0 M â”‚ train â”‚
â”‚[2m [0m[2m171[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.2.ls_1           â”‚ Identity                        â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m172[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.2.ln_2           â”‚ LayerNorm                       â”‚  2.0 K â”‚ train â”‚
â”‚[2m [0m[2m173[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.2.mlp            â”‚ Sequential                      â”‚  8.4 M â”‚ train â”‚
â”‚[2m [0m[2m174[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.2.mlp.c_fc       â”‚ Linear                          â”‚  4.2 M â”‚ train â”‚
â”‚[2m [0m[2m175[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.2.mlp.gelu       â”‚ GELU                            â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m176[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.2.mlp.c_proj     â”‚ Linear                          â”‚  4.2 M â”‚ train â”‚
â”‚[2m [0m[2m177[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.2.ls_2           â”‚ Identity                        â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m178[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.3                â”‚ ResidualAttentionBlock          â”‚ 12.6 M â”‚ train â”‚
â”‚[2m [0m[2m179[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.3.ln_1           â”‚ LayerNorm                       â”‚  2.0 K â”‚ train â”‚
â”‚[2m [0m[2m180[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.3.attn           â”‚ MultiheadAttention              â”‚  4.2 M â”‚ train â”‚
â”‚[2m [0m[2m181[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.3.attn.out_proj  â”‚ NonDynamicallyQuantizableLinear â”‚  1.0 M â”‚ train â”‚
â”‚[2m [0m[2m182[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.3.ls_1           â”‚ Identity                        â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m183[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.3.ln_2           â”‚ LayerNorm                       â”‚  2.0 K â”‚ train â”‚
â”‚[2m [0m[2m184[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.3.mlp            â”‚ Sequential                      â”‚  8.4 M â”‚ train â”‚
â”‚[2m [0m[2m185[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.3.mlp.c_fc       â”‚ Linear                          â”‚  4.2 M â”‚ train â”‚
â”‚[2m [0m[2m186[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.3.mlp.gelu       â”‚ GELU                            â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m187[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.3.mlp.c_proj     â”‚ Linear                          â”‚  4.2 M â”‚ train â”‚
â”‚[2m [0m[2m188[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.3.ls_2           â”‚ Identity                        â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m189[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.4                â”‚ ResidualAttentionBlock          â”‚ 12.6 M â”‚ train â”‚
â”‚[2m [0m[2m190[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.4.ln_1           â”‚ LayerNorm                       â”‚  2.0 K â”‚ train â”‚
â”‚[2m [0m[2m191[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.4.attn           â”‚ MultiheadAttention              â”‚  4.2 M â”‚ train â”‚
â”‚[2m [0m[2m192[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.4.attn.out_proj  â”‚ NonDynamicallyQuantizableLinear â”‚  1.0 M â”‚ train â”‚
â”‚[2m [0m[2m193[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.4.ls_1           â”‚ Identity                        â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m194[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.4.ln_2           â”‚ LayerNorm                       â”‚  2.0 K â”‚ train â”‚
â”‚[2m [0m[2m195[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.4.mlp            â”‚ Sequential                      â”‚  8.4 M â”‚ train â”‚
â”‚[2m [0m[2m196[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.4.mlp.c_fc       â”‚ Linear                          â”‚  4.2 M â”‚ train â”‚
â”‚[2m [0m[2m197[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.4.mlp.gelu       â”‚ GELU                            â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m198[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.4.mlp.c_proj     â”‚ Linear                          â”‚  4.2 M â”‚ train â”‚
â”‚[2m [0m[2m199[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.4.ls_2           â”‚ Identity                        â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m200[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.5                â”‚ ResidualAttentionBlock          â”‚ 12.6 M â”‚ train â”‚
â”‚[2m [0m[2m201[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.5.ln_1           â”‚ LayerNorm                       â”‚  2.0 K â”‚ train â”‚
â”‚[2m [0m[2m202[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.5.attn           â”‚ MultiheadAttention              â”‚  4.2 M â”‚ train â”‚
â”‚[2m [0m[2m203[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.5.attn.out_proj  â”‚ NonDynamicallyQuantizableLinear â”‚  1.0 M â”‚ train â”‚
â”‚[2m [0m[2m204[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.5.ls_1           â”‚ Identity                        â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m205[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.5.ln_2           â”‚ LayerNorm                       â”‚  2.0 K â”‚ train â”‚
â”‚[2m [0m[2m206[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.5.mlp            â”‚ Sequential                      â”‚  8.4 M â”‚ train â”‚
â”‚[2m [0m[2m207[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.5.mlp.c_fc       â”‚ Linear                          â”‚  4.2 M â”‚ train â”‚
â”‚[2m [0m[2m208[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.5.mlp.gelu       â”‚ GELU                            â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m209[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.5.mlp.c_proj     â”‚ Linear                          â”‚  4.2 M â”‚ train â”‚
â”‚[2m [0m[2m210[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.5.ls_2           â”‚ Identity                        â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m211[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.6                â”‚ ResidualAttentionBlock          â”‚ 12.6 M â”‚ train â”‚
â”‚[2m [0m[2m212[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.6.ln_1           â”‚ LayerNorm                       â”‚  2.0 K â”‚ train â”‚
â”‚[2m [0m[2m213[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.6.attn           â”‚ MultiheadAttention              â”‚  4.2 M â”‚ train â”‚
â”‚[2m [0m[2m214[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.6.attn.out_proj  â”‚ NonDynamicallyQuantizableLinear â”‚  1.0 M â”‚ train â”‚
â”‚[2m [0m[2m215[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.6.ls_1           â”‚ Identity                        â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m216[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.6.ln_2           â”‚ LayerNorm                       â”‚  2.0 K â”‚ train â”‚
â”‚[2m [0m[2m217[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.6.mlp            â”‚ Sequential                      â”‚  8.4 M â”‚ train â”‚
â”‚[2m [0m[2m218[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.6.mlp.c_fc       â”‚ Linear                          â”‚  4.2 M â”‚ train â”‚
â”‚[2m [0m[2m219[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.6.mlp.gelu       â”‚ GELU                            â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m220[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.6.mlp.c_proj     â”‚ Linear                          â”‚  4.2 M â”‚ train â”‚
â”‚[2m [0m[2m221[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.6.ls_2           â”‚ Identity                        â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m222[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.7                â”‚ ResidualAttentionBlock          â”‚ 12.6 M â”‚ train â”‚
â”‚[2m [0m[2m223[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.7.ln_1           â”‚ LayerNorm                       â”‚  2.0 K â”‚ train â”‚
â”‚[2m [0m[2m224[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.7.attn           â”‚ MultiheadAttention              â”‚  4.2 M â”‚ train â”‚
â”‚[2m [0m[2m225[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.7.attn.out_proj  â”‚ NonDynamicallyQuantizableLinear â”‚  1.0 M â”‚ train â”‚
â”‚[2m [0m[2m226[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.7.ls_1           â”‚ Identity                        â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m227[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.7.ln_2           â”‚ LayerNorm                       â”‚  2.0 K â”‚ train â”‚
â”‚[2m [0m[2m228[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.7.mlp            â”‚ Sequential                      â”‚  8.4 M â”‚ train â”‚
â”‚[2m [0m[2m229[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.7.mlp.c_fc       â”‚ Linear                          â”‚  4.2 M â”‚ train â”‚
â”‚[2m [0m[2m230[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.7.mlp.gelu       â”‚ GELU                            â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m231[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.7.mlp.c_proj     â”‚ Linear                          â”‚  4.2 M â”‚ train â”‚
â”‚[2m [0m[2m232[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.7.ls_2           â”‚ Identity                        â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m233[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.8                â”‚ ResidualAttentionBlock          â”‚ 12.6 M â”‚ train â”‚
â”‚[2m [0m[2m234[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.8.ln_1           â”‚ LayerNorm                       â”‚  2.0 K â”‚ train â”‚
â”‚[2m [0m[2m235[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.8.attn           â”‚ MultiheadAttention              â”‚  4.2 M â”‚ train â”‚
â”‚[2m [0m[2m236[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.8.attn.out_proj  â”‚ NonDynamicallyQuantizableLinear â”‚  1.0 M â”‚ train â”‚
â”‚[2m [0m[2m237[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.8.ls_1           â”‚ Identity                        â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m238[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.8.ln_2           â”‚ LayerNorm                       â”‚  2.0 K â”‚ train â”‚
â”‚[2m [0m[2m239[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.8.mlp            â”‚ Sequential                      â”‚  8.4 M â”‚ train â”‚
â”‚[2m [0m[2m240[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.8.mlp.c_fc       â”‚ Linear                          â”‚  4.2 M â”‚ train â”‚
â”‚[2m [0m[2m241[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.8.mlp.gelu       â”‚ GELU                            â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m242[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.8.mlp.c_proj     â”‚ Linear                          â”‚  4.2 M â”‚ train â”‚
â”‚[2m [0m[2m243[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.8.ls_2           â”‚ Identity                        â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m244[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.9                â”‚ ResidualAttentionBlock          â”‚ 12.6 M â”‚ train â”‚
â”‚[2m [0m[2m245[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.9.ln_1           â”‚ LayerNorm                       â”‚  2.0 K â”‚ train â”‚
â”‚[2m [0m[2m246[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.9.attn           â”‚ MultiheadAttention              â”‚  4.2 M â”‚ train â”‚
â”‚[2m [0m[2m247[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.9.attn.out_proj  â”‚ NonDynamicallyQuantizableLinear â”‚  1.0 M â”‚ train â”‚
â”‚[2m [0m[2m248[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.9.ls_1           â”‚ Identity                        â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m249[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.9.ln_2           â”‚ LayerNorm                       â”‚  2.0 K â”‚ train â”‚
â”‚[2m [0m[2m250[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.9.mlp            â”‚ Sequential                      â”‚  8.4 M â”‚ train â”‚
â”‚[2m [0m[2m251[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.9.mlp.c_fc       â”‚ Linear                          â”‚  4.2 M â”‚ train â”‚
â”‚[2m [0m[2m252[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.9.mlp.gelu       â”‚ GELU                            â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m253[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.9.mlp.c_proj     â”‚ Linear                          â”‚  4.2 M â”‚ train â”‚
â”‚[2m [0m[2m254[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.9.ls_2           â”‚ Identity                        â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m255[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.10               â”‚ ResidualAttentionBlock          â”‚ 12.6 M â”‚ train â”‚
â”‚[2m [0m[2m256[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.10.ln_1          â”‚ LayerNorm                       â”‚  2.0 K â”‚ train â”‚
â”‚[2m [0m[2m257[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.10.attn          â”‚ MultiheadAttention              â”‚  4.2 M â”‚ train â”‚
â”‚[2m [0m[2m258[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.10.attn.out_proj â”‚ NonDynamicallyQuantizableLinear â”‚  1.0 M â”‚ train â”‚
â”‚[2m [0m[2m259[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.10.ls_1          â”‚ Identity                        â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m260[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.10.ln_2          â”‚ LayerNorm                       â”‚  2.0 K â”‚ train â”‚
â”‚[2m [0m[2m261[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.10.mlp           â”‚ Sequential                      â”‚  8.4 M â”‚ train â”‚
â”‚[2m [0m[2m262[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.10.mlp.c_fc      â”‚ Linear                          â”‚  4.2 M â”‚ train â”‚
â”‚[2m [0m[2m263[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.10.mlp.gelu      â”‚ GELU                            â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m264[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.10.mlp.c_proj    â”‚ Linear                          â”‚  4.2 M â”‚ train â”‚
â”‚[2m [0m[2m265[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.10.ls_2          â”‚ Identity                        â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m266[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.11               â”‚ ResidualAttentionBlock          â”‚ 12.6 M â”‚ train â”‚
â”‚[2m [0m[2m267[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.11.ln_1          â”‚ LayerNorm                       â”‚  2.0 K â”‚ train â”‚
â”‚[2m [0m[2m268[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.11.attn          â”‚ MultiheadAttention              â”‚  4.2 M â”‚ train â”‚
â”‚[2m [0m[2m269[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.11.attn.out_proj â”‚ NonDynamicallyQuantizableLinear â”‚  1.0 M â”‚ train â”‚
â”‚[2m [0m[2m270[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.11.ls_1          â”‚ Identity                        â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m271[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.11.ln_2          â”‚ LayerNorm                       â”‚  2.0 K â”‚ train â”‚
â”‚[2m [0m[2m272[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.11.mlp           â”‚ Sequential                      â”‚  8.4 M â”‚ train â”‚
â”‚[2m [0m[2m273[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.11.mlp.c_fc      â”‚ Linear                          â”‚  4.2 M â”‚ train â”‚
â”‚[2m [0m[2m274[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.11.mlp.gelu      â”‚ GELU                            â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m275[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.11.mlp.c_proj    â”‚ Linear                          â”‚  4.2 M â”‚ train â”‚
â”‚[2m [0m[2m276[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.11.ls_2          â”‚ Identity                        â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m277[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.12               â”‚ ResidualAttentionBlock          â”‚ 12.6 M â”‚ train â”‚
â”‚[2m [0m[2m278[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.12.ln_1          â”‚ LayerNorm                       â”‚  2.0 K â”‚ train â”‚
â”‚[2m [0m[2m279[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.12.attn          â”‚ MultiheadAttention              â”‚  4.2 M â”‚ train â”‚
â”‚[2m [0m[2m280[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.12.attn.out_proj â”‚ NonDynamicallyQuantizableLinear â”‚  1.0 M â”‚ train â”‚
â”‚[2m [0m[2m281[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.12.ls_1          â”‚ Identity                        â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m282[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.12.ln_2          â”‚ LayerNorm                       â”‚  2.0 K â”‚ train â”‚
â”‚[2m [0m[2m283[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.12.mlp           â”‚ Sequential                      â”‚  8.4 M â”‚ train â”‚
â”‚[2m [0m[2m284[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.12.mlp.c_fc      â”‚ Linear                          â”‚  4.2 M â”‚ train â”‚
â”‚[2m [0m[2m285[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.12.mlp.gelu      â”‚ GELU                            â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m286[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.12.mlp.c_proj    â”‚ Linear                          â”‚  4.2 M â”‚ train â”‚
â”‚[2m [0m[2m287[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.12.ls_2          â”‚ Identity                        â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m288[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.13               â”‚ ResidualAttentionBlock          â”‚ 12.6 M â”‚ train â”‚
â”‚[2m [0m[2m289[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.13.ln_1          â”‚ LayerNorm                       â”‚  2.0 K â”‚ train â”‚
â”‚[2m [0m[2m290[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.13.attn          â”‚ MultiheadAttention              â”‚  4.2 M â”‚ train â”‚
â”‚[2m [0m[2m291[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.13.attn.out_proj â”‚ NonDynamicallyQuantizableLinear â”‚  1.0 M â”‚ train â”‚
â”‚[2m [0m[2m292[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.13.ls_1          â”‚ Identity                        â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m293[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.13.ln_2          â”‚ LayerNorm                       â”‚  2.0 K â”‚ train â”‚
â”‚[2m [0m[2m294[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.13.mlp           â”‚ Sequential                      â”‚  8.4 M â”‚ train â”‚
â”‚[2m [0m[2m295[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.13.mlp.c_fc      â”‚ Linear                          â”‚  4.2 M â”‚ train â”‚
â”‚[2m [0m[2m296[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.13.mlp.gelu      â”‚ GELU                            â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m297[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.13.mlp.c_proj    â”‚ Linear                          â”‚  4.2 M â”‚ train â”‚
â”‚[2m [0m[2m298[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.13.ls_2          â”‚ Identity                        â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m299[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.14               â”‚ ResidualAttentionBlock          â”‚ 12.6 M â”‚ train â”‚
â”‚[2m [0m[2m300[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.14.ln_1          â”‚ LayerNorm                       â”‚  2.0 K â”‚ train â”‚
â”‚[2m [0m[2m301[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.14.attn          â”‚ MultiheadAttention              â”‚  4.2 M â”‚ train â”‚
â”‚[2m [0m[2m302[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.14.attn.out_proj â”‚ NonDynamicallyQuantizableLinear â”‚  1.0 M â”‚ train â”‚
â”‚[2m [0m[2m303[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.14.ls_1          â”‚ Identity                        â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m304[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.14.ln_2          â”‚ LayerNorm                       â”‚  2.0 K â”‚ train â”‚
â”‚[2m [0m[2m305[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.14.mlp           â”‚ Sequential                      â”‚  8.4 M â”‚ train â”‚
â”‚[2m [0m[2m306[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.14.mlp.c_fc      â”‚ Linear                          â”‚  4.2 M â”‚ train â”‚
â”‚[2m [0m[2m307[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.14.mlp.gelu      â”‚ GELU                            â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m308[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.14.mlp.c_proj    â”‚ Linear                          â”‚  4.2 M â”‚ train â”‚
â”‚[2m [0m[2m309[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.14.ls_2          â”‚ Identity                        â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m310[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.15               â”‚ ResidualAttentionBlock          â”‚ 12.6 M â”‚ train â”‚
â”‚[2m [0m[2m311[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.15.ln_1          â”‚ LayerNorm                       â”‚  2.0 K â”‚ train â”‚
â”‚[2m [0m[2m312[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.15.attn          â”‚ MultiheadAttention              â”‚  4.2 M â”‚ train â”‚
â”‚[2m [0m[2m313[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.15.attn.out_proj â”‚ NonDynamicallyQuantizableLinear â”‚  1.0 M â”‚ train â”‚
â”‚[2m [0m[2m314[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.15.ls_1          â”‚ Identity                        â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m315[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.15.ln_2          â”‚ LayerNorm                       â”‚  2.0 K â”‚ train â”‚
â”‚[2m [0m[2m316[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.15.mlp           â”‚ Sequential                      â”‚  8.4 M â”‚ train â”‚
â”‚[2m [0m[2m317[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.15.mlp.c_fc      â”‚ Linear                          â”‚  4.2 M â”‚ train â”‚
â”‚[2m [0m[2m318[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.15.mlp.gelu      â”‚ GELU                            â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m319[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.15.mlp.c_proj    â”‚ Linear                          â”‚  4.2 M â”‚ train â”‚
â”‚[2m [0m[2m320[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.15.ls_2          â”‚ Identity                        â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m321[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.16               â”‚ ResidualAttentionBlock          â”‚ 12.6 M â”‚ train â”‚
â”‚[2m [0m[2m322[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.16.ln_1          â”‚ LayerNorm                       â”‚  2.0 K â”‚ train â”‚
â”‚[2m [0m[2m323[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.16.attn          â”‚ MultiheadAttention              â”‚  4.2 M â”‚ train â”‚
â”‚[2m [0m[2m324[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.16.attn.out_proj â”‚ NonDynamicallyQuantizableLinear â”‚  1.0 M â”‚ train â”‚
â”‚[2m [0m[2m325[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.16.ls_1          â”‚ Identity                        â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m326[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.16.ln_2          â”‚ LayerNorm                       â”‚  2.0 K â”‚ train â”‚
â”‚[2m [0m[2m327[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.16.mlp           â”‚ Sequential                      â”‚  8.4 M â”‚ train â”‚
â”‚[2m [0m[2m328[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.16.mlp.c_fc      â”‚ Linear                          â”‚  4.2 M â”‚ train â”‚
â”‚[2m [0m[2m329[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.16.mlp.gelu      â”‚ GELU                            â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m330[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.16.mlp.c_proj    â”‚ Linear                          â”‚  4.2 M â”‚ train â”‚
â”‚[2m [0m[2m331[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.16.ls_2          â”‚ Identity                        â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m332[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.17               â”‚ ResidualAttentionBlock          â”‚ 12.6 M â”‚ train â”‚
â”‚[2m [0m[2m333[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.17.ln_1          â”‚ LayerNorm                       â”‚  2.0 K â”‚ train â”‚
â”‚[2m [0m[2m334[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.17.attn          â”‚ MultiheadAttention              â”‚  4.2 M â”‚ train â”‚
â”‚[2m [0m[2m335[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.17.attn.out_proj â”‚ NonDynamicallyQuantizableLinear â”‚  1.0 M â”‚ train â”‚
â”‚[2m [0m[2m336[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.17.ls_1          â”‚ Identity                        â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m337[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.17.ln_2          â”‚ LayerNorm                       â”‚  2.0 K â”‚ train â”‚
â”‚[2m [0m[2m338[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.17.mlp           â”‚ Sequential                      â”‚  8.4 M â”‚ train â”‚
â”‚[2m [0m[2m339[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.17.mlp.c_fc      â”‚ Linear                          â”‚  4.2 M â”‚ train â”‚
â”‚[2m [0m[2m340[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.17.mlp.gelu      â”‚ GELU                            â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m341[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.17.mlp.c_proj    â”‚ Linear                          â”‚  4.2 M â”‚ train â”‚
â”‚[2m [0m[2m342[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.17.ls_2          â”‚ Identity                        â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m343[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.18               â”‚ ResidualAttentionBlock          â”‚ 12.6 M â”‚ train â”‚
â”‚[2m [0m[2m344[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.18.ln_1          â”‚ LayerNorm                       â”‚  2.0 K â”‚ train â”‚
â”‚[2m [0m[2m345[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.18.attn          â”‚ MultiheadAttention              â”‚  4.2 M â”‚ train â”‚
â”‚[2m [0m[2m346[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.18.attn.out_proj â”‚ NonDynamicallyQuantizableLinear â”‚  1.0 M â”‚ train â”‚
â”‚[2m [0m[2m347[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.18.ls_1          â”‚ Identity                        â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m348[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.18.ln_2          â”‚ LayerNorm                       â”‚  2.0 K â”‚ train â”‚
â”‚[2m [0m[2m349[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.18.mlp           â”‚ Sequential                      â”‚  8.4 M â”‚ train â”‚
â”‚[2m [0m[2m350[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.18.mlp.c_fc      â”‚ Linear                          â”‚  4.2 M â”‚ train â”‚
â”‚[2m [0m[2m351[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.18.mlp.gelu      â”‚ GELU                            â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m352[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.18.mlp.c_proj    â”‚ Linear                          â”‚  4.2 M â”‚ train â”‚
â”‚[2m [0m[2m353[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.18.ls_2          â”‚ Identity                        â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m354[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.19               â”‚ ResidualAttentionBlock          â”‚ 12.6 M â”‚ train â”‚
â”‚[2m [0m[2m355[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.19.ln_1          â”‚ LayerNorm                       â”‚  2.0 K â”‚ train â”‚
â”‚[2m [0m[2m356[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.19.attn          â”‚ MultiheadAttention              â”‚  4.2 M â”‚ train â”‚
â”‚[2m [0m[2m357[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.19.attn.out_proj â”‚ NonDynamicallyQuantizableLinear â”‚  1.0 M â”‚ train â”‚
â”‚[2m [0m[2m358[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.19.ls_1          â”‚ Identity                        â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m359[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.19.ln_2          â”‚ LayerNorm                       â”‚  2.0 K â”‚ train â”‚
â”‚[2m [0m[2m360[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.19.mlp           â”‚ Sequential                      â”‚  8.4 M â”‚ train â”‚
â”‚[2m [0m[2m361[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.19.mlp.c_fc      â”‚ Linear                          â”‚  4.2 M â”‚ train â”‚
â”‚[2m [0m[2m362[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.19.mlp.gelu      â”‚ GELU                            â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m363[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.19.mlp.c_proj    â”‚ Linear                          â”‚  4.2 M â”‚ train â”‚
â”‚[2m [0m[2m364[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.19.ls_2          â”‚ Identity                        â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m365[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.20               â”‚ ResidualAttentionBlock          â”‚ 12.6 M â”‚ train â”‚
â”‚[2m [0m[2m366[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.20.ln_1          â”‚ LayerNorm                       â”‚  2.0 K â”‚ train â”‚
â”‚[2m [0m[2m367[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.20.attn          â”‚ MultiheadAttention              â”‚  4.2 M â”‚ train â”‚
â”‚[2m [0m[2m368[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.20.attn.out_proj â”‚ NonDynamicallyQuantizableLinear â”‚  1.0 M â”‚ train â”‚
â”‚[2m [0m[2m369[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.20.ls_1          â”‚ Identity                        â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m370[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.20.ln_2          â”‚ LayerNorm                       â”‚  2.0 K â”‚ train â”‚
â”‚[2m [0m[2m371[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.20.mlp           â”‚ Sequential                      â”‚  8.4 M â”‚ train â”‚
â”‚[2m [0m[2m372[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.20.mlp.c_fc      â”‚ Linear                          â”‚  4.2 M â”‚ train â”‚
â”‚[2m [0m[2m373[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.20.mlp.gelu      â”‚ GELU                            â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m374[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.20.mlp.c_proj    â”‚ Linear                          â”‚  4.2 M â”‚ train â”‚
â”‚[2m [0m[2m375[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.20.ls_2          â”‚ Identity                        â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m376[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.21               â”‚ ResidualAttentionBlock          â”‚ 12.6 M â”‚ train â”‚
â”‚[2m [0m[2m377[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.21.ln_1          â”‚ LayerNorm                       â”‚  2.0 K â”‚ train â”‚
â”‚[2m [0m[2m378[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.21.attn          â”‚ MultiheadAttention              â”‚  4.2 M â”‚ train â”‚
â”‚[2m [0m[2m379[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.21.attn.out_proj â”‚ NonDynamicallyQuantizableLinear â”‚  1.0 M â”‚ train â”‚
â”‚[2m [0m[2m380[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.21.ls_1          â”‚ Identity                        â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m381[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.21.ln_2          â”‚ LayerNorm                       â”‚  2.0 K â”‚ train â”‚
â”‚[2m [0m[2m382[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.21.mlp           â”‚ Sequential                      â”‚  8.4 M â”‚ train â”‚
â”‚[2m [0m[2m383[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.21.mlp.c_fc      â”‚ Linear                          â”‚  4.2 M â”‚ train â”‚
â”‚[2m [0m[2m384[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.21.mlp.gelu      â”‚ GELU                            â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m385[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.21.mlp.c_proj    â”‚ Linear                          â”‚  4.2 M â”‚ train â”‚
â”‚[2m [0m[2m386[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.21.ls_2          â”‚ Identity                        â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m387[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.22               â”‚ ResidualAttentionBlock          â”‚ 12.6 M â”‚ train â”‚
â”‚[2m [0m[2m388[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.22.ln_1          â”‚ LayerNorm                       â”‚  2.0 K â”‚ train â”‚
â”‚[2m [0m[2m389[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.22.attn          â”‚ MultiheadAttention              â”‚  4.2 M â”‚ train â”‚
â”‚[2m [0m[2m390[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.22.attn.out_proj â”‚ NonDynamicallyQuantizableLinear â”‚  1.0 M â”‚ train â”‚
â”‚[2m [0m[2m391[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.22.ls_1          â”‚ Identity                        â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m392[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.22.ln_2          â”‚ LayerNorm                       â”‚  2.0 K â”‚ train â”‚
â”‚[2m [0m[2m393[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.22.mlp           â”‚ Sequential                      â”‚  8.4 M â”‚ train â”‚
â”‚[2m [0m[2m394[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.22.mlp.c_fc      â”‚ Linear                          â”‚  4.2 M â”‚ train â”‚
â”‚[2m [0m[2m395[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.22.mlp.gelu      â”‚ GELU                            â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m396[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.22.mlp.c_proj    â”‚ Linear                          â”‚  4.2 M â”‚ train â”‚
â”‚[2m [0m[2m397[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.22.ls_2          â”‚ Identity                        â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m398[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.23               â”‚ ResidualAttentionBlock          â”‚ 12.6 M â”‚ train â”‚
â”‚[2m [0m[2m399[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.23.ln_1          â”‚ LayerNorm                       â”‚  2.0 K â”‚ train â”‚
â”‚[2m [0m[2m400[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.23.attn          â”‚ MultiheadAttention              â”‚  4.2 M â”‚ train â”‚
â”‚[2m [0m[2m401[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.23.attn.out_proj â”‚ NonDynamicallyQuantizableLinear â”‚  1.0 M â”‚ train â”‚
â”‚[2m [0m[2m402[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.23.ls_1          â”‚ Identity                        â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m403[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.23.ln_2          â”‚ LayerNorm                       â”‚  2.0 K â”‚ train â”‚
â”‚[2m [0m[2m404[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.23.mlp           â”‚ Sequential                      â”‚  8.4 M â”‚ train â”‚
â”‚[2m [0m[2m405[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.23.mlp.c_fc      â”‚ Linear                          â”‚  4.2 M â”‚ train â”‚
â”‚[2m [0m[2m406[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.23.mlp.gelu      â”‚ GELU                            â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m407[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.23.mlp.c_proj    â”‚ Linear                          â”‚  4.2 M â”‚ train â”‚
â”‚[2m [0m[2m408[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.23.ls_2          â”‚ Identity                        â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m409[0m[2m [0mâ”‚ net.model.visual.attn_pool                              â”‚ AttentionalPooler               â”‚  3.0 M â”‚ train â”‚
â”‚[2m [0m[2m410[0m[2m [0mâ”‚ net.model.visual.attn_pool.attn                         â”‚ MultiheadAttention              â”‚  2.8 M â”‚ train â”‚
â”‚[2m [0m[2m411[0m[2m [0mâ”‚ net.model.visual.attn_pool.attn.out_proj                â”‚ NonDynamicallyQuantizableLinear â”‚  590 K â”‚ train â”‚
â”‚[2m [0m[2m412[0m[2m [0mâ”‚ net.model.visual.attn_pool.ln_q                         â”‚ LayerNorm                       â”‚  1.5 K â”‚ train â”‚
â”‚[2m [0m[2m413[0m[2m [0mâ”‚ net.model.visual.attn_pool.ln_k                         â”‚ LayerNorm                       â”‚  2.0 K â”‚ train â”‚
â”‚[2m [0m[2m414[0m[2m [0mâ”‚ net.model.visual.ln_post                                â”‚ LayerNorm                       â”‚  1.5 K â”‚ train â”‚
â”‚[2m [0m[2m415[0m[2m [0mâ”‚ net.model.text_decoder                                  â”‚ MultimodalTransformer           â”‚  208 M â”‚ train â”‚
â”‚[2m [0m[2m416[0m[2m [0mâ”‚ net.model.text_decoder.resblocks                        â”‚ ModuleList                      â”‚ 85.1 M â”‚ train â”‚
â”‚[2m [0m[2m417[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.0                      â”‚ ResidualAttentionBlock          â”‚  7.1 M â”‚ train â”‚
â”‚[2m [0m[2m418[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.0.ln_1                 â”‚ LayerNorm                       â”‚  1.5 K â”‚ train â”‚
â”‚[2m [0m[2m419[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.0.attn                 â”‚ MultiheadAttention              â”‚  2.4 M â”‚ train â”‚
â”‚[2m [0m[2m420[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.0.attn.out_proj        â”‚ NonDynamicallyQuantizableLinear â”‚  590 K â”‚ train â”‚
â”‚[2m [0m[2m421[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.0.ls_1                 â”‚ Identity                        â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m422[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.0.ln_2                 â”‚ LayerNorm                       â”‚  1.5 K â”‚ train â”‚
â”‚[2m [0m[2m423[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.0.mlp                  â”‚ Sequential                      â”‚  4.7 M â”‚ train â”‚
â”‚[2m [0m[2m424[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.0.mlp.c_fc             â”‚ Linear                          â”‚  2.4 M â”‚ train â”‚
â”‚[2m [0m[2m425[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.0.mlp.gelu             â”‚ GELU                            â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m426[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.0.mlp.c_proj           â”‚ Linear                          â”‚  2.4 M â”‚ train â”‚
â”‚[2m [0m[2m427[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.0.ls_2                 â”‚ Identity                        â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m428[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.1                      â”‚ ResidualAttentionBlock          â”‚  7.1 M â”‚ train â”‚
â”‚[2m [0m[2m429[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.1.ln_1                 â”‚ LayerNorm                       â”‚  1.5 K â”‚ train â”‚
â”‚[2m [0m[2m430[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.1.attn                 â”‚ MultiheadAttention              â”‚  2.4 M â”‚ train â”‚
â”‚[2m [0m[2m431[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.1.attn.out_proj        â”‚ NonDynamicallyQuantizableLinear â”‚  590 K â”‚ train â”‚
â”‚[2m [0m[2m432[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.1.ls_1                 â”‚ Identity                        â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m433[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.1.ln_2                 â”‚ LayerNorm                       â”‚  1.5 K â”‚ train â”‚
â”‚[2m [0m[2m434[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.1.mlp                  â”‚ Sequential                      â”‚  4.7 M â”‚ train â”‚
â”‚[2m [0m[2m435[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.1.mlp.c_fc             â”‚ Linear                          â”‚  2.4 M â”‚ train â”‚
â”‚[2m [0m[2m436[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.1.mlp.gelu             â”‚ GELU                            â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m437[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.1.mlp.c_proj           â”‚ Linear                          â”‚  2.4 M â”‚ train â”‚
â”‚[2m [0m[2m438[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.1.ls_2                 â”‚ Identity                        â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m439[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.2                      â”‚ ResidualAttentionBlock          â”‚  7.1 M â”‚ train â”‚
â”‚[2m [0m[2m440[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.2.ln_1                 â”‚ LayerNorm                       â”‚  1.5 K â”‚ train â”‚
â”‚[2m [0m[2m441[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.2.attn                 â”‚ MultiheadAttention              â”‚  2.4 M â”‚ train â”‚
â”‚[2m [0m[2m442[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.2.attn.out_proj        â”‚ NonDynamicallyQuantizableLinear â”‚  590 K â”‚ train â”‚
â”‚[2m [0m[2m443[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.2.ls_1                 â”‚ Identity                        â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m444[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.2.ln_2                 â”‚ LayerNorm                       â”‚  1.5 K â”‚ train â”‚
â”‚[2m [0m[2m445[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.2.mlp                  â”‚ Sequential                      â”‚  4.7 M â”‚ train â”‚
â”‚[2m [0m[2m446[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.2.mlp.c_fc             â”‚ Linear                          â”‚  2.4 M â”‚ train â”‚
â”‚[2m [0m[2m447[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.2.mlp.gelu             â”‚ GELU                            â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m448[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.2.mlp.c_proj           â”‚ Linear                          â”‚  2.4 M â”‚ train â”‚
â”‚[2m [0m[2m449[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.2.ls_2                 â”‚ Identity                        â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m450[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.3                      â”‚ ResidualAttentionBlock          â”‚  7.1 M â”‚ train â”‚
â”‚[2m [0m[2m451[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.3.ln_1                 â”‚ LayerNorm                       â”‚  1.5 K â”‚ train â”‚
â”‚[2m [0m[2m452[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.3.attn                 â”‚ MultiheadAttention              â”‚  2.4 M â”‚ train â”‚
â”‚[2m [0m[2m453[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.3.attn.out_proj        â”‚ NonDynamicallyQuantizableLinear â”‚  590 K â”‚ train â”‚
â”‚[2m [0m[2m454[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.3.ls_1                 â”‚ Identity                        â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m455[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.3.ln_2                 â”‚ LayerNorm                       â”‚  1.5 K â”‚ train â”‚
â”‚[2m [0m[2m456[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.3.mlp                  â”‚ Sequential                      â”‚  4.7 M â”‚ train â”‚
â”‚[2m [0m[2m457[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.3.mlp.c_fc             â”‚ Linear                          â”‚  2.4 M â”‚ train â”‚
â”‚[2m [0m[2m458[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.3.mlp.gelu             â”‚ GELU                            â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m459[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.3.mlp.c_proj           â”‚ Linear                          â”‚  2.4 M â”‚ train â”‚
â”‚[2m [0m[2m460[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.3.ls_2                 â”‚ Identity                        â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m461[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.4                      â”‚ ResidualAttentionBlock          â”‚  7.1 M â”‚ train â”‚
â”‚[2m [0m[2m462[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.4.ln_1                 â”‚ LayerNorm                       â”‚  1.5 K â”‚ train â”‚
â”‚[2m [0m[2m463[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.4.attn                 â”‚ MultiheadAttention              â”‚  2.4 M â”‚ train â”‚
â”‚[2m [0m[2m464[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.4.attn.out_proj        â”‚ NonDynamicallyQuantizableLinear â”‚  590 K â”‚ train â”‚
â”‚[2m [0m[2m465[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.4.ls_1                 â”‚ Identity                        â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m466[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.4.ln_2                 â”‚ LayerNorm                       â”‚  1.5 K â”‚ train â”‚
â”‚[2m [0m[2m467[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.4.mlp                  â”‚ Sequential                      â”‚  4.7 M â”‚ train â”‚
â”‚[2m [0m[2m468[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.4.mlp.c_fc             â”‚ Linear                          â”‚  2.4 M â”‚ train â”‚
â”‚[2m [0m[2m469[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.4.mlp.gelu             â”‚ GELU                            â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m470[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.4.mlp.c_proj           â”‚ Linear                          â”‚  2.4 M â”‚ train â”‚
â”‚[2m [0m[2m471[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.4.ls_2                 â”‚ Identity                        â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m472[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.5                      â”‚ ResidualAttentionBlock          â”‚  7.1 M â”‚ train â”‚
â”‚[2m [0m[2m473[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.5.ln_1                 â”‚ LayerNorm                       â”‚  1.5 K â”‚ train â”‚
â”‚[2m [0m[2m474[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.5.attn                 â”‚ MultiheadAttention              â”‚  2.4 M â”‚ train â”‚
â”‚[2m [0m[2m475[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.5.attn.out_proj        â”‚ NonDynamicallyQuantizableLinear â”‚  590 K â”‚ train â”‚
â”‚[2m [0m[2m476[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.5.ls_1                 â”‚ Identity                        â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m477[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.5.ln_2                 â”‚ LayerNorm                       â”‚  1.5 K â”‚ train â”‚
â”‚[2m [0m[2m478[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.5.mlp                  â”‚ Sequential                      â”‚  4.7 M â”‚ train â”‚
â”‚[2m [0m[2m479[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.5.mlp.c_fc             â”‚ Linear                          â”‚  2.4 M â”‚ train â”‚
â”‚[2m [0m[2m480[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.5.mlp.gelu             â”‚ GELU                            â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m481[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.5.mlp.c_proj           â”‚ Linear                          â”‚  2.4 M â”‚ train â”‚
â”‚[2m [0m[2m482[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.5.ls_2                 â”‚ Identity                        â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m483[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.6                      â”‚ ResidualAttentionBlock          â”‚  7.1 M â”‚ train â”‚
â”‚[2m [0m[2m484[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.6.ln_1                 â”‚ LayerNorm                       â”‚  1.5 K â”‚ train â”‚
â”‚[2m [0m[2m485[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.6.attn                 â”‚ MultiheadAttention              â”‚  2.4 M â”‚ train â”‚
â”‚[2m [0m[2m486[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.6.attn.out_proj        â”‚ NonDynamicallyQuantizableLinear â”‚  590 K â”‚ train â”‚
â”‚[2m [0m[2m487[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.6.ls_1                 â”‚ Identity                        â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m488[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.6.ln_2                 â”‚ LayerNorm                       â”‚  1.5 K â”‚ train â”‚
â”‚[2m [0m[2m489[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.6.mlp                  â”‚ Sequential                      â”‚  4.7 M â”‚ train â”‚
â”‚[2m [0m[2m490[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.6.mlp.c_fc             â”‚ Linear                          â”‚  2.4 M â”‚ train â”‚
â”‚[2m [0m[2m491[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.6.mlp.gelu             â”‚ GELU                            â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m492[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.6.mlp.c_proj           â”‚ Linear                          â”‚  2.4 M â”‚ train â”‚
â”‚[2m [0m[2m493[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.6.ls_2                 â”‚ Identity                        â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m494[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.7                      â”‚ ResidualAttentionBlock          â”‚  7.1 M â”‚ train â”‚
â”‚[2m [0m[2m495[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.7.ln_1                 â”‚ LayerNorm                       â”‚  1.5 K â”‚ train â”‚
â”‚[2m [0m[2m496[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.7.attn                 â”‚ MultiheadAttention              â”‚  2.4 M â”‚ train â”‚
â”‚[2m [0m[2m497[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.7.attn.out_proj        â”‚ NonDynamicallyQuantizableLinear â”‚  590 K â”‚ train â”‚
â”‚[2m [0m[2m498[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.7.ls_1                 â”‚ Identity                        â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m499[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.7.ln_2                 â”‚ LayerNorm                       â”‚  1.5 K â”‚ train â”‚
â”‚[2m [0m[2m500[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.7.mlp                  â”‚ Sequential                      â”‚  4.7 M â”‚ train â”‚
â”‚[2m [0m[2m501[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.7.mlp.c_fc             â”‚ Linear                          â”‚  2.4 M â”‚ train â”‚
â”‚[2m [0m[2m502[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.7.mlp.gelu             â”‚ GELU                            â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m503[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.7.mlp.c_proj           â”‚ Linear                          â”‚  2.4 M â”‚ train â”‚
â”‚[2m [0m[2m504[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.7.ls_2                 â”‚ Identity                        â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m505[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.8                      â”‚ ResidualAttentionBlock          â”‚  7.1 M â”‚ train â”‚
â”‚[2m [0m[2m506[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.8.ln_1                 â”‚ LayerNorm                       â”‚  1.5 K â”‚ train â”‚
â”‚[2m [0m[2m507[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.8.attn                 â”‚ MultiheadAttention              â”‚  2.4 M â”‚ train â”‚
â”‚[2m [0m[2m508[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.8.attn.out_proj        â”‚ NonDynamicallyQuantizableLinear â”‚  590 K â”‚ train â”‚
â”‚[2m [0m[2m509[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.8.ls_1                 â”‚ Identity                        â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m510[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.8.ln_2                 â”‚ LayerNorm                       â”‚  1.5 K â”‚ train â”‚
â”‚[2m [0m[2m511[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.8.mlp                  â”‚ Sequential                      â”‚  4.7 M â”‚ train â”‚
â”‚[2m [0m[2m512[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.8.mlp.c_fc             â”‚ Linear                          â”‚  2.4 M â”‚ train â”‚
â”‚[2m [0m[2m513[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.8.mlp.gelu             â”‚ GELU                            â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m514[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.8.mlp.c_proj           â”‚ Linear                          â”‚  2.4 M â”‚ train â”‚
â”‚[2m [0m[2m515[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.8.ls_2                 â”‚ Identity                        â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m516[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.9                      â”‚ ResidualAttentionBlock          â”‚  7.1 M â”‚ train â”‚
â”‚[2m [0m[2m517[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.9.ln_1                 â”‚ LayerNorm                       â”‚  1.5 K â”‚ train â”‚
â”‚[2m [0m[2m518[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.9.attn                 â”‚ MultiheadAttention              â”‚  2.4 M â”‚ train â”‚
â”‚[2m [0m[2m519[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.9.attn.out_proj        â”‚ NonDynamicallyQuantizableLinear â”‚  590 K â”‚ train â”‚
â”‚[2m [0m[2m520[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.9.ls_1                 â”‚ Identity                        â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m521[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.9.ln_2                 â”‚ LayerNorm                       â”‚  1.5 K â”‚ train â”‚
â”‚[2m [0m[2m522[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.9.mlp                  â”‚ Sequential                      â”‚  4.7 M â”‚ train â”‚
â”‚[2m [0m[2m523[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.9.mlp.c_fc             â”‚ Linear                          â”‚  2.4 M â”‚ train â”‚
â”‚[2m [0m[2m524[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.9.mlp.gelu             â”‚ GELU                            â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m525[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.9.mlp.c_proj           â”‚ Linear                          â”‚  2.4 M â”‚ train â”‚
â”‚[2m [0m[2m526[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.9.ls_2                 â”‚ Identity                        â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m527[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.10                     â”‚ ResidualAttentionBlock          â”‚  7.1 M â”‚ train â”‚
â”‚[2m [0m[2m528[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.10.ln_1                â”‚ LayerNorm                       â”‚  1.5 K â”‚ train â”‚
â”‚[2m [0m[2m529[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.10.attn                â”‚ MultiheadAttention              â”‚  2.4 M â”‚ train â”‚
â”‚[2m [0m[2m530[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.10.attn.out_proj       â”‚ NonDynamicallyQuantizableLinear â”‚  590 K â”‚ train â”‚
â”‚[2m [0m[2m531[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.10.ls_1                â”‚ Identity                        â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m532[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.10.ln_2                â”‚ LayerNorm                       â”‚  1.5 K â”‚ train â”‚
â”‚[2m [0m[2m533[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.10.mlp                 â”‚ Sequential                      â”‚  4.7 M â”‚ train â”‚
â”‚[2m [0m[2m534[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.10.mlp.c_fc            â”‚ Linear                          â”‚  2.4 M â”‚ train â”‚
â”‚[2m [0m[2m535[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.10.mlp.gelu            â”‚ GELU                            â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m536[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.10.mlp.c_proj          â”‚ Linear                          â”‚  2.4 M â”‚ train â”‚
â”‚[2m [0m[2m537[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.10.ls_2                â”‚ Identity                        â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m538[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.11                     â”‚ ResidualAttentionBlock          â”‚  7.1 M â”‚ train â”‚
â”‚[2m [0m[2m539[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.11.ln_1                â”‚ LayerNorm                       â”‚  1.5 K â”‚ train â”‚
â”‚[2m [0m[2m540[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.11.attn                â”‚ MultiheadAttention              â”‚  2.4 M â”‚ train â”‚
â”‚[2m [0m[2m541[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.11.attn.out_proj       â”‚ NonDynamicallyQuantizableLinear â”‚  590 K â”‚ train â”‚
â”‚[2m [0m[2m542[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.11.ls_1                â”‚ Identity                        â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m543[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.11.ln_2                â”‚ LayerNorm                       â”‚  1.5 K â”‚ train â”‚
â”‚[2m [0m[2m544[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.11.mlp                 â”‚ Sequential                      â”‚  4.7 M â”‚ train â”‚
â”‚[2m [0m[2m545[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.11.mlp.c_fc            â”‚ Linear                          â”‚  2.4 M â”‚ train â”‚
â”‚[2m [0m[2m546[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.11.mlp.gelu            â”‚ GELU                            â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m547[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.11.mlp.c_proj          â”‚ Linear                          â”‚  2.4 M â”‚ train â”‚
â”‚[2m [0m[2m548[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.11.ls_2                â”‚ Identity                        â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m549[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn                       â”‚ ModuleList                      â”‚ 85.1 M â”‚ train â”‚
â”‚[2m [0m[2m550[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.0                     â”‚ ResidualAttentionBlock          â”‚  7.1 M â”‚ train â”‚
â”‚[2m [0m[2m551[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.0.ln_1                â”‚ LayerNorm                       â”‚  1.5 K â”‚ train â”‚
â”‚[2m [0m[2m552[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.0.attn                â”‚ MultiheadAttention              â”‚  2.4 M â”‚ train â”‚
â”‚[2m [0m[2m553[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.0.attn.out_proj       â”‚ NonDynamicallyQuantizableLinear â”‚  590 K â”‚ train â”‚
â”‚[2m [0m[2m554[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.0.ls_1                â”‚ Identity                        â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m555[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.0.ln_1_kv             â”‚ LayerNorm                       â”‚  1.5 K â”‚ train â”‚
â”‚[2m [0m[2m556[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.0.ln_2                â”‚ LayerNorm                       â”‚  1.5 K â”‚ train â”‚
â”‚[2m [0m[2m557[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.0.mlp                 â”‚ Sequential                      â”‚  4.7 M â”‚ train â”‚
â”‚[2m [0m[2m558[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.0.mlp.c_fc            â”‚ Linear                          â”‚  2.4 M â”‚ train â”‚
â”‚[2m [0m[2m559[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.0.mlp.gelu            â”‚ GELU                            â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m560[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.0.mlp.c_proj          â”‚ Linear                          â”‚  2.4 M â”‚ train â”‚
â”‚[2m [0m[2m561[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.0.ls_2                â”‚ Identity                        â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m562[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.1                     â”‚ ResidualAttentionBlock          â”‚  7.1 M â”‚ train â”‚
â”‚[2m [0m[2m563[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.1.ln_1                â”‚ LayerNorm                       â”‚  1.5 K â”‚ train â”‚
â”‚[2m [0m[2m564[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.1.attn                â”‚ MultiheadAttention              â”‚  2.4 M â”‚ train â”‚
â”‚[2m [0m[2m565[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.1.attn.out_proj       â”‚ NonDynamicallyQuantizableLinear â”‚  590 K â”‚ train â”‚
â”‚[2m [0m[2m566[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.1.ls_1                â”‚ Identity                        â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m567[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.1.ln_1_kv             â”‚ LayerNorm                       â”‚  1.5 K â”‚ train â”‚
â”‚[2m [0m[2m568[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.1.ln_2                â”‚ LayerNorm                       â”‚  1.5 K â”‚ train â”‚
â”‚[2m [0m[2m569[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.1.mlp                 â”‚ Sequential                      â”‚  4.7 M â”‚ train â”‚
â”‚[2m [0m[2m570[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.1.mlp.c_fc            â”‚ Linear                          â”‚  2.4 M â”‚ train â”‚
â”‚[2m [0m[2m571[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.1.mlp.gelu            â”‚ GELU                            â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m572[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.1.mlp.c_proj          â”‚ Linear                          â”‚  2.4 M â”‚ train â”‚
â”‚[2m [0m[2m573[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.1.ls_2                â”‚ Identity                        â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m574[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.2                     â”‚ ResidualAttentionBlock          â”‚  7.1 M â”‚ train â”‚
â”‚[2m [0m[2m575[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.2.ln_1                â”‚ LayerNorm                       â”‚  1.5 K â”‚ train â”‚
â”‚[2m [0m[2m576[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.2.attn                â”‚ MultiheadAttention              â”‚  2.4 M â”‚ train â”‚
â”‚[2m [0m[2m577[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.2.attn.out_proj       â”‚ NonDynamicallyQuantizableLinear â”‚  590 K â”‚ train â”‚
â”‚[2m [0m[2m578[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.2.ls_1                â”‚ Identity                        â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m579[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.2.ln_1_kv             â”‚ LayerNorm                       â”‚  1.5 K â”‚ train â”‚
â”‚[2m [0m[2m580[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.2.ln_2                â”‚ LayerNorm                       â”‚  1.5 K â”‚ train â”‚
â”‚[2m [0m[2m581[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.2.mlp                 â”‚ Sequential                      â”‚  4.7 M â”‚ train â”‚
â”‚[2m [0m[2m582[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.2.mlp.c_fc            â”‚ Linear                          â”‚  2.4 M â”‚ train â”‚
â”‚[2m [0m[2m583[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.2.mlp.gelu            â”‚ GELU                            â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m584[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.2.mlp.c_proj          â”‚ Linear                          â”‚  2.4 M â”‚ train â”‚
â”‚[2m [0m[2m585[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.2.ls_2                â”‚ Identity                        â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m586[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.3                     â”‚ ResidualAttentionBlock          â”‚  7.1 M â”‚ train â”‚
â”‚[2m [0m[2m587[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.3.ln_1                â”‚ LayerNorm                       â”‚  1.5 K â”‚ train â”‚
â”‚[2m [0m[2m588[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.3.attn                â”‚ MultiheadAttention              â”‚  2.4 M â”‚ train â”‚
â”‚[2m [0m[2m589[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.3.attn.out_proj       â”‚ NonDynamicallyQuantizableLinear â”‚  590 K â”‚ train â”‚
â”‚[2m [0m[2m590[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.3.ls_1                â”‚ Identity                        â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m591[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.3.ln_1_kv             â”‚ LayerNorm                       â”‚  1.5 K â”‚ train â”‚
â”‚[2m [0m[2m592[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.3.ln_2                â”‚ LayerNorm                       â”‚  1.5 K â”‚ train â”‚
â”‚[2m [0m[2m593[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.3.mlp                 â”‚ Sequential                      â”‚  4.7 M â”‚ train â”‚
â”‚[2m [0m[2m594[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.3.mlp.c_fc            â”‚ Linear                          â”‚  2.4 M â”‚ train â”‚
â”‚[2m [0m[2m595[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.3.mlp.gelu            â”‚ GELU                            â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m596[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.3.mlp.c_proj          â”‚ Linear                          â”‚  2.4 M â”‚ train â”‚
â”‚[2m [0m[2m597[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.3.ls_2                â”‚ Identity                        â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m598[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.4                     â”‚ ResidualAttentionBlock          â”‚  7.1 M â”‚ train â”‚
â”‚[2m [0m[2m599[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.4.ln_1                â”‚ LayerNorm                       â”‚  1.5 K â”‚ train â”‚
â”‚[2m [0m[2m600[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.4.attn                â”‚ MultiheadAttention              â”‚  2.4 M â”‚ train â”‚
â”‚[2m [0m[2m601[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.4.attn.out_proj       â”‚ NonDynamicallyQuantizableLinear â”‚  590 K â”‚ train â”‚
â”‚[2m [0m[2m602[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.4.ls_1                â”‚ Identity                        â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m603[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.4.ln_1_kv             â”‚ LayerNorm                       â”‚  1.5 K â”‚ train â”‚
â”‚[2m [0m[2m604[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.4.ln_2                â”‚ LayerNorm                       â”‚  1.5 K â”‚ train â”‚
â”‚[2m [0m[2m605[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.4.mlp                 â”‚ Sequential                      â”‚  4.7 M â”‚ train â”‚
â”‚[2m [0m[2m606[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.4.mlp.c_fc            â”‚ Linear                          â”‚  2.4 M â”‚ train â”‚
â”‚[2m [0m[2m607[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.4.mlp.gelu            â”‚ GELU                            â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m608[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.4.mlp.c_proj          â”‚ Linear                          â”‚  2.4 M â”‚ train â”‚
â”‚[2m [0m[2m609[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.4.ls_2                â”‚ Identity                        â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m610[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.5                     â”‚ ResidualAttentionBlock          â”‚  7.1 M â”‚ train â”‚
â”‚[2m [0m[2m611[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.5.ln_1                â”‚ LayerNorm                       â”‚  1.5 K â”‚ train â”‚
â”‚[2m [0m[2m612[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.5.attn                â”‚ MultiheadAttention              â”‚  2.4 M â”‚ train â”‚
â”‚[2m [0m[2m613[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.5.attn.out_proj       â”‚ NonDynamicallyQuantizableLinear â”‚  590 K â”‚ train â”‚
â”‚[2m [0m[2m614[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.5.ls_1                â”‚ Identity                        â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m615[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.5.ln_1_kv             â”‚ LayerNorm                       â”‚  1.5 K â”‚ train â”‚
â”‚[2m [0m[2m616[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.5.ln_2                â”‚ LayerNorm                       â”‚  1.5 K â”‚ train â”‚
â”‚[2m [0m[2m617[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.5.mlp                 â”‚ Sequential                      â”‚  4.7 M â”‚ train â”‚
â”‚[2m [0m[2m618[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.5.mlp.c_fc            â”‚ Linear                          â”‚  2.4 M â”‚ train â”‚
â”‚[2m [0m[2m619[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.5.mlp.gelu            â”‚ GELU                            â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m620[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.5.mlp.c_proj          â”‚ Linear                          â”‚  2.4 M â”‚ train â”‚
â”‚[2m [0m[2m621[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.5.ls_2                â”‚ Identity                        â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m622[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.6                     â”‚ ResidualAttentionBlock          â”‚  7.1 M â”‚ train â”‚
â”‚[2m [0m[2m623[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.6.ln_1                â”‚ LayerNorm                       â”‚  1.5 K â”‚ train â”‚
â”‚[2m [0m[2m624[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.6.attn                â”‚ MultiheadAttention              â”‚  2.4 M â”‚ train â”‚
â”‚[2m [0m[2m625[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.6.attn.out_proj       â”‚ NonDynamicallyQuantizableLinear â”‚  590 K â”‚ train â”‚
â”‚[2m [0m[2m626[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.6.ls_1                â”‚ Identity                        â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m627[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.6.ln_1_kv             â”‚ LayerNorm                       â”‚  1.5 K â”‚ train â”‚
â”‚[2m [0m[2m628[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.6.ln_2                â”‚ LayerNorm                       â”‚  1.5 K â”‚ train â”‚
â”‚[2m [0m[2m629[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.6.mlp                 â”‚ Sequential                      â”‚  4.7 M â”‚ train â”‚
â”‚[2m [0m[2m630[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.6.mlp.c_fc            â”‚ Linear                          â”‚  2.4 M â”‚ train â”‚
â”‚[2m [0m[2m631[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.6.mlp.gelu            â”‚ GELU                            â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m632[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.6.mlp.c_proj          â”‚ Linear                          â”‚  2.4 M â”‚ train â”‚
â”‚[2m [0m[2m633[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.6.ls_2                â”‚ Identity                        â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m634[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.7                     â”‚ ResidualAttentionBlock          â”‚  7.1 M â”‚ train â”‚
â”‚[2m [0m[2m635[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.7.ln_1                â”‚ LayerNorm                       â”‚  1.5 K â”‚ train â”‚
â”‚[2m [0m[2m636[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.7.attn                â”‚ MultiheadAttention              â”‚  2.4 M â”‚ train â”‚
â”‚[2m [0m[2m637[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.7.attn.out_proj       â”‚ NonDynamicallyQuantizableLinear â”‚  590 K â”‚ train â”‚
â”‚[2m [0m[2m638[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.7.ls_1                â”‚ Identity                        â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m639[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.7.ln_1_kv             â”‚ LayerNorm                       â”‚  1.5 K â”‚ train â”‚
â”‚[2m [0m[2m640[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.7.ln_2                â”‚ LayerNorm                       â”‚  1.5 K â”‚ train â”‚
â”‚[2m [0m[2m641[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.7.mlp                 â”‚ Sequential                      â”‚  4.7 M â”‚ train â”‚
â”‚[2m [0m[2m642[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.7.mlp.c_fc            â”‚ Linear                          â”‚  2.4 M â”‚ train â”‚
â”‚[2m [0m[2m643[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.7.mlp.gelu            â”‚ GELU                            â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m644[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.7.mlp.c_proj          â”‚ Linear                          â”‚  2.4 M â”‚ train â”‚
â”‚[2m [0m[2m645[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.7.ls_2                â”‚ Identity                        â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m646[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.8                     â”‚ ResidualAttentionBlock          â”‚  7.1 M â”‚ train â”‚
â”‚[2m [0m[2m647[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.8.ln_1                â”‚ LayerNorm                       â”‚  1.5 K â”‚ train â”‚
â”‚[2m [0m[2m648[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.8.attn                â”‚ MultiheadAttention              â”‚  2.4 M â”‚ train â”‚
â”‚[2m [0m[2m649[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.8.attn.out_proj       â”‚ NonDynamicallyQuantizableLinear â”‚  590 K â”‚ train â”‚
â”‚[2m [0m[2m650[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.8.ls_1                â”‚ Identity                        â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m651[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.8.ln_1_kv             â”‚ LayerNorm                       â”‚  1.5 K â”‚ train â”‚
â”‚[2m [0m[2m652[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.8.ln_2                â”‚ LayerNorm                       â”‚  1.5 K â”‚ train â”‚
â”‚[2m [0m[2m653[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.8.mlp                 â”‚ Sequential                      â”‚  4.7 M â”‚ train â”‚
â”‚[2m [0m[2m654[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.8.mlp.c_fc            â”‚ Linear                          â”‚  2.4 M â”‚ train â”‚
â”‚[2m [0m[2m655[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.8.mlp.gelu            â”‚ GELU                            â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m656[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.8.mlp.c_proj          â”‚ Linear                          â”‚  2.4 M â”‚ train â”‚
â”‚[2m [0m[2m657[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.8.ls_2                â”‚ Identity                        â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m658[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.9                     â”‚ ResidualAttentionBlock          â”‚  7.1 M â”‚ train â”‚
â”‚[2m [0m[2m659[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.9.ln_1                â”‚ LayerNorm                       â”‚  1.5 K â”‚ train â”‚
â”‚[2m [0m[2m660[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.9.attn                â”‚ MultiheadAttention              â”‚  2.4 M â”‚ train â”‚
â”‚[2m [0m[2m661[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.9.attn.out_proj       â”‚ NonDynamicallyQuantizableLinear â”‚  590 K â”‚ train â”‚
â”‚[2m [0m[2m662[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.9.ls_1                â”‚ Identity                        â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m663[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.9.ln_1_kv             â”‚ LayerNorm                       â”‚  1.5 K â”‚ train â”‚
â”‚[2m [0m[2m664[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.9.ln_2                â”‚ LayerNorm                       â”‚  1.5 K â”‚ train â”‚
â”‚[2m [0m[2m665[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.9.mlp                 â”‚ Sequential                      â”‚  4.7 M â”‚ train â”‚
â”‚[2m [0m[2m666[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.9.mlp.c_fc            â”‚ Linear                          â”‚  2.4 M â”‚ train â”‚
â”‚[2m [0m[2m667[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.9.mlp.gelu            â”‚ GELU                            â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m668[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.9.mlp.c_proj          â”‚ Linear                          â”‚  2.4 M â”‚ train â”‚
â”‚[2m [0m[2m669[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.9.ls_2                â”‚ Identity                        â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m670[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.10                    â”‚ ResidualAttentionBlock          â”‚  7.1 M â”‚ train â”‚
â”‚[2m [0m[2m671[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.10.ln_1               â”‚ LayerNorm                       â”‚  1.5 K â”‚ train â”‚
â”‚[2m [0m[2m672[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.10.attn               â”‚ MultiheadAttention              â”‚  2.4 M â”‚ train â”‚
â”‚[2m [0m[2m673[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.10.attn.out_proj      â”‚ NonDynamicallyQuantizableLinear â”‚  590 K â”‚ train â”‚
â”‚[2m [0m[2m674[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.10.ls_1               â”‚ Identity                        â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m675[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.10.ln_1_kv            â”‚ LayerNorm                       â”‚  1.5 K â”‚ train â”‚
â”‚[2m [0m[2m676[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.10.ln_2               â”‚ LayerNorm                       â”‚  1.5 K â”‚ train â”‚
â”‚[2m [0m[2m677[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.10.mlp                â”‚ Sequential                      â”‚  4.7 M â”‚ train â”‚
â”‚[2m [0m[2m678[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.10.mlp.c_fc           â”‚ Linear                          â”‚  2.4 M â”‚ train â”‚
â”‚[2m [0m[2m679[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.10.mlp.gelu           â”‚ GELU                            â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m680[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.10.mlp.c_proj         â”‚ Linear                          â”‚  2.4 M â”‚ train â”‚
â”‚[2m [0m[2m681[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.10.ls_2               â”‚ Identity                        â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m682[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.11                    â”‚ ResidualAttentionBlock          â”‚  7.1 M â”‚ train â”‚
â”‚[2m [0m[2m683[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.11.ln_1               â”‚ LayerNorm                       â”‚  1.5 K â”‚ train â”‚
â”‚[2m [0m[2m684[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.11.attn               â”‚ MultiheadAttention              â”‚  2.4 M â”‚ train â”‚
â”‚[2m [0m[2m685[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.11.attn.out_proj      â”‚ NonDynamicallyQuantizableLinear â”‚  590 K â”‚ train â”‚
â”‚[2m [0m[2m686[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.11.ls_1               â”‚ Identity                        â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m687[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.11.ln_1_kv            â”‚ LayerNorm                       â”‚  1.5 K â”‚ train â”‚
â”‚[2m [0m[2m688[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.11.ln_2               â”‚ LayerNorm                       â”‚  1.5 K â”‚ train â”‚
â”‚[2m [0m[2m689[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.11.mlp                â”‚ Sequential                      â”‚  4.7 M â”‚ train â”‚
â”‚[2m [0m[2m690[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.11.mlp.c_fc           â”‚ Linear                          â”‚  2.4 M â”‚ train â”‚
â”‚[2m [0m[2m691[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.11.mlp.gelu           â”‚ GELU                            â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m692[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.11.mlp.c_proj         â”‚ Linear                          â”‚  2.4 M â”‚ train â”‚
â”‚[2m [0m[2m693[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.11.ls_2               â”‚ Identity                        â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m694[0m[2m [0mâ”‚ net.model.text_decoder.ln_final                         â”‚ LayerNorm                       â”‚  1.5 K â”‚ train â”‚
â”‚[2m [0m[2m695[0m[2m [0mâ”‚ net.tta_loss                                            â”‚ ByolLoss                        â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m696[0m[2m [0mâ”‚ net.video_proj                                          â”‚ VideoProjector                  â”‚  591 K â”‚ train â”‚
â”‚[2m [0m[2m697[0m[2m [0mâ”‚ net.video_proj.transform                                â”‚ Sequential                      â”‚  1.5 K â”‚ train â”‚
â”‚[2m [0m[2m698[0m[2m [0mâ”‚ net.video_proj.transform.0                              â”‚ LayerNorm                       â”‚  1.5 K â”‚ train â”‚
â”‚[2m [0m[2m699[0m[2m [0mâ”‚ net.video_proj.transform.1                              â”‚ Dropout                         â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m700[0m[2m [0mâ”‚ net.fusion                                              â”‚ Fusion                          â”‚  6.2 K â”‚ train â”‚
â”‚[2m [0m[2m701[0m[2m [0mâ”‚ net.fusion.attn                                         â”‚ Sequential                      â”‚  6.2 K â”‚ train â”‚
â”‚[2m [0m[2m702[0m[2m [0mâ”‚ net.fusion.attn.0                                       â”‚ Linear                          â”‚  6.1 K â”‚ train â”‚
â”‚[2m [0m[2m703[0m[2m [0mâ”‚ net.fusion.attn.1                                       â”‚ Linear                          â”‚     10 â”‚ train â”‚
â”‚[2m [0m[2m704[0m[2m [0mâ”‚ net.fusion.attn.2                                       â”‚ Softmax                         â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m705[0m[2m [0mâ”‚ binary_acc                                              â”‚ BinaryAccuracy                  â”‚      0 â”‚ train â”‚
â””â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”˜
[1mTrainable params[0m: 1.2 M
[1mNon-trainable params[0m: 637 M
[1mTotal params[0m: 639 M
[1mTotal estimated model params size (MB)[0m: 2.6 K
[1mModules in train mode[0m: 706
[1mModules in eval mode[0m: 0
/home/def/miniforge3/envs/fewshot/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:425: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.
`Trainer.fit` stopped: `max_epochs=0` reached.
[[36m2025-02-14 10:05:18,209[0m][[34m__main__[0m][[32mINFO[0m] - Starting testing![0m
[[36m2025-02-14 10:05:18,210[0m][[34m__main__[0m][[33mWARNING[0m] - Best ckpt not found! Using current weights for testing...[0m
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
/home/def/miniforge3/envs/fewshot/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:425: The 'test_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.
[2KStart testing...
[2KAttention weights: tensor([[0.5594, 0.4406],â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 0/203 [2m0:00:00 â€¢ -:--:--[0m [2;4m0.00it/s[0m  
        [0.5545, 0.4455],
        [0.5568, 0.4432],
        [0.5564, 0.4436],
        [0.5544, 0.4456],
        [0.5536, 0.4464],
        [0.5548, 0.4452],
        [0.5578, 0.4422],
        [0.5589, 0.4411],
[2K        [0.5551, 0.4449]], device='cuda:0', grad_fn=<SoftmaxBackward0>):00:00 â€¢ -:--:--[0m [2;4m0.00it/s[0m  
[2K/home/def/fewshot/src/models/components/tt_method.py:317: UserWarning: The use of `x.T` on tensors of dimension other than 2 to reverse their shape is deprecated and it will throw an error in a future release. Consider `x.mT` to transpose batches of matrices or
`x.permute(*torch.arange(x.ndim - 1, -1, -1))` to reverse the dimensions of a tensor. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3683.)
  dot_product = (x @ y.T)
[2KClass label: HighJumpâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 0/203 [2m0:00:00 â€¢ -:--:--[0m [2;4m0.00it/s[0m  
[2KAttention weights: tensor([[0.6006, 0.3994]], device='cuda:0', grad_fn=<SoftmaxBackward0>)m [2;4m0.00it/s[0m  
[2KStep 0 - TTA Loss: 0.7637â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 0/203 [2m0:00:00 â€¢ -:--:--[0m [2;4m0.00it/s[0m  
[2KAttention weights: tensor([[0.5831, 0.4169]], device='cuda:0', grad_fn=<SoftmaxBackward0>)m [2;4m0.00it/s[0m  
[2KAttention weights: tensor([[0.5471, 0.4529]], device='cuda:0', grad_fn=<SoftmaxBackward0>)m [2;4m0.00it/s[0m  
[2KAttention weights: tensor([[0.4905, 0.5095]], device='cuda:0', grad_fn=<SoftmaxBackward0>)m [2;4m0.00it/s[0m  
[2KAttention weights: tensor([[0.4887, 0.5113]], device='cuda:0', grad_fn=<SoftmaxBackward0>)m [2;4m0.00it/s[0m  
[2KAttention weights: tensor([[0.5206, 0.4794]], device='cuda:0', grad_fn=<SoftmaxBackward0>)m [2;4m0.00it/s[0m  
[2KAttention weights: tensor([[0.5534, 0.4466]], device='cuda:0', grad_fn=<SoftmaxBackward0>)m [2;4m0.00it/s[0m  
[2KAttention weights: tensor([[0.5780, 0.4220]], device='cuda:0', grad_fn=<SoftmaxBackward0>)m [2;4m0.00it/s[0m  
[2KAttention weights: tensor([[0.5927, 0.4073]], device='cuda:0', grad_fn=<SoftmaxBackward0>)m [2;4m0.00it/s[0m  
[2KAttention weights: tensor([[0.5992, 0.4008]], device='cuda:0', grad_fn=<SoftmaxBackward0>)m [2;4m0.00it/s[0m  
[2KAttention weights: tensor([[0.5530, 0.4470]], device='cuda:0')203 [2m0:00:00 â€¢ -:--:--[0m [2;4m0.00it/s[0m  
[2KAttention weights: tensor([[0.6431, 0.3569],â”â”â”â”â”â”â”â”â”â”â”[0m 0/203 [2m0:00:00 â€¢ -:--:--[0m [2;4m0.00it/s[0m  
        [0.5988, 0.4012],
        [0.6204, 0.3796],
        [0.6057, 0.3943],
        [0.5395, 0.4605],
        [0.6007, 0.3993],
        [0.6129, 0.3871],
        [0.6368, 0.3632],
        [0.6621, 0.3379],
[2K        [0.6141, 0.3859]], device='cuda:0')â”â”â”â”â”â”â”â”â”â”â”â”[0m 0/203 [2m0:00:00 â€¢ -:--:--[0m [2;4m0.00it/s[0m  
[2KAttention weights: tensor([[0.5594, 0.4406],â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 1/203 [2m0:00:02 â€¢ -:--:--[0m [2;4m0.00it/s[0m  
        [0.5545, 0.4455],
        [0.5568, 0.4432],
        [0.5564, 0.4436],
        [0.5544, 0.4456],
        [0.5536, 0.4464],
        [0.5548, 0.4452],
        [0.5578, 0.4422],
        [0.5590, 0.4410],
[2K        [0.5551, 0.4449]], device='cuda:0', grad_fn=<SoftmaxBackward0>):00:02 â€¢ -:--:--[0m [2;4m0.00it/s[0m  
[2KClass label: HammerThrowâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 1/203 [2m0:00:02 â€¢ -:--:--[0m [2;4m0.00it/s[0m  
[2KAttention weights: tensor([[0.5355, 0.4644]], device='cuda:0', grad_fn=<SoftmaxBackward0>)m [2;4m0.00it/s[0m  
[2KStep 0 - TTA Loss: 0.9328â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 1/203 [2m0:00:02 â€¢ -:--:--[0m [2;4m0.00it/s[0m  
[2KAttention weights: tensor([[0.5355, 0.4644]], device='cuda:0', grad_fn=<SoftmaxBackward0>)m [2;4m0.00it/s[0m  
[2KAttention weights: tensor([[0.5361, 0.4639]], device='cuda:0', grad_fn=<SoftmaxBackward0>)m [2;4m0.00it/s[0m  
[2KAttention weights: tensor([[0.5385, 0.4615]], device='cuda:0', grad_fn=<SoftmaxBackward0>)m [2;4m0.00it/s[0m  
[2KAttention weights: tensor([[0.5441, 0.4559]], device='cuda:0', grad_fn=<SoftmaxBackward0>)m [2;4m0.00it/s[0m  
[2KAttention weights: tensor([[0.5514, 0.4486]], device='cuda:0', grad_fn=<SoftmaxBackward0>)m [2;4m0.00it/s[0m  
[2KAttention weights: tensor([[0.5607, 0.4393]], device='cuda:0', grad_fn=<SoftmaxBackward0>)m [2;4m0.00it/s[0m  
[2KAttention weights: tensor([[0.5658, 0.4342]], device='cuda:0', grad_fn=<SoftmaxBackward0>)m [2;4m0.00it/s[0m  
[2KAttention weights: tensor([[0.5619, 0.4381]], device='cuda:0', grad_fn=<SoftmaxBackward0>)m [2;4m0.00it/s[0m  
[2KAttention weights: tensor([[0.5479, 0.4521]], device='cuda:0', grad_fn=<SoftmaxBackward0>)m [2;4m0.00it/s[0m  
[2KAttention weights: tensor([[0.5544, 0.4456]], device='cuda:0')203 [2m0:00:02 â€¢ -:--:--[0m [2;4m0.00it/s[0m  
[2KAttention weights: tensor([[0.6476, 0.3524],â”â”â”â”â”â”â”â”â”â”â”[0m 1/203 [2m0:00:02 â€¢ -:--:--[0m [2;4m0.00it/s[0m  
        [0.6038, 0.3962],
        [0.6340, 0.3660],
        [0.6169, 0.3831],
        [0.5303, 0.4697],
        [0.6509, 0.3491],
        [0.6401, 0.3599],
        [0.6521, 0.3479],
        [0.6805, 0.3195],
[2K        [0.6307, 0.3693]], device='cuda:0')â”â”â”â”â”â”â”â”â”â”â”â”[0m 1/203 [2m0:00:02 â€¢ -:--:--[0m [2;4m0.00it/s[0m  
[2KAttention weights: tensor([[0.5594, 0.4406],â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 2/203 [2m0:00:04 â€¢ 0:05:22[0m [2;4m0.62it/s[0m  
        [0.5545, 0.4455],
        [0.5567, 0.4433],
        [0.5564, 0.4436],
        [0.5544, 0.4456],
        [0.5536, 0.4464],
        [0.5547, 0.4453],
        [0.5578, 0.4422],
        [0.5589, 0.4411],
[2K        [0.5550, 0.4450]], device='cuda:0', grad_fn=<SoftmaxBackward0>):00:04 â€¢ 0:05:22[0m [2;4m0.62it/s[0m  
[2KClass label: TennisSwingâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 2/203 [2m0:00:04 â€¢ 0:05:22[0m [2;4m0.62it/s[0m  
[2KAttention weights: tensor([[0.6635, 0.3365]], device='cuda:0', grad_fn=<SoftmaxBackward0>)m [2;4m0.62it/s[0m  
[2KStep 0 - TTA Loss: 0.5947â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 2/203 [2m0:00:04 â€¢ 0:05:22[0m [2;4m0.62it/s[0m  
[2KAttention weights: tensor([[0.6511, 0.3489]], device='cuda:0', grad_fn=<SoftmaxBackward0>)m [2;4m0.62it/s[0m  
[2KAttention weights: tensor([[0.6293, 0.3707]], device='cuda:0', grad_fn=<SoftmaxBackward0>)m [2;4m0.62it/s[0m  
[2KAttention weights: tensor([[0.6032, 0.3968]], device='cuda:0', grad_fn=<SoftmaxBackward0>)m [2;4m0.62it/s[0m  
[2KAttention weights: tensor([[0.5744, 0.4256]], device='cuda:0', grad_fn=<SoftmaxBackward0>)m [2;4m0.62it/s[0m  
[2KAttention weights: tensor([[0.5482, 0.4518]], device='cuda:0', grad_fn=<SoftmaxBackward0>)m [2;4m0.62it/s[0m  
[2KAttention weights: tensor([[0.5295, 0.4705]], device='cuda:0', grad_fn=<SoftmaxBackward0>)m [2;4m0.62it/s[0m  
[2KAttention weights: tensor([[0.5184, 0.4816]], device='cuda:0', grad_fn=<SoftmaxBackward0>)m [2;4m0.62it/s[0m  
[2KAttention weights: tensor([[0.5144, 0.4856]], device='cuda:0', grad_fn=<SoftmaxBackward0>)m [2;4m0.62it/s[0m  
[2KAttention weights: tensor([[0.5131, 0.4869]], device='cuda:0', grad_fn=<SoftmaxBackward0>)m [2;4m0.62it/s[0m  
[2KAttention weights: tensor([[0.5536, 0.4464]], device='cuda:0')203 [2m0:00:04 â€¢ 0:05:22[0m [2;4m0.62it/s[0m  
[2KAttention weights: tensor([[0.5411, 0.4589],â”â”â”â”â”â”â”â”â”â”â”[0m 2/203 [2m0:00:04 â€¢ 0:05:22[0m [2;4m0.62it/s[0m  
        [0.5248, 0.4752],
        [0.5409, 0.4591],
        [0.5057, 0.4943],
        [0.4111, 0.5889],
        [0.5295, 0.4705],
        [0.5497, 0.4503],
        [0.5384, 0.4616],
        [0.5129, 0.4871],
[2K        [0.5208, 0.4792]], device='cuda:0')â”â”â”â”â”â”â”â”â”â”â”â”[0m 2/203 [2m0:00:04 â€¢ 0:05:22[0m [2;4m0.62it/s[0m  
[2KAttention weights: tensor([[0.5592, 0.4408],â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 3/203 [2m0:00:05 â€¢ 0:04:27[0m [2;4m0.75it/s[0m  
        [0.5544, 0.4456],
        [0.5566, 0.4434],
        [0.5562, 0.4438],
        [0.5541, 0.4459],
        [0.5535, 0.4465],
        [0.5546, 0.4454],
        [0.5576, 0.4424],
        [0.5587, 0.4413],
[2K        [0.5549, 0.4451]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”[0m 3/203 [2m0:00:05 â€¢ 0:04:27[0m [2;4m0.75it/s[0m  
[2KClass label: HighJump[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 3/203 [2m0:00:05 â€¢ 0:04:27[0m [2;4m0.75it/s[0m  
[2KAttention weights: tensor([[0.6016, 0.3984]], device='cuda:0', grad_fn=<SoftmaxBackward0>)0:00:05 â€¢ 0:04:27[0m [2;4m0.75it/s[0m  
[2KStep 0 - TTA Loss: 0.6633[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 3/203 [2m0:00:05 â€¢ 0:04:27[0m [2;4m0.75it/s[0m  
[2KAttention weights: tensor([[0.6016, 0.3984]], device='cuda:0', grad_fn=<SoftmaxBackward0>)0:00:05 â€¢ 0:04:27[0m [2;4m0.75it/s[0m  
[2KAttention weights: tensor([[0.6023, 0.3977]], device='cuda:0', grad_fn=<SoftmaxBackward0>)0:00:05 â€¢ 0:04:27[0m [2;4m0.75it/s[0m  
[2KAttention weights: tensor([[0.6063, 0.3937]], device='cuda:0', grad_fn=<SoftmaxBackward0>)0:00:05 â€¢ 0:04:27[0m [2;4m0.75it/s[0m  
[2KAttention weights: tensor([[0.6181, 0.3819]], device='cuda:0', grad_fn=<SoftmaxBackward0>)0:00:05 â€¢ 0:04:27[0m [2;4m0.75it/s[0m  
[2KAttention weights: tensor([[0.6415, 0.3585]], device='cuda:0', grad_fn=<SoftmaxBackward0>)0:00:05 â€¢ 0:04:27[0m [2;4m0.75it/s[0m  
[2KAttention weights: tensor([[0.6776, 0.3224]], device='cuda:0', grad_fn=<SoftmaxBackward0>)0:00:05 â€¢ 0:04:27[0m [2;4m0.75it/s[0m  
[2KAttention weights: tensor([[0.7182, 0.2818]], device='cuda:0', grad_fn=<SoftmaxBackward0>)0:00:05 â€¢ 0:04:27[0m [2;4m0.75it/s[0m  
[2KAttention weights: tensor([[0.7540, 0.2460]], device='cuda:0', grad_fn=<SoftmaxBackward0>)0:00:05 â€¢ 0:04:27[0m [2;4m0.75it/s[0m  
[2KAttention weights: tensor([[0.7761, 0.2239]], device='cuda:0', grad_fn=<SoftmaxBackward0>)0:00:05 â€¢ 0:04:27[0m [2;4m0.75it/s[0m  
[2KAttention weights: tensor([[0.5588, 0.4412]], device='cuda:0')â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 3/203 [2m0:00:05 â€¢ 0:04:27[0m [2;4m0.75it/s[0m  
[2KAttention weights: tensor([[0.7408, 0.2592],â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 3/203 [2m0:00:05 â€¢ 0:04:27[0m [2;4m0.75it/s[0m  
        [0.6785, 0.3215],
        [0.7240, 0.2760],
        [0.7075, 0.2925],
        [0.6790, 0.3210],
        [0.8083, 0.1917],
        [0.7616, 0.2384],
        [0.7613, 0.2387],
        [0.7668, 0.2332],
[2K        [0.7369, 0.2631]], device='cuda:0')â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 3/203 [2m0:00:05 â€¢ 0:04:27[0m [2;4m0.75it/s[0m  
[2KAttention weights: tensor([[0.5592, 0.4408],â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 4/203 [2m0:00:12 â€¢ 0:11:26[0m [2;4m0.29it/s[0m  
        [0.5544, 0.4456],
        [0.5566, 0.4434],
        [0.5562, 0.4438],
        [0.5541, 0.4459],
        [0.5535, 0.4465],
        [0.5546, 0.4454],
        [0.5576, 0.4424],
        [0.5587, 0.4413],
[2K        [0.5548, 0.4452]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”[0m 4/203 [2m0:00:12 â€¢ 0:11:26[0m [2;4m0.29it/s[0m  
[2KClass label: GolfSwing[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 4/203 [2m0:00:12 â€¢ 0:11:26[0m [2;4m0.29it/s[0m  
[2KAttention weights: tensor([[0.6092, 0.3908]], device='cuda:0', grad_fn=<SoftmaxBackward0>)0:00:12 â€¢ 0:11:26[0m [2;4m0.29it/s[0m  
[2KStep 0 - TTA Loss: 0.8853[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 4/203 [2m0:00:12 â€¢ 0:11:26[0m [2;4m0.29it/s[0m  
[2KAttention weights: tensor([[0.6237, 0.3763]], device='cuda:0', grad_fn=<SoftmaxBackward0>)0:00:12 â€¢ 0:11:26[0m [2;4m0.29it/s[0m  
[2KAttention weights: tensor([[0.6309, 0.3691]], device='cuda:0', grad_fn=<SoftmaxBackward0>)0:00:12 â€¢ 0:11:26[0m [2;4m0.29it/s[0m  
[2KAttention weights: tensor([[0.6321, 0.3679]], device='cuda:0', grad_fn=<SoftmaxBackward0>)0:00:12 â€¢ 0:11:26[0m [2;4m0.29it/s[0m  
[2KAttention weights: tensor([[0.6250, 0.3750]], device='cuda:0', grad_fn=<SoftmaxBackward0>)0:00:12 â€¢ 0:11:26[0m [2;4m0.29it/s[0m  
[2KAttention weights: tensor([[0.6128, 0.3872]], device='cuda:0', grad_fn=<SoftmaxBackward0>)0:00:12 â€¢ 0:11:26[0m [2;4m0.29it/s[0m  
[2KAttention weights: tensor([[0.5977, 0.4023]], device='cuda:0', grad_fn=<SoftmaxBackward0>)0:00:12 â€¢ 0:11:26[0m [2;4m0.29it/s[0m  
[2KAttention weights: tensor([[0.5838, 0.4162]], device='cuda:0', grad_fn=<SoftmaxBackward0>)0:00:12 â€¢ 0:11:26[0m [2;4m0.29it/s[0m  
[2KAttention weights: tensor([[0.5723, 0.4277]], device='cuda:0', grad_fn=<SoftmaxBackward0>)0:00:12 â€¢ 0:11:26[0m [2;4m0.29it/s[0m  
[2KAttention weights: tensor([[0.5658, 0.4342]], device='cuda:0', grad_fn=<SoftmaxBackward0>)0:00:12 â€¢ 0:11:26[0m [2;4m0.29it/s[0m  
[2KAttention weights: tensor([[0.5546, 0.4454]], device='cuda:0')â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 4/203 [2m0:00:12 â€¢ 0:11:26[0m [2;4m0.29it/s[0m  
[2KAttention weights: tensor([[0.6638, 0.3362],â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 4/203 [2m0:00:12 â€¢ 0:11:26[0m [2;4m0.29it/s[0m  
        [0.6177, 0.3823],
        [0.6666, 0.3334],
        [0.5639, 0.4361],
        [0.6026, 0.3974],
        [0.7323, 0.2677],
        [0.6952, 0.3048],
        [0.6785, 0.3215],
        [0.6904, 0.3096],
[2K        [0.6709, 0.3291]], device='cuda:0')â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 4/203 [2m0:00:12 â€¢ 0:11:26[0m [2;4m0.29it/s[0m  
[2KAttention weights: tensor([[0.5592, 0.4408],â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 5/203 [2m0:00:13 â€¢ 0:09:06[0m [2;4m0.36it/s[0m  
        [0.5544, 0.4456],
        [0.5566, 0.4434],
        [0.5561, 0.4439],
        [0.5541, 0.4459],
        [0.5534, 0.4466],
        [0.5546, 0.4454],
        [0.5576, 0.4424],
        [0.5586, 0.4414],
[2K        [0.5548, 0.4452]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”[0m 5/203 [2m0:00:13 â€¢ 0:09:06[0m [2;4m0.36it/s[0m  
[2KClass label: HammerThrowm[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 5/203 [2m0:00:13 â€¢ 0:09:06[0m [2;4m0.36it/s[0m  
[2KAttention weights: tensor([[0.5441, 0.4559]], device='cuda:0', grad_fn=<SoftmaxBackward0>)0:00:13 â€¢ 0:09:06[0m [2;4m0.36it/s[0m  
[2KStep 0 - TTA Loss: 0.6748[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 5/203 [2m0:00:13 â€¢ 0:09:06[0m [2;4m0.36it/s[0m  
[2KAttention weights: tensor([[0.5441, 0.4559]], device='cuda:0', grad_fn=<SoftmaxBackward0>)0:00:13 â€¢ 0:09:06[0m [2;4m0.36it/s[0m  
[2KAttention weights: tensor([[0.5436, 0.4564]], device='cuda:0', grad_fn=<SoftmaxBackward0>)0:00:13 â€¢ 0:09:06[0m [2;4m0.36it/s[0m  
[2KAttention weights: tensor([[0.5415, 0.4585]], device='cuda:0', grad_fn=<SoftmaxBackward0>)0:00:13 â€¢ 0:09:06[0m [2;4m0.36it/s[0m  
[2KAttention weights: tensor([[0.5357, 0.4643]], device='cuda:0', grad_fn=<SoftmaxBackward0>)0:00:13 â€¢ 0:09:06[0m [2;4m0.36it/s[0m  
[2KAttention weights: tensor([[0.5268, 0.4732]], device='cuda:0', grad_fn=<SoftmaxBackward0>)0:00:13 â€¢ 0:09:06[0m [2;4m0.36it/s[0m  
[2KAttention weights: tensor([[0.5131, 0.4869]], device='cuda:0', grad_fn=<SoftmaxBackward0>)0:00:13 â€¢ 0:09:06[0m [2;4m0.36it/s[0m  
[2KAttention weights: tensor([[0.4893, 0.5107]], device='cuda:0', grad_fn=<SoftmaxBackward0>)0:00:13 â€¢ 0:09:06[0m [2;4m0.36it/s[0m  
[2KAttention weights: tensor([[0.4532, 0.5468]], device='cuda:0', grad_fn=<SoftmaxBackward0>)0:00:13 â€¢ 0:09:06[0m [2;4m0.36it/s[0m  
[2KAttention weights: tensor([[0.4133, 0.5867]], device='cuda:0', grad_fn=<SoftmaxBackward0>)0:00:13 â€¢ 0:09:06[0m [2;4m0.36it/s[0m  
[2KAttention weights: tensor([[0.5511, 0.4489]], device='cuda:0')â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 5/203 [2m0:00:13 â€¢ 0:09:06[0m [2;4m0.36it/s[0m  
[2KAttention weights: tensor([[0.5105, 0.4895],â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 5/203 [2m0:00:13 â€¢ 0:09:06[0m [2;4m0.36it/s[0m  
        [0.5061, 0.4939],
        [0.5327, 0.4673],
        [0.4034, 0.5966],
        [0.3912, 0.6088],
        [0.5134, 0.4866],
        [0.5258, 0.4742],
        [0.5081, 0.4919],
        [0.5425, 0.4575],
[2K        [0.5082, 0.4918]], device='cuda:0')â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 5/203 [2m0:00:13 â€¢ 0:09:06[0m [2;4m0.36it/s[0m  
[2KAttention weights: tensor([[0.5591, 0.4409],m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 6/203 [2m0:00:15 â€¢ 0:08:22[0m [2;4m0.39it/s[0m  
        [0.5543, 0.4457],
        [0.5565, 0.4435],
        [0.5561, 0.4439],
        [0.5541, 0.4459],
        [0.5534, 0.4466],
        [0.5545, 0.4455],
        [0.5576, 0.4424],
        [0.5586, 0.4414],
[2K        [0.5548, 0.4452]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 6/203 [2m0:00:15 â€¢ 0:08:22[0m [2;4m0.39it/s[0m  
[2KClass label: HammerThrowm[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 6/203 [2m0:00:15 â€¢ 0:08:22[0m [2;4m0.39it/s[0m  
[2KAttention weights: tensor([[0.5313, 0.4687]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 6/203 [2m0:00:15 â€¢ 0:08:22[0m [2;4m0.39it/s[0m  
[2KStep 0 - TTA Loss: 0.7723[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 6/203 [2m0:00:15 â€¢ 0:08:22[0m [2;4m0.39it/s[0m  
[2KAttention weights: tensor([[0.5172, 0.4828]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 6/203 [2m0:00:15 â€¢ 0:08:22[0m [2;4m0.39it/s[0m  
[2KAttention weights: tensor([[0.5066, 0.4934]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 6/203 [2m0:00:15 â€¢ 0:08:22[0m [2;4m0.39it/s[0m  
[2KAttention weights: tensor([[0.4955, 0.5045]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 6/203 [2m0:00:15 â€¢ 0:08:22[0m [2;4m0.39it/s[0m  
[2KAttention weights: tensor([[0.4819, 0.5181]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 6/203 [2m0:00:15 â€¢ 0:08:22[0m [2;4m0.39it/s[0m  
[2KAttention weights: tensor([[0.4684, 0.5316]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 6/203 [2m0:00:15 â€¢ 0:08:22[0m [2;4m0.39it/s[0m  
[2KAttention weights: tensor([[0.4643, 0.5357]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 6/203 [2m0:00:15 â€¢ 0:08:22[0m [2;4m0.39it/s[0m  
[2KAttention weights: tensor([[0.4691, 0.5309]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 6/203 [2m0:00:15 â€¢ 0:08:22[0m [2;4m0.39it/s[0m  
[2KAttention weights: tensor([[0.4733, 0.5267]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 6/203 [2m0:00:15 â€¢ 0:08:22[0m [2;4m0.39it/s[0m  
[2KAttention weights: tensor([[0.4768, 0.5232]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 6/203 [2m0:00:15 â€¢ 0:08:22[0m [2;4m0.39it/s[0m  
[2KAttention weights: tensor([[0.5530, 0.4470]], device='cuda:0')â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 6/203 [2m0:00:15 â€¢ 0:08:22[0m [2;4m0.39it/s[0m  
[2KAttention weights: tensor([[0.5753, 0.4247],8;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 6/203 [2m0:00:15 â€¢ 0:08:22[0m [2;4m0.39it/s[0m  
        [0.5448, 0.4552],
        [0.5785, 0.4215],
        [0.4836, 0.5164],
        [0.4780, 0.5220],
        [0.5621, 0.4379],
        [0.5713, 0.4287],
        [0.5696, 0.4304],
        [0.5971, 0.4029],
[2K        [0.5640, 0.4360]], device='cuda:0')38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 6/203 [2m0:00:15 â€¢ 0:08:22[0m [2;4m0.39it/s[0m  
[2KAttention weights: tensor([[0.5591, 0.4409],m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 7/203 [2m0:00:23 â€¢ 0:11:25[0m [2;4m0.29it/s[0m  
        [0.5543, 0.4457],
        [0.5565, 0.4435],
        [0.5560, 0.4440],
        [0.5541, 0.4459],
        [0.5534, 0.4466],
        [0.5546, 0.4454],
        [0.5576, 0.4424],
        [0.5586, 0.4414],
[2K        [0.5548, 0.4452]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 7/203 [2m0:00:23 â€¢ 0:11:25[0m [2;4m0.29it/s[0m  
[2KClass label: Billiards[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 7/203 [2m0:00:23 â€¢ 0:11:25[0m [2;4m0.29it/s[0m  
[2KAttention weights: tensor([[0.5941, 0.4059]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 7/203 [2m0:00:23 â€¢ 0:11:25[0m [2;4m0.29it/s[0m  
[2KStep 0 - TTA Loss: 0.5127[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 7/203 [2m0:00:23 â€¢ 0:11:25[0m [2;4m0.29it/s[0m  
[2KAttention weights: tensor([[0.5941, 0.4059]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 7/203 [2m0:00:23 â€¢ 0:11:25[0m [2;4m0.29it/s[0m  
[2KAttention weights: tensor([[0.5937, 0.4063]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 7/203 [2m0:00:23 â€¢ 0:11:25[0m [2;4m0.29it/s[0m  
[2KAttention weights: tensor([[0.5911, 0.4089]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 7/203 [2m0:00:23 â€¢ 0:11:25[0m [2;4m0.29it/s[0m  
[2KAttention weights: tensor([[0.5832, 0.4168]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 7/203 [2m0:00:23 â€¢ 0:11:25[0m [2;4m0.29it/s[0m  
[2KAttention weights: tensor([[0.5648, 0.4352]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 7/203 [2m0:00:23 â€¢ 0:11:25[0m [2;4m0.29it/s[0m  
[2KAttention weights: tensor([[0.5296, 0.4704]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 7/203 [2m0:00:23 â€¢ 0:11:25[0m [2;4m0.29it/s[0m  
[2KAttention weights: tensor([[0.4777, 0.5223]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 7/203 [2m0:00:23 â€¢ 0:11:25[0m [2;4m0.29it/s[0m  
[2KAttention weights: tensor([[0.4205, 0.5795]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 7/203 [2m0:00:23 â€¢ 0:11:25[0m [2;4m0.29it/s[0m  
[2KAttention weights: tensor([[0.3820, 0.6180]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 7/203 [2m0:00:23 â€¢ 0:11:25[0m [2;4m0.29it/s[0m  
[2KAttention weights: tensor([[0.5489, 0.4511]], device='cuda:0')â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 7/203 [2m0:00:23 â€¢ 0:11:25[0m [2;4m0.29it/s[0m  
[2KAttention weights: tensor([[0.6160, 0.3840],8;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 7/203 [2m0:00:23 â€¢ 0:11:25[0m [2;4m0.29it/s[0m  
        [0.3728, 0.6272],
        [0.6090, 0.3910],
        [0.5469, 0.4531],
        [0.5665, 0.4335],
        [0.5790, 0.4210],
        [0.5926, 0.4074],
        [0.5850, 0.4150],
        [0.6158, 0.3842],
[2K        [0.6151, 0.3849]], device='cuda:0')38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 7/203 [2m0:00:23 â€¢ 0:11:25[0m [2;4m0.29it/s[0m  
[2KAttention weights: tensor([[0.5591, 0.4409],mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 8/203 [2m0:00:25 â€¢ 0:10:38[0m [2;4m0.31it/s[0m  
        [0.5542, 0.4458],
        [0.5565, 0.4435],
        [0.5560, 0.4440],
        [0.5541, 0.4459],
        [0.5534, 0.4466],
        [0.5545, 0.4455],
        [0.5575, 0.4425],
        [0.5586, 0.4414],
[2K        [0.5548, 0.4452]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 8/203 [2m0:00:25 â€¢ 0:10:38[0m [2;4m0.31it/s[0m  
[2KClass label: BaseballPitch[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 8/203 [2m0:00:25 â€¢ 0:10:38[0m [2;4m0.31it/s[0m  
[2KAttention weights: tensor([[0.6417, 0.3583]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 8/203 [2m0:00:25 â€¢ 0:10:38[0m [2;4m0.31it/s[0m  
[2KStep 0 - TTA Loss: 0.6360[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 8/203 [2m0:00:25 â€¢ 0:10:38[0m [2;4m0.31it/s[0m  
[2KAttention weights: tensor([[0.6427, 0.3573]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 8/203 [2m0:00:25 â€¢ 0:10:38[0m [2;4m0.31it/s[0m  
[2KAttention weights: tensor([[0.6520, 0.3480]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 8/203 [2m0:00:25 â€¢ 0:10:38[0m [2;4m0.31it/s[0m  
[2KAttention weights: tensor([[0.6665, 0.3335]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 8/203 [2m0:00:25 â€¢ 0:10:38[0m [2;4m0.31it/s[0m  
[2KAttention weights: tensor([[0.6773, 0.3227]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 8/203 [2m0:00:25 â€¢ 0:10:38[0m [2;4m0.31it/s[0m  
[2KAttention weights: tensor([[0.6866, 0.3134]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 8/203 [2m0:00:25 â€¢ 0:10:38[0m [2;4m0.31it/s[0m  
[2KAttention weights: tensor([[0.6871, 0.3129]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 8/203 [2m0:00:25 â€¢ 0:10:38[0m [2;4m0.31it/s[0m  
[2KAttention weights: tensor([[0.6830, 0.3170]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 8/203 [2m0:00:25 â€¢ 0:10:38[0m [2;4m0.31it/s[0m  
[2KAttention weights: tensor([[0.6781, 0.3219]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 8/203 [2m0:00:25 â€¢ 0:10:38[0m [2;4m0.31it/s[0m  
[2KAttention weights: tensor([[0.6745, 0.3255]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 8/203 [2m0:00:25 â€¢ 0:10:38[0m [2;4m0.31it/s[0m  
[2KAttention weights: tensor([[0.5589, 0.4411]], device='cuda:0')â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 8/203 [2m0:00:25 â€¢ 0:10:38[0m [2;4m0.31it/s[0m  
[2KAttention weights: tensor([[0.6733, 0.3267],0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 8/203 [2m0:00:25 â€¢ 0:10:38[0m [2;4m0.31it/s[0m  
        [0.5581, 0.4419],
        [0.6401, 0.3599],
        [0.6103, 0.3897],
        [0.5958, 0.4042],
        [0.6240, 0.3760],
        [0.6358, 0.3642],
        [0.6548, 0.3452],
        [0.6754, 0.3246],
[2K        [0.6409, 0.3591]], device='cuda:0')[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 8/203 [2m0:00:25 â€¢ 0:10:38[0m [2;4m0.31it/s[0m  
[2KAttention weights: tensor([[0.5591, 0.4409],mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 9/203 [2m0:00:26 â€¢ 0:09:50[0m [2;4m0.33it/s[0m  
        [0.5542, 0.4458],
        [0.5565, 0.4435],
        [0.5560, 0.4440],
        [0.5541, 0.4459],
        [0.5534, 0.4466],
        [0.5546, 0.4454],
        [0.5575, 0.4425],
        [0.5586, 0.4414],
[2K        [0.5548, 0.4452]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 9/203 [2m0:00:26 â€¢ 0:09:50[0m [2;4m0.33it/s[0m  
[2KClass label: BaseballPitch[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 9/203 [2m0:00:26 â€¢ 0:09:50[0m [2;4m0.33it/s[0m  
[2KAttention weights: tensor([[0.6435, 0.3565]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 9/203 [2m0:00:26 â€¢ 0:09:50[0m [2;4m0.33it/s[0m  
[2KStep 0 - TTA Loss: 0.5742[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 9/203 [2m0:00:26 â€¢ 0:09:50[0m [2;4m0.33it/s[0m  
[2KAttention weights: tensor([[0.6435, 0.3565]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 9/203 [2m0:00:26 â€¢ 0:09:50[0m [2;4m0.33it/s[0m  
[2KAttention weights: tensor([[0.6427, 0.3573]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 9/203 [2m0:00:26 â€¢ 0:09:50[0m [2;4m0.33it/s[0m  
[2KAttention weights: tensor([[0.6410, 0.3590]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 9/203 [2m0:00:26 â€¢ 0:09:50[0m [2;4m0.33it/s[0m  
[2KAttention weights: tensor([[0.6379, 0.3621]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 9/203 [2m0:00:26 â€¢ 0:09:50[0m [2;4m0.33it/s[0m  
[2KAttention weights: tensor([[0.6344, 0.3656]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 9/203 [2m0:00:26 â€¢ 0:09:50[0m [2;4m0.33it/s[0m  
[2KAttention weights: tensor([[0.6285, 0.3715]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 9/203 [2m0:00:26 â€¢ 0:09:50[0m [2;4m0.33it/s[0m  
[2KAttention weights: tensor([[0.6156, 0.3844]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 9/203 [2m0:00:26 â€¢ 0:09:50[0m [2;4m0.33it/s[0m  
[2KAttention weights: tensor([[0.5879, 0.4121]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 9/203 [2m0:00:26 â€¢ 0:09:50[0m [2;4m0.33it/s[0m  
[2KAttention weights: tensor([[0.5522, 0.4478]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 9/203 [2m0:00:26 â€¢ 0:09:50[0m [2;4m0.33it/s[0m  
[2KAttention weights: tensor([[0.5550, 0.4450]], device='cuda:0')â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 9/203 [2m0:00:26 â€¢ 0:09:50[0m [2;4m0.33it/s[0m  
[2KAttention weights: tensor([[0.5230, 0.4770],0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 9/203 [2m0:00:26 â€¢ 0:09:50[0m [2;4m0.33it/s[0m  
        [0.5451, 0.4549],
        [0.5950, 0.4050],
        [0.5503, 0.4497],
        [0.4913, 0.5087],
        [0.5571, 0.4429],
        [0.5638, 0.4362],
        [0.5714, 0.4286],
        [0.6107, 0.3893],
[2K        [0.5873, 0.4127]], device='cuda:0')[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 9/203 [2m0:00:26 â€¢ 0:09:50[0m [2;4m0.33it/s[0m  
[2KAttention weights: tensor([[0.5590, 0.4410],mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 10/203 [2m0:00:27 â€¢ 0:08:59[0m [2;4m0.36it/s[0m  
        [0.5542, 0.4458],
        [0.5565, 0.4435],
        [0.5559, 0.4441],
        [0.5541, 0.4459],
        [0.5534, 0.4466],
        [0.5545, 0.4455],
        [0.5575, 0.4425],
        [0.5585, 0.4415],
[2K        [0.5548, 0.4452]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 10/203 [2m0:00:27 â€¢ 0:08:59[0m [2;4m0.36it/s[0m  
[2KClass label: TennisSwingm[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 10/203 [2m0:00:27 â€¢ 0:08:59[0m [2;4m0.36it/s[0m  
[2KAttention weights: tensor([[0.6613, 0.3387]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 10/203 [2m0:00:27 â€¢ 0:08:59[0m [2;4m0.36it/s[0m  
[2KStep 0 - TTA Loss: 0.5448[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 10/203 [2m0:00:27 â€¢ 0:08:59[0m [2;4m0.36it/s[0m  
[2KAttention weights: tensor([[0.6474, 0.3526]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 10/203 [2m0:00:27 â€¢ 0:08:59[0m [2;4m0.36it/s[0m  
[2KAttention weights: tensor([[0.6147, 0.3853]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 10/203 [2m0:00:27 â€¢ 0:08:59[0m [2;4m0.36it/s[0m  
[2KAttention weights: tensor([[0.5731, 0.4269]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 10/203 [2m0:00:27 â€¢ 0:08:59[0m [2;4m0.36it/s[0m  
[2KAttention weights: tensor([[0.5310, 0.4690]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 10/203 [2m0:00:27 â€¢ 0:08:59[0m [2;4m0.36it/s[0m  
[2KAttention weights: tensor([[0.4950, 0.5050]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 10/203 [2m0:00:27 â€¢ 0:08:59[0m [2;4m0.36it/s[0m  
[2KAttention weights: tensor([[0.4699, 0.5301]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 10/203 [2m0:00:27 â€¢ 0:08:59[0m [2;4m0.36it/s[0m  
[2KAttention weights: tensor([[0.4580, 0.5420]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 10/203 [2m0:00:27 â€¢ 0:08:59[0m [2;4m0.36it/s[0m  
[2KAttention weights: tensor([[0.4526, 0.5474]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 10/203 [2m0:00:27 â€¢ 0:08:59[0m [2;4m0.36it/s[0m  
[2KAttention weights: tensor([[0.4508, 0.5492]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 10/203 [2m0:00:27 â€¢ 0:08:59[0m [2;4m0.36it/s[0m  
[2KAttention weights: tensor([[0.5518, 0.4482]], device='cuda:0')â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 10/203 [2m0:00:27 â€¢ 0:08:59[0m [2;4m0.36it/s[0m  
[2KAttention weights: tensor([[0.4527, 0.5473],0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 10/203 [2m0:00:27 â€¢ 0:08:59[0m [2;4m0.36it/s[0m  
        [0.4908, 0.5092],
        [0.5193, 0.4807],
        [0.4600, 0.5400],
        [0.4212, 0.5788],
        [0.4789, 0.5211],
        [0.5111, 0.4889],
        [0.4937, 0.5063],
        [0.4505, 0.5495],
[2K        [0.4994, 0.5006]], device='cuda:0')[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 10/203 [2m0:00:27 â€¢ 0:08:59[0m [2;4m0.36it/s[0m  
[2KAttention weights: tensor([[0.5588, 0.4412],0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 11/203 [2m0:00:28 â€¢ 0:08:19[0m [2;4m0.39it/s[0m   
        [0.5541, 0.4459],
        [0.5564, 0.4436],
        [0.5558, 0.4442],
        [0.5540, 0.4460],
        [0.5533, 0.4467],
        [0.5544, 0.4456],
        [0.5574, 0.4426],
        [0.5584, 0.4416],
[2K        [0.5547, 0.4453]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 11/203 [2m0:00:28 â€¢ 0:08:19[0m [2;4m0.39it/s[0m  
[2KClass label: HammerThrow0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 11/203 [2m0:00:28 â€¢ 0:08:19[0m [2;4m0.39it/s[0m  
[2KAttention weights: tensor([[0.5379, 0.4621]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 11/203 [2m0:00:28 â€¢ 0:08:19[0m [2;4m0.39it/s[0m  
[2KStep 0 - TTA Loss: 0.7240m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 11/203 [2m0:00:28 â€¢ 0:08:19[0m [2;4m0.39it/s[0m  
[2KAttention weights: tensor([[0.5379, 0.4621]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 11/203 [2m0:00:28 â€¢ 0:08:19[0m [2;4m0.39it/s[0m  
[2KAttention weights: tensor([[0.5381, 0.4619]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 11/203 [2m0:00:28 â€¢ 0:08:19[0m [2;4m0.39it/s[0m  
[2KAttention weights: tensor([[0.5394, 0.4606]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 11/203 [2m0:00:28 â€¢ 0:08:19[0m [2;4m0.39it/s[0m  
[2KAttention weights: tensor([[0.5428, 0.4572]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 11/203 [2m0:00:28 â€¢ 0:08:19[0m [2;4m0.39it/s[0m  
[2KAttention weights: tensor([[0.5466, 0.4534]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 11/203 [2m0:00:28 â€¢ 0:08:19[0m [2;4m0.39it/s[0m  
[2KAttention weights: tensor([[0.5494, 0.4506]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 11/203 [2m0:00:28 â€¢ 0:08:19[0m [2;4m0.39it/s[0m  
[2KAttention weights: tensor([[0.5480, 0.4520]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 11/203 [2m0:00:28 â€¢ 0:08:19[0m [2;4m0.39it/s[0m  
[2KAttention weights: tensor([[0.5412, 0.4588]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 11/203 [2m0:00:28 â€¢ 0:08:19[0m [2;4m0.39it/s[0m  
[2KAttention weights: tensor([[0.5253, 0.4747]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 11/203 [2m0:00:28 â€¢ 0:08:19[0m [2;4m0.39it/s[0m  
[2KAttention weights: tensor([[0.5536, 0.4464]], device='cuda:0')â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 11/203 [2m0:00:28 â€¢ 0:08:19[0m [2;4m0.39it/s[0m  
[2KAttention weights: tensor([[0.6013, 0.3987],38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 11/203 [2m0:00:28 â€¢ 0:08:19[0m [2;4m0.39it/s[0m  
        [0.5728, 0.4272],
        [0.6008, 0.3992],
        [0.5775, 0.4225],
        [0.5084, 0.4916],
        [0.5760, 0.4240],
        [0.5898, 0.4102],
        [0.6044, 0.3956],
        [0.6284, 0.3716],
[2K        [0.5923, 0.4077]], device='cuda:0')[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 11/203 [2m0:00:28 â€¢ 0:08:19[0m [2;4m0.39it/s[0m  
[2KAttention weights: tensor([[0.5588, 0.4412],0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 12/203 [2m0:00:29 â€¢ 0:07:52[0m [2;4m0.41it/s[0m  
        [0.5541, 0.4459],
        [0.5564, 0.4436],
        [0.5558, 0.4442],
        [0.5540, 0.4460],
        [0.5533, 0.4467],
        [0.5544, 0.4456],
        [0.5574, 0.4426],
        [0.5584, 0.4416],
[2K        [0.5547, 0.4453]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 12/203 [2m0:00:29 â€¢ 0:07:52[0m [2;4m0.41it/s[0m  
[2KClass label: CleanAndJerkm[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 12/203 [2m0:00:29 â€¢ 0:07:52[0m [2;4m0.41it/s[0m  
[2KAttention weights: tensor([[0.6270, 0.3730]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 12/203 [2m0:00:29 â€¢ 0:07:52[0m [2;4m0.41it/s[0m  
[2KStep 0 - TTA Loss: 0.6825m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 12/203 [2m0:00:29 â€¢ 0:07:52[0m [2;4m0.41it/s[0m  
[2KAttention weights: tensor([[0.6308, 0.3692]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 12/203 [2m0:00:29 â€¢ 0:07:52[0m [2;4m0.41it/s[0m  
[2KAttention weights: tensor([[0.6368, 0.3632]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 12/203 [2m0:00:29 â€¢ 0:07:52[0m [2;4m0.41it/s[0m  
[2KAttention weights: tensor([[0.6409, 0.3591]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 12/203 [2m0:00:29 â€¢ 0:07:52[0m [2;4m0.41it/s[0m  
[2KAttention weights: tensor([[0.6373, 0.3627]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 12/203 [2m0:00:29 â€¢ 0:07:52[0m [2;4m0.41it/s[0m  
[2KAttention weights: tensor([[0.6270, 0.3730]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 12/203 [2m0:00:29 â€¢ 0:07:52[0m [2;4m0.41it/s[0m  
[2KAttention weights: tensor([[0.6171, 0.3829]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 12/203 [2m0:00:29 â€¢ 0:07:52[0m [2;4m0.41it/s[0m  
[2KAttention weights: tensor([[0.6101, 0.3899]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 12/203 [2m0:00:29 â€¢ 0:07:52[0m [2;4m0.41it/s[0m  
[2KAttention weights: tensor([[0.6080, 0.3920]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 12/203 [2m0:00:29 â€¢ 0:07:52[0m [2;4m0.41it/s[0m  
[2KAttention weights: tensor([[0.6078, 0.3922]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 12/203 [2m0:00:29 â€¢ 0:07:52[0m [2;4m0.41it/s[0m  
[2KAttention weights: tensor([[0.5551, 0.4449]], device='cuda:0')â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 12/203 [2m0:00:29 â€¢ 0:07:52[0m [2;4m0.41it/s[0m  
[2KAttention weights: tensor([[0.5975, 0.4025],38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 12/203 [2m0:00:29 â€¢ 0:07:52[0m [2;4m0.41it/s[0m  
        [0.5713, 0.4287],
        [0.6085, 0.3915],
        [0.5728, 0.4272],
        [0.4809, 0.5191],
        [0.5657, 0.4343],
        [0.5825, 0.4175],
        [0.5966, 0.4034],
        [0.6288, 0.3712],
[2K        [0.5866, 0.4134]], device='cuda:0')[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 12/203 [2m0:00:29 â€¢ 0:07:52[0m [2;4m0.41it/s[0m  
[2KAttention weights: tensor([[0.5588, 0.4412],4mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 13/203 [2m0:00:30 â€¢ 0:07:21[0m [2;4m0.43it/s[0m  
        [0.5541, 0.4459],
        [0.5564, 0.4436],
        [0.5558, 0.4442],
        [0.5540, 0.4460],
        [0.5533, 0.4467],
        [0.5544, 0.4456],
        [0.5574, 0.4426],
        [0.5584, 0.4416],
[2K        [0.5547, 0.4453]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 13/203 [2m0:00:30 â€¢ 0:07:21[0m [2;4m0.43it/s[0m  
[2KClass label: BaseballPitch[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 13/203 [2m0:00:30 â€¢ 0:07:21[0m [2;4m0.43it/s[0m  
[2KAttention weights: tensor([[0.6420, 0.3580]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 13/203 [2m0:00:30 â€¢ 0:07:21[0m [2;4m0.43it/s[0m  
[2KStep 0 - TTA Loss: 0.6498m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 13/203 [2m0:00:30 â€¢ 0:07:21[0m [2;4m0.43it/s[0m  
[2KAttention weights: tensor([[0.6420, 0.3580]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 13/203 [2m0:00:30 â€¢ 0:07:21[0m [2;4m0.43it/s[0m  
[2KAttention weights: tensor([[0.6439, 0.3561]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 13/203 [2m0:00:30 â€¢ 0:07:21[0m [2;4m0.43it/s[0m  
[2KAttention weights: tensor([[0.6536, 0.3464]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 13/203 [2m0:00:30 â€¢ 0:07:21[0m [2;4m0.43it/s[0m  
[2KAttention weights: tensor([[0.6789, 0.3211]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 13/203 [2m0:00:30 â€¢ 0:07:21[0m [2;4m0.43it/s[0m  
[2KAttention weights: tensor([[0.7236, 0.2764]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 13/203 [2m0:00:30 â€¢ 0:07:21[0m [2;4m0.43it/s[0m  
[2KAttention weights: tensor([[0.7818, 0.2182]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 13/203 [2m0:00:30 â€¢ 0:07:21[0m [2;4m0.43it/s[0m  
[2KAttention weights: tensor([[0.8378, 0.1622]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 13/203 [2m0:00:30 â€¢ 0:07:21[0m [2;4m0.43it/s[0m  
[2KAttention weights: tensor([[0.8878, 0.1122]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 13/203 [2m0:00:30 â€¢ 0:07:21[0m [2;4m0.43it/s[0m  
[2KAttention weights: tensor([[0.9432, 0.0568]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 13/203 [2m0:00:30 â€¢ 0:07:21[0m [2;4m0.43it/s[0m  
[2KAttention weights: tensor([[0.5752, 0.4248]], device='cuda:0')â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 13/203 [2m0:00:30 â€¢ 0:07:21[0m [2;4m0.43it/s[0m  
[2KAttention weights: tensor([[0.9875, 0.0125],[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 13/203 [2m0:00:30 â€¢ 0:07:21[0m [2;4m0.43it/s[0m  
        [0.8412, 0.1588],
        [0.8417, 0.1583],
        [0.9101, 0.0899],
        [0.8822, 0.1178],
        [0.8717, 0.1283],
        [0.8922, 0.1078],
        [0.9350, 0.0650],
        [0.9151, 0.0849],
[2K        [0.8431, 0.1569]], device='cuda:0')[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 13/203 [2m0:00:30 â€¢ 0:07:21[0m [2;4m0.43it/s[0m  
[2KAttention weights: tensor([[0.5589, 0.4411],4mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 14/203 [2m0:00:31 â€¢ 0:07:04[0m [2;4m0.45it/s[0m  
        [0.5541, 0.4459],
        [0.5565, 0.4435],
        [0.5559, 0.4441],
        [0.5541, 0.4459],
        [0.5534, 0.4466],
        [0.5545, 0.4455],
        [0.5575, 0.4425],
        [0.5584, 0.4416],
[2K        [0.5547, 0.4453]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 14/203 [2m0:00:31 â€¢ 0:07:04[0m [2;4m0.45it/s[0m  
[2KClass label: GolfSwing[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 14/203 [2m0:00:31 â€¢ 0:07:04[0m [2;4m0.45it/s[0m  
[2KAttention weights: tensor([[0.6052, 0.3948]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 14/203 [2m0:00:31 â€¢ 0:07:04[0m [2;4m0.45it/s[0m  
[2KStep 0 - TTA Loss: 0.9453m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 14/203 [2m0:00:31 â€¢ 0:07:04[0m [2;4m0.45it/s[0m  
[2KAttention weights: tensor([[0.7559, 0.2441]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 14/203 [2m0:00:31 â€¢ 0:07:04[0m [2;4m0.45it/s[0m  
[2KAttention weights: tensor([[0.8530, 0.1470]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 14/203 [2m0:00:31 â€¢ 0:07:04[0m [2;4m0.45it/s[0m  
[2KAttention weights: tensor([[0.9066, 0.0934]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 14/203 [2m0:00:31 â€¢ 0:07:04[0m [2;4m0.45it/s[0m  
[2KAttention weights: tensor([[0.9339, 0.0661]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 14/203 [2m0:00:31 â€¢ 0:07:04[0m [2;4m0.45it/s[0m  
[2KAttention weights: tensor([[0.9470, 0.0530]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 14/203 [2m0:00:31 â€¢ 0:07:04[0m [2;4m0.45it/s[0m  
[2KAttention weights: tensor([[0.9520, 0.0480]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 14/203 [2m0:00:31 â€¢ 0:07:04[0m [2;4m0.45it/s[0m  
[2KAttention weights: tensor([[0.9527, 0.0473]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 14/203 [2m0:00:31 â€¢ 0:07:04[0m [2;4m0.45it/s[0m  
[2KAttention weights: tensor([[0.9515, 0.0485]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 14/203 [2m0:00:31 â€¢ 0:07:04[0m [2;4m0.45it/s[0m  
[2KAttention weights: tensor([[0.9502, 0.0498]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 14/203 [2m0:00:31 â€¢ 0:07:04[0m [2;4m0.45it/s[0m  
[2KAttention weights: tensor([[0.5743, 0.4257]], device='cuda:0')â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 14/203 [2m0:00:31 â€¢ 0:07:04[0m [2;4m0.45it/s[0m  
[2KAttention weights: tensor([[0.9985, 0.0015],[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 14/203 [2m0:00:31 â€¢ 0:07:04[0m [2;4m0.45it/s[0m  
        [0.9041, 0.0959],
        [0.8847, 0.1153],
        [0.9497, 0.0503],
        [0.9503, 0.0497],
        [0.9312, 0.0688],
        [0.9491, 0.0509],
        [0.9766, 0.0234],
        [0.9581, 0.0419],
[2K        [0.8922, 0.1078]], device='cuda:0')[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 14/203 [2m0:00:31 â€¢ 0:07:04[0m [2;4m0.45it/s[0m  
[2KAttention weights: tensor([[0.5592, 0.4408],4mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 15/203 [2m0:00:32 â€¢ 0:06:42[0m [2;4m0.47it/s[0m  
        [0.5543, 0.4457],
        [0.5566, 0.4434],
        [0.5561, 0.4439],
        [0.5543, 0.4457],
        [0.5535, 0.4465],
        [0.5546, 0.4454],
        [0.5576, 0.4424],
        [0.5586, 0.4414],
[2K        [0.5549, 0.4451]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 15/203 [2m0:00:32 â€¢ 0:06:42[0m [2;4m0.47it/s[0m  
[2KClass label: PoleVault[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 15/203 [2m0:00:32 â€¢ 0:06:42[0m [2;4m0.47it/s[0m  
[2KAttention weights: tensor([[0.6138, 0.3862]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 15/203 [2m0:00:32 â€¢ 0:06:42[0m [2;4m0.47it/s[0m  
[2KStep 0 - TTA Loss: 1.1451m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 15/203 [2m0:00:32 â€¢ 0:06:42[0m [2;4m0.47it/s[0m  
[2KAttention weights: tensor([[0.6138, 0.3862]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 15/203 [2m0:00:32 â€¢ 0:06:42[0m [2;4m0.47it/s[0m  
[2KAttention weights: tensor([[0.6139, 0.3861]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 15/203 [2m0:00:32 â€¢ 0:06:42[0m [2;4m0.47it/s[0m  
[2KAttention weights: tensor([[0.6149, 0.3851]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 15/203 [2m0:00:32 â€¢ 0:06:42[0m [2;4m0.47it/s[0m  
[2KAttention weights: tensor([[0.6175, 0.3825]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 15/203 [2m0:00:32 â€¢ 0:06:42[0m [2;4m0.47it/s[0m  
[2KAttention weights: tensor([[0.6233, 0.3767]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 15/203 [2m0:00:32 â€¢ 0:06:42[0m [2;4m0.47it/s[0m  
[2KAttention weights: tensor([[0.6328, 0.3672]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 15/203 [2m0:00:32 â€¢ 0:06:42[0m [2;4m0.47it/s[0m  
[2KAttention weights: tensor([[0.6420, 0.3580]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 15/203 [2m0:00:32 â€¢ 0:06:42[0m [2;4m0.47it/s[0m  
[2KAttention weights: tensor([[0.6467, 0.3532]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 15/203 [2m0:00:32 â€¢ 0:06:42[0m [2;4m0.47it/s[0m  
[2KAttention weights: tensor([[0.6397, 0.3603]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 15/203 [2m0:00:32 â€¢ 0:06:42[0m [2;4m0.47it/s[0m  
[2KAttention weights: tensor([[0.5546, 0.4454]], device='cuda:0')â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 15/203 [2m0:00:32 â€¢ 0:06:42[0m [2;4m0.47it/s[0m  
[2KAttention weights: tensor([[0.7492, 0.2508],[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 15/203 [2m0:00:32 â€¢ 0:06:42[0m [2;4m0.47it/s[0m  
        [0.5626, 0.4374],
        [0.6022, 0.3978],
        [0.3945, 0.6055],
        [0.5596, 0.4404],
        [0.5954, 0.4046],
        [0.6346, 0.3654],
        [0.6299, 0.3701],
        [0.6114, 0.3886],
[2K        [0.5785, 0.4215]], device='cuda:0')[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 15/203 [2m0:00:32 â€¢ 0:06:42[0m [2;4m0.47it/s[0m  
[2KAttention weights: tensor([[0.5592, 0.4408],[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 16/203 [2m0:00:33 â€¢ 0:06:27[0m [2;4m0.48it/s[0m   
        [0.5543, 0.4457],
        [0.5566, 0.4434],
        [0.5561, 0.4439],
        [0.5542, 0.4458],
        [0.5535, 0.4465],
        [0.5546, 0.4454],
        [0.5576, 0.4424],
        [0.5586, 0.4414],
[2K        [0.5549, 0.4451]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 16/203 [2m0:00:33 â€¢ 0:06:27[0m [2;4m0.48it/s[0m  
[2KClass label: HighJumpâ”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 16/203 [2m0:00:33 â€¢ 0:06:27[0m [2;4m0.48it/s[0m  
[2KAttention weights: tensor([[0.5963, 0.4037]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 16/203 [2m0:00:33 â€¢ 0:06:27[0m [2;4m0.48it/s[0m  
[2KStep 0 - TTA Loss: 0.80040m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 16/203 [2m0:00:33 â€¢ 0:06:27[0m [2;4m0.48it/s[0m  
[2KAttention weights: tensor([[0.5830, 0.4170]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 16/203 [2m0:00:33 â€¢ 0:06:27[0m [2;4m0.48it/s[0m  
[2KAttention weights: tensor([[0.5631, 0.4369]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 16/203 [2m0:00:33 â€¢ 0:06:27[0m [2;4m0.48it/s[0m  
[2KAttention weights: tensor([[0.5408, 0.4592]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 16/203 [2m0:00:33 â€¢ 0:06:27[0m [2;4m0.48it/s[0m  
[2KAttention weights: tensor([[0.5150, 0.4850]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 16/203 [2m0:00:33 â€¢ 0:06:27[0m [2;4m0.48it/s[0m  
[2KAttention weights: tensor([[0.4872, 0.5128]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 16/203 [2m0:00:33 â€¢ 0:06:27[0m [2;4m0.48it/s[0m  
[2KAttention weights: tensor([[0.4610, 0.5390]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 16/203 [2m0:00:33 â€¢ 0:06:27[0m [2;4m0.48it/s[0m  
[2KAttention weights: tensor([[0.4394, 0.5606]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 16/203 [2m0:00:33 â€¢ 0:06:27[0m [2;4m0.48it/s[0m  
[2KAttention weights: tensor([[0.4249, 0.5751]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 16/203 [2m0:00:33 â€¢ 0:06:27[0m [2;4m0.48it/s[0m  
[2KAttention weights: tensor([[0.4175, 0.5825]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 16/203 [2m0:00:33 â€¢ 0:06:27[0m [2;4m0.48it/s[0m  
[2KAttention weights: tensor([[0.5484, 0.4516]], device='cuda:0')â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 16/203 [2m0:00:33 â€¢ 0:06:27[0m [2;4m0.48it/s[0m  
[2KAttention weights: tensor([[0.6334, 0.3666],[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 16/203 [2m0:00:33 â€¢ 0:06:27[0m [2;4m0.48it/s[0m  
        [0.5008, 0.4992],
        [0.5153, 0.4847],
        [0.3793, 0.6207],
        [0.4346, 0.5654],
        [0.4153, 0.5847],
        [0.4873, 0.5127],
        [0.5185, 0.4815],
        [0.5207, 0.4793],
[2K        [0.4778, 0.5222]], device='cuda:0')[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 16/203 [2m0:00:33 â€¢ 0:06:27[0m [2;4m0.48it/s[0m  
[2KAttention weights: tensor([[0.5592, 0.4408],[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 17/203 [2m0:00:34 â€¢ 0:06:29[0m [2;4m0.48it/s[0m  
        [0.5542, 0.4458],
        [0.5565, 0.4435],
        [0.5560, 0.4440],
        [0.5541, 0.4459],
        [0.5533, 0.4467],
        [0.5544, 0.4456],
        [0.5576, 0.4424],
        [0.5586, 0.4414],
[2K        [0.5548, 0.4452]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 17/203 [2m0:00:34 â€¢ 0:06:29[0m [2;4m0.48it/s[0m  
[2KClass label: GolfSwingâ”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 17/203 [2m0:00:34 â€¢ 0:06:29[0m [2;4m0.48it/s[0m  
[2KAttention weights: tensor([[0.6022, 0.3978]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 17/203 [2m0:00:34 â€¢ 0:06:29[0m [2;4m0.48it/s[0m  
[2KStep 0 - TTA Loss: 0.76120m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 17/203 [2m0:00:34 â€¢ 0:06:29[0m [2;4m0.48it/s[0m  
[2KAttention weights: tensor([[0.6022, 0.3978]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 17/203 [2m0:00:34 â€¢ 0:06:29[0m [2;4m0.48it/s[0m  
[2KAttention weights: tensor([[0.6011, 0.3989]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 17/203 [2m0:00:34 â€¢ 0:06:29[0m [2;4m0.48it/s[0m  
[2KAttention weights: tensor([[0.5973, 0.4027]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 17/203 [2m0:00:34 â€¢ 0:06:29[0m [2;4m0.48it/s[0m  
[2KAttention weights: tensor([[0.5893, 0.4107]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 17/203 [2m0:00:34 â€¢ 0:06:29[0m [2;4m0.48it/s[0m  
[2KAttention weights: tensor([[0.5765, 0.4235]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 17/203 [2m0:00:34 â€¢ 0:06:29[0m [2;4m0.48it/s[0m  
[2KAttention weights: tensor([[0.5581, 0.4419]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 17/203 [2m0:00:34 â€¢ 0:06:29[0m [2;4m0.48it/s[0m  
[2KAttention weights: tensor([[0.5324, 0.4676]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 17/203 [2m0:00:34 â€¢ 0:06:29[0m [2;4m0.48it/s[0m  
[2KAttention weights: tensor([[0.4999, 0.5001]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 17/203 [2m0:00:34 â€¢ 0:06:29[0m [2;4m0.48it/s[0m  
[2KAttention weights: tensor([[0.4654, 0.5346]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 17/203 [2m0:00:34 â€¢ 0:06:29[0m [2;4m0.48it/s[0m  
[2KAttention weights: tensor([[0.5510, 0.4490]], device='cuda:0')â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 17/203 [2m0:00:34 â€¢ 0:06:29[0m [2;4m0.48it/s[0m  
[2KAttention weights: tensor([[0.5487, 0.4513],[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 17/203 [2m0:00:34 â€¢ 0:06:29[0m [2;4m0.48it/s[0m  
        [0.4948, 0.5052],
        [0.5135, 0.4865],
        [0.4389, 0.5611],
        [0.4047, 0.5953],
        [0.3979, 0.6021],
        [0.4689, 0.5311],
        [0.4964, 0.5036],
        [0.5281, 0.4719],
[2K        [0.4806, 0.5194]], device='cuda:0')[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 17/203 [2m0:00:34 â€¢ 0:06:29[0m [2;4m0.48it/s[0m  
[2KAttention weights: tensor([[0.5591, 0.4409],24mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 18/203 [2m0:00:35 â€¢ 0:05:03[0m [2;4m0.61it/s[0m  
        [0.5541, 0.4459],
        [0.5565, 0.4435],
        [0.5560, 0.4440],
        [0.5541, 0.4459],
        [0.5532, 0.4468],
        [0.5543, 0.4457],
        [0.5575, 0.4425],
        [0.5585, 0.4415],
[2K        [0.5548, 0.4452]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 18/203 [2m0:00:35 â€¢ 0:05:03[0m [2;4m0.61it/s[0m  
[2KClass label: ThrowDiscus[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 18/203 [2m0:00:35 â€¢ 0:05:03[0m [2;4m0.61it/s[0m  
[2KAttention weights: tensor([[0.6146, 0.3854]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 18/203 [2m0:00:35 â€¢ 0:05:03[0m [2;4m0.61it/s[0m  
[2KStep 0 - TTA Loss: 0.67430m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 18/203 [2m0:00:35 â€¢ 0:05:03[0m [2;4m0.61it/s[0m  
[2KAttention weights: tensor([[0.5698, 0.4302]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 18/203 [2m0:00:35 â€¢ 0:05:03[0m [2;4m0.61it/s[0m  
[2KAttention weights: tensor([[0.5043, 0.4957]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 18/203 [2m0:00:35 â€¢ 0:05:03[0m [2;4m0.61it/s[0m  
[2KAttention weights: tensor([[0.4324, 0.5676]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 18/203 [2m0:00:35 â€¢ 0:05:03[0m [2;4m0.61it/s[0m  
[2KAttention weights: tensor([[0.3714, 0.6286]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 18/203 [2m0:00:35 â€¢ 0:05:03[0m [2;4m0.61it/s[0m  
[2KAttention weights: tensor([[0.3293, 0.6707]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 18/203 [2m0:00:35 â€¢ 0:05:03[0m [2;4m0.61it/s[0m  
[2KAttention weights: tensor([[0.3061, 0.6939]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 18/203 [2m0:00:35 â€¢ 0:05:03[0m [2;4m0.61it/s[0m  
[2KAttention weights: tensor([[0.2959, 0.7041]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 18/203 [2m0:00:35 â€¢ 0:05:03[0m [2;4m0.61it/s[0m  
[2KAttention weights: tensor([[0.2926, 0.7074]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 18/203 [2m0:00:35 â€¢ 0:05:03[0m [2;4m0.61it/s[0m  
[2KAttention weights: tensor([[0.2912, 0.7088]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 18/203 [2m0:00:35 â€¢ 0:05:03[0m [2;4m0.61it/s[0m  
[2KAttention weights: tensor([[0.5451, 0.4549]], device='cuda:0')â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 18/203 [2m0:00:35 â€¢ 0:05:03[0m [2;4m0.61it/s[0m  
[2KAttention weights: tensor([[0.5158, 0.4842],[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 18/203 [2m0:00:35 â€¢ 0:05:03[0m [2;4m0.61it/s[0m  
        [0.4775, 0.5225],
        [0.3932, 0.6068],
        [0.4048, 0.5952],
        [0.3277, 0.6723],
        [0.3524, 0.6476],
        [0.4190, 0.5810],
        [0.4782, 0.5218],
        [0.4502, 0.5498],
[2K        [0.2911, 0.7089]], device='cuda:0')â•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 18/203 [2m0:00:35 â€¢ 0:05:03[0m [2;4m0.61it/s[0m  
[2KAttention weights: tensor([[0.5590, 0.4410],24mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 19/203 [2m0:00:36 â€¢ 0:04:55[0m [2;4m0.63it/s[0m  
        [0.5541, 0.4459],
        [0.5564, 0.4436],
        [0.5559, 0.4441],
        [0.5539, 0.4461],
        [0.5531, 0.4469],
        [0.5542, 0.4458],
        [0.5574, 0.4426],
        [0.5584, 0.4416],
[2K        [0.5546, 0.4454]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 19/203 [2m0:00:36 â€¢ 0:04:55[0m [2;4m0.63it/s[0m  
[2KClass label: SoccerPenaltym[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 19/203 [2m0:00:36 â€¢ 0:04:55[0m [2;4m0.63it/s[0m  
[2KAttention weights: tensor([[0.6390, 0.3610]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 19/203 [2m0:00:36 â€¢ 0:04:55[0m [2;4m0.63it/s[0m  
[2KStep 0 - TTA Loss: 0.60470m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 19/203 [2m0:00:36 â€¢ 0:04:55[0m [2;4m0.63it/s[0m  
[2KAttention weights: tensor([[0.6390, 0.3610]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 19/203 [2m0:00:36 â€¢ 0:04:55[0m [2;4m0.63it/s[0m  
[2KAttention weights: tensor([[0.6392, 0.3608]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 19/203 [2m0:00:36 â€¢ 0:04:55[0m [2;4m0.63it/s[0m  
[2KAttention weights: tensor([[0.6400, 0.3600]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 19/203 [2m0:00:36 â€¢ 0:04:55[0m [2;4m0.63it/s[0m  
[2KAttention weights: tensor([[0.6422, 0.3578]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 19/203 [2m0:00:36 â€¢ 0:04:55[0m [2;4m0.63it/s[0m  
[2KAttention weights: tensor([[0.6451, 0.3549]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 19/203 [2m0:00:36 â€¢ 0:04:55[0m [2;4m0.63it/s[0m  
[2KAttention weights: tensor([[0.6461, 0.3539]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 19/203 [2m0:00:36 â€¢ 0:04:55[0m [2;4m0.63it/s[0m  
[2KAttention weights: tensor([[0.6447, 0.3553]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 19/203 [2m0:00:36 â€¢ 0:04:55[0m [2;4m0.63it/s[0m  
[2KAttention weights: tensor([[0.6407, 0.3593]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 19/203 [2m0:00:36 â€¢ 0:04:55[0m [2;4m0.63it/s[0m  
[2KAttention weights: tensor([[0.6440, 0.3560]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 19/203 [2m0:00:36 â€¢ 0:04:55[0m [2;4m0.63it/s[0m  
[2KAttention weights: tensor([[0.5568, 0.4432]], device='cuda:0')â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 19/203 [2m0:00:36 â€¢ 0:04:55[0m [2;4m0.63it/s[0m  
[2KAttention weights: tensor([[0.6565, 0.3435],[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 19/203 [2m0:00:36 â€¢ 0:04:55[0m [2;4m0.63it/s[0m  
        [0.6013, 0.3987],
        [0.6234, 0.3766],
        [0.6095, 0.3905],
        [0.5505, 0.4495],
        [0.6006, 0.3994],
        [0.6190, 0.3810],
        [0.6655, 0.3345],
        [0.6710, 0.3290],
[2K        [0.6177, 0.3823]], device='cuda:0')â•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 19/203 [2m0:00:36 â€¢ 0:04:55[0m [2;4m0.63it/s[0m  
[2KAttention weights: tensor([[0.5590, 0.4410],24mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 20/203 [2m0:00:37 â€¢ 0:04:39[0m [2;4m0.66it/s[0m  
        [0.5540, 0.4460],
        [0.5563, 0.4437],
        [0.5558, 0.4442],
        [0.5539, 0.4461],
        [0.5531, 0.4469],
        [0.5542, 0.4458],
        [0.5574, 0.4426],
        [0.5584, 0.4416],
[2K        [0.5546, 0.4454]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 20/203 [2m0:00:37 â€¢ 0:04:39[0m [2;4m0.66it/s[0m  
[2KClass label: HighJumpâ”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 20/203 [2m0:00:37 â€¢ 0:04:39[0m [2;4m0.66it/s[0m  
[2KAttention weights: tensor([[0.5988, 0.4012]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 20/203 [2m0:00:37 â€¢ 0:04:39[0m [2;4m0.66it/s[0m  
[2KStep 0 - TTA Loss: 0.65460m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 20/203 [2m0:00:37 â€¢ 0:04:39[0m [2;4m0.66it/s[0m  
[2KAttention weights: tensor([[0.6156, 0.3844]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 20/203 [2m0:00:37 â€¢ 0:04:39[0m [2;4m0.66it/s[0m  
[2KAttention weights: tensor([[0.6393, 0.3607]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 20/203 [2m0:00:37 â€¢ 0:04:39[0m [2;4m0.66it/s[0m  
[2KAttention weights: tensor([[0.6629, 0.3371]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 20/203 [2m0:00:37 â€¢ 0:04:39[0m [2;4m0.66it/s[0m  
[2KAttention weights: tensor([[0.6799, 0.3201]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 20/203 [2m0:00:37 â€¢ 0:04:39[0m [2;4m0.66it/s[0m  
[2KAttention weights: tensor([[0.6890, 0.3110]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 20/203 [2m0:00:37 â€¢ 0:04:39[0m [2;4m0.66it/s[0m  
[2KAttention weights: tensor([[0.6921, 0.3079]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 20/203 [2m0:00:37 â€¢ 0:04:39[0m [2;4m0.66it/s[0m  
[2KAttention weights: tensor([[0.6921, 0.3079]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 20/203 [2m0:00:37 â€¢ 0:04:39[0m [2;4m0.66it/s[0m  
[2KAttention weights: tensor([[0.6914, 0.3086]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 20/203 [2m0:00:37 â€¢ 0:04:39[0m [2;4m0.66it/s[0m  
[2KAttention weights: tensor([[0.6909, 0.3091]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 20/203 [2m0:00:37 â€¢ 0:04:39[0m [2;4m0.66it/s[0m  
[2KAttention weights: tensor([[0.5551, 0.4449]], device='cuda:0')â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 20/203 [2m0:00:37 â€¢ 0:04:39[0m [2;4m0.66it/s[0m  
[2KAttention weights: tensor([[0.7087, 0.2913],[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 20/203 [2m0:00:37 â€¢ 0:04:39[0m [2;4m0.66it/s[0m  
        [0.6527, 0.3473],
        [0.6650, 0.3350],
        [0.6654, 0.3346],
        [0.6209, 0.3791],
        [0.6909, 0.3091],
        [0.6821, 0.3179],
        [0.7486, 0.2514],
        [0.7255, 0.2745],
[2K        [0.6676, 0.3324]], device='cuda:0')â•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 20/203 [2m0:00:37 â€¢ 0:04:39[0m [2;4m0.66it/s[0m  
[2KAttention weights: tensor([[0.5590, 0.4410],[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 21/203 [2m0:00:42 â€¢ 0:05:19[0m [2;4m0.57it/s[0m   
        [0.5540, 0.4460],
        [0.5563, 0.4437],
        [0.5558, 0.4442],
        [0.5539, 0.4461],
        [0.5531, 0.4469],
        [0.5542, 0.4458],
        [0.5574, 0.4426],
        [0.5584, 0.4416],
[2K        [0.5546, 0.4454]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 21/203 [2m0:00:42 â€¢ 0:05:19[0m [2;4m0.57it/s[0m  
[2KClass label: BaseballPitch0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 21/203 [2m0:00:42 â€¢ 0:05:19[0m [2;4m0.57it/s[0m  
[2KAttention weights: tensor([[0.6426, 0.3574]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 21/203 [2m0:00:42 â€¢ 0:05:19[0m [2;4m0.57it/s[0m  
[2KStep 0 - TTA Loss: 0.8420[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 21/203 [2m0:00:42 â€¢ 0:05:19[0m [2;4m0.57it/s[0m  
[2KAttention weights: tensor([[0.6426, 0.3574]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 21/203 [2m0:00:42 â€¢ 0:05:19[0m [2;4m0.57it/s[0m  
[2KAttention weights: tensor([[0.6420, 0.3580]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 21/203 [2m0:00:42 â€¢ 0:05:19[0m [2;4m0.57it/s[0m  
[2KAttention weights: tensor([[0.6389, 0.3611]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 21/203 [2m0:00:42 â€¢ 0:05:19[0m [2;4m0.57it/s[0m  
[2KAttention weights: tensor([[0.6332, 0.3668]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 21/203 [2m0:00:42 â€¢ 0:05:19[0m [2;4m0.57it/s[0m  
[2KAttention weights: tensor([[0.6236, 0.3764]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 21/203 [2m0:00:42 â€¢ 0:05:19[0m [2;4m0.57it/s[0m  
[2KAttention weights: tensor([[0.6084, 0.3916]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 21/203 [2m0:00:42 â€¢ 0:05:19[0m [2;4m0.57it/s[0m  
[2KAttention weights: tensor([[0.5868, 0.4132]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 21/203 [2m0:00:42 â€¢ 0:05:19[0m [2;4m0.57it/s[0m  
[2KAttention weights: tensor([[0.5660, 0.4340]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 21/203 [2m0:00:42 â€¢ 0:05:19[0m [2;4m0.57it/s[0m  
[2KAttention weights: tensor([[0.5651, 0.4349]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 21/203 [2m0:00:42 â€¢ 0:05:19[0m [2;4m0.57it/s[0m  
[2KAttention weights: tensor([[0.5565, 0.4435]], device='cuda:0')â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 21/203 [2m0:00:42 â€¢ 0:05:19[0m [2;4m0.57it/s[0m  
[2KAttention weights: tensor([[0.5953, 0.4047],[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 21/203 [2m0:00:42 â€¢ 0:05:19[0m [2;4m0.57it/s[0m  
        [0.5764, 0.4236],
        [0.6028, 0.3972],
        [0.5778, 0.4222],
        [0.5087, 0.4913],
        [0.5673, 0.4327],
        [0.5856, 0.4144],
        [0.6149, 0.3851],
        [0.6380, 0.3620],
[2K        [0.5936, 0.4064]], device='cuda:0')m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 21/203 [2m0:00:42 â€¢ 0:05:19[0m [2;4m0.57it/s[0m  
[2KAttention weights: tensor([[0.5590, 0.4410],[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 22/203 [2m0:00:43 â€¢ 0:05:25[0m [2;4m0.56it/s[0m  
        [0.5540, 0.4460],
        [0.5563, 0.4437],
        [0.5558, 0.4442],
        [0.5539, 0.4461],
        [0.5531, 0.4469],
        [0.5541, 0.4459],
        [0.5573, 0.4427],
        [0.5583, 0.4417],
[2K        [0.5546, 0.4454]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 22/203 [2m0:00:43 â€¢ 0:05:25[0m [2;4m0.56it/s[0m  
[2KClass label: CleanAndJerk[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 22/203 [2m0:00:43 â€¢ 0:05:25[0m [2;4m0.56it/s[0m  
[2KAttention weights: tensor([[0.6208, 0.3792]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 22/203 [2m0:00:43 â€¢ 0:05:25[0m [2;4m0.56it/s[0m  
[2KStep 0 - TTA Loss: 0.9441[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 22/203 [2m0:00:43 â€¢ 0:05:25[0m [2;4m0.56it/s[0m  
[2KAttention weights: tensor([[0.6286, 0.3714]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 22/203 [2m0:00:43 â€¢ 0:05:25[0m [2;4m0.56it/s[0m  
[2KAttention weights: tensor([[0.6367, 0.3633]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 22/203 [2m0:00:43 â€¢ 0:05:25[0m [2;4m0.56it/s[0m  
[2KAttention weights: tensor([[0.6417, 0.3583]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 22/203 [2m0:00:43 â€¢ 0:05:25[0m [2;4m0.56it/s[0m  
[2KAttention weights: tensor([[0.6419, 0.3581]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 22/203 [2m0:00:43 â€¢ 0:05:25[0m [2;4m0.56it/s[0m  
[2KAttention weights: tensor([[0.6370, 0.3630]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 22/203 [2m0:00:43 â€¢ 0:05:25[0m [2;4m0.56it/s[0m  
[2KAttention weights: tensor([[0.6286, 0.3714]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 22/203 [2m0:00:43 â€¢ 0:05:25[0m [2;4m0.56it/s[0m  
[2KAttention weights: tensor([[0.6188, 0.3812]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 22/203 [2m0:00:43 â€¢ 0:05:25[0m [2;4m0.56it/s[0m  
[2KAttention weights: tensor([[0.6101, 0.3899]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 22/203 [2m0:00:43 â€¢ 0:05:25[0m [2;4m0.56it/s[0m  
[2KAttention weights: tensor([[0.6050, 0.3950]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 22/203 [2m0:00:43 â€¢ 0:05:25[0m [2;4m0.56it/s[0m  
[2KAttention weights: tensor([[0.5553, 0.4447]], device='cuda:0')â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 22/203 [2m0:00:43 â€¢ 0:05:25[0m [2;4m0.56it/s[0m  
[2KAttention weights: tensor([[0.7369, 0.2631],[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 22/203 [2m0:00:43 â€¢ 0:05:25[0m [2;4m0.56it/s[0m  
        [0.6218, 0.3782],
        [0.6034, 0.3966],
        [0.6423, 0.3577],
        [0.5766, 0.4234],
        [0.6176, 0.3824],
        [0.6398, 0.3602],
        [0.6868, 0.3132],
        [0.6877, 0.3123],
[2K        [0.6162, 0.3838]], device='cuda:0')m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 22/203 [2m0:00:43 â€¢ 0:05:25[0m [2;4m0.56it/s[0m  
[2KAttention weights: tensor([[0.5590, 0.4410],224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 23/203 [2m0:00:44 â€¢ 0:05:11[0m [2;4m0.58it/s[0m  
        [0.5540, 0.4460],
        [0.5563, 0.4437],
        [0.5558, 0.4442],
        [0.5539, 0.4461],
        [0.5530, 0.4470],
        [0.5541, 0.4459],
        [0.5573, 0.4427],
        [0.5583, 0.4417],
[2K        [0.5546, 0.4454]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 23/203 [2m0:00:44 â€¢ 0:05:11[0m [2;4m0.58it/s[0m  
[2KClass label: TennisSwing[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 23/203 [2m0:00:44 â€¢ 0:05:11[0m [2;4m0.58it/s[0m  
[2KAttention weights: tensor([[0.6597, 0.3403]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 23/203 [2m0:00:44 â€¢ 0:05:11[0m [2;4m0.58it/s[0m  
[2KStep 0 - TTA Loss: 0.7673[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 23/203 [2m0:00:44 â€¢ 0:05:11[0m [2;4m0.58it/s[0m  
[2KAttention weights: tensor([[0.6597, 0.3403]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 23/203 [2m0:00:44 â€¢ 0:05:11[0m [2;4m0.58it/s[0m  
[2KAttention weights: tensor([[0.6585, 0.3415]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 23/203 [2m0:00:44 â€¢ 0:05:11[0m [2;4m0.58it/s[0m  
[2KAttention weights: tensor([[0.6532, 0.3468]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 23/203 [2m0:00:44 â€¢ 0:05:11[0m [2;4m0.58it/s[0m  
[2KAttention weights: tensor([[0.6398, 0.3602]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 23/203 [2m0:00:44 â€¢ 0:05:11[0m [2;4m0.58it/s[0m  
[2KAttention weights: tensor([[0.6135, 0.3865]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 23/203 [2m0:00:44 â€¢ 0:05:11[0m [2;4m0.58it/s[0m  
[2KAttention weights: tensor([[0.5712, 0.4288]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 23/203 [2m0:00:44 â€¢ 0:05:11[0m [2;4m0.58it/s[0m  
[2KAttention weights: tensor([[0.5059, 0.4941]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 23/203 [2m0:00:44 â€¢ 0:05:11[0m [2;4m0.58it/s[0m  
[2KAttention weights: tensor([[0.4275, 0.5725]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 23/203 [2m0:00:44 â€¢ 0:05:11[0m [2;4m0.58it/s[0m  
[2KAttention weights: tensor([[0.3608, 0.6392]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 23/203 [2m0:00:44 â€¢ 0:05:11[0m [2;4m0.58it/s[0m  
[2KAttention weights: tensor([[0.5493, 0.4507]], device='cuda:0')â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 23/203 [2m0:00:44 â€¢ 0:05:11[0m [2;4m0.58it/s[0m  
[2KAttention weights: tensor([[0.4909, 0.5091],â•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 23/203 [2m0:00:44 â€¢ 0:05:11[0m [2;4m0.58it/s[0m  
        [0.4445, 0.5555],
        [0.3558, 0.6442],
        [0.4040, 0.5960],
        [0.3549, 0.6451],
        [0.3884, 0.6116],
        [0.4525, 0.5475],
        [0.4635, 0.5365],
        [0.3263, 0.6737],
[2K        [0.3758, 0.6242]], device='cuda:0')mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 23/203 [2m0:00:44 â€¢ 0:05:11[0m [2;4m0.58it/s[0m  
[2KAttention weights: tensor([[0.5589, 0.4411],224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 24/203 [2m0:00:45 â€¢ 0:03:56[0m [2;4m0.76it/s[0m  
        [0.5539, 0.4461],
        [0.5561, 0.4439],
        [0.5557, 0.4443],
        [0.5538, 0.4462],
        [0.5529, 0.4471],
        [0.5540, 0.4460],
        [0.5572, 0.4428],
        [0.5582, 0.4418],
[2K        [0.5544, 0.4456]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 24/203 [2m0:00:45 â€¢ 0:03:56[0m [2;4m0.76it/s[0m  
[2KClass label: Billiardsâ”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 24/203 [2m0:00:45 â€¢ 0:03:56[0m [2;4m0.76it/s[0m  
[2KAttention weights: tensor([[0.5936, 0.4064]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 24/203 [2m0:00:45 â€¢ 0:03:56[0m [2;4m0.76it/s[0m  
[2KStep 0 - TTA Loss: 0.9861[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 24/203 [2m0:00:45 â€¢ 0:03:56[0m [2;4m0.76it/s[0m  
[2KAttention weights: tensor([[0.5764, 0.4236]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 24/203 [2m0:00:45 â€¢ 0:03:56[0m [2;4m0.76it/s[0m  
[2KAttention weights: tensor([[0.5608, 0.4392]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 24/203 [2m0:00:45 â€¢ 0:03:56[0m [2;4m0.76it/s[0m  
[2KAttention weights: tensor([[0.5450, 0.4550]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 24/203 [2m0:00:45 â€¢ 0:03:56[0m [2;4m0.76it/s[0m  
[2KAttention weights: tensor([[0.5296, 0.4704]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 24/203 [2m0:00:45 â€¢ 0:03:56[0m [2;4m0.76it/s[0m  
[2KAttention weights: tensor([[0.5161, 0.4839]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 24/203 [2m0:00:45 â€¢ 0:03:56[0m [2;4m0.76it/s[0m  
[2KAttention weights: tensor([[0.5049, 0.4951]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 24/203 [2m0:00:45 â€¢ 0:03:56[0m [2;4m0.76it/s[0m  
[2KAttention weights: tensor([[0.4957, 0.5043]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 24/203 [2m0:00:45 â€¢ 0:03:56[0m [2;4m0.76it/s[0m  
[2KAttention weights: tensor([[0.4901, 0.5099]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 24/203 [2m0:00:45 â€¢ 0:03:56[0m [2;4m0.76it/s[0m  
[2KAttention weights: tensor([[0.4877, 0.5123]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 24/203 [2m0:00:45 â€¢ 0:03:56[0m [2;4m0.76it/s[0m  
[2KAttention weights: tensor([[0.5504, 0.4496]], device='cuda:0')â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 24/203 [2m0:00:45 â€¢ 0:03:56[0m [2;4m0.76it/s[0m  
[2KAttention weights: tensor([[0.5704, 0.4296],â•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 24/203 [2m0:00:45 â€¢ 0:03:56[0m [2;4m0.76it/s[0m  
        [0.4870, 0.5130],
        [0.4745, 0.5255],
        [0.5009, 0.4991],
        [0.4392, 0.5608],
        [0.4925, 0.5075],
        [0.5293, 0.4707],
        [0.5467, 0.4533],
        [0.5042, 0.4958],
[2K        [0.4922, 0.5078]], device='cuda:0')mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 24/203 [2m0:00:45 â€¢ 0:03:56[0m [2;4m0.76it/s[0m  
[2KAttention weights: tensor([[0.5588, 0.4412],224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 25/203 [2m0:00:47 â€¢ 0:04:00[0m [2;4m0.74it/s[0m  
        [0.5538, 0.4462],
        [0.5560, 0.4440],
        [0.5556, 0.4444],
        [0.5537, 0.4463],
        [0.5529, 0.4471],
        [0.5540, 0.4460],
        [0.5572, 0.4428],
        [0.5581, 0.4419],
[2K        [0.5544, 0.4456]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 25/203 [2m0:00:47 â€¢ 0:04:00[0m [2;4m0.74it/s[0m  
[2KClass label: GolfSwingâ”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 25/203 [2m0:00:47 â€¢ 0:04:00[0m [2;4m0.74it/s[0m  
[2KAttention weights: tensor([[0.5986, 0.4014]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 25/203 [2m0:00:47 â€¢ 0:04:00[0m [2;4m0.74it/s[0m  
[2KStep 0 - TTA Loss: 0.7427[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 25/203 [2m0:00:47 â€¢ 0:04:00[0m [2;4m0.74it/s[0m  
[2KAttention weights: tensor([[0.5986, 0.4014]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 25/203 [2m0:00:47 â€¢ 0:04:00[0m [2;4m0.74it/s[0m  
[2KAttention weights: tensor([[0.5986, 0.4014]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 25/203 [2m0:00:47 â€¢ 0:04:00[0m [2;4m0.74it/s[0m  
[2KAttention weights: tensor([[0.5987, 0.4013]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 25/203 [2m0:00:47 â€¢ 0:04:00[0m [2;4m0.74it/s[0m  
[2KAttention weights: tensor([[0.5994, 0.4006]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 25/203 [2m0:00:47 â€¢ 0:04:00[0m [2;4m0.74it/s[0m  
[2KAttention weights: tensor([[0.6005, 0.3995]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 25/203 [2m0:00:47 â€¢ 0:04:00[0m [2;4m0.74it/s[0m  
[2KAttention weights: tensor([[0.5995, 0.4005]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 25/203 [2m0:00:47 â€¢ 0:04:00[0m [2;4m0.74it/s[0m  
[2KAttention weights: tensor([[0.5933, 0.4067]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 25/203 [2m0:00:47 â€¢ 0:04:00[0m [2;4m0.74it/s[0m  
[2KAttention weights: tensor([[0.5744, 0.4256]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 25/203 [2m0:00:47 â€¢ 0:04:00[0m [2;4m0.74it/s[0m  
[2KAttention weights: tensor([[0.5390, 0.4610]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 25/203 [2m0:00:47 â€¢ 0:04:00[0m [2;4m0.74it/s[0m  
[2KAttention weights: tensor([[0.5524, 0.4476]], device='cuda:0')â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 25/203 [2m0:00:47 â€¢ 0:04:00[0m [2;4m0.74it/s[0m  
[2KAttention weights: tensor([[0.5767, 0.4233],â•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 25/203 [2m0:00:47 â€¢ 0:04:00[0m [2;4m0.74it/s[0m  
        [0.5061, 0.4939],
        [0.5588, 0.4412],
        [0.4889, 0.5111],
        [0.4769, 0.5231],
        [0.5360, 0.4640],
        [0.5604, 0.4396],
        [0.5635, 0.4365],
        [0.5763, 0.4237],
[2K        [0.5515, 0.4485]], device='cuda:0')mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 25/203 [2m0:00:47 â€¢ 0:04:00[0m [2;4m0.74it/s[0m  
[2KAttention weights: tensor([[0.5588, 0.4412],â•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 26/203 [2m0:00:48 â€¢ 0:03:56[0m [2;4m0.75it/s[0m   
        [0.5538, 0.4462],
        [0.5560, 0.4440],
        [0.5556, 0.4444],
        [0.5537, 0.4463],
        [0.5529, 0.4471],
        [0.5540, 0.4460],
        [0.5572, 0.4428],
        [0.5581, 0.4419],
[2K        [0.5544, 0.4456]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 26/203 [2m0:00:48 â€¢ 0:03:56[0m [2;4m0.75it/s[0m  
[2KClass label: PoleVaultâ”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 26/203 [2m0:00:48 â€¢ 0:03:56[0m [2;4m0.75it/s[0m  
[2KAttention weights: tensor([[0.6103, 0.3897]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 26/203 [2m0:00:48 â€¢ 0:03:56[0m [2;4m0.75it/s[0m  
[2KStep 0 - TTA Loss: 0.6636[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 26/203 [2m0:00:48 â€¢ 0:03:56[0m [2;4m0.75it/s[0m  
[2KAttention weights: tensor([[0.6075, 0.3925]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 26/203 [2m0:00:48 â€¢ 0:03:56[0m [2;4m0.75it/s[0m  
[2KAttention weights: tensor([[0.6176, 0.3824]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 26/203 [2m0:00:48 â€¢ 0:03:56[0m [2;4m0.75it/s[0m  
[2KAttention weights: tensor([[0.6291, 0.3709]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 26/203 [2m0:00:48 â€¢ 0:03:56[0m [2;4m0.75it/s[0m  
[2KAttention weights: tensor([[0.6376, 0.3624]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 26/203 [2m0:00:48 â€¢ 0:03:56[0m [2;4m0.75it/s[0m  
[2KAttention weights: tensor([[0.6475, 0.3525]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 26/203 [2m0:00:48 â€¢ 0:03:56[0m [2;4m0.75it/s[0m  
[2KAttention weights: tensor([[0.6619, 0.3381]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 26/203 [2m0:00:48 â€¢ 0:03:56[0m [2;4m0.75it/s[0m  
[2KAttention weights: tensor([[0.6766, 0.3234]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 26/203 [2m0:00:48 â€¢ 0:03:56[0m [2;4m0.75it/s[0m  
[2KAttention weights: tensor([[0.6879, 0.3121]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 26/203 [2m0:00:48 â€¢ 0:03:56[0m [2;4m0.75it/s[0m  
[2KAttention weights: tensor([[0.6940, 0.3060]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 26/203 [2m0:00:48 â€¢ 0:03:56[0m [2;4m0.75it/s[0m  
[2KAttention weights: tensor([[0.5566, 0.4434]], device='cuda:0')â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 26/203 [2m0:00:48 â€¢ 0:03:56[0m [2;4m0.75it/s[0m  
[2KAttention weights: tensor([[0.6387, 0.3613],m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 26/203 [2m0:00:48 â€¢ 0:03:56[0m [2;4m0.75it/s[0m  
        [0.5562, 0.4438],
        [0.6314, 0.3686],
        [0.4923, 0.5077],
        [0.5633, 0.4367],
        [0.6457, 0.3543],
        [0.6958, 0.3042],
        [0.6355, 0.3645],
        [0.6242, 0.3758],
[2K        [0.6263, 0.3737]], device='cuda:0')0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 26/203 [2m0:00:48 â€¢ 0:03:56[0m [2;4m0.75it/s[0m  
[2KAttention weights: tensor([[0.5588, 0.4412],â•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 27/203 [2m0:00:54 â€¢ 0:04:27[0m [2;4m0.66it/s[0m  
        [0.5538, 0.4462],
        [0.5560, 0.4440],
        [0.5556, 0.4444],
        [0.5537, 0.4463],
        [0.5529, 0.4471],
        [0.5540, 0.4460],
        [0.5572, 0.4428],
        [0.5581, 0.4419],
[2K        [0.5544, 0.4456]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 27/203 [2m0:00:54 â€¢ 0:04:27[0m [2;4m0.66it/s[0m  
[2KClass label: GolfSwingâ”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 27/203 [2m0:00:54 â€¢ 0:04:27[0m [2;4m0.66it/s[0m  
[2KAttention weights: tensor([[0.6072, 0.3928]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 27/203 [2m0:00:54 â€¢ 0:04:27[0m [2;4m0.66it/s[0m  
[2KStep 0 - TTA Loss: 0.7170[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 27/203 [2m0:00:54 â€¢ 0:04:27[0m [2;4m0.66it/s[0m  
[2KAttention weights: tensor([[0.6072, 0.3928]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 27/203 [2m0:00:54 â€¢ 0:04:27[0m [2;4m0.66it/s[0m  
[2KAttention weights: tensor([[0.6077, 0.3923]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 27/203 [2m0:00:54 â€¢ 0:04:27[0m [2;4m0.66it/s[0m  
[2KAttention weights: tensor([[0.6093, 0.3907]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 27/203 [2m0:00:54 â€¢ 0:04:27[0m [2;4m0.66it/s[0m  
[2KAttention weights: tensor([[0.6119, 0.3881]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 27/203 [2m0:00:54 â€¢ 0:04:27[0m [2;4m0.66it/s[0m  
[2KAttention weights: tensor([[0.6149, 0.3851]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 27/203 [2m0:00:54 â€¢ 0:04:27[0m [2;4m0.66it/s[0m  
[2KAttention weights: tensor([[0.6157, 0.3843]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 27/203 [2m0:00:54 â€¢ 0:04:27[0m [2;4m0.66it/s[0m  
[2KAttention weights: tensor([[0.6111, 0.3889]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 27/203 [2m0:00:54 â€¢ 0:04:27[0m [2;4m0.66it/s[0m  
[2KAttention weights: tensor([[0.5973, 0.4027]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 27/203 [2m0:00:54 â€¢ 0:04:27[0m [2;4m0.66it/s[0m  
[2KAttention weights: tensor([[0.5725, 0.4275]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 27/203 [2m0:00:54 â€¢ 0:04:27[0m [2;4m0.66it/s[0m  
[2KAttention weights: tensor([[0.5535, 0.4465]], device='cuda:0')â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 27/203 [2m0:00:54 â€¢ 0:04:27[0m [2;4m0.66it/s[0m  
[2KAttention weights: tensor([[0.6680, 0.3320],m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 27/203 [2m0:00:54 â€¢ 0:04:27[0m [2;4m0.66it/s[0m  
        [0.5987, 0.4013],
        [0.6606, 0.3394],
        [0.5436, 0.4564],
        [0.5902, 0.4098],
        [0.6750, 0.3250],
        [0.7248, 0.2752],
        [0.6700, 0.3300],
        [0.6597, 0.3403],
[2K        [0.6511, 0.3489]], device='cuda:0')0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 27/203 [2m0:00:54 â€¢ 0:04:27[0m [2;4m0.66it/s[0m  
[2KAttention weights: tensor([[0.5588, 0.4412],;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 28/203 [2m0:00:56 â€¢ 0:04:30[0m [2;4m0.65it/s[0m  
        [0.5538, 0.4462],
        [0.5561, 0.4439],
        [0.5556, 0.4444],
        [0.5537, 0.4463],
        [0.5529, 0.4471],
        [0.5540, 0.4460],
        [0.5572, 0.4428],
        [0.5581, 0.4419],
[2K        [0.5544, 0.4456]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 28/203 [2m0:00:56 â€¢ 0:04:30[0m [2;4m0.65it/s[0m  
[2KClass label: PoleVaultâ”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 28/203 [2m0:00:56 â€¢ 0:04:30[0m [2;4m0.65it/s[0m  
[2KAttention weights: tensor([[0.6117, 0.3883]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 28/203 [2m0:00:56 â€¢ 0:04:30[0m [2;4m0.65it/s[0m  
[2KStep 0 - TTA Loss: 1.0295[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 28/203 [2m0:00:56 â€¢ 0:04:30[0m [2;4m0.65it/s[0m  
[2KAttention weights: tensor([[0.6308, 0.3692]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 28/203 [2m0:00:56 â€¢ 0:04:30[0m [2;4m0.65it/s[0m  
[2KAttention weights: tensor([[0.6520, 0.3480]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 28/203 [2m0:00:56 â€¢ 0:04:30[0m [2;4m0.65it/s[0m  
[2KAttention weights: tensor([[0.6785, 0.3215]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 28/203 [2m0:00:56 â€¢ 0:04:30[0m [2;4m0.65it/s[0m  
[2KAttention weights: tensor([[0.7021, 0.2979]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 28/203 [2m0:00:56 â€¢ 0:04:30[0m [2;4m0.65it/s[0m  
[2KAttention weights: tensor([[0.7190, 0.2810]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 28/203 [2m0:00:56 â€¢ 0:04:30[0m [2;4m0.65it/s[0m  
[2KAttention weights: tensor([[0.7294, 0.2706]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 28/203 [2m0:00:56 â€¢ 0:04:30[0m [2;4m0.65it/s[0m  
[2KAttention weights: tensor([[0.7346, 0.2654]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 28/203 [2m0:00:56 â€¢ 0:04:30[0m [2;4m0.65it/s[0m  
[2KAttention weights: tensor([[0.7364, 0.2636]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 28/203 [2m0:00:56 â€¢ 0:04:30[0m [2;4m0.65it/s[0m  
[2KAttention weights: tensor([[0.7363, 0.2637]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 28/203 [2m0:00:56 â€¢ 0:04:30[0m [2;4m0.65it/s[0m  
[2KAttention weights: tensor([[0.5577, 0.4423]], device='cuda:0')â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 28/203 [2m0:00:56 â€¢ 0:04:30[0m [2;4m0.65it/s[0m  
[2KAttention weights: tensor([[0.6715, 0.3285],mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 28/203 [2m0:00:56 â€¢ 0:04:30[0m [2;4m0.65it/s[0m  
        [0.6048, 0.3952],
        [0.6665, 0.3335],
        [0.5335, 0.4665],
        [0.5985, 0.4015],
        [0.6844, 0.3156],
        [0.7361, 0.2639],
        [0.6741, 0.3259],
        [0.6590, 0.3410],
[2K        [0.6601, 0.3399]], device='cuda:0')4mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 28/203 [2m0:00:56 â€¢ 0:04:30[0m [2;4m0.65it/s[0m  
[2KAttention weights: tensor([[0.5589, 0.4411],;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 29/203 [2m0:00:56 â€¢ 0:04:29[0m [2;4m0.65it/s[0m  
        [0.5539, 0.4461],
        [0.5561, 0.4439],
        [0.5556, 0.4444],
        [0.5538, 0.4462],
        [0.5530, 0.4470],
        [0.5541, 0.4459],
        [0.5572, 0.4428],
        [0.5581, 0.4419],
[2K        [0.5544, 0.4456]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 29/203 [2m0:00:56 â€¢ 0:04:29[0m [2;4m0.65it/s[0m  
[2KClass label: Billiardsâ”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 29/203 [2m0:00:56 â€¢ 0:04:29[0m [2;4m0.65it/s[0m  
[2KAttention weights: tensor([[0.5924, 0.4076]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 29/203 [2m0:00:56 â€¢ 0:04:29[0m [2;4m0.65it/s[0m  
[2KStep 0 - TTA Loss: 0.6243[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 29/203 [2m0:00:56 â€¢ 0:04:29[0m [2;4m0.65it/s[0m  
[2KAttention weights: tensor([[0.5924, 0.4076]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 29/203 [2m0:00:56 â€¢ 0:04:29[0m [2;4m0.65it/s[0m  
[2KAttention weights: tensor([[0.5924, 0.4076]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 29/203 [2m0:00:56 â€¢ 0:04:29[0m [2;4m0.65it/s[0m  
[2KAttention weights: tensor([[0.5920, 0.4080]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 29/203 [2m0:00:56 â€¢ 0:04:29[0m [2;4m0.65it/s[0m  
[2KAttention weights: tensor([[0.5914, 0.4086]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 29/203 [2m0:00:56 â€¢ 0:04:29[0m [2;4m0.65it/s[0m  
[2KAttention weights: tensor([[0.5886, 0.4114]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 29/203 [2m0:00:56 â€¢ 0:04:29[0m [2;4m0.65it/s[0m  
[2KAttention weights: tensor([[0.5809, 0.4191]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 29/203 [2m0:00:56 â€¢ 0:04:29[0m [2;4m0.65it/s[0m  
[2KAttention weights: tensor([[0.5686, 0.4314]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 29/203 [2m0:00:56 â€¢ 0:04:29[0m [2;4m0.65it/s[0m  
[2KAttention weights: tensor([[0.5704, 0.4296]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 29/203 [2m0:00:56 â€¢ 0:04:29[0m [2;4m0.65it/s[0m  
[2KAttention weights: tensor([[0.6095, 0.3905]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 29/203 [2m0:00:56 â€¢ 0:04:29[0m [2;4m0.65it/s[0m  
[2KAttention weights: tensor([[0.5553, 0.4447]], device='cuda:0')â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 29/203 [2m0:00:56 â€¢ 0:04:29[0m [2;4m0.65it/s[0m  
[2KAttention weights: tensor([[0.6495, 0.3505],mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 29/203 [2m0:00:56 â€¢ 0:04:29[0m [2;4m0.65it/s[0m  
        [0.6882, 0.3118],
        [0.6213, 0.3787],
        [0.6022, 0.3978],
        [0.5412, 0.4588],
        [0.6019, 0.3981],
        [0.6079, 0.3921],
        [0.6509, 0.3491],
        [0.6674, 0.3326],
[2K        [0.6086, 0.3914]], device='cuda:0')4mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 29/203 [2m0:00:56 â€¢ 0:04:29[0m [2;4m0.65it/s[0m  
[2KAttention weights: tensor([[0.5588, 0.4412],;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 30/203 [2m0:00:58 â€¢ 0:04:32[0m [2;4m0.64it/s[0m  
        [0.5539, 0.4461],
        [0.5561, 0.4439],
        [0.5556, 0.4444],
        [0.5538, 0.4462],
        [0.5530, 0.4470],
        [0.5541, 0.4459],
        [0.5572, 0.4428],
        [0.5581, 0.4419],
[2K        [0.5544, 0.4456]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 30/203 [2m0:00:58 â€¢ 0:04:32[0m [2;4m0.64it/s[0m  
[2KClass label: ThrowDiscusâ”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 30/203 [2m0:00:58 â€¢ 0:04:32[0m [2;4m0.64it/s[0m  
[2KAttention weights: tensor([[0.6136, 0.3864]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 30/203 [2m0:00:58 â€¢ 0:04:32[0m [2;4m0.64it/s[0m  
[2KStep 0 - TTA Loss: 0.6318[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 30/203 [2m0:00:58 â€¢ 0:04:32[0m [2;4m0.64it/s[0m  
[2KAttention weights: tensor([[0.6044, 0.3956]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 30/203 [2m0:00:58 â€¢ 0:04:32[0m [2;4m0.64it/s[0m  
[2KAttention weights: tensor([[0.5749, 0.4251]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 30/203 [2m0:00:58 â€¢ 0:04:32[0m [2;4m0.64it/s[0m  
[2KAttention weights: tensor([[0.5331, 0.4669]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 30/203 [2m0:00:58 â€¢ 0:04:32[0m [2;4m0.64it/s[0m  
[2KAttention weights: tensor([[0.4833, 0.5167]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 30/203 [2m0:00:58 â€¢ 0:04:32[0m [2;4m0.64it/s[0m  
[2KAttention weights: tensor([[0.4390, 0.5610]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 30/203 [2m0:00:58 â€¢ 0:04:32[0m [2;4m0.64it/s[0m  
[2KAttention weights: tensor([[0.4032, 0.5968]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 30/203 [2m0:00:58 â€¢ 0:04:32[0m [2;4m0.64it/s[0m  
[2KAttention weights: tensor([[0.3794, 0.6206]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 30/203 [2m0:00:58 â€¢ 0:04:32[0m [2;4m0.64it/s[0m  
[2KAttention weights: tensor([[0.3658, 0.6342]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 30/203 [2m0:00:58 â€¢ 0:04:32[0m [2;4m0.64it/s[0m  
[2KAttention weights: tensor([[0.3600, 0.6400]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 30/203 [2m0:00:58 â€¢ 0:04:32[0m [2;4m0.64it/s[0m  
[2KAttention weights: tensor([[0.5471, 0.4529]], device='cuda:0')â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 30/203 [2m0:00:58 â€¢ 0:04:32[0m [2;4m0.64it/s[0m  
[2KAttention weights: tensor([[0.6287, 0.3713],mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 30/203 [2m0:00:58 â€¢ 0:04:32[0m [2;4m0.64it/s[0m  
        [0.8112, 0.1888],
        [0.4711, 0.5289],
        [0.5656, 0.4344],
        [0.4405, 0.5595],
        [0.5205, 0.4795],
        [0.5453, 0.4547],
        [0.6554, 0.3446],
        [0.6003, 0.3997],
[2K        [0.3585, 0.6415]], device='cuda:0')4mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 30/203 [2m0:00:58 â€¢ 0:04:32[0m [2;4m0.64it/s[0m  
[2KAttention weights: tensor([[0.5588, 0.4412],mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 31/203 [2m0:00:59 â€¢ 0:04:44[0m [2;4m0.61it/s[0m   
        [0.5539, 0.4461],
        [0.5560, 0.4440],
        [0.5556, 0.4444],
        [0.5537, 0.4463],
        [0.5529, 0.4471],
        [0.5541, 0.4459],
        [0.5572, 0.4428],
        [0.5581, 0.4419],
[2K        [0.5543, 0.4457]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 31/203 [2m0:00:59 â€¢ 0:04:44[0m [2;4m0.61it/s[0m  
[2KClass label: CleanAndJerkâ”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 31/203 [2m0:00:59 â€¢ 0:04:44[0m [2;4m0.61it/s[0m  
[2KAttention weights: tensor([[0.6171, 0.3829]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 31/203 [2m0:00:59 â€¢ 0:04:44[0m [2;4m0.61it/s[0m  
[2KStep 0 - TTA Loss: 0.6875â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 31/203 [2m0:00:59 â€¢ 0:04:44[0m [2;4m0.61it/s[0m  
[2KAttention weights: tensor([[0.6171, 0.3829]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 31/203 [2m0:00:59 â€¢ 0:04:44[0m [2;4m0.61it/s[0m  
[2KAttention weights: tensor([[0.6167, 0.3833]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 31/203 [2m0:00:59 â€¢ 0:04:44[0m [2;4m0.61it/s[0m  
[2KAttention weights: tensor([[0.6155, 0.3845]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 31/203 [2m0:00:59 â€¢ 0:04:44[0m [2;4m0.61it/s[0m  
[2KAttention weights: tensor([[0.6134, 0.3866]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 31/203 [2m0:00:59 â€¢ 0:04:44[0m [2;4m0.61it/s[0m  
[2KAttention weights: tensor([[0.6110, 0.3890]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 31/203 [2m0:00:59 â€¢ 0:04:44[0m [2;4m0.61it/s[0m  
[2KAttention weights: tensor([[0.6086, 0.3914]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 31/203 [2m0:00:59 â€¢ 0:04:44[0m [2;4m0.61it/s[0m  
[2KAttention weights: tensor([[0.6045, 0.3955]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 31/203 [2m0:00:59 â€¢ 0:04:44[0m [2;4m0.61it/s[0m  
[2KAttention weights: tensor([[0.5929, 0.4071]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 31/203 [2m0:00:59 â€¢ 0:04:44[0m [2;4m0.61it/s[0m  
[2KAttention weights: tensor([[0.5710, 0.4290]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 31/203 [2m0:00:59 â€¢ 0:04:44[0m [2;4m0.61it/s[0m  
[2KAttention weights: tensor([[0.5532, 0.4468]], device='cuda:0')â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 31/203 [2m0:00:59 â€¢ 0:04:44[0m [2;4m0.61it/s[0m  
[2KAttention weights: tensor([[0.6171, 0.3829],0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 31/203 [2m0:00:59 â€¢ 0:04:44[0m [2;4m0.61it/s[0m  
        [0.6259, 0.3741],
        [0.5403, 0.4597],
        [0.5694, 0.4306],
        [0.4749, 0.5251],
        [0.5452, 0.4548],
        [0.5659, 0.4341],
        [0.6200, 0.3800],
        [0.6115, 0.3885],
[2K        [0.4851, 0.5149]], device='cuda:0')[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 31/203 [2m0:00:59 â€¢ 0:04:44[0m [2;4m0.61it/s[0m  
[2KAttention weights: tensor([[0.5588, 0.4412],mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 32/203 [2m0:01:02 â€¢ 0:05:00[0m [2;4m0.57it/s[0m  
        [0.5539, 0.4461],
        [0.5560, 0.4440],
        [0.5556, 0.4444],
        [0.5537, 0.4463],
        [0.5529, 0.4471],
        [0.5541, 0.4459],
        [0.5572, 0.4428],
        [0.5581, 0.4419],
[2K        [0.5543, 0.4457]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 32/203 [2m0:01:02 â€¢ 0:05:00[0m [2;4m0.57it/s[0m  
[2KClass label: TennisSwingâ”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 32/203 [2m0:01:02 â€¢ 0:05:00[0m [2;4m0.57it/s[0m  
[2KAttention weights: tensor([[0.6621, 0.3379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 32/203 [2m0:01:02 â€¢ 0:05:00[0m [2;4m0.57it/s[0m  
[2KStep 0 - TTA Loss: 0.6474â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 32/203 [2m0:01:02 â€¢ 0:05:00[0m [2;4m0.57it/s[0m  
[2KAttention weights: tensor([[0.6323, 0.3677]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 32/203 [2m0:01:02 â€¢ 0:05:00[0m [2;4m0.57it/s[0m  
[2KAttention weights: tensor([[0.5859, 0.4141]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 32/203 [2m0:01:02 â€¢ 0:05:00[0m [2;4m0.57it/s[0m  
[2KAttention weights: tensor([[0.5231, 0.4769]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 32/203 [2m0:01:02 â€¢ 0:05:00[0m [2;4m0.57it/s[0m  
[2KAttention weights: tensor([[0.4508, 0.5492]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 32/203 [2m0:01:02 â€¢ 0:05:00[0m [2;4m0.57it/s[0m  
[2KAttention weights: tensor([[0.3827, 0.6173]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 32/203 [2m0:01:02 â€¢ 0:05:00[0m [2;4m0.57it/s[0m  
[2KAttention weights: tensor([[0.3329, 0.6671]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 32/203 [2m0:01:02 â€¢ 0:05:00[0m [2;4m0.57it/s[0m  
[2KAttention weights: tensor([[0.3049, 0.6951]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 32/203 [2m0:01:02 â€¢ 0:05:00[0m [2;4m0.57it/s[0m  
[2KAttention weights: tensor([[0.2932, 0.7068]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 32/203 [2m0:01:02 â€¢ 0:05:00[0m [2;4m0.57it/s[0m  
[2KAttention weights: tensor([[0.2899, 0.7101]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 32/203 [2m0:01:02 â€¢ 0:05:00[0m [2;4m0.57it/s[0m  
[2KAttention weights: tensor([[0.5471, 0.4529]], device='cuda:0')â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 32/203 [2m0:01:02 â€¢ 0:05:00[0m [2;4m0.57it/s[0m  
[2KAttention weights: tensor([[0.4569, 0.5431],0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 32/203 [2m0:01:02 â€¢ 0:05:00[0m [2;4m0.57it/s[0m  
        [0.4774, 0.5226],
        [0.3612, 0.6388],
        [0.3784, 0.6216],
        [0.3203, 0.6797],
        [0.3633, 0.6367],
        [0.4305, 0.5695],
        [0.4403, 0.5597],
        [0.2896, 0.7104],
[2K        [0.3222, 0.6778]], device='cuda:0')[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 32/203 [2m0:01:02 â€¢ 0:05:00[0m [2;4m0.57it/s[0m  
[2KAttention weights: tensor([[0.5587, 0.4413],6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 33/203 [2m0:01:08 â€¢ 0:06:07[0m [2;4m0.46it/s[0m  
        [0.5538, 0.4462],
        [0.5559, 0.4441],
        [0.5555, 0.4445],
        [0.5535, 0.4465],
        [0.5528, 0.4472],
        [0.5540, 0.4460],
        [0.5571, 0.4429],
        [0.5579, 0.4421],
[2K        [0.5542, 0.4458]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 33/203 [2m0:01:08 â€¢ 0:06:07[0m [2;4m0.46it/s[0m  
[2KClass label: CleanAndJerkâ”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 33/203 [2m0:01:08 â€¢ 0:06:07[0m [2;4m0.46it/s[0m  
[2KAttention weights: tensor([[0.6215, 0.3785]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 33/203 [2m0:01:08 â€¢ 0:06:07[0m [2;4m0.46it/s[0m  
[2KStep 0 - TTA Loss: 0.5101â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 33/203 [2m0:01:08 â€¢ 0:06:07[0m [2;4m0.46it/s[0m  
[2KAttention weights: tensor([[0.6215, 0.3785]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 33/203 [2m0:01:08 â€¢ 0:06:07[0m [2;4m0.46it/s[0m  
[2KAttention weights: tensor([[0.6220, 0.3780]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 33/203 [2m0:01:08 â€¢ 0:06:07[0m [2;4m0.46it/s[0m  
[2KAttention weights: tensor([[0.6250, 0.3750]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 33/203 [2m0:01:08 â€¢ 0:06:07[0m [2;4m0.46it/s[0m  
[2KAttention weights: tensor([[0.6335, 0.3665]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 33/203 [2m0:01:08 â€¢ 0:06:07[0m [2;4m0.46it/s[0m  
[2KAttention weights: tensor([[0.6495, 0.3505]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 33/203 [2m0:01:08 â€¢ 0:06:07[0m [2;4m0.46it/s[0m  
[2KAttention weights: tensor([[0.6725, 0.3275]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 33/203 [2m0:01:08 â€¢ 0:06:07[0m [2;4m0.46it/s[0m  
[2KAttention weights: tensor([[0.6978, 0.3022]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 33/203 [2m0:01:08 â€¢ 0:06:07[0m [2;4m0.46it/s[0m  
[2KAttention weights: tensor([[0.7170, 0.2830]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 33/203 [2m0:01:08 â€¢ 0:06:07[0m [2;4m0.46it/s[0m  
[2KAttention weights: tensor([[0.7217, 0.2783]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 33/203 [2m0:01:08 â€¢ 0:06:07[0m [2;4m0.46it/s[0m  
[2KAttention weights: tensor([[0.5571, 0.4429]], device='cuda:0')â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 33/203 [2m0:01:08 â€¢ 0:06:07[0m [2;4m0.46it/s[0m  
[2KAttention weights: tensor([[0.6618, 0.3382],4mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 33/203 [2m0:01:08 â€¢ 0:06:07[0m [2;4m0.46it/s[0m  
        [0.6147, 0.3853],
        [0.7157, 0.2843],
        [0.6259, 0.3741],
        [0.5788, 0.4212],
        [0.6346, 0.3654],
        [0.6470, 0.3530],
        [0.6539, 0.3461],
        [0.6854, 0.3146],
[2K        [0.6669, 0.3331]], device='cuda:0')24mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 33/203 [2m0:01:08 â€¢ 0:06:07[0m [2;4m0.46it/s[0m  
[2KAttention weights: tensor([[0.5587, 0.4413],6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 34/203 [2m0:01:11 â€¢ 0:06:19[0m [2;4m0.45it/s[0m  
        [0.5538, 0.4462],
        [0.5559, 0.4441],
        [0.5555, 0.4445],
        [0.5535, 0.4465],
        [0.5528, 0.4472],
        [0.5540, 0.4460],
        [0.5571, 0.4429],
        [0.5579, 0.4421],
[2K        [0.5541, 0.4459]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 34/203 [2m0:01:11 â€¢ 0:06:19[0m [2;4m0.45it/s[0m  
[2KClass label: PoleVaultâ”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 34/203 [2m0:01:11 â€¢ 0:06:19[0m [2;4m0.45it/s[0m  
[2KAttention weights: tensor([[0.6146, 0.3854]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 34/203 [2m0:01:11 â€¢ 0:06:19[0m [2;4m0.45it/s[0m  
[2KStep 0 - TTA Loss: 0.6912â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 34/203 [2m0:01:11 â€¢ 0:06:19[0m [2;4m0.45it/s[0m  
[2KAttention weights: tensor([[0.6049, 0.3951]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 34/203 [2m0:01:11 â€¢ 0:06:19[0m [2;4m0.45it/s[0m  
[2KAttention weights: tensor([[0.5897, 0.4103]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 34/203 [2m0:01:11 â€¢ 0:06:19[0m [2;4m0.45it/s[0m  
[2KAttention weights: tensor([[0.5685, 0.4315]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 34/203 [2m0:01:11 â€¢ 0:06:19[0m [2;4m0.45it/s[0m  
[2KAttention weights: tensor([[0.5449, 0.4551]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 34/203 [2m0:01:11 â€¢ 0:06:19[0m [2;4m0.45it/s[0m  
[2KAttention weights: tensor([[0.5229, 0.4771]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 34/203 [2m0:01:11 â€¢ 0:06:19[0m [2;4m0.45it/s[0m  
[2KAttention weights: tensor([[0.5064, 0.4936]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 34/203 [2m0:01:11 â€¢ 0:06:19[0m [2;4m0.45it/s[0m  
[2KAttention weights: tensor([[0.4969, 0.5031]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 34/203 [2m0:01:11 â€¢ 0:06:19[0m [2;4m0.45it/s[0m  
[2KAttention weights: tensor([[0.4925, 0.5075]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 34/203 [2m0:01:11 â€¢ 0:06:19[0m [2;4m0.45it/s[0m  
[2KAttention weights: tensor([[0.4912, 0.5088]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 34/203 [2m0:01:11 â€¢ 0:06:19[0m [2;4m0.45it/s[0m  
[2KAttention weights: tensor([[0.5502, 0.4498]], device='cuda:0')â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 34/203 [2m0:01:11 â€¢ 0:06:19[0m [2;4m0.45it/s[0m  
[2KAttention weights: tensor([[0.5685, 0.4315],4mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 34/203 [2m0:01:11 â€¢ 0:06:19[0m [2;4m0.45it/s[0m  
        [0.5449, 0.4551],
        [0.5373, 0.4627],
        [0.5395, 0.4605],
        [0.4513, 0.5487],
        [0.4968, 0.5032],
        [0.4910, 0.5090],
        [0.5567, 0.4433],
        [0.5899, 0.4101],
[2K        [0.5277, 0.4723]], device='cuda:0')24mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 34/203 [2m0:01:11 â€¢ 0:06:19[0m [2;4m0.45it/s[0m  
[2KAttention weights: tensor([[0.5586, 0.4414],6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 35/203 [2m0:01:13 â€¢ 0:06:26[0m [2;4m0.44it/s[0m  
        [0.5537, 0.4463],
        [0.5558, 0.4442],
        [0.5554, 0.4446],
        [0.5534, 0.4466],
        [0.5527, 0.4473],
        [0.5538, 0.4462],
        [0.5570, 0.4430],
        [0.5578, 0.4422],
[2K        [0.5540, 0.4460]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 35/203 [2m0:01:13 â€¢ 0:06:26[0m [2;4m0.44it/s[0m  
[2KClass label: GolfSwingâ”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 35/203 [2m0:01:13 â€¢ 0:06:26[0m [2;4m0.44it/s[0m  
[2KAttention weights: tensor([[0.6049, 0.3951]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 35/203 [2m0:01:13 â€¢ 0:06:26[0m [2;4m0.44it/s[0m  
[2KStep 0 - TTA Loss: 1.1108â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 35/203 [2m0:01:13 â€¢ 0:06:26[0m [2;4m0.44it/s[0m  
[2KAttention weights: tensor([[0.6049, 0.3951]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 35/203 [2m0:01:13 â€¢ 0:06:26[0m [2;4m0.44it/s[0m  
[2KAttention weights: tensor([[0.6052, 0.3948]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 35/203 [2m0:01:13 â€¢ 0:06:26[0m [2;4m0.44it/s[0m  
[2KAttention weights: tensor([[0.6065, 0.3935]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 35/203 [2m0:01:13 â€¢ 0:06:26[0m [2;4m0.44it/s[0m  
[2KAttention weights: tensor([[0.6124, 0.3876]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 35/203 [2m0:01:13 â€¢ 0:06:26[0m [2;4m0.44it/s[0m  
[2KAttention weights: tensor([[0.6242, 0.3758]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 35/203 [2m0:01:13 â€¢ 0:06:26[0m [2;4m0.44it/s[0m  
[2KAttention weights: tensor([[0.6415, 0.3585]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 35/203 [2m0:01:13 â€¢ 0:06:26[0m [2;4m0.44it/s[0m  
[2KAttention weights: tensor([[0.6435, 0.3565]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 35/203 [2m0:01:13 â€¢ 0:06:26[0m [2;4m0.44it/s[0m  
[2KAttention weights: tensor([[0.6207, 0.3793]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 35/203 [2m0:01:13 â€¢ 0:06:26[0m [2;4m0.44it/s[0m  
[2KAttention weights: tensor([[0.5649, 0.4351]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 35/203 [2m0:01:13 â€¢ 0:06:26[0m [2;4m0.44it/s[0m  
[2KAttention weights: tensor([[0.5528, 0.4472]], device='cuda:0')â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 35/203 [2m0:01:13 â€¢ 0:06:26[0m [2;4m0.44it/s[0m  
[2KAttention weights: tensor([[0.5916, 0.4084],4mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 35/203 [2m0:01:13 â€¢ 0:06:26[0m [2;4m0.44it/s[0m  
        [0.5603, 0.4397],
        [0.5884, 0.4116],
        [0.5175, 0.4825],
        [0.4916, 0.5084],
        [0.5548, 0.4452],
        [0.5680, 0.4320],
        [0.5835, 0.4165],
        [0.6136, 0.3864],
[2K        [0.5732, 0.4268]], device='cuda:0')24mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 35/203 [2m0:01:13 â€¢ 0:06:26[0m [2;4m0.44it/s[0m  
[2KAttention weights: tensor([[0.5586, 0.4414],7mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 36/203 [2m0:01:14 â€¢ 0:06:22[0m [2;4m0.44it/s[0m   
        [0.5537, 0.4463],
        [0.5557, 0.4443],
        [0.5554, 0.4446],
        [0.5534, 0.4466],
        [0.5527, 0.4473],
        [0.5538, 0.4462],
        [0.5570, 0.4430],
        [0.5578, 0.4422],
[2K        [0.5540, 0.4460]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 36/203 [2m0:01:14 â€¢ 0:06:22[0m [2;4m0.44it/s[0m  
[2KClass label: TennisSwingâ”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 36/203 [2m0:01:14 â€¢ 0:06:22[0m [2;4m0.44it/s[0m  
[2KAttention weights: tensor([[0.6624, 0.3376]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 36/203 [2m0:01:14 â€¢ 0:06:22[0m [2;4m0.44it/s[0m  
[2KStep 0 - TTA Loss: 0.7326â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 36/203 [2m0:01:14 â€¢ 0:06:22[0m [2;4m0.44it/s[0m  
[2KAttention weights: tensor([[0.6269, 0.3731]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 36/203 [2m0:01:14 â€¢ 0:06:22[0m [2;4m0.44it/s[0m  
[2KAttention weights: tensor([[0.5976, 0.4024]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 36/203 [2m0:01:14 â€¢ 0:06:22[0m [2;4m0.44it/s[0m  
[2KAttention weights: tensor([[0.5684, 0.4316]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 36/203 [2m0:01:14 â€¢ 0:06:22[0m [2;4m0.44it/s[0m  
[2KAttention weights: tensor([[0.5472, 0.4528]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 36/203 [2m0:01:14 â€¢ 0:06:22[0m [2;4m0.44it/s[0m  
[2KAttention weights: tensor([[0.5243, 0.4757]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 36/203 [2m0:01:14 â€¢ 0:06:22[0m [2;4m0.44it/s[0m  
[2KAttention weights: tensor([[0.4973, 0.5027]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 36/203 [2m0:01:14 â€¢ 0:06:22[0m [2;4m0.44it/s[0m  
[2KAttention weights: tensor([[0.4740, 0.5260]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 36/203 [2m0:01:14 â€¢ 0:06:22[0m [2;4m0.44it/s[0m  
[2KAttention weights: tensor([[0.4592, 0.5408]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 36/203 [2m0:01:14 â€¢ 0:06:22[0m [2;4m0.44it/s[0m  
[2KAttention weights: tensor([[0.4519, 0.5481]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 36/203 [2m0:01:14 â€¢ 0:06:22[0m [2;4m0.44it/s[0m  
[2KAttention weights: tensor([[0.5509, 0.4491]], device='cuda:0')â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 36/203 [2m0:01:14 â€¢ 0:06:22[0m [2;4m0.44it/s[0m  
[2KAttention weights: tensor([[0.4904, 0.5096],[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 36/203 [2m0:01:14 â€¢ 0:06:22[0m [2;4m0.44it/s[0m  
        [0.4754, 0.5246],
        [0.5062, 0.4938],
        [0.3609, 0.6391],
        [0.3982, 0.6018],
        [0.4563, 0.5437],
        [0.4928, 0.5072],
        [0.4795, 0.5205],
        [0.4498, 0.5502],
[2K        [0.4751, 0.5249]], device='cuda:0')[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 36/203 [2m0:01:14 â€¢ 0:06:22[0m [2;4m0.44it/s[0m  
[2KAttention weights: tensor([[0.5585, 0.4415],7mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 37/203 [2m0:01:15 â€¢ 0:06:19[0m [2;4m0.44it/s[0m  
        [0.5537, 0.4463],
        [0.5557, 0.4443],
        [0.5553, 0.4447],
        [0.5533, 0.4467],
        [0.5526, 0.4474],
        [0.5537, 0.4463],
        [0.5569, 0.4431],
        [0.5577, 0.4423],
[2K        [0.5539, 0.4461]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 37/203 [2m0:01:15 â€¢ 0:06:19[0m [2;4m0.44it/s[0m  
[2KClass label: SoccerPenaltyâ”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 37/203 [2m0:01:15 â€¢ 0:06:19[0m [2;4m0.44it/s[0m  
[2KAttention weights: tensor([[0.6354, 0.3646]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 37/203 [2m0:01:15 â€¢ 0:06:19[0m [2;4m0.44it/s[0m  
[2KStep 0 - TTA Loss: 0.9106â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 37/203 [2m0:01:15 â€¢ 0:06:19[0m [2;4m0.44it/s[0m  
[2KAttention weights: tensor([[0.6354, 0.3646]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 37/203 [2m0:01:15 â€¢ 0:06:19[0m [2;4m0.44it/s[0m  
[2KAttention weights: tensor([[0.6358, 0.3642]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 37/203 [2m0:01:15 â€¢ 0:06:19[0m [2;4m0.44it/s[0m  
[2KAttention weights: tensor([[0.6398, 0.3602]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 37/203 [2m0:01:15 â€¢ 0:06:19[0m [2;4m0.44it/s[0m  
[2KAttention weights: tensor([[0.6517, 0.3483]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 37/203 [2m0:01:15 â€¢ 0:06:19[0m [2;4m0.44it/s[0m  
[2KAttention weights: tensor([[0.6766, 0.3234]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 37/203 [2m0:01:15 â€¢ 0:06:19[0m [2;4m0.44it/s[0m  
[2KAttention weights: tensor([[0.7136, 0.2864]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 37/203 [2m0:01:15 â€¢ 0:06:19[0m [2;4m0.44it/s[0m  
[2KAttention weights: tensor([[0.7621, 0.2379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 37/203 [2m0:01:15 â€¢ 0:06:19[0m [2;4m0.44it/s[0m  
[2KAttention weights: tensor([[0.8015, 0.1985]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 37/203 [2m0:01:15 â€¢ 0:06:19[0m [2;4m0.44it/s[0m  
[2KAttention weights: tensor([[0.8168, 0.1832]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 37/203 [2m0:01:15 â€¢ 0:06:19[0m [2;4m0.44it/s[0m  
[2KAttention weights: tensor([[0.5601, 0.4399]], device='cuda:0')â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 37/203 [2m0:01:15 â€¢ 0:06:19[0m [2;4m0.44it/s[0m  
[2KAttention weights: tensor([[0.7081, 0.2919],[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 37/203 [2m0:01:15 â€¢ 0:06:19[0m [2;4m0.44it/s[0m  
        [0.6451, 0.3549],
        [0.6160, 0.3840],
        [0.6261, 0.3739],
        [0.6179, 0.3821],
        [0.6489, 0.3511],
        [0.6697, 0.3303],
        [0.8169, 0.1831],
        [0.6231, 0.3769],
[2K        [0.6022, 0.3978]], device='cuda:0')[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 37/203 [2m0:01:15 â€¢ 0:06:19[0m [2;4m0.44it/s[0m  
[2KAttention weights: tensor([[0.5585, 0.4415],7mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 38/203 [2m0:01:17 â€¢ 0:06:19[0m [2;4m0.44it/s[0m  
        [0.5537, 0.4463],
        [0.5557, 0.4443],
        [0.5553, 0.4447],
        [0.5534, 0.4466],
        [0.5526, 0.4474],
        [0.5538, 0.4462],
        [0.5570, 0.4430],
        [0.5577, 0.4423],
[2K        [0.5540, 0.4460]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 38/203 [2m0:01:17 â€¢ 0:06:19[0m [2;4m0.44it/s[0m  
[2KClass label: PoleVaultâ”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 38/203 [2m0:01:17 â€¢ 0:06:19[0m [2;4m0.44it/s[0m  
[2KAttention weights: tensor([[0.6142, 0.3858]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 38/203 [2m0:01:17 â€¢ 0:06:19[0m [2;4m0.44it/s[0m  
[2KStep 0 - TTA Loss: 0.7632â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 38/203 [2m0:01:17 â€¢ 0:06:19[0m [2;4m0.44it/s[0m  
[2KAttention weights: tensor([[0.6196, 0.3804]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 38/203 [2m0:01:17 â€¢ 0:06:19[0m [2;4m0.44it/s[0m  
[2KAttention weights: tensor([[0.6312, 0.3688]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 38/203 [2m0:01:17 â€¢ 0:06:19[0m [2;4m0.44it/s[0m  
[2KAttention weights: tensor([[0.6409, 0.3591]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 38/203 [2m0:01:17 â€¢ 0:06:19[0m [2;4m0.44it/s[0m  
[2KAttention weights: tensor([[0.6434, 0.3566]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 38/203 [2m0:01:17 â€¢ 0:06:19[0m [2;4m0.44it/s[0m  
[2KAttention weights: tensor([[0.6401, 0.3599]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 38/203 [2m0:01:17 â€¢ 0:06:19[0m [2;4m0.44it/s[0m  
[2KAttention weights: tensor([[0.6350, 0.3650]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 38/203 [2m0:01:17 â€¢ 0:06:19[0m [2;4m0.44it/s[0m  
[2KAttention weights: tensor([[0.6315, 0.3685]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 38/203 [2m0:01:17 â€¢ 0:06:19[0m [2;4m0.44it/s[0m  
[2KAttention weights: tensor([[0.6306, 0.3694]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 38/203 [2m0:01:17 â€¢ 0:06:19[0m [2;4m0.44it/s[0m  
[2KAttention weights: tensor([[0.6307, 0.3693]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 38/203 [2m0:01:17 â€¢ 0:06:19[0m [2;4m0.44it/s[0m  
[2KAttention weights: tensor([[0.5540, 0.4460]], device='cuda:0')â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 38/203 [2m0:01:17 â€¢ 0:06:19[0m [2;4m0.44it/s[0m  
[2KAttention weights: tensor([[0.6445, 0.3555],[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 38/203 [2m0:01:17 â€¢ 0:06:19[0m [2;4m0.44it/s[0m  
        [0.5886, 0.4114],
        [0.6067, 0.3933],
        [0.5816, 0.4184],
        [0.5444, 0.4556],
        [0.5978, 0.4022],
        [0.6309, 0.3691],
        [0.6617, 0.3383],
        [0.5991, 0.4009],
[2K        [0.5941, 0.4059]], device='cuda:0')[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 38/203 [2m0:01:17 â€¢ 0:06:19[0m [2;4m0.44it/s[0m  
[2KAttention weights: tensor([[0.5586, 0.4414],;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 39/203 [2m0:01:25 â€¢ 0:07:22[0m [2;4m0.37it/s[0m  
        [0.5537, 0.4463],
        [0.5557, 0.4443],
        [0.5553, 0.4447],
        [0.5534, 0.4466],
        [0.5527, 0.4473],
        [0.5538, 0.4462],
        [0.5571, 0.4429],
        [0.5577, 0.4423],
[2K        [0.5540, 0.4460]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 39/203 [2m0:01:25 â€¢ 0:07:22[0m [2;4m0.37it/s[0m  
[2KClass label: GolfSwingâ”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 39/203 [2m0:01:25 â€¢ 0:07:22[0m [2;4m0.37it/s[0m  
[2KAttention weights: tensor([[0.6019, 0.3981]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 39/203 [2m0:01:25 â€¢ 0:07:22[0m [2;4m0.37it/s[0m  
[2KStep 0 - TTA Loss: 0.8041â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 39/203 [2m0:01:25 â€¢ 0:07:22[0m [2;4m0.37it/s[0m  
[2KAttention weights: tensor([[0.6019, 0.3981]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 39/203 [2m0:01:25 â€¢ 0:07:22[0m [2;4m0.37it/s[0m  
[2KAttention weights: tensor([[0.6018, 0.3982]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 39/203 [2m0:01:25 â€¢ 0:07:22[0m [2;4m0.37it/s[0m  
[2KAttention weights: tensor([[0.6012, 0.3988]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 39/203 [2m0:01:25 â€¢ 0:07:22[0m [2;4m0.37it/s[0m  
[2KAttention weights: tensor([[0.5978, 0.4022]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 39/203 [2m0:01:25 â€¢ 0:07:22[0m [2;4m0.37it/s[0m  
[2KAttention weights: tensor([[0.5911, 0.4089]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 39/203 [2m0:01:25 â€¢ 0:07:22[0m [2;4m0.37it/s[0m  
[2KAttention weights: tensor([[0.5803, 0.4197]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 39/203 [2m0:01:25 â€¢ 0:07:22[0m [2;4m0.37it/s[0m  
[2KAttention weights: tensor([[0.5637, 0.4363]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 39/203 [2m0:01:25 â€¢ 0:07:22[0m [2;4m0.37it/s[0m  
[2KAttention weights: tensor([[0.5382, 0.4618]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 39/203 [2m0:01:25 â€¢ 0:07:22[0m [2;4m0.37it/s[0m  
[2KAttention weights: tensor([[0.5017, 0.4983]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 39/203 [2m0:01:25 â€¢ 0:07:22[0m [2;4m0.37it/s[0m  
[2KAttention weights: tensor([[0.5507, 0.4493]], device='cuda:0')mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 39/203 [2m0:01:25 â€¢ 0:07:22[0m [2;4m0.37it/s[0m  
[2KAttention weights: tensor([[0.5774, 0.4226],24mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 39/203 [2m0:01:25 â€¢ 0:07:22[0m [2;4m0.37it/s[0m  
        [0.5432, 0.4568],
        [0.5768, 0.4232],
        [0.4589, 0.5411],
        [0.4845, 0.5155],
        [0.5503, 0.4497],
        [0.5750, 0.4250],
        [0.5763, 0.4237],
        [0.5826, 0.4174],
[2K        [0.5578, 0.4422]], device='cuda:0')224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 39/203 [2m0:01:25 â€¢ 0:07:22[0m [2;4m0.37it/s[0m  
[2KAttention weights: tensor([[0.5586, 0.4414],;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 40/203 [2m0:01:28 â€¢ 0:08:42[0m [2;4m0.31it/s[0m  
        [0.5537, 0.4463],
        [0.5557, 0.4443],
        [0.5553, 0.4447],
        [0.5534, 0.4466],
        [0.5527, 0.4473],
        [0.5538, 0.4462],
        [0.5570, 0.4430],
        [0.5577, 0.4423],
[2K        [0.5540, 0.4460]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 40/203 [2m0:01:28 â€¢ 0:08:42[0m [2;4m0.31it/s[0m  
[2KClass label: PoleVaultâ”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 40/203 [2m0:01:28 â€¢ 0:08:42[0m [2;4m0.31it/s[0m  
[2KAttention weights: tensor([[0.6130, 0.3870]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 40/203 [2m0:01:28 â€¢ 0:08:42[0m [2;4m0.31it/s[0m  
[2KStep 0 - TTA Loss: 0.6503â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 40/203 [2m0:01:28 â€¢ 0:08:42[0m [2;4m0.31it/s[0m  
[2KAttention weights: tensor([[0.5924, 0.4076]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 40/203 [2m0:01:28 â€¢ 0:08:42[0m [2;4m0.31it/s[0m  
[2KAttention weights: tensor([[0.5642, 0.4358]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 40/203 [2m0:01:28 â€¢ 0:08:42[0m [2;4m0.31it/s[0m  
[2KAttention weights: tensor([[0.5287, 0.4713]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 40/203 [2m0:01:28 â€¢ 0:08:42[0m [2;4m0.31it/s[0m  
[2KAttention weights: tensor([[0.4888, 0.5112]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 40/203 [2m0:01:28 â€¢ 0:08:42[0m [2;4m0.31it/s[0m  
[2KAttention weights: tensor([[0.4539, 0.5461]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 40/203 [2m0:01:28 â€¢ 0:08:42[0m [2;4m0.31it/s[0m  
[2KAttention weights: tensor([[0.4272, 0.5728]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 40/203 [2m0:01:28 â€¢ 0:08:42[0m [2;4m0.31it/s[0m  
[2KAttention weights: tensor([[0.4102, 0.5898]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 40/203 [2m0:01:28 â€¢ 0:08:42[0m [2;4m0.31it/s[0m  
[2KAttention weights: tensor([[0.4014, 0.5986]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 40/203 [2m0:01:28 â€¢ 0:08:42[0m [2;4m0.31it/s[0m  
[2KAttention weights: tensor([[0.3982, 0.6018]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 40/203 [2m0:01:28 â€¢ 0:08:42[0m [2;4m0.31it/s[0m  
[2KAttention weights: tensor([[0.5472, 0.4528]], device='cuda:0')mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 40/203 [2m0:01:28 â€¢ 0:08:42[0m [2;4m0.31it/s[0m  
[2KAttention weights: tensor([[0.4687, 0.5313],24mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 40/203 [2m0:01:28 â€¢ 0:08:42[0m [2;4m0.31it/s[0m  
        [0.4683, 0.5317],
        [0.4841, 0.5159],
        [0.3635, 0.6365],
        [0.3646, 0.6354],
        [0.4066, 0.5934],
        [0.3974, 0.6026],
        [0.4551, 0.5449],
        [0.4963, 0.5037],
[2K        [0.4507, 0.5493]], device='cuda:0')224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 40/203 [2m0:01:28 â€¢ 0:08:42[0m [2;4m0.31it/s[0m  
[2KAttention weights: tensor([[0.5585, 0.4415],37mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 41/203 [2m0:01:36 â€¢ 0:09:32[0m [2;4m0.28it/s[0m   
        [0.5536, 0.4464],
        [0.5556, 0.4444],
        [0.5552, 0.4448],
        [0.5533, 0.4467],
        [0.5526, 0.4474],
        [0.5537, 0.4463],
        [0.5570, 0.4430],
        [0.5576, 0.4424],
[2K        [0.5539, 0.4461]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 41/203 [2m0:01:36 â€¢ 0:09:32[0m [2;4m0.28it/s[0m  
[2KClass label: PoleVaultâ”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 41/203 [2m0:01:36 â€¢ 0:09:32[0m [2;4m0.28it/s[0m  
[2KAttention weights: tensor([[0.6086, 0.3914]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 41/203 [2m0:01:36 â€¢ 0:09:32[0m [2;4m0.28it/s[0m  
[2KStep 0 - TTA Loss: 0.7856â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 41/203 [2m0:01:36 â€¢ 0:09:32[0m [2;4m0.28it/s[0m  
[2KAttention weights: tensor([[0.6086, 0.3914]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 41/203 [2m0:01:36 â€¢ 0:09:32[0m [2;4m0.28it/s[0m  
[2KAttention weights: tensor([[0.6080, 0.3920]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 41/203 [2m0:01:36 â€¢ 0:09:32[0m [2;4m0.28it/s[0m  
[2KAttention weights: tensor([[0.6057, 0.3943]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 41/203 [2m0:01:36 â€¢ 0:09:32[0m [2;4m0.28it/s[0m  
[2KAttention weights: tensor([[0.6014, 0.3986]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 41/203 [2m0:01:36 â€¢ 0:09:32[0m [2;4m0.28it/s[0m  
[2KAttention weights: tensor([[0.5952, 0.4048]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 41/203 [2m0:01:36 â€¢ 0:09:32[0m [2;4m0.28it/s[0m  
[2KAttention weights: tensor([[0.5841, 0.4159]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 41/203 [2m0:01:36 â€¢ 0:09:32[0m [2;4m0.28it/s[0m  
[2KAttention weights: tensor([[0.5674, 0.4326]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 41/203 [2m0:01:36 â€¢ 0:09:32[0m [2;4m0.28it/s[0m  
[2KAttention weights: tensor([[0.5450, 0.4550]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 41/203 [2m0:01:36 â€¢ 0:09:32[0m [2;4m0.28it/s[0m  
[2KAttention weights: tensor([[0.5229, 0.4771]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 41/203 [2m0:01:36 â€¢ 0:09:32[0m [2;4m0.28it/s[0m  
[2KAttention weights: tensor([[0.5502, 0.4498]], device='cuda:0')â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 41/203 [2m0:01:36 â€¢ 0:09:32[0m [2;4m0.28it/s[0m  
[2KAttention weights: tensor([[0.5630, 0.4370],[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 41/203 [2m0:01:36 â€¢ 0:09:32[0m [2;4m0.28it/s[0m  
        [0.5392, 0.4608],
        [0.5565, 0.4435],
        [0.5190, 0.4810],
        [0.4543, 0.5457],
        [0.5025, 0.4975],
        [0.4968, 0.5032],
        [0.5509, 0.4491],
        [0.5938, 0.4062],
[2K        [0.5395, 0.4605]], device='cuda:0')â•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 41/203 [2m0:01:36 â€¢ 0:09:32[0m [2;4m0.28it/s[0m  
[2KAttention weights: tensor([[0.5585, 0.4415],37mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 42/203 [2m0:01:41 â€¢ 0:09:52[0m [2;4m0.27it/s[0m  
        [0.5536, 0.4464],
        [0.5556, 0.4444],
        [0.5552, 0.4448],
        [0.5533, 0.4467],
        [0.5525, 0.4475],
        [0.5536, 0.4464],
        [0.5570, 0.4430],
        [0.5576, 0.4424],
[2K        [0.5539, 0.4461]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 42/203 [2m0:01:41 â€¢ 0:09:52[0m [2;4m0.27it/s[0m  
[2KClass label: ThrowDiscusâ”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 42/203 [2m0:01:41 â€¢ 0:09:52[0m [2;4m0.27it/s[0m  
[2KAttention weights: tensor([[0.6108, 0.3892]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 42/203 [2m0:01:41 â€¢ 0:09:52[0m [2;4m0.27it/s[0m  
[2KStep 0 - TTA Loss: 0.9402â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 42/203 [2m0:01:41 â€¢ 0:09:52[0m [2;4m0.27it/s[0m  
[2KAttention weights: tensor([[0.6110, 0.3890]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 42/203 [2m0:01:41 â€¢ 0:09:52[0m [2;4m0.27it/s[0m  
[2KAttention weights: tensor([[0.6226, 0.3774]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 42/203 [2m0:01:41 â€¢ 0:09:52[0m [2;4m0.27it/s[0m  
[2KAttention weights: tensor([[0.6386, 0.3614]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 42/203 [2m0:01:41 â€¢ 0:09:52[0m [2;4m0.27it/s[0m  
[2KAttention weights: tensor([[0.6543, 0.3457]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 42/203 [2m0:01:41 â€¢ 0:09:52[0m [2;4m0.27it/s[0m  
[2KAttention weights: tensor([[0.6666, 0.3334]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 42/203 [2m0:01:41 â€¢ 0:09:52[0m [2;4m0.27it/s[0m  
[2KAttention weights: tensor([[0.6733, 0.3267]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 42/203 [2m0:01:41 â€¢ 0:09:52[0m [2;4m0.27it/s[0m  
[2KAttention weights: tensor([[0.6739, 0.3261]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 42/203 [2m0:01:41 â€¢ 0:09:52[0m [2;4m0.27it/s[0m  
[2KAttention weights: tensor([[0.6722, 0.3278]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 42/203 [2m0:01:41 â€¢ 0:09:52[0m [2;4m0.27it/s[0m  
[2KAttention weights: tensor([[0.6705, 0.3295]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 42/203 [2m0:01:41 â€¢ 0:09:52[0m [2;4m0.27it/s[0m  
[2KAttention weights: tensor([[0.5552, 0.4448]], device='cuda:0')â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 42/203 [2m0:01:41 â€¢ 0:09:52[0m [2;4m0.27it/s[0m  
[2KAttention weights: tensor([[0.6111, 0.3889],[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 42/203 [2m0:01:41 â€¢ 0:09:52[0m [2;4m0.27it/s[0m  
        [0.5746, 0.4254],
        [0.6409, 0.3591],
        [0.5848, 0.4152],
        [0.5356, 0.4644],
        [0.5789, 0.4211],
        [0.5640, 0.4360],
        [0.6004, 0.3996],
        [0.6628, 0.3372],
[2K        [0.6698, 0.3302]], device='cuda:0')â•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 42/203 [2m0:01:41 â€¢ 0:09:52[0m [2;4m0.27it/s[0m  
[2KAttention weights: tensor([[0.5585, 0.4415],37mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 43/203 [2m0:01:42 â€¢ 0:09:27[0m [2;4m0.28it/s[0m  
        [0.5536, 0.4464],
        [0.5556, 0.4444],
        [0.5552, 0.4448],
        [0.5533, 0.4467],
        [0.5525, 0.4475],
        [0.5536, 0.4464],
        [0.5570, 0.4430],
        [0.5576, 0.4424],
[2K        [0.5539, 0.4461]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 43/203 [2m0:01:42 â€¢ 0:09:27[0m [2;4m0.28it/s[0m  
[2KClass label: ThrowDiscusâ”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 43/203 [2m0:01:42 â€¢ 0:09:27[0m [2;4m0.28it/s[0m  
[2KAttention weights: tensor([[0.6117, 0.3883]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 43/203 [2m0:01:42 â€¢ 0:09:27[0m [2;4m0.28it/s[0m  
[2KStep 0 - TTA Loss: 0.6915â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 43/203 [2m0:01:42 â€¢ 0:09:27[0m [2;4m0.28it/s[0m  
[2KAttention weights: tensor([[0.6117, 0.3883]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 43/203 [2m0:01:42 â€¢ 0:09:27[0m [2;4m0.28it/s[0m  
[2KAttention weights: tensor([[0.6111, 0.3889]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 43/203 [2m0:01:42 â€¢ 0:09:27[0m [2;4m0.28it/s[0m  
[2KAttention weights: tensor([[0.6092, 0.3908]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 43/203 [2m0:01:42 â€¢ 0:09:27[0m [2;4m0.28it/s[0m  
[2KAttention weights: tensor([[0.6061, 0.3939]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 43/203 [2m0:01:42 â€¢ 0:09:27[0m [2;4m0.28it/s[0m  
[2KAttention weights: tensor([[0.6005, 0.3995]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 43/203 [2m0:01:42 â€¢ 0:09:27[0m [2;4m0.28it/s[0m  
[2KAttention weights: tensor([[0.5910, 0.4090]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 43/203 [2m0:01:42 â€¢ 0:09:27[0m [2;4m0.28it/s[0m  
[2KAttention weights: tensor([[0.5751, 0.4249]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 43/203 [2m0:01:42 â€¢ 0:09:27[0m [2;4m0.28it/s[0m  
[2KAttention weights: tensor([[0.5503, 0.4497]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 43/203 [2m0:01:42 â€¢ 0:09:27[0m [2;4m0.28it/s[0m  
[2KAttention weights: tensor([[0.5232, 0.4768]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 43/203 [2m0:01:42 â€¢ 0:09:27[0m [2;4m0.28it/s[0m  
[2KAttention weights: tensor([[0.5505, 0.4495]], device='cuda:0')â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 43/203 [2m0:01:42 â€¢ 0:09:27[0m [2;4m0.28it/s[0m  
[2KAttention weights: tensor([[0.5993, 0.4007],[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 43/203 [2m0:01:42 â€¢ 0:09:27[0m [2;4m0.28it/s[0m  
        [0.5609, 0.4391],
        [0.5431, 0.4569],
        [0.5536, 0.4464],
        [0.4623, 0.5377],
        [0.5291, 0.4709],
        [0.5477, 0.4523],
        [0.5896, 0.4104],
        [0.6038, 0.3962],
[2K        [0.4971, 0.5029]], device='cuda:0')â•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 43/203 [2m0:01:42 â€¢ 0:09:27[0m [2;4m0.28it/s[0m  
[2KAttention weights: tensor([[0.5585, 0.4415],8;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 44/203 [2m0:01:45 â€¢ 0:12:34[0m [2;4m0.21it/s[0m  
        [0.5536, 0.4464],
        [0.5556, 0.4444],
        [0.5552, 0.4448],
        [0.5532, 0.4468],
        [0.5525, 0.4475],
        [0.5536, 0.4464],
        [0.5570, 0.4430],
        [0.5576, 0.4424],
[2K        [0.5539, 0.4461]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 44/203 [2m0:01:45 â€¢ 0:12:34[0m [2;4m0.21it/s[0m  
[2KClass label: PoleVaultâ”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 44/203 [2m0:01:45 â€¢ 0:12:34[0m [2;4m0.21it/s[0m  
[2KAttention weights: tensor([[0.6072, 0.3928]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 44/203 [2m0:01:45 â€¢ 0:12:34[0m [2;4m0.21it/s[0m  
[2KStep 0 - TTA Loss: 0.5985â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 44/203 [2m0:01:45 â€¢ 0:12:34[0m [2;4m0.21it/s[0m  
[2KAttention weights: tensor([[0.6029, 0.3971]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 44/203 [2m0:01:45 â€¢ 0:12:34[0m [2;4m0.21it/s[0m  
[2KAttention weights: tensor([[0.6029, 0.3971]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 44/203 [2m0:01:45 â€¢ 0:12:34[0m [2;4m0.21it/s[0m  
[2KAttention weights: tensor([[0.6022, 0.3978]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 44/203 [2m0:01:45 â€¢ 0:12:34[0m [2;4m0.21it/s[0m  
[2KAttention weights: tensor([[0.5952, 0.4048]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 44/203 [2m0:01:45 â€¢ 0:12:34[0m [2;4m0.21it/s[0m  
[2KAttention weights: tensor([[0.5884, 0.4116]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 44/203 [2m0:01:45 â€¢ 0:12:34[0m [2;4m0.21it/s[0m  
[2KAttention weights: tensor([[0.5903, 0.4097]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 44/203 [2m0:01:45 â€¢ 0:12:34[0m [2;4m0.21it/s[0m  
[2KAttention weights: tensor([[0.6004, 0.3996]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 44/203 [2m0:01:45 â€¢ 0:12:34[0m [2;4m0.21it/s[0m  
[2KAttention weights: tensor([[0.6115, 0.3885]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 44/203 [2m0:01:45 â€¢ 0:12:34[0m [2;4m0.21it/s[0m  
[2KAttention weights: tensor([[0.6187, 0.3813]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 44/203 [2m0:01:45 â€¢ 0:12:34[0m [2;4m0.21it/s[0m  
[2KAttention weights: tensor([[0.5536, 0.4464]], device='cuda:0')7mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 44/203 [2m0:01:45 â€¢ 0:12:34[0m [2;4m0.21it/s[0m  
[2KAttention weights: tensor([[0.6435, 0.3565],224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 44/203 [2m0:01:45 â€¢ 0:12:34[0m [2;4m0.21it/s[0m  
        [0.5864, 0.4136],
        [0.5876, 0.4124],
        [0.5920, 0.4080],
        [0.5244, 0.4756],
        [0.5921, 0.4079],
        [0.6210, 0.3790],
        [0.6390, 0.3610],
        [0.6422, 0.3578],
[2K        [0.5524, 0.4476]], device='cuda:0');224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 44/203 [2m0:01:45 â€¢ 0:12:34[0m [2;4m0.21it/s[0m  
[2KAttention weights: tensor([[0.5585, 0.4415],8;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 45/203 [2m0:01:59 â€¢ 0:14:56[0m [2;4m0.18it/s[0m  
        [0.5536, 0.4464],
        [0.5556, 0.4444],
        [0.5551, 0.4449],
        [0.5532, 0.4468],
        [0.5525, 0.4475],
        [0.5536, 0.4464],
        [0.5569, 0.4431],
        [0.5576, 0.4424],
[2K        [0.5539, 0.4461]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 45/203 [2m0:01:59 â€¢ 0:14:56[0m [2;4m0.18it/s[0m  
[2KClass label: GolfSwingâ”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 45/203 [2m0:01:59 â€¢ 0:14:56[0m [2;4m0.18it/s[0m  
[2KAttention weights: tensor([[0.6035, 0.3965]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 45/203 [2m0:01:59 â€¢ 0:14:56[0m [2;4m0.18it/s[0m  
[2KStep 0 - TTA Loss: 0.8335â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 45/203 [2m0:01:59 â€¢ 0:14:56[0m [2;4m0.18it/s[0m  
[2KAttention weights: tensor([[0.6035, 0.3965]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 45/203 [2m0:01:59 â€¢ 0:14:56[0m [2;4m0.18it/s[0m  
[2KAttention weights: tensor([[0.6047, 0.3953]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 45/203 [2m0:01:59 â€¢ 0:14:56[0m [2;4m0.18it/s[0m  
[2KAttention weights: tensor([[0.6093, 0.3907]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 45/203 [2m0:01:59 â€¢ 0:14:56[0m [2;4m0.18it/s[0m  
[2KAttention weights: tensor([[0.6182, 0.3818]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 45/203 [2m0:01:59 â€¢ 0:14:56[0m [2;4m0.18it/s[0m  
[2KAttention weights: tensor([[0.6318, 0.3682]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 45/203 [2m0:01:59 â€¢ 0:14:56[0m [2;4m0.18it/s[0m  
[2KAttention weights: tensor([[0.6471, 0.3529]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 45/203 [2m0:01:59 â€¢ 0:14:56[0m [2;4m0.18it/s[0m  
[2KAttention weights: tensor([[0.6587, 0.3413]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 45/203 [2m0:01:59 â€¢ 0:14:56[0m [2;4m0.18it/s[0m  
[2KAttention weights: tensor([[0.6623, 0.3377]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 45/203 [2m0:01:59 â€¢ 0:14:56[0m [2;4m0.18it/s[0m  
[2KAttention weights: tensor([[0.6515, 0.3485]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 45/203 [2m0:01:59 â€¢ 0:14:56[0m [2;4m0.18it/s[0m  
[2KAttention weights: tensor([[0.5549, 0.4451]], device='cuda:0')7mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 45/203 [2m0:01:59 â€¢ 0:14:56[0m [2;4m0.18it/s[0m  
[2KAttention weights: tensor([[0.7133, 0.2867],224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 45/203 [2m0:01:59 â€¢ 0:14:56[0m [2;4m0.18it/s[0m  
        [0.6380, 0.3620],
        [0.6906, 0.3094],
        [0.6293, 0.3707],
        [0.6379, 0.3621],
        [0.7192, 0.2808],
        [0.7616, 0.2384],
        [0.7165, 0.2835],
        [0.7092, 0.2908],
[2K        [0.6859, 0.3141]], device='cuda:0');224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 45/203 [2m0:01:59 â€¢ 0:14:56[0m [2;4m0.18it/s[0m  
[2KAttention weights: tensor([[0.5585, 0.4415],237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 46/203 [2m0:02:03 â€¢ 0:14:13[0m [2;4m0.18it/s[0m   
        [0.5536, 0.4464],
        [0.5556, 0.4444],
        [0.5552, 0.4448],
        [0.5533, 0.4467],
        [0.5525, 0.4475],
        [0.5536, 0.4464],
        [0.5570, 0.4430],
        [0.5576, 0.4424],
[2K        [0.5539, 0.4461]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 46/203 [2m0:02:03 â€¢ 0:14:13[0m [2;4m0.18it/s[0m  
[2KClass label: GolfSwingâ”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 46/203 [2m0:02:03 â€¢ 0:14:13[0m [2;4m0.18it/s[0m  
[2KAttention weights: tensor([[0.6014, 0.3986]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 46/203 [2m0:02:03 â€¢ 0:14:13[0m [2;4m0.18it/s[0m  
[2KStep 0 - TTA Loss: 0.7972â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 46/203 [2m0:02:03 â€¢ 0:14:13[0m [2;4m0.18it/s[0m  
[2KAttention weights: tensor([[0.5692, 0.4308]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 46/203 [2m0:02:03 â€¢ 0:14:13[0m [2;4m0.18it/s[0m  
[2KAttention weights: tensor([[0.5303, 0.4697]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 46/203 [2m0:02:03 â€¢ 0:14:13[0m [2;4m0.18it/s[0m  
[2KAttention weights: tensor([[0.4850, 0.5150]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 46/203 [2m0:02:03 â€¢ 0:14:13[0m [2;4m0.18it/s[0m  
[2KAttention weights: tensor([[0.4396, 0.5604]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 46/203 [2m0:02:03 â€¢ 0:14:13[0m [2;4m0.18it/s[0m  
[2KAttention weights: tensor([[0.3899, 0.6101]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 46/203 [2m0:02:03 â€¢ 0:14:13[0m [2;4m0.18it/s[0m  
[2KAttention weights: tensor([[0.3492, 0.6508]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 46/203 [2m0:02:03 â€¢ 0:14:13[0m [2;4m0.18it/s[0m  
[2KAttention weights: tensor([[0.3218, 0.6782]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 46/203 [2m0:02:03 â€¢ 0:14:13[0m [2;4m0.18it/s[0m  
[2KAttention weights: tensor([[0.3068, 0.6932]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 46/203 [2m0:02:03 â€¢ 0:14:13[0m [2;4m0.18it/s[0m  
[2KAttention weights: tensor([[0.3006, 0.6994]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 46/203 [2m0:02:03 â€¢ 0:14:13[0m [2;4m0.18it/s[0m  
[2KAttention weights: tensor([[0.5481, 0.4519]], device='cuda:0')â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 46/203 [2m0:02:03 â€¢ 0:14:13[0m [2;4m0.18it/s[0m  
[2KAttention weights: tensor([[0.5277, 0.4723],â•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 46/203 [2m0:02:03 â€¢ 0:14:13[0m [2;4m0.18it/s[0m  
        [0.4908, 0.5092],
        [0.5639, 0.4361],
        [0.2991, 0.7009],
        [0.4612, 0.5388],
        [0.5494, 0.4506],
        [0.6024, 0.3976],
        [0.5290, 0.4710],
        [0.5226, 0.4774],
[2K        [0.5313, 0.4687]], device='cuda:0')mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 46/203 [2m0:02:03 â€¢ 0:14:13[0m [2;4m0.18it/s[0m  
[2KAttention weights: tensor([[0.5585, 0.4415],237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 47/203 [2m0:02:06 â€¢ 0:13:00[0m [2;4m0.20it/s[0m  
        [0.5536, 0.4464],
        [0.5556, 0.4444],
        [0.5551, 0.4449],
        [0.5533, 0.4467],
        [0.5525, 0.4475],
        [0.5537, 0.4463],
        [0.5569, 0.4431],
        [0.5575, 0.4425],
[2K        [0.5539, 0.4461]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 47/203 [2m0:02:06 â€¢ 0:13:00[0m [2;4m0.20it/s[0m  
[2KClass label: PoleVaultâ”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 47/203 [2m0:02:06 â€¢ 0:13:00[0m [2;4m0.20it/s[0m  
[2KAttention weights: tensor([[0.6083, 0.3917]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 47/203 [2m0:02:06 â€¢ 0:13:00[0m [2;4m0.20it/s[0m  
[2KStep 0 - TTA Loss: 0.7597â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 47/203 [2m0:02:06 â€¢ 0:13:00[0m [2;4m0.20it/s[0m  
[2KAttention weights: tensor([[0.6083, 0.3917]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 47/203 [2m0:02:06 â€¢ 0:13:00[0m [2;4m0.20it/s[0m  
[2KAttention weights: tensor([[0.6087, 0.3913]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 47/203 [2m0:02:06 â€¢ 0:13:00[0m [2;4m0.20it/s[0m  
[2KAttention weights: tensor([[0.6116, 0.3884]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 47/203 [2m0:02:06 â€¢ 0:13:00[0m [2;4m0.20it/s[0m  
[2KAttention weights: tensor([[0.6206, 0.3794]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 47/203 [2m0:02:06 â€¢ 0:13:00[0m [2;4m0.20it/s[0m  
[2KAttention weights: tensor([[0.6380, 0.3620]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 47/203 [2m0:02:06 â€¢ 0:13:00[0m [2;4m0.20it/s[0m  
[2KAttention weights: tensor([[0.6643, 0.3357]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 47/203 [2m0:02:06 â€¢ 0:13:00[0m [2;4m0.20it/s[0m  
[2KAttention weights: tensor([[0.6967, 0.3033]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 47/203 [2m0:02:06 â€¢ 0:13:00[0m [2;4m0.20it/s[0m  
[2KAttention weights: tensor([[0.7255, 0.2745]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 47/203 [2m0:02:06 â€¢ 0:13:00[0m [2;4m0.20it/s[0m  
[2KAttention weights: tensor([[0.7478, 0.2522]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 47/203 [2m0:02:06 â€¢ 0:13:00[0m [2;4m0.20it/s[0m  
[2KAttention weights: tensor([[0.5575, 0.4425]], device='cuda:0')â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 47/203 [2m0:02:06 â€¢ 0:13:00[0m [2;4m0.20it/s[0m  
[2KAttention weights: tensor([[0.7040, 0.2960],â•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 47/203 [2m0:02:06 â€¢ 0:13:00[0m [2;4m0.20it/s[0m  
        [0.6231, 0.3769],
        [0.6885, 0.3115],
        [0.5742, 0.4258],
        [0.6390, 0.3610],
        [0.7194, 0.2806],
        [0.7670, 0.2330],
        [0.7083, 0.2917],
        [0.6913, 0.3087],
[2K        [0.6869, 0.3131]], device='cuda:0')mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 47/203 [2m0:02:06 â€¢ 0:13:00[0m [2;4m0.20it/s[0m  
[2KAttention weights: tensor([[0.5585, 0.4415],237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 48/203 [2m0:02:20 â€¢ 0:17:52[0m [2;4m0.14it/s[0m  
        [0.5536, 0.4464],
        [0.5556, 0.4444],
        [0.5551, 0.4449],
        [0.5533, 0.4467],
        [0.5526, 0.4474],
        [0.5537, 0.4463],
        [0.5570, 0.4430],
        [0.5576, 0.4424],
[2K        [0.5539, 0.4461]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 48/203 [2m0:02:20 â€¢ 0:17:52[0m [2;4m0.14it/s[0m  
[2KClass label: TennisSwingâ”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 48/203 [2m0:02:20 â€¢ 0:17:52[0m [2;4m0.14it/s[0m  
[2KAttention weights: tensor([[0.6638, 0.3362]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 48/203 [2m0:02:20 â€¢ 0:17:52[0m [2;4m0.14it/s[0m  
[2KStep 0 - TTA Loss: 0.7885â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 48/203 [2m0:02:20 â€¢ 0:17:52[0m [2;4m0.14it/s[0m  
[2KAttention weights: tensor([[0.6669, 0.3331]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 48/203 [2m0:02:20 â€¢ 0:17:52[0m [2;4m0.14it/s[0m  
[2KAttention weights: tensor([[0.6683, 0.3317]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 48/203 [2m0:02:20 â€¢ 0:17:52[0m [2;4m0.14it/s[0m  
[2KAttention weights: tensor([[0.6696, 0.3304]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 48/203 [2m0:02:20 â€¢ 0:17:52[0m [2;4m0.14it/s[0m  
[2KAttention weights: tensor([[0.6664, 0.3336]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 48/203 [2m0:02:20 â€¢ 0:17:52[0m [2;4m0.14it/s[0m  
[2KAttention weights: tensor([[0.6590, 0.3410]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 48/203 [2m0:02:20 â€¢ 0:17:52[0m [2;4m0.14it/s[0m  
[2KAttention weights: tensor([[0.6478, 0.3522]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 48/203 [2m0:02:20 â€¢ 0:17:52[0m [2;4m0.14it/s[0m  
[2KAttention weights: tensor([[0.6365, 0.3635]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 48/203 [2m0:02:20 â€¢ 0:17:52[0m [2;4m0.14it/s[0m  
[2KAttention weights: tensor([[0.6271, 0.3729]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 48/203 [2m0:02:20 â€¢ 0:17:52[0m [2;4m0.14it/s[0m  
[2KAttention weights: tensor([[0.6214, 0.3786]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 48/203 [2m0:02:20 â€¢ 0:17:52[0m [2;4m0.14it/s[0m  
[2KAttention weights: tensor([[0.5555, 0.4445]], device='cuda:0')â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 48/203 [2m0:02:20 â€¢ 0:17:52[0m [2;4m0.14it/s[0m  
[2KAttention weights: tensor([[0.6466, 0.3534],â•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 48/203 [2m0:02:20 â€¢ 0:17:52[0m [2;4m0.14it/s[0m  
        [0.5857, 0.4143],
        [0.6374, 0.3626],
        [0.5474, 0.4526],
        [0.5698, 0.4302],
        [0.6428, 0.3572],
        [0.6896, 0.3104],
        [0.6466, 0.3534],
        [0.6197, 0.3803],
[2K        [0.6285, 0.3715]], device='cuda:0')mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 48/203 [2m0:02:20 â€¢ 0:17:52[0m [2;4m0.14it/s[0m  
[2KAttention weights: tensor([[0.5585, 0.4415],98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 49/203 [2m0:02:21 â€¢ 0:14:11[0m [2;4m0.18it/s[0m  
        [0.5536, 0.4464],
        [0.5557, 0.4443],
        [0.5551, 0.4449],
        [0.5533, 0.4467],
        [0.5526, 0.4474],
        [0.5538, 0.4462],
        [0.5570, 0.4430],
        [0.5576, 0.4424],
[2K        [0.5539, 0.4461]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 49/203 [2m0:02:21 â€¢ 0:14:11[0m [2;4m0.18it/s[0m  
[2KClass label: CleanAndJerkâ”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 49/203 [2m0:02:21 â€¢ 0:14:11[0m [2;4m0.18it/s[0m  
[2KAttention weights: tensor([[0.6206, 0.3794]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 49/203 [2m0:02:21 â€¢ 0:14:11[0m [2;4m0.18it/s[0m  
[2KStep 0 - TTA Loss: 0.6582â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 49/203 [2m0:02:21 â€¢ 0:14:11[0m [2;4m0.18it/s[0m  
[2KAttention weights: tensor([[0.6206, 0.3794]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 49/203 [2m0:02:21 â€¢ 0:14:11[0m [2;4m0.18it/s[0m  
[2KAttention weights: tensor([[0.6205, 0.3795]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 49/203 [2m0:02:21 â€¢ 0:14:11[0m [2;4m0.18it/s[0m  
[2KAttention weights: tensor([[0.6208, 0.3792]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 49/203 [2m0:02:21 â€¢ 0:14:11[0m [2;4m0.18it/s[0m  
[2KAttention weights: tensor([[0.6234, 0.3766]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 49/203 [2m0:02:21 â€¢ 0:14:11[0m [2;4m0.18it/s[0m  
[2KAttention weights: tensor([[0.6296, 0.3704]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 49/203 [2m0:02:21 â€¢ 0:14:11[0m [2;4m0.18it/s[0m  
[2KAttention weights: tensor([[0.6415, 0.3585]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 49/203 [2m0:02:21 â€¢ 0:14:11[0m [2;4m0.18it/s[0m  
[2KAttention weights: tensor([[0.6571, 0.3429]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 49/203 [2m0:02:21 â€¢ 0:14:11[0m [2;4m0.18it/s[0m  
[2KAttention weights: tensor([[0.6692, 0.3308]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 49/203 [2m0:02:21 â€¢ 0:14:11[0m [2;4m0.18it/s[0m  
[2KAttention weights: tensor([[0.6726, 0.3274]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 49/203 [2m0:02:21 â€¢ 0:14:11[0m [2;4m0.18it/s[0m  
[2KAttention weights: tensor([[0.5558, 0.4442]], device='cuda:0')37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 49/203 [2m0:02:21 â€¢ 0:14:11[0m [2;4m0.18it/s[0m  
[2KAttention weights: tensor([[0.6041, 0.3959],;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 49/203 [2m0:02:21 â€¢ 0:14:11[0m [2;4m0.18it/s[0m  
        [0.5599, 0.4401],
        [0.6681, 0.3319],
        [0.5515, 0.4485],
        [0.5272, 0.4728],
        [0.5773, 0.4227],
        [0.6150, 0.3850],
        [0.5972, 0.4028],
        [0.5617, 0.4383],
[2K        [0.6129, 0.3871]], device='cuda:0')6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 49/203 [2m0:02:21 â€¢ 0:14:11[0m [2;4m0.18it/s[0m  
[2KAttention weights: tensor([[0.5585, 0.4415],98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 50/203 [2m0:02:25 â€¢ 0:13:29[0m [2;4m0.19it/s[0m  
        [0.5536, 0.4464],
        [0.5557, 0.4443],
        [0.5551, 0.4449],
        [0.5533, 0.4467],
        [0.5526, 0.4474],
        [0.5538, 0.4462],
        [0.5570, 0.4430],
        [0.5576, 0.4424],
[2K        [0.5540, 0.4460]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 50/203 [2m0:02:25 â€¢ 0:13:29[0m [2;4m0.19it/s[0m  
[2KClass label: BaseballPitchâ”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 50/203 [2m0:02:25 â€¢ 0:13:29[0m [2;4m0.19it/s[0m  
[2KAttention weights: tensor([[0.6436, 0.3564]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 50/203 [2m0:02:25 â€¢ 0:13:29[0m [2;4m0.19it/s[0m  
[2KStep 0 - TTA Loss: 0.4336â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 50/203 [2m0:02:25 â€¢ 0:13:29[0m [2;4m0.19it/s[0m  
[2KAttention weights: tensor([[0.6256, 0.3744]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 50/203 [2m0:02:25 â€¢ 0:13:29[0m [2;4m0.19it/s[0m  
[2KAttention weights: tensor([[0.5939, 0.4061]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 50/203 [2m0:02:25 â€¢ 0:13:29[0m [2;4m0.19it/s[0m  
[2KAttention weights: tensor([[0.5559, 0.4441]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 50/203 [2m0:02:25 â€¢ 0:13:29[0m [2;4m0.19it/s[0m  
[2KAttention weights: tensor([[0.5327, 0.4673]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 50/203 [2m0:02:25 â€¢ 0:13:29[0m [2;4m0.19it/s[0m  
[2KAttention weights: tensor([[0.5359, 0.4641]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 50/203 [2m0:02:25 â€¢ 0:13:29[0m [2;4m0.19it/s[0m  
[2KAttention weights: tensor([[0.5585, 0.4415]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 50/203 [2m0:02:25 â€¢ 0:13:29[0m [2;4m0.19it/s[0m  
[2KAttention weights: tensor([[0.5830, 0.4170]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 50/203 [2m0:02:25 â€¢ 0:13:29[0m [2;4m0.19it/s[0m  
[2KAttention weights: tensor([[0.6021, 0.3979]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 50/203 [2m0:02:25 â€¢ 0:13:29[0m [2;4m0.19it/s[0m  
[2KAttention weights: tensor([[0.6122, 0.3878]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 50/203 [2m0:02:25 â€¢ 0:13:29[0m [2;4m0.19it/s[0m  
[2KAttention weights: tensor([[0.5569, 0.4431]], device='cuda:0')37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 50/203 [2m0:02:25 â€¢ 0:13:29[0m [2;4m0.19it/s[0m  
[2KAttention weights: tensor([[0.6150, 0.3850],;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 50/203 [2m0:02:25 â€¢ 0:13:29[0m [2;4m0.19it/s[0m  
        [0.5633, 0.4367],
        [0.6037, 0.3963],
        [0.5592, 0.4408],
        [0.5141, 0.4859],
        [0.5692, 0.4308],
        [0.6004, 0.3996],
        [0.6021, 0.3979],
        [0.5787, 0.4213],
[2K        [0.5854, 0.4146]], device='cuda:0')6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 50/203 [2m0:02:25 â€¢ 0:13:29[0m [2;4m0.19it/s[0m  
[2KAttention weights: tensor([[0.5585, 0.4415],;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 51/203 [2m0:02:29 â€¢ 0:13:13[0m [2;4m0.19it/s[0m   
        [0.5536, 0.4464],
        [0.5557, 0.4443],
        [0.5551, 0.4449],
        [0.5533, 0.4467],
        [0.5526, 0.4474],
        [0.5538, 0.4462],
        [0.5570, 0.4430],
        [0.5575, 0.4425],
[2K        [0.5540, 0.4460]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 51/203 [2m0:02:29 â€¢ 0:13:13[0m [2;4m0.19it/s[0m  
[2KClass label: BaseballPitchâ”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 51/203 [2m0:02:29 â€¢ 0:13:13[0m [2;4m0.19it/s[0m  
[2KAttention weights: tensor([[0.6413, 0.3587]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 51/203 [2m0:02:29 â€¢ 0:13:13[0m [2;4m0.19it/s[0m  
[2KStep 0 - TTA Loss: 0.9787â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 51/203 [2m0:02:29 â€¢ 0:13:13[0m [2;4m0.19it/s[0m  
[2KAttention weights: tensor([[0.6413, 0.3587]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 51/203 [2m0:02:29 â€¢ 0:13:13[0m [2;4m0.19it/s[0m  
[2KAttention weights: tensor([[0.6435, 0.3565]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 51/203 [2m0:02:29 â€¢ 0:13:13[0m [2;4m0.19it/s[0m  
[2KAttention weights: tensor([[0.6515, 0.3485]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 51/203 [2m0:02:29 â€¢ 0:13:13[0m [2;4m0.19it/s[0m  
[2KAttention weights: tensor([[0.6670, 0.3330]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 51/203 [2m0:02:29 â€¢ 0:13:13[0m [2;4m0.19it/s[0m  
[2KAttention weights: tensor([[0.6910, 0.3090]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 51/203 [2m0:02:29 â€¢ 0:13:13[0m [2;4m0.19it/s[0m  
[2KAttention weights: tensor([[0.7201, 0.2799]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 51/203 [2m0:02:29 â€¢ 0:13:13[0m [2;4m0.19it/s[0m  
[2KAttention weights: tensor([[0.7507, 0.2493]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 51/203 [2m0:02:29 â€¢ 0:13:13[0m [2;4m0.19it/s[0m  
[2KAttention weights: tensor([[0.7697, 0.2303]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 51/203 [2m0:02:29 â€¢ 0:13:13[0m [2;4m0.19it/s[0m  
[2KAttention weights: tensor([[0.7624, 0.2376]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 51/203 [2m0:02:29 â€¢ 0:13:13[0m [2;4m0.19it/s[0m  
[2KAttention weights: tensor([[0.5593, 0.4407]], device='cuda:0')â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 51/203 [2m0:02:29 â€¢ 0:13:13[0m [2;4m0.19it/s[0m  
[2KAttention weights: tensor([[0.7251, 0.2749],mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 51/203 [2m0:02:29 â€¢ 0:13:13[0m [2;4m0.19it/s[0m  
        [0.6192, 0.3808],
        [0.6387, 0.3613],
        [0.6395, 0.3605],
        [0.5856, 0.4144],
        [0.6313, 0.3687],
        [0.6488, 0.3512],
        [0.6794, 0.3206],
        [0.6833, 0.3167],
[2K        [0.6380, 0.3620]], device='cuda:0')7mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 51/203 [2m0:02:29 â€¢ 0:13:13[0m [2;4m0.19it/s[0m  
[2KAttention weights: tensor([[0.5584, 0.4416],;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 52/203 [2m0:02:31 â€¢ 0:11:29[0m [2;4m0.22it/s[0m  
        [0.5536, 0.4464],
        [0.5557, 0.4443],
        [0.5551, 0.4449],
        [0.5533, 0.4467],
        [0.5526, 0.4474],
        [0.5538, 0.4462],
        [0.5570, 0.4430],
        [0.5575, 0.4425],
[2K        [0.5539, 0.4461]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 52/203 [2m0:02:31 â€¢ 0:11:29[0m [2;4m0.22it/s[0m  
[2KClass label: CleanAndJerkâ”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 52/203 [2m0:02:31 â€¢ 0:11:29[0m [2;4m0.22it/s[0m  
[2KAttention weights: tensor([[0.6191, 0.3809]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 52/203 [2m0:02:31 â€¢ 0:11:29[0m [2;4m0.22it/s[0m  
[2KStep 0 - TTA Loss: 0.7054â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 52/203 [2m0:02:31 â€¢ 0:11:29[0m [2;4m0.22it/s[0m  
[2KAttention weights: tensor([[0.6276, 0.3724]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 52/203 [2m0:02:31 â€¢ 0:11:29[0m [2;4m0.22it/s[0m  
[2KAttention weights: tensor([[0.6518, 0.3482]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 52/203 [2m0:02:31 â€¢ 0:11:29[0m [2;4m0.22it/s[0m  
[2KAttention weights: tensor([[0.6823, 0.3177]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 52/203 [2m0:02:31 â€¢ 0:11:29[0m [2;4m0.22it/s[0m  
[2KAttention weights: tensor([[0.7087, 0.2913]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 52/203 [2m0:02:31 â€¢ 0:11:29[0m [2;4m0.22it/s[0m  
[2KAttention weights: tensor([[0.7242, 0.2758]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 52/203 [2m0:02:31 â€¢ 0:11:29[0m [2;4m0.22it/s[0m  
[2KAttention weights: tensor([[0.7309, 0.2691]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 52/203 [2m0:02:31 â€¢ 0:11:29[0m [2;4m0.22it/s[0m  
[2KAttention weights: tensor([[0.7317, 0.2683]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 52/203 [2m0:02:31 â€¢ 0:11:29[0m [2;4m0.22it/s[0m  
[2KAttention weights: tensor([[0.7304, 0.2696]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 52/203 [2m0:02:31 â€¢ 0:11:29[0m [2;4m0.22it/s[0m  
[2KAttention weights: tensor([[0.7289, 0.2711]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 52/203 [2m0:02:31 â€¢ 0:11:29[0m [2;4m0.22it/s[0m  
[2KAttention weights: tensor([[0.5579, 0.4421]], device='cuda:0')â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 52/203 [2m0:02:31 â€¢ 0:11:29[0m [2;4m0.22it/s[0m  
[2KAttention weights: tensor([[0.4953, 0.5047],mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 52/203 [2m0:02:31 â€¢ 0:11:29[0m [2;4m0.22it/s[0m  
        [0.5651, 0.4349],
        [0.7285, 0.2715],
        [0.5675, 0.4325],
        [0.5148, 0.4852],
        [0.5981, 0.4019],
        [0.5974, 0.4026],
        [0.5734, 0.4266],
        [0.6426, 0.3574],
[2K        [0.6630, 0.3370]], device='cuda:0')7mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 52/203 [2m0:02:31 â€¢ 0:11:29[0m [2;4m0.22it/s[0m  
[2KAttention weights: tensor([[0.5584, 0.4416],;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 53/203 [2m0:02:32 â€¢ 0:10:08[0m [2;4m0.25it/s[0m  
        [0.5536, 0.4464],
        [0.5557, 0.4443],
        [0.5550, 0.4450],
        [0.5533, 0.4467],
        [0.5526, 0.4474],
        [0.5537, 0.4463],
        [0.5569, 0.4431],
        [0.5575, 0.4425],
[2K        [0.5539, 0.4461]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 53/203 [2m0:02:32 â€¢ 0:10:08[0m [2;4m0.25it/s[0m  
[2KClass label: Billiardsâ”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 53/203 [2m0:02:32 â€¢ 0:10:08[0m [2;4m0.25it/s[0m  
[2KAttention weights: tensor([[0.5921, 0.4079]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 53/203 [2m0:02:32 â€¢ 0:10:08[0m [2;4m0.25it/s[0m  
[2KStep 0 - TTA Loss: 0.9414â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 53/203 [2m0:02:32 â€¢ 0:10:08[0m [2;4m0.25it/s[0m  
[2KAttention weights: tensor([[0.5921, 0.4079]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 53/203 [2m0:02:32 â€¢ 0:10:08[0m [2;4m0.25it/s[0m  
[2KAttention weights: tensor([[0.5918, 0.4082]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 53/203 [2m0:02:32 â€¢ 0:10:08[0m [2;4m0.25it/s[0m  
[2KAttention weights: tensor([[0.5909, 0.4091]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 53/203 [2m0:02:32 â€¢ 0:10:08[0m [2;4m0.25it/s[0m  
[2KAttention weights: tensor([[0.5885, 0.4115]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 53/203 [2m0:02:32 â€¢ 0:10:08[0m [2;4m0.25it/s[0m  
[2KAttention weights: tensor([[0.5831, 0.4169]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 53/203 [2m0:02:32 â€¢ 0:10:08[0m [2;4m0.25it/s[0m  
[2KAttention weights: tensor([[0.5707, 0.4293]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 53/203 [2m0:02:32 â€¢ 0:10:08[0m [2;4m0.25it/s[0m  
[2KAttention weights: tensor([[0.5476, 0.4524]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 53/203 [2m0:02:32 â€¢ 0:10:08[0m [2;4m0.25it/s[0m  
[2KAttention weights: tensor([[0.5107, 0.4893]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 53/203 [2m0:02:32 â€¢ 0:10:08[0m [2;4m0.25it/s[0m  
[2KAttention weights: tensor([[0.4614, 0.5386]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 53/203 [2m0:02:32 â€¢ 0:10:08[0m [2;4m0.25it/s[0m  
[2KAttention weights: tensor([[0.5493, 0.4507]], device='cuda:0')â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 53/203 [2m0:02:32 â€¢ 0:10:08[0m [2;4m0.25it/s[0m  
[2KAttention weights: tensor([[0.5512, 0.4488],mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 53/203 [2m0:02:32 â€¢ 0:10:08[0m [2;4m0.25it/s[0m  
        [0.4113, 0.5887],
        [0.5383, 0.4617],
        [0.5234, 0.4766],
        [0.4593, 0.5407],
        [0.5244, 0.4756],
        [0.5467, 0.4533],
        [0.5504, 0.4496],
        [0.5806, 0.4194],
[2K        [0.5441, 0.4559]], device='cuda:0')7mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 53/203 [2m0:02:32 â€¢ 0:10:08[0m [2;4m0.25it/s[0m  
[2KAttention weights: tensor([[0.5583, 0.4417],;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 54/203 [2m0:02:36 â€¢ 0:06:57[0m [2;4m0.36it/s[0m  
        [0.5535, 0.4465],
        [0.5557, 0.4443],
        [0.5550, 0.4450],
        [0.5533, 0.4467],
        [0.5525, 0.4475],
        [0.5537, 0.4463],
        [0.5569, 0.4431],
        [0.5575, 0.4425],
[2K        [0.5539, 0.4461]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 54/203 [2m0:02:36 â€¢ 0:06:57[0m [2;4m0.36it/s[0m  
[2KClass label: SoccerPenaltyâ”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 54/203 [2m0:02:36 â€¢ 0:06:57[0m [2;4m0.36it/s[0m  
[2KAttention weights: tensor([[0.6339, 0.3661]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 54/203 [2m0:02:36 â€¢ 0:06:57[0m [2;4m0.36it/s[0m  
[2KStep 0 - TTA Loss: 0.5300â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 54/203 [2m0:02:36 â€¢ 0:06:57[0m [2;4m0.36it/s[0m  
[2KAttention weights: tensor([[0.6400, 0.3600]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 54/203 [2m0:02:36 â€¢ 0:06:57[0m [2;4m0.36it/s[0m  
[2KAttention weights: tensor([[0.6581, 0.3419]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 54/203 [2m0:02:36 â€¢ 0:06:57[0m [2;4m0.36it/s[0m  
[2KAttention weights: tensor([[0.6768, 0.3232]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 54/203 [2m0:02:36 â€¢ 0:06:57[0m [2;4m0.36it/s[0m  
[2KAttention weights: tensor([[0.6897, 0.3103]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 54/203 [2m0:02:36 â€¢ 0:06:57[0m [2;4m0.36it/s[0m  
[2KAttention weights: tensor([[0.6908, 0.3092]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 54/203 [2m0:02:36 â€¢ 0:06:57[0m [2;4m0.36it/s[0m  
[2KAttention weights: tensor([[0.6841, 0.3159]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 54/203 [2m0:02:36 â€¢ 0:06:57[0m [2;4m0.36it/s[0m  
[2KAttention weights: tensor([[0.6805, 0.3195]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 54/203 [2m0:02:36 â€¢ 0:06:57[0m [2;4m0.36it/s[0m  
[2KAttention weights: tensor([[0.6780, 0.3220]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 54/203 [2m0:02:36 â€¢ 0:06:57[0m [2;4m0.36it/s[0m  
[2KAttention weights: tensor([[0.6772, 0.3228]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 54/203 [2m0:02:36 â€¢ 0:06:57[0m [2;4m0.36it/s[0m  
[2KAttention weights: tensor([[0.5569, 0.4431]], device='cuda:0')237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 54/203 [2m0:02:36 â€¢ 0:06:57[0m [2;4m0.36it/s[0m  
[2KAttention weights: tensor([[0.6251, 0.3749],6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 54/203 [2m0:02:36 â€¢ 0:06:57[0m [2;4m0.36it/s[0m  
        [0.4480, 0.5520],
        [0.5841, 0.4159],
        [0.5850, 0.4150],
        [0.5346, 0.4654],
        [0.5901, 0.4099],
        [0.6060, 0.3940],
        [0.6774, 0.3226],
        [0.6334, 0.3666],
[2K        [0.5882, 0.4118]], device='cuda:0');6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 54/203 [2m0:02:36 â€¢ 0:06:57[0m [2;4m0.36it/s[0m  
[2KAttention weights: tensor([[0.5583, 0.4417],;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 55/203 [2m0:02:42 â€¢ 0:07:48[0m [2;4m0.32it/s[0m  
        [0.5534, 0.4466],
        [0.5556, 0.4444],
        [0.5549, 0.4451],
        [0.5532, 0.4468],
        [0.5525, 0.4475],
        [0.5537, 0.4463],
        [0.5568, 0.4432],
        [0.5574, 0.4426],
[2K        [0.5538, 0.4462]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 55/203 [2m0:02:42 â€¢ 0:07:48[0m [2;4m0.32it/s[0m  
[2KClass label: PoleVaultâ”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 55/203 [2m0:02:42 â€¢ 0:07:48[0m [2;4m0.32it/s[0m  
[2KAttention weights: tensor([[0.6101, 0.3899]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 55/203 [2m0:02:42 â€¢ 0:07:48[0m [2;4m0.32it/s[0m  
[2KStep 0 - TTA Loss: 0.8527â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 55/203 [2m0:02:42 â€¢ 0:07:48[0m [2;4m0.32it/s[0m  
[2KAttention weights: tensor([[0.6101, 0.3899]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 55/203 [2m0:02:42 â€¢ 0:07:48[0m [2;4m0.32it/s[0m  
[2KAttention weights: tensor([[0.6104, 0.3896]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 55/203 [2m0:02:42 â€¢ 0:07:48[0m [2;4m0.32it/s[0m  
[2KAttention weights: tensor([[0.6119, 0.3881]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 55/203 [2m0:02:42 â€¢ 0:07:48[0m [2;4m0.32it/s[0m  
[2KAttention weights: tensor([[0.6160, 0.3840]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 55/203 [2m0:02:42 â€¢ 0:07:48[0m [2;4m0.32it/s[0m  
[2KAttention weights: tensor([[0.6243, 0.3757]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 55/203 [2m0:02:42 â€¢ 0:07:48[0m [2;4m0.32it/s[0m  
[2KAttention weights: tensor([[0.6367, 0.3633]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 55/203 [2m0:02:42 â€¢ 0:07:48[0m [2;4m0.32it/s[0m  
[2KAttention weights: tensor([[0.6520, 0.3480]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 55/203 [2m0:02:42 â€¢ 0:07:48[0m [2;4m0.32it/s[0m  
[2KAttention weights: tensor([[0.6615, 0.3385]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 55/203 [2m0:02:42 â€¢ 0:07:48[0m [2;4m0.32it/s[0m  
[2KAttention weights: tensor([[0.6616, 0.3384]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 55/203 [2m0:02:42 â€¢ 0:07:48[0m [2;4m0.32it/s[0m  
[2KAttention weights: tensor([[0.5545, 0.4455]], device='cuda:0')237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 55/203 [2m0:02:42 â€¢ 0:07:48[0m [2;4m0.32it/s[0m  
[2KAttention weights: tensor([[0.6698, 0.3302],6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 55/203 [2m0:02:42 â€¢ 0:07:48[0m [2;4m0.32it/s[0m  
        [0.5885, 0.4115],
        [0.6439, 0.3561],
        [0.6304, 0.3696],
        [0.5779, 0.4221],
        [0.6456, 0.3544],
        [0.6634, 0.3366],
        [0.6759, 0.3241],
        [0.6823, 0.3177],
[2K        [0.6408, 0.3592]], device='cuda:0');6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 55/203 [2m0:02:42 â€¢ 0:07:48[0m [2;4m0.32it/s[0m  
[2KAttention weights: tensor([[0.5583, 0.4417],5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 56/203 [2m0:02:44 â€¢ 0:07:28[0m [2;4m0.33it/s[0m   
        [0.5535, 0.4465],
        [0.5557, 0.4443],
        [0.5550, 0.4450],
        [0.5533, 0.4467],
        [0.5526, 0.4474],
        [0.5538, 0.4462],
        [0.5569, 0.4431],
        [0.5574, 0.4426],
[2K        [0.5539, 0.4461]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 56/203 [2m0:02:44 â€¢ 0:07:28[0m [2;4m0.33it/s[0m  
[2KClass label: HighJumpâ”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 56/203 [2m0:02:44 â€¢ 0:07:28[0m [2;4m0.33it/s[0m  
[2KAttention weights: tensor([[0.6014, 0.3986]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 56/203 [2m0:02:44 â€¢ 0:07:28[0m [2;4m0.33it/s[0m  
[2KStep 0 - TTA Loss: 1.3911â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 56/203 [2m0:02:44 â€¢ 0:07:28[0m [2;4m0.33it/s[0m  
[2KAttention weights: tensor([[0.6116, 0.3884]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 56/203 [2m0:02:44 â€¢ 0:07:28[0m [2;4m0.33it/s[0m  
[2KAttention weights: tensor([[0.6231, 0.3769]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 56/203 [2m0:02:44 â€¢ 0:07:28[0m [2;4m0.33it/s[0m  
[2KAttention weights: tensor([[0.6377, 0.3623]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 56/203 [2m0:02:44 â€¢ 0:07:28[0m [2;4m0.33it/s[0m  
[2KAttention weights: tensor([[0.6460, 0.3540]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 56/203 [2m0:02:44 â€¢ 0:07:28[0m [2;4m0.33it/s[0m  
[2KAttention weights: tensor([[0.6487, 0.3513]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 56/203 [2m0:02:44 â€¢ 0:07:28[0m [2;4m0.33it/s[0m  
[2KAttention weights: tensor([[0.6544, 0.3456]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 56/203 [2m0:02:44 â€¢ 0:07:28[0m [2;4m0.33it/s[0m  
[2KAttention weights: tensor([[0.6616, 0.3384]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 56/203 [2m0:02:44 â€¢ 0:07:28[0m [2;4m0.33it/s[0m  
[2KAttention weights: tensor([[0.6706, 0.3294]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 56/203 [2m0:02:44 â€¢ 0:07:28[0m [2;4m0.33it/s[0m  
[2KAttention weights: tensor([[0.6767, 0.3233]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 56/203 [2m0:02:44 â€¢ 0:07:28[0m [2;4m0.33it/s[0m  
[2KAttention weights: tensor([[0.5542, 0.4458]], device='cuda:0')â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 56/203 [2m0:02:44 â€¢ 0:07:28[0m [2;4m0.33it/s[0m  
[2KAttention weights: tensor([[0.6747, 0.3253],7mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 56/203 [2m0:02:44 â€¢ 0:07:28[0m [2;4m0.33it/s[0m  
        [0.6101, 0.3899],
        [0.6523, 0.3477],
        [0.6392, 0.3608],
        [0.5946, 0.4054],
        [0.6791, 0.3209],
        [0.6640, 0.3360],
        [0.6845, 0.3155],
        [0.6999, 0.3001],
[2K        [0.6578, 0.3422]], device='cuda:0')37mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 56/203 [2m0:02:44 â€¢ 0:07:28[0m [2;4m0.33it/s[0m  
[2KAttention weights: tensor([[0.5584, 0.4416],5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 57/203 [2m0:02:45 â€¢ 0:06:47[0m [2;4m0.36it/s[0m  
        [0.5535, 0.4465],
        [0.5557, 0.4443],
        [0.5550, 0.4450],
        [0.5534, 0.4466],
        [0.5527, 0.4473],
        [0.5539, 0.4461],
        [0.5569, 0.4431],
        [0.5575, 0.4425],
[2K        [0.5540, 0.4460]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 57/203 [2m0:02:45 â€¢ 0:06:47[0m [2;4m0.36it/s[0m  
[2KClass label: PoleVaultâ”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 57/203 [2m0:02:45 â€¢ 0:06:47[0m [2;4m0.36it/s[0m  
[2KAttention weights: tensor([[0.6102, 0.3898]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 57/203 [2m0:02:45 â€¢ 0:06:47[0m [2;4m0.36it/s[0m  
[2KStep 0 - TTA Loss: 0.6769â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 57/203 [2m0:02:45 â€¢ 0:06:47[0m [2;4m0.36it/s[0m  
[2KAttention weights: tensor([[0.6102, 0.3898]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 57/203 [2m0:02:45 â€¢ 0:06:47[0m [2;4m0.36it/s[0m  
[2KAttention weights: tensor([[0.6115, 0.3885]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 57/203 [2m0:02:45 â€¢ 0:06:47[0m [2;4m0.36it/s[0m  
[2KAttention weights: tensor([[0.6166, 0.3834]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 57/203 [2m0:02:45 â€¢ 0:06:47[0m [2;4m0.36it/s[0m  
[2KAttention weights: tensor([[0.6257, 0.3743]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 57/203 [2m0:02:45 â€¢ 0:06:47[0m [2;4m0.36it/s[0m  
[2KAttention weights: tensor([[0.6370, 0.3630]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 57/203 [2m0:02:45 â€¢ 0:06:47[0m [2;4m0.36it/s[0m  
[2KAttention weights: tensor([[0.6466, 0.3534]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 57/203 [2m0:02:45 â€¢ 0:06:47[0m [2;4m0.36it/s[0m  
[2KAttention weights: tensor([[0.6496, 0.3504]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 57/203 [2m0:02:45 â€¢ 0:06:47[0m [2;4m0.36it/s[0m  
[2KAttention weights: tensor([[0.6456, 0.3544]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 57/203 [2m0:02:45 â€¢ 0:06:47[0m [2;4m0.36it/s[0m  
[2KAttention weights: tensor([[0.6354, 0.3646]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 57/203 [2m0:02:45 â€¢ 0:06:47[0m [2;4m0.36it/s[0m  
[2KAttention weights: tensor([[0.5536, 0.4464]], device='cuda:0')â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 57/203 [2m0:02:45 â€¢ 0:06:47[0m [2;4m0.36it/s[0m  
[2KAttention weights: tensor([[0.6643, 0.3357],7mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 57/203 [2m0:02:45 â€¢ 0:06:47[0m [2;4m0.36it/s[0m  
        [0.6199, 0.3801],
        [0.6569, 0.3431],
        [0.6396, 0.3604],
        [0.5915, 0.4085],
        [0.7075, 0.2925],
        [0.6287, 0.3713],
        [0.6747, 0.3253],
        [0.7186, 0.2814],
[2K        [0.6666, 0.3334]], device='cuda:0')37mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 57/203 [2m0:02:45 â€¢ 0:06:47[0m [2;4m0.36it/s[0m  
[2KAttention weights: tensor([[0.5583, 0.4417],5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 58/203 [2m0:02:51 â€¢ 0:08:01[0m [2;4m0.30it/s[0m  
        [0.5535, 0.4465],
        [0.5557, 0.4443],
        [0.5550, 0.4450],
        [0.5533, 0.4467],
        [0.5527, 0.4473],
        [0.5538, 0.4462],
        [0.5569, 0.4431],
        [0.5575, 0.4425],
[2K        [0.5540, 0.4460]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 58/203 [2m0:02:51 â€¢ 0:08:01[0m [2;4m0.30it/s[0m  
[2KClass label: SoccerPenaltyâ”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 58/203 [2m0:02:51 â€¢ 0:08:01[0m [2;4m0.30it/s[0m  
[2KAttention weights: tensor([[0.6366, 0.3634]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 58/203 [2m0:02:51 â€¢ 0:08:01[0m [2;4m0.30it/s[0m  
[2KStep 0 - TTA Loss: 0.6939â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 58/203 [2m0:02:51 â€¢ 0:08:01[0m [2;4m0.30it/s[0m  
[2KAttention weights: tensor([[0.6554, 0.3446]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 58/203 [2m0:02:51 â€¢ 0:08:01[0m [2;4m0.30it/s[0m  
[2KAttention weights: tensor([[0.6762, 0.3238]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 58/203 [2m0:02:51 â€¢ 0:08:01[0m [2;4m0.30it/s[0m  
[2KAttention weights: tensor([[0.6874, 0.3126]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 58/203 [2m0:02:51 â€¢ 0:08:01[0m [2;4m0.30it/s[0m  
[2KAttention weights: tensor([[0.6951, 0.3049]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 58/203 [2m0:02:51 â€¢ 0:08:01[0m [2;4m0.30it/s[0m  
[2KAttention weights: tensor([[0.7092, 0.2908]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 58/203 [2m0:02:51 â€¢ 0:08:01[0m [2;4m0.30it/s[0m  
[2KAttention weights: tensor([[0.7301, 0.2699]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 58/203 [2m0:02:51 â€¢ 0:08:01[0m [2;4m0.30it/s[0m  
[2KAttention weights: tensor([[0.7516, 0.2484]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 58/203 [2m0:02:51 â€¢ 0:08:01[0m [2;4m0.30it/s[0m  
[2KAttention weights: tensor([[0.7686, 0.2314]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 58/203 [2m0:02:51 â€¢ 0:08:01[0m [2;4m0.30it/s[0m  
[2KAttention weights: tensor([[0.7778, 0.2222]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 58/203 [2m0:02:51 â€¢ 0:08:01[0m [2;4m0.30it/s[0m  
[2KAttention weights: tensor([[0.5598, 0.4402]], device='cuda:0')â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 58/203 [2m0:02:51 â€¢ 0:08:01[0m [2;4m0.30it/s[0m  
[2KAttention weights: tensor([[0.7108, 0.2892],7mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 58/203 [2m0:02:51 â€¢ 0:08:01[0m [2;4m0.30it/s[0m  
        [0.6592, 0.3408],
        [0.6589, 0.3411],
        [0.6774, 0.3226],
        [0.6336, 0.3664],
        [0.7100, 0.2900],
        [0.6511, 0.3489],
        [0.7804, 0.2196],
        [0.7407, 0.2593],
[2K        [0.6650, 0.3350]], device='cuda:0')37mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 58/203 [2m0:02:51 â€¢ 0:08:01[0m [2;4m0.30it/s[0m  
[2KAttention weights: tensor([[0.5583, 0.4417],2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 59/203 [2m0:02:53 â€¢ 0:07:29[0m [2;4m0.32it/s[0m  
        [0.5535, 0.4465],
        [0.5557, 0.4443],
        [0.5550, 0.4450],
        [0.5533, 0.4467],
        [0.5527, 0.4473],
        [0.5538, 0.4462],
        [0.5569, 0.4431],
        [0.5575, 0.4425],
[2K        [0.5540, 0.4460]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 59/203 [2m0:02:53 â€¢ 0:07:29[0m [2;4m0.32it/s[0m  
[2KClass label: Billiardsâ”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 59/203 [2m0:02:53 â€¢ 0:07:29[0m [2;4m0.32it/s[0m  
[2KAttention weights: tensor([[0.5940, 0.4060]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 59/203 [2m0:02:53 â€¢ 0:07:29[0m [2;4m0.32it/s[0m  
[2KStep 0 - TTA Loss: 0.8350â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 59/203 [2m0:02:53 â€¢ 0:07:29[0m [2;4m0.32it/s[0m  
[2KAttention weights: tensor([[0.5940, 0.4060]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 59/203 [2m0:02:53 â€¢ 0:07:29[0m [2;4m0.32it/s[0m  
[2KAttention weights: tensor([[0.5951, 0.4049]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 59/203 [2m0:02:53 â€¢ 0:07:29[0m [2;4m0.32it/s[0m  
[2KAttention weights: tensor([[0.5989, 0.4011]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 59/203 [2m0:02:53 â€¢ 0:07:29[0m [2;4m0.32it/s[0m  
[2KAttention weights: tensor([[0.6059, 0.3941]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 59/203 [2m0:02:53 â€¢ 0:07:29[0m [2;4m0.32it/s[0m  
[2KAttention weights: tensor([[0.6153, 0.3847]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 59/203 [2m0:02:53 â€¢ 0:07:29[0m [2;4m0.32it/s[0m  
[2KAttention weights: tensor([[0.6241, 0.3759]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 59/203 [2m0:02:53 â€¢ 0:07:29[0m [2;4m0.32it/s[0m  
[2KAttention weights: tensor([[0.6290, 0.3710]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 59/203 [2m0:02:53 â€¢ 0:07:29[0m [2;4m0.32it/s[0m  
[2KAttention weights: tensor([[0.6370, 0.3630]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 59/203 [2m0:02:53 â€¢ 0:07:29[0m [2;4m0.32it/s[0m  
[2KAttention weights: tensor([[0.6388, 0.3612]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 59/203 [2m0:02:53 â€¢ 0:07:29[0m [2;4m0.32it/s[0m  
[2KAttention weights: tensor([[0.5539, 0.4461]], device='cuda:0');237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 59/203 [2m0:02:53 â€¢ 0:07:29[0m [2;4m0.32it/s[0m  
[2KAttention weights: tensor([[0.7533, 0.2467],;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 59/203 [2m0:02:53 â€¢ 0:07:29[0m [2;4m0.32it/s[0m  
        [0.6342, 0.3658],
        [0.6714, 0.3286],
        [0.7031, 0.2969],
        [0.6732, 0.3268],
        [0.7175, 0.2825],
        [0.7076, 0.2924],
        [0.8479, 0.1521],
        [0.7520, 0.2480],
[2K        [0.6754, 0.3246]], device='cuda:0')8;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 59/203 [2m0:02:53 â€¢ 0:07:29[0m [2;4m0.32it/s[0m  
[2KAttention weights: tensor([[0.5584, 0.4416],2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 60/203 [2m0:02:57 â€¢ 0:07:12[0m [2;4m0.33it/s[0m  
        [0.5535, 0.4465],
        [0.5557, 0.4443],
        [0.5550, 0.4450],
        [0.5533, 0.4467],
        [0.5527, 0.4473],
        [0.5538, 0.4462],
        [0.5570, 0.4430],
        [0.5575, 0.4425],
[2K        [0.5540, 0.4460]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 60/203 [2m0:02:57 â€¢ 0:07:12[0m [2;4m0.33it/s[0m  
[2KClass label: CleanAndJerkâ”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 60/203 [2m0:02:57 â€¢ 0:07:12[0m [2;4m0.33it/s[0m  
[2KAttention weights: tensor([[0.6175, 0.3825]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 60/203 [2m0:02:57 â€¢ 0:07:12[0m [2;4m0.33it/s[0m  
[2KStep 0 - TTA Loss: 0.7157â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 60/203 [2m0:02:57 â€¢ 0:07:12[0m [2;4m0.33it/s[0m  
[2KAttention weights: tensor([[0.6564, 0.3436]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 60/203 [2m0:02:57 â€¢ 0:07:12[0m [2;4m0.33it/s[0m  
[2KAttention weights: tensor([[0.7091, 0.2909]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 60/203 [2m0:02:57 â€¢ 0:07:12[0m [2;4m0.33it/s[0m  
[2KAttention weights: tensor([[0.7625, 0.2375]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 60/203 [2m0:02:57 â€¢ 0:07:12[0m [2;4m0.33it/s[0m  
[2KAttention weights: tensor([[0.8038, 0.1962]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 60/203 [2m0:02:57 â€¢ 0:07:12[0m [2;4m0.33it/s[0m  
[2KAttention weights: tensor([[0.8284, 0.1716]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 60/203 [2m0:02:57 â€¢ 0:07:12[0m [2;4m0.33it/s[0m  
[2KAttention weights: tensor([[0.8423, 0.1577]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 60/203 [2m0:02:57 â€¢ 0:07:12[0m [2;4m0.33it/s[0m  
[2KAttention weights: tensor([[0.8506, 0.1494]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 60/203 [2m0:02:57 â€¢ 0:07:12[0m [2;4m0.33it/s[0m  
[2KAttention weights: tensor([[0.8558, 0.1442]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 60/203 [2m0:02:57 â€¢ 0:07:12[0m [2;4m0.33it/s[0m  
[2KAttention weights: tensor([[0.8587, 0.1413]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 60/203 [2m0:02:57 â€¢ 0:07:12[0m [2;4m0.33it/s[0m  
[2KAttention weights: tensor([[0.5633, 0.4367]], device='cuda:0');237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 60/203 [2m0:02:57 â€¢ 0:07:12[0m [2;4m0.33it/s[0m  
[2KAttention weights: tensor([[0.7725, 0.2275],;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 60/203 [2m0:02:57 â€¢ 0:07:12[0m [2;4m0.33it/s[0m  
        [0.6390, 0.3610],
        [0.8596, 0.1404],
        [0.7396, 0.2604],
        [0.7399, 0.2601],
        [0.7701, 0.2299],
        [0.7601, 0.2399],
        [0.8283, 0.1717],
        [0.8051, 0.1949],
[2K        [0.8012, 0.1988]], device='cuda:0')8;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 60/203 [2m0:02:57 â€¢ 0:07:12[0m [2;4m0.33it/s[0m  
[2KAttention weights: tensor([[0.5584, 0.4416],;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 61/203 [2m0:03:03 â€¢ 0:09:04[0m [2;4m0.26it/s[0m   
        [0.5535, 0.4465],
        [0.5558, 0.4442],
        [0.5551, 0.4449],
        [0.5534, 0.4466],
        [0.5527, 0.4473],
        [0.5538, 0.4462],
        [0.5571, 0.4429],
        [0.5575, 0.4425],
[2K        [0.5540, 0.4460]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 61/203 [2m0:03:03 â€¢ 0:09:04[0m [2;4m0.26it/s[0m  
[2KClass label: Billiardsâ”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 61/203 [2m0:03:03 â€¢ 0:09:04[0m [2;4m0.26it/s[0m  
[2KAttention weights: tensor([[0.5899, 0.4101]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 61/203 [2m0:03:03 â€¢ 0:09:04[0m [2;4m0.26it/s[0m  
[2KStep 0 - TTA Loss: 0.8407â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 61/203 [2m0:03:03 â€¢ 0:09:04[0m [2;4m0.26it/s[0m  
[2KAttention weights: tensor([[0.5899, 0.4101]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 61/203 [2m0:03:03 â€¢ 0:09:04[0m [2;4m0.26it/s[0m  
[2KAttention weights: tensor([[0.5890, 0.4110]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 61/203 [2m0:03:03 â€¢ 0:09:04[0m [2;4m0.26it/s[0m  
[2KAttention weights: tensor([[0.5840, 0.4160]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 61/203 [2m0:03:03 â€¢ 0:09:04[0m [2;4m0.26it/s[0m  
[2KAttention weights: tensor([[0.5693, 0.4307]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 61/203 [2m0:03:03 â€¢ 0:09:04[0m [2;4m0.26it/s[0m  
[2KAttention weights: tensor([[0.5388, 0.4612]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 61/203 [2m0:03:03 â€¢ 0:09:04[0m [2;4m0.26it/s[0m  
[2KAttention weights: tensor([[0.4873, 0.5127]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 61/203 [2m0:03:03 â€¢ 0:09:04[0m [2;4m0.26it/s[0m  
[2KAttention weights: tensor([[0.4127, 0.5873]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 61/203 [2m0:03:03 â€¢ 0:09:04[0m [2;4m0.26it/s[0m  
[2KAttention weights: tensor([[0.3238, 0.6762]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 61/203 [2m0:03:03 â€¢ 0:09:04[0m [2;4m0.26it/s[0m  
[2KAttention weights: tensor([[0.2378, 0.7622]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 61/203 [2m0:03:03 â€¢ 0:09:04[0m [2;4m0.26it/s[0m  
[2KAttention weights: tensor([[0.5435, 0.4565]], device='cuda:0')mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 61/203 [2m0:03:03 â€¢ 0:09:04[0m [2;4m0.26it/s[0m  
[2KAttention weights: tensor([[0.5491, 0.4509],37mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 61/203 [2m0:03:03 â€¢ 0:09:04[0m [2;4m0.26it/s[0m  
        [0.1694, 0.8306],
        [0.6653, 0.3347],
        [0.5032, 0.4968],
        [0.4822, 0.5178],
        [0.5300, 0.4700],
        [0.5595, 0.4405],
        [0.5153, 0.4847],
        [0.5773, 0.4227],
[2K        [0.6153, 0.3847]], device='cuda:0')237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 61/203 [2m0:03:03 â€¢ 0:09:04[0m [2;4m0.26it/s[0m  
[2KAttention weights: tensor([[0.5584, 0.4416],;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 62/203 [2m0:03:07 â€¢ 0:08:23[0m [2;4m0.28it/s[0m  
        [0.5534, 0.4466],
        [0.5558, 0.4442],
        [0.5550, 0.4450],
        [0.5534, 0.4466],
        [0.5527, 0.4473],
        [0.5538, 0.4462],
        [0.5570, 0.4430],
        [0.5575, 0.4425],
[2K        [0.5540, 0.4460]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 62/203 [2m0:03:07 â€¢ 0:08:23[0m [2;4m0.28it/s[0m  
[2KClass label: Billiardsâ”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 62/203 [2m0:03:07 â€¢ 0:08:23[0m [2;4m0.28it/s[0m  
[2KAttention weights: tensor([[0.5887, 0.4113]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 62/203 [2m0:03:07 â€¢ 0:08:23[0m [2;4m0.28it/s[0m  
[2KStep 0 - TTA Loss: 0.4917â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 62/203 [2m0:03:07 â€¢ 0:08:23[0m [2;4m0.28it/s[0m  
[2KAttention weights: tensor([[0.4862, 0.5138]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 62/203 [2m0:03:07 â€¢ 0:08:23[0m [2;4m0.28it/s[0m  
[2KAttention weights: tensor([[0.3882, 0.6118]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 62/203 [2m0:03:07 â€¢ 0:08:23[0m [2;4m0.28it/s[0m  
[2KAttention weights: tensor([[0.3071, 0.6929]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 62/203 [2m0:03:07 â€¢ 0:08:23[0m [2;4m0.28it/s[0m  
[2KAttention weights: tensor([[0.2494, 0.7506]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 62/203 [2m0:03:07 â€¢ 0:08:23[0m [2;4m0.28it/s[0m  
[2KAttention weights: tensor([[0.2127, 0.7873]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 62/203 [2m0:03:07 â€¢ 0:08:23[0m [2;4m0.28it/s[0m  
[2KAttention weights: tensor([[0.1912, 0.8088]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 62/203 [2m0:03:07 â€¢ 0:08:23[0m [2;4m0.28it/s[0m  
[2KAttention weights: tensor([[0.1795, 0.8205]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 62/203 [2m0:03:07 â€¢ 0:08:23[0m [2;4m0.28it/s[0m  
[2KAttention weights: tensor([[0.1740, 0.8260]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 62/203 [2m0:03:07 â€¢ 0:08:23[0m [2;4m0.28it/s[0m  
[2KAttention weights: tensor([[0.1721, 0.8279]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 62/203 [2m0:03:07 â€¢ 0:08:23[0m [2;4m0.28it/s[0m  
[2KAttention weights: tensor([[0.5433, 0.4567]], device='cuda:0')mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 62/203 [2m0:03:07 â€¢ 0:08:23[0m [2;4m0.28it/s[0m  
[2KAttention weights: tensor([[0.5327, 0.4673],37mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 62/203 [2m0:03:07 â€¢ 0:08:23[0m [2;4m0.28it/s[0m  
        [0.1717, 0.8283],
        [0.6164, 0.3836],
        [0.4798, 0.5202],
        [0.4555, 0.5445],
        [0.5053, 0.4947],
        [0.5358, 0.4642],
        [0.4950, 0.5050],
        [0.5515, 0.4485],
[2K        [0.5795, 0.4205]], device='cuda:0')237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 62/203 [2m0:03:07 â€¢ 0:08:23[0m [2;4m0.28it/s[0m  
[2KAttention weights: tensor([[0.5583, 0.4417],;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 63/203 [2m0:03:14 â€¢ 0:11:25[0m [2;4m0.20it/s[0m  
        [0.5533, 0.4467],
        [0.5558, 0.4442],
        [0.5550, 0.4450],
        [0.5533, 0.4467],
        [0.5527, 0.4473],
        [0.5537, 0.4463],
        [0.5570, 0.4430],
        [0.5575, 0.4425],
[2K        [0.5540, 0.4460]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 63/203 [2m0:03:14 â€¢ 0:11:25[0m [2;4m0.20it/s[0m  
[2KClass label: CleanAndJerkâ”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 63/203 [2m0:03:14 â€¢ 0:11:25[0m [2;4m0.20it/s[0m  
[2KAttention weights: tensor([[0.6260, 0.3740]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 63/203 [2m0:03:14 â€¢ 0:11:25[0m [2;4m0.20it/s[0m  
[2KStep 0 - TTA Loss: 0.5028â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 63/203 [2m0:03:14 â€¢ 0:11:25[0m [2;4m0.20it/s[0m  
[2KAttention weights: tensor([[0.6260, 0.3740]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 63/203 [2m0:03:14 â€¢ 0:11:25[0m [2;4m0.20it/s[0m  
[2KAttention weights: tensor([[0.6263, 0.3737]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 63/203 [2m0:03:14 â€¢ 0:11:25[0m [2;4m0.20it/s[0m  
[2KAttention weights: tensor([[0.6293, 0.3707]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 63/203 [2m0:03:14 â€¢ 0:11:25[0m [2;4m0.20it/s[0m  
[2KAttention weights: tensor([[0.6362, 0.3638]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 63/203 [2m0:03:14 â€¢ 0:11:25[0m [2;4m0.20it/s[0m  
[2KAttention weights: tensor([[0.6512, 0.3488]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 63/203 [2m0:03:14 â€¢ 0:11:25[0m [2;4m0.20it/s[0m  
[2KAttention weights: tensor([[0.6703, 0.3297]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 63/203 [2m0:03:14 â€¢ 0:11:25[0m [2;4m0.20it/s[0m  
[2KAttention weights: tensor([[0.6898, 0.3102]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 63/203 [2m0:03:14 â€¢ 0:11:25[0m [2;4m0.20it/s[0m  
[2KAttention weights: tensor([[0.7070, 0.2930]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 63/203 [2m0:03:14 â€¢ 0:11:25[0m [2;4m0.20it/s[0m  
[2KAttention weights: tensor([[0.7271, 0.2729]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 63/203 [2m0:03:14 â€¢ 0:11:25[0m [2;4m0.20it/s[0m  
[2KAttention weights: tensor([[0.5585, 0.4415]], device='cuda:0')mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 63/203 [2m0:03:14 â€¢ 0:11:25[0m [2;4m0.20it/s[0m  
[2KAttention weights: tensor([[0.6766, 0.3234],37mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 63/203 [2m0:03:14 â€¢ 0:11:25[0m [2;4m0.20it/s[0m  
        [0.5779, 0.4221],
        [0.7635, 0.2365],
        [0.6467, 0.3533],
        [0.6104, 0.3896],
        [0.6626, 0.3374],
        [0.6691, 0.3309],
        [0.6678, 0.3322],
        [0.7149, 0.2851],
[2K        [0.7109, 0.2891]], device='cuda:0')237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 63/203 [2m0:03:14 â€¢ 0:11:25[0m [2;4m0.20it/s[0m  
[2KAttention weights: tensor([[0.5583, 0.4417],;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 64/203 [2m0:03:20 â€¢ 0:11:20[0m [2;4m0.20it/s[0m  
        [0.5533, 0.4467],
        [0.5558, 0.4442],
        [0.5550, 0.4450],
        [0.5533, 0.4467],
        [0.5527, 0.4473],
        [0.5537, 0.4463],
        [0.5570, 0.4430],
        [0.5575, 0.4425],
[2K        [0.5540, 0.4460]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 64/203 [2m0:03:20 â€¢ 0:11:20[0m [2;4m0.20it/s[0m  
[2KClass label: BaseballPitchâ”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 64/203 [2m0:03:20 â€¢ 0:11:20[0m [2;4m0.20it/s[0m  
[2KAttention weights: tensor([[0.6414, 0.3586]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 64/203 [2m0:03:20 â€¢ 0:11:20[0m [2;4m0.20it/s[0m  
[2KStep 0 - TTA Loss: 0.4437â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 64/203 [2m0:03:20 â€¢ 0:11:20[0m [2;4m0.20it/s[0m  
[2KAttention weights: tensor([[0.6686, 0.3314]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 64/203 [2m0:03:20 â€¢ 0:11:20[0m [2;4m0.20it/s[0m  
[2KAttention weights: tensor([[0.6995, 0.3005]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 64/203 [2m0:03:20 â€¢ 0:11:20[0m [2;4m0.20it/s[0m  
[2KAttention weights: tensor([[0.7294, 0.2706]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 64/203 [2m0:03:20 â€¢ 0:11:20[0m [2;4m0.20it/s[0m  
[2KAttention weights: tensor([[0.7512, 0.2488]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 64/203 [2m0:03:20 â€¢ 0:11:20[0m [2;4m0.20it/s[0m  
[2KAttention weights: tensor([[0.7615, 0.2385]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 64/203 [2m0:03:20 â€¢ 0:11:20[0m [2;4m0.20it/s[0m  
[2KAttention weights: tensor([[0.7630, 0.2370]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 64/203 [2m0:03:20 â€¢ 0:11:20[0m [2;4m0.20it/s[0m  
[2KAttention weights: tensor([[0.7586, 0.2414]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 64/203 [2m0:03:20 â€¢ 0:11:20[0m [2;4m0.20it/s[0m  
[2KAttention weights: tensor([[0.7534, 0.2466]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 64/203 [2m0:03:20 â€¢ 0:11:20[0m [2;4m0.20it/s[0m  
[2KAttention weights: tensor([[0.7500, 0.2500]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 64/203 [2m0:03:20 â€¢ 0:11:20[0m [2;4m0.20it/s[0m  
[2KAttention weights: tensor([[0.5604, 0.4396]], device='cuda:0')5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 64/203 [2m0:03:20 â€¢ 0:11:20[0m [2;4m0.20it/s[0m  
[2KAttention weights: tensor([[0.7489, 0.2511],8;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 64/203 [2m0:03:20 â€¢ 0:11:20[0m [2;4m0.20it/s[0m  
        [0.6221, 0.3779],
        [0.7887, 0.2113],
        [0.6855, 0.3145],
        [0.6548, 0.3452],
        [0.6912, 0.3088],
        [0.7007, 0.2993],
        [0.7095, 0.2905],
        [0.7486, 0.2514],
[2K        [0.7377, 0.2623]], device='cuda:0')98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 64/203 [2m0:03:20 â€¢ 0:11:20[0m [2;4m0.20it/s[0m  
[2KAttention weights: tensor([[0.5584, 0.4416],;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 65/203 [2m0:03:25 â€¢ 0:12:59[0m [2;4m0.18it/s[0m  
        [0.5533, 0.4467],
        [0.5558, 0.4442],
        [0.5550, 0.4450],
        [0.5534, 0.4466],
        [0.5527, 0.4473],
        [0.5538, 0.4462],
        [0.5570, 0.4430],
        [0.5575, 0.4425],
[2K        [0.5540, 0.4460]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 65/203 [2m0:03:25 â€¢ 0:12:59[0m [2;4m0.18it/s[0m  
[2KClass label: BaseballPitchâ”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 65/203 [2m0:03:25 â€¢ 0:12:59[0m [2;4m0.18it/s[0m  
[2KAttention weights: tensor([[0.6430, 0.3570]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 65/203 [2m0:03:25 â€¢ 0:12:59[0m [2;4m0.18it/s[0m  
[2KStep 0 - TTA Loss: 0.8582â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 65/203 [2m0:03:25 â€¢ 0:12:59[0m [2;4m0.18it/s[0m  
[2KAttention weights: tensor([[0.6430, 0.3570]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 65/203 [2m0:03:25 â€¢ 0:12:59[0m [2;4m0.18it/s[0m  
[2KAttention weights: tensor([[0.6424, 0.3576]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 65/203 [2m0:03:25 â€¢ 0:12:59[0m [2;4m0.18it/s[0m  
[2KAttention weights: tensor([[0.6411, 0.3589]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 65/203 [2m0:03:25 â€¢ 0:12:59[0m [2;4m0.18it/s[0m  
[2KAttention weights: tensor([[0.6406, 0.3594]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 65/203 [2m0:03:25 â€¢ 0:12:59[0m [2;4m0.18it/s[0m  
[2KAttention weights: tensor([[0.6433, 0.3567]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 65/203 [2m0:03:25 â€¢ 0:12:59[0m [2;4m0.18it/s[0m  
[2KAttention weights: tensor([[0.6515, 0.3485]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 65/203 [2m0:03:25 â€¢ 0:12:59[0m [2;4m0.18it/s[0m  
[2KAttention weights: tensor([[0.6627, 0.3373]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 65/203 [2m0:03:25 â€¢ 0:12:59[0m [2;4m0.18it/s[0m  
[2KAttention weights: tensor([[0.6740, 0.3260]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 65/203 [2m0:03:25 â€¢ 0:12:59[0m [2;4m0.18it/s[0m  
[2KAttention weights: tensor([[0.6808, 0.3192]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 65/203 [2m0:03:25 â€¢ 0:12:59[0m [2;4m0.18it/s[0m  
[2KAttention weights: tensor([[0.5584, 0.4416]], device='cuda:0')5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 65/203 [2m0:03:25 â€¢ 0:12:59[0m [2;4m0.18it/s[0m  
[2KAttention weights: tensor([[0.6821, 0.3179],8;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 65/203 [2m0:03:25 â€¢ 0:12:59[0m [2;4m0.18it/s[0m  
        [0.6083, 0.3917],
        [0.6638, 0.3362],
        [0.6328, 0.3672],
        [0.5753, 0.4247],
        [0.6276, 0.3724],
        [0.6379, 0.3621],
        [0.6606, 0.3394],
        [0.6891, 0.3109],
[2K        [0.6473, 0.3527]], device='cuda:0')98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 65/203 [2m0:03:25 â€¢ 0:12:59[0m [2;4m0.18it/s[0m  
[2KAttention weights: tensor([[0.5584, 0.4416],8;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 66/203 [2m0:03:26 â€¢ 0:11:05[0m [2;4m0.21it/s[0m   
        [0.5533, 0.4467],
        [0.5558, 0.4442],
        [0.5550, 0.4450],
        [0.5534, 0.4466],
        [0.5527, 0.4473],
        [0.5538, 0.4462],
        [0.5570, 0.4430],
        [0.5575, 0.4425],
[2K        [0.5540, 0.4460]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 66/203 [2m0:03:26 â€¢ 0:11:05[0m [2;4m0.21it/s[0m  
[2KClass label: SoccerPenaltyâ”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 66/203 [2m0:03:26 â€¢ 0:11:05[0m [2;4m0.21it/s[0m  
[2KAttention weights: tensor([[0.6356, 0.3644]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 66/203 [2m0:03:26 â€¢ 0:11:05[0m [2;4m0.21it/s[0m  
[2KStep 0 - TTA Loss: 0.9126â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 66/203 [2m0:03:26 â€¢ 0:11:05[0m [2;4m0.21it/s[0m  
[2KAttention weights: tensor([[0.6408, 0.3592]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 66/203 [2m0:03:26 â€¢ 0:11:05[0m [2;4m0.21it/s[0m  
[2KAttention weights: tensor([[0.6491, 0.3509]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 66/203 [2m0:03:26 â€¢ 0:11:05[0m [2;4m0.21it/s[0m  
[2KAttention weights: tensor([[0.6547, 0.3453]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 66/203 [2m0:03:26 â€¢ 0:11:05[0m [2;4m0.21it/s[0m  
[2KAttention weights: tensor([[0.6599, 0.3401]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 66/203 [2m0:03:26 â€¢ 0:11:05[0m [2;4m0.21it/s[0m  
[2KAttention weights: tensor([[0.6594, 0.3406]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 66/203 [2m0:03:26 â€¢ 0:11:05[0m [2;4m0.21it/s[0m  
[2KAttention weights: tensor([[0.6715, 0.3285]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 66/203 [2m0:03:26 â€¢ 0:11:05[0m [2;4m0.21it/s[0m  
[2KAttention weights: tensor([[0.6745, 0.3255]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 66/203 [2m0:03:26 â€¢ 0:11:05[0m [2;4m0.21it/s[0m  
[2KAttention weights: tensor([[0.6733, 0.3267]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 66/203 [2m0:03:26 â€¢ 0:11:05[0m [2;4m0.21it/s[0m  
[2KAttention weights: tensor([[0.6706, 0.3294]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 66/203 [2m0:03:26 â€¢ 0:11:05[0m [2;4m0.21it/s[0m  
[2KAttention weights: tensor([[0.5577, 0.4423]], device='cuda:0')7mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 66/203 [2m0:03:26 â€¢ 0:11:05[0m [2;4m0.21it/s[0m  
[2KAttention weights: tensor([[0.6621, 0.3379],237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 66/203 [2m0:03:26 â€¢ 0:11:05[0m [2;4m0.21it/s[0m  
        [0.6073, 0.3927],
        [0.6488, 0.3512],
        [0.6237, 0.3763],
        [0.5634, 0.4366],
        [0.6210, 0.3790],
        [0.6309, 0.3691],
        [0.6695, 0.3305],
        [0.6793, 0.3207],
[2K        [0.6346, 0.3654]], device='cuda:0');237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 66/203 [2m0:03:26 â€¢ 0:11:05[0m [2;4m0.21it/s[0m  
[2KAttention weights: tensor([[0.5584, 0.4416],8;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 67/203 [2m0:03:27 â€¢ 0:08:55[0m [2;4m0.25it/s[0m  
        [0.5533, 0.4467],
        [0.5559, 0.4441],
        [0.5550, 0.4450],
        [0.5534, 0.4466],
        [0.5527, 0.4473],
        [0.5538, 0.4462],
        [0.5570, 0.4430],
        [0.5575, 0.4425],
[2K        [0.5540, 0.4460]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 67/203 [2m0:03:27 â€¢ 0:08:55[0m [2;4m0.25it/s[0m  
[2KClass label: PoleVaultâ”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 67/203 [2m0:03:27 â€¢ 0:08:55[0m [2;4m0.25it/s[0m  
[2KAttention weights: tensor([[0.6111, 0.3889]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 67/203 [2m0:03:27 â€¢ 0:08:55[0m [2;4m0.25it/s[0m  
[2KStep 0 - TTA Loss: 0.6729â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 67/203 [2m0:03:27 â€¢ 0:08:55[0m [2;4m0.25it/s[0m  
[2KAttention weights: tensor([[0.6111, 0.3889]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 67/203 [2m0:03:27 â€¢ 0:08:55[0m [2;4m0.25it/s[0m  
[2KAttention weights: tensor([[0.6111, 0.3889]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 67/203 [2m0:03:27 â€¢ 0:08:55[0m [2;4m0.25it/s[0m  
[2KAttention weights: tensor([[0.6117, 0.3883]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 67/203 [2m0:03:27 â€¢ 0:08:55[0m [2;4m0.25it/s[0m  
[2KAttention weights: tensor([[0.6152, 0.3848]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 67/203 [2m0:03:27 â€¢ 0:08:55[0m [2;4m0.25it/s[0m  
[2KAttention weights: tensor([[0.6236, 0.3764]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 67/203 [2m0:03:27 â€¢ 0:08:55[0m [2;4m0.25it/s[0m  
[2KAttention weights: tensor([[0.6331, 0.3669]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 67/203 [2m0:03:27 â€¢ 0:08:55[0m [2;4m0.25it/s[0m  
[2KAttention weights: tensor([[0.6391, 0.3609]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 67/203 [2m0:03:27 â€¢ 0:08:55[0m [2;4m0.25it/s[0m  
[2KAttention weights: tensor([[0.6452, 0.3548]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 67/203 [2m0:03:27 â€¢ 0:08:55[0m [2;4m0.25it/s[0m  
[2KAttention weights: tensor([[0.6545, 0.3455]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 67/203 [2m0:03:27 â€¢ 0:08:55[0m [2;4m0.25it/s[0m  
[2KAttention weights: tensor([[0.5553, 0.4447]], device='cuda:0')7mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 67/203 [2m0:03:27 â€¢ 0:08:55[0m [2;4m0.25it/s[0m  
[2KAttention weights: tensor([[0.6624, 0.3376],237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 67/203 [2m0:03:27 â€¢ 0:08:55[0m [2;4m0.25it/s[0m  
        [0.5987, 0.4013],
        [0.6608, 0.3392],
        [0.6201, 0.3799],
        [0.5744, 0.4256],
        [0.6532, 0.3468],
        [0.6882, 0.3118],
        [0.6139, 0.3861],
        [0.6772, 0.3228],
[2K        [0.6592, 0.3408]], device='cuda:0');237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 67/203 [2m0:03:27 â€¢ 0:08:55[0m [2;4m0.25it/s[0m  
[2KAttention weights: tensor([[0.5584, 0.4416],8;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 68/203 [2m0:03:47 â€¢ 0:15:24[0m [2;4m0.15it/s[0m  
        [0.5533, 0.4467],
        [0.5558, 0.4442],
        [0.5550, 0.4450],
        [0.5534, 0.4466],
        [0.5527, 0.4473],
        [0.5538, 0.4462],
        [0.5570, 0.4430],
        [0.5575, 0.4425],
[2K        [0.5540, 0.4460]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 68/203 [2m0:03:47 â€¢ 0:15:24[0m [2;4m0.15it/s[0m  
[2KClass label: TennisSwingâ”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 68/203 [2m0:03:47 â€¢ 0:15:24[0m [2;4m0.15it/s[0m  
[2KAttention weights: tensor([[0.6629, 0.3371]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 68/203 [2m0:03:47 â€¢ 0:15:24[0m [2;4m0.15it/s[0m  
[2KStep 0 - TTA Loss: 0.7329â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 68/203 [2m0:03:47 â€¢ 0:15:24[0m [2;4m0.15it/s[0m  
[2KAttention weights: tensor([[0.6813, 0.3187]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 68/203 [2m0:03:47 â€¢ 0:15:24[0m [2;4m0.15it/s[0m  
[2KAttention weights: tensor([[0.7050, 0.2950]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 68/203 [2m0:03:47 â€¢ 0:15:24[0m [2;4m0.15it/s[0m  
[2KAttention weights: tensor([[0.7284, 0.2716]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 68/203 [2m0:03:47 â€¢ 0:15:24[0m [2;4m0.15it/s[0m  
[2KAttention weights: tensor([[0.7439, 0.2561]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 68/203 [2m0:03:47 â€¢ 0:15:24[0m [2;4m0.15it/s[0m  
[2KAttention weights: tensor([[0.7487, 0.2513]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 68/203 [2m0:03:47 â€¢ 0:15:24[0m [2;4m0.15it/s[0m  
[2KAttention weights: tensor([[0.7436, 0.2564]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 68/203 [2m0:03:47 â€¢ 0:15:24[0m [2;4m0.15it/s[0m  
[2KAttention weights: tensor([[0.7335, 0.2665]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 68/203 [2m0:03:47 â€¢ 0:15:24[0m [2;4m0.15it/s[0m  
[2KAttention weights: tensor([[0.7254, 0.2746]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 68/203 [2m0:03:47 â€¢ 0:15:24[0m [2;4m0.15it/s[0m  
[2KAttention weights: tensor([[0.7209, 0.2791]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 68/203 [2m0:03:47 â€¢ 0:15:24[0m [2;4m0.15it/s[0m  
[2KAttention weights: tensor([[0.5583, 0.4417]], device='cuda:0')7mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 68/203 [2m0:03:47 â€¢ 0:15:24[0m [2;4m0.15it/s[0m  
[2KAttention weights: tensor([[0.7097, 0.2903],237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 68/203 [2m0:03:47 â€¢ 0:15:24[0m [2;4m0.15it/s[0m  
        [0.6357, 0.3643],
        [0.6987, 0.3013],
        [0.6638, 0.3362],
        [0.6320, 0.3680],
        [0.7070, 0.2930],
        [0.7437, 0.2563],
        [0.6814, 0.3186],
        [0.7196, 0.2804],
[2K        [0.7034, 0.2966]], device='cuda:0');237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 68/203 [2m0:03:47 â€¢ 0:15:24[0m [2;4m0.15it/s[0m  
[2KAttention weights: tensor([[0.5584, 0.4416],8;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 69/203 [2m0:03:49 â€¢ 0:12:53[0m [2;4m0.17it/s[0m  
        [0.5533, 0.4467],
        [0.5558, 0.4442],
        [0.5550, 0.4450],
        [0.5534, 0.4466],
        [0.5527, 0.4473],
        [0.5538, 0.4462],
        [0.5570, 0.4430],
        [0.5575, 0.4425],
[2K        [0.5540, 0.4460]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 69/203 [2m0:03:49 â€¢ 0:12:53[0m [2;4m0.17it/s[0m  
[2KClass label: PoleVaultâ”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 69/203 [2m0:03:49 â€¢ 0:12:53[0m [2;4m0.17it/s[0m  
[2KAttention weights: tensor([[0.6095, 0.3905]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 69/203 [2m0:03:49 â€¢ 0:12:53[0m [2;4m0.17it/s[0m  
[2KStep 0 - TTA Loss: 1.1805â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 69/203 [2m0:03:49 â€¢ 0:12:53[0m [2;4m0.17it/s[0m  
[2KAttention weights: tensor([[0.6095, 0.3905]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 69/203 [2m0:03:49 â€¢ 0:12:53[0m [2;4m0.17it/s[0m  
[2KAttention weights: tensor([[0.6095, 0.3905]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 69/203 [2m0:03:49 â€¢ 0:12:53[0m [2;4m0.17it/s[0m  
[2KAttention weights: tensor([[0.6098, 0.3902]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 69/203 [2m0:03:49 â€¢ 0:12:53[0m [2;4m0.17it/s[0m  
[2KAttention weights: tensor([[0.6125, 0.3875]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 69/203 [2m0:03:49 â€¢ 0:12:53[0m [2;4m0.17it/s[0m  
[2KAttention weights: tensor([[0.6172, 0.3828]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 69/203 [2m0:03:49 â€¢ 0:12:53[0m [2;4m0.17it/s[0m  
[2KAttention weights: tensor([[0.6237, 0.3763]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 69/203 [2m0:03:49 â€¢ 0:12:53[0m [2;4m0.17it/s[0m  
[2KAttention weights: tensor([[0.6275, 0.3725]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 69/203 [2m0:03:49 â€¢ 0:12:53[0m [2;4m0.17it/s[0m  
[2KAttention weights: tensor([[0.6262, 0.3738]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 69/203 [2m0:03:49 â€¢ 0:12:53[0m [2;4m0.17it/s[0m  
[2KAttention weights: tensor([[0.6307, 0.3693]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 69/203 [2m0:03:49 â€¢ 0:12:53[0m [2;4m0.17it/s[0m  
[2KAttention weights: tensor([[0.5539, 0.4461]], device='cuda:0');5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 69/203 [2m0:03:49 â€¢ 0:12:53[0m [2;4m0.17it/s[0m  
[2KAttention weights: tensor([[0.6164, 0.3836],98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 69/203 [2m0:03:49 â€¢ 0:12:53[0m [2;4m0.17it/s[0m  
        [0.5639, 0.4361],
        [0.5996, 0.4004],
        [0.5629, 0.4371],
        [0.5220, 0.4780],
        [0.5863, 0.4137],
        [0.6357, 0.3643],
        [0.6032, 0.3968],
        [0.5540, 0.4460],
[2K        [0.5841, 0.4159]], device='cuda:0');98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 69/203 [2m0:03:49 â€¢ 0:12:53[0m [2;4m0.17it/s[0m  
[2KAttention weights: tensor([[0.5583, 0.4417],8;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 70/203 [2m0:03:53 â€¢ 0:12:35[0m [2;4m0.18it/s[0m  
        [0.5533, 0.4467],
        [0.5558, 0.4442],
        [0.5550, 0.4450],
        [0.5533, 0.4467],
        [0.5527, 0.4473],
        [0.5537, 0.4463],
        [0.5570, 0.4430],
        [0.5574, 0.4426],
[2K        [0.5540, 0.4460]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 70/203 [2m0:03:53 â€¢ 0:12:35[0m [2;4m0.18it/s[0m  
[2KClass label: PoleVaultâ”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 70/203 [2m0:03:53 â€¢ 0:12:35[0m [2;4m0.18it/s[0m  
[2KAttention weights: tensor([[0.6188, 0.3812]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 70/203 [2m0:03:53 â€¢ 0:12:35[0m [2;4m0.18it/s[0m  
[2KStep 0 - TTA Loss: 0.6813â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 70/203 [2m0:03:53 â€¢ 0:12:35[0m [2;4m0.18it/s[0m  
[2KAttention weights: tensor([[0.6302, 0.3698]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 70/203 [2m0:03:53 â€¢ 0:12:35[0m [2;4m0.18it/s[0m  
[2KAttention weights: tensor([[0.6515, 0.3485]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 70/203 [2m0:03:53 â€¢ 0:12:35[0m [2;4m0.18it/s[0m  
[2KAttention weights: tensor([[0.6710, 0.3290]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 70/203 [2m0:03:53 â€¢ 0:12:35[0m [2;4m0.18it/s[0m  
[2KAttention weights: tensor([[0.6887, 0.3113]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 70/203 [2m0:03:53 â€¢ 0:12:35[0m [2;4m0.18it/s[0m  
[2KAttention weights: tensor([[0.7005, 0.2995]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 70/203 [2m0:03:53 â€¢ 0:12:35[0m [2;4m0.18it/s[0m  
[2KAttention weights: tensor([[0.7079, 0.2921]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 70/203 [2m0:03:53 â€¢ 0:12:35[0m [2;4m0.18it/s[0m  
[2KAttention weights: tensor([[0.7118, 0.2882]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 70/203 [2m0:03:53 â€¢ 0:12:35[0m [2;4m0.18it/s[0m  
[2KAttention weights: tensor([[0.7131, 0.2869]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 70/203 [2m0:03:53 â€¢ 0:12:35[0m [2;4m0.18it/s[0m  
[2KAttention weights: tensor([[0.7136, 0.2864]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 70/203 [2m0:03:53 â€¢ 0:12:35[0m [2;4m0.18it/s[0m  
[2KAttention weights: tensor([[0.5561, 0.4439]], device='cuda:0');5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 70/203 [2m0:03:53 â€¢ 0:12:35[0m [2;4m0.18it/s[0m  
[2KAttention weights: tensor([[0.6834, 0.3166],98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 70/203 [2m0:03:53 â€¢ 0:12:35[0m [2;4m0.18it/s[0m  
        [0.6152, 0.3848],
        [0.6587, 0.3413],
        [0.6278, 0.3722],
        [0.5943, 0.4057],
        [0.6690, 0.3310],
        [0.7138, 0.2862],
        [0.6779, 0.3221],
        [0.6433, 0.3567],
[2K        [0.6561, 0.3439]], device='cuda:0');98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 70/203 [2m0:03:53 â€¢ 0:12:35[0m [2;4m0.18it/s[0m  
[2KAttention weights: tensor([[0.5583, 0.4417],8;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 71/203 [2m0:03:58 â€¢ 0:07:46[0m [2;4m0.28it/s[0m  
        [0.5533, 0.4467],
        [0.5558, 0.4442],
        [0.5550, 0.4450],
        [0.5534, 0.4466],
        [0.5527, 0.4473],
        [0.5538, 0.4462],
        [0.5570, 0.4430],
        [0.5574, 0.4426],
[2K        [0.5540, 0.4460]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 71/203 [2m0:03:58 â€¢ 0:07:46[0m [2;4m0.28it/s[0m  
[2KClass label: HighJumpâ”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 71/203 [2m0:03:58 â€¢ 0:07:46[0m [2;4m0.28it/s[0m  
[2KAttention weights: tensor([[0.6030, 0.3970]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 71/203 [2m0:03:58 â€¢ 0:07:46[0m [2;4m0.28it/s[0m  
[2KStep 0 - TTA Loss: 0.6418â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 71/203 [2m0:03:58 â€¢ 0:07:46[0m [2;4m0.28it/s[0m  
[2KAttention weights: tensor([[0.6030, 0.3970]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 71/203 [2m0:03:58 â€¢ 0:07:46[0m [2;4m0.28it/s[0m  
[2KAttention weights: tensor([[0.6035, 0.3965]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 71/203 [2m0:03:58 â€¢ 0:07:46[0m [2;4m0.28it/s[0m  
[2KAttention weights: tensor([[0.6053, 0.3947]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 71/203 [2m0:03:58 â€¢ 0:07:46[0m [2;4m0.28it/s[0m  
[2KAttention weights: tensor([[0.6109, 0.3891]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 71/203 [2m0:03:58 â€¢ 0:07:46[0m [2;4m0.28it/s[0m  
[2KAttention weights: tensor([[0.6188, 0.3812]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 71/203 [2m0:03:58 â€¢ 0:07:46[0m [2;4m0.28it/s[0m  
[2KAttention weights: tensor([[0.6273, 0.3727]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 71/203 [2m0:03:58 â€¢ 0:07:46[0m [2;4m0.28it/s[0m  
[2KAttention weights: tensor([[0.6374, 0.3626]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 71/203 [2m0:03:58 â€¢ 0:07:46[0m [2;4m0.28it/s[0m  
[2KAttention weights: tensor([[0.6445, 0.3555]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 71/203 [2m0:03:58 â€¢ 0:07:46[0m [2;4m0.28it/s[0m  
[2KAttention weights: tensor([[0.6470, 0.3530]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 71/203 [2m0:03:58 â€¢ 0:07:46[0m [2;4m0.28it/s[0m  
[2KAttention weights: tensor([[0.5535, 0.4465]], device='cuda:0');5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 71/203 [2m0:03:58 â€¢ 0:07:46[0m [2;4m0.28it/s[0m  
[2KAttention weights: tensor([[0.6642, 0.3358],98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 71/203 [2m0:03:58 â€¢ 0:07:46[0m [2;4m0.28it/s[0m  
        [0.6134, 0.3866],
        [0.6457, 0.3543],
        [0.6284, 0.3716],
        [0.5734, 0.4266],
        [0.6545, 0.3455],
        [0.6511, 0.3489],
        [0.6633, 0.3367],
        [0.6833, 0.3167],
[2K        [0.6463, 0.3537]], device='cuda:0');98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 71/203 [2m0:03:58 â€¢ 0:07:46[0m [2;4m0.28it/s[0m  
[2KAttention weights: tensor([[0.5583, 0.4417],38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 72/203 [2m0:04:04 â€¢ 0:08:49[0m [2;4m0.25it/s[0m   
        [0.5533, 0.4467],
        [0.5558, 0.4442],
        [0.5550, 0.4450],
        [0.5533, 0.4467],
        [0.5527, 0.4473],
        [0.5538, 0.4462],
        [0.5570, 0.4430],
        [0.5574, 0.4426],
[2K        [0.5540, 0.4460]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 72/203 [2m0:04:04 â€¢ 0:08:49[0m [2;4m0.25it/s[0m  
[2KClass label: PoleVaultâ”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 72/203 [2m0:04:04 â€¢ 0:08:49[0m [2;4m0.25it/s[0m  
[2KAttention weights: tensor([[0.6133, 0.3867]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 72/203 [2m0:04:04 â€¢ 0:08:49[0m [2;4m0.25it/s[0m  
[2KStep 0 - TTA Loss: 0.7094â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 72/203 [2m0:04:04 â€¢ 0:08:49[0m [2;4m0.25it/s[0m  
[2KAttention weights: tensor([[0.6432, 0.3568]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 72/203 [2m0:04:04 â€¢ 0:08:49[0m [2;4m0.25it/s[0m  
[2KAttention weights: tensor([[0.6894, 0.3106]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 72/203 [2m0:04:04 â€¢ 0:08:49[0m [2;4m0.25it/s[0m  
[2KAttention weights: tensor([[0.7499, 0.2501]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 72/203 [2m0:04:04 â€¢ 0:08:49[0m [2;4m0.25it/s[0m  
[2KAttention weights: tensor([[0.8121, 0.1879]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 72/203 [2m0:04:04 â€¢ 0:08:49[0m [2;4m0.25it/s[0m  
[2KAttention weights: tensor([[0.8622, 0.1378]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 72/203 [2m0:04:04 â€¢ 0:08:49[0m [2;4m0.25it/s[0m  
[2KAttention weights: tensor([[0.8997, 0.1003]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 72/203 [2m0:04:04 â€¢ 0:08:49[0m [2;4m0.25it/s[0m  
[2KAttention weights: tensor([[0.9230, 0.0770]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 72/203 [2m0:04:04 â€¢ 0:08:49[0m [2;4m0.25it/s[0m  
[2KAttention weights: tensor([[0.9350, 0.0650]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 72/203 [2m0:04:04 â€¢ 0:08:49[0m [2;4m0.25it/s[0m  
[2KAttention weights: tensor([[0.9399, 0.0601]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 72/203 [2m0:04:04 â€¢ 0:08:49[0m [2;4m0.25it/s[0m  
[2KAttention weights: tensor([[0.5683, 0.4317]], device='cuda:0')37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 72/203 [2m0:04:04 â€¢ 0:08:49[0m [2;4m0.25it/s[0m  
[2KAttention weights: tensor([[0.8820, 0.1180],;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 72/203 [2m0:04:04 â€¢ 0:08:49[0m [2;4m0.25it/s[0m  
        [0.7806, 0.2194],
        [0.8503, 0.1497],
        [0.8341, 0.1659],
        [0.8607, 0.1393],
        [0.9144, 0.0856],
        [0.9413, 0.0587],
        [0.8926, 0.1074],
        [0.8608, 0.1392],
[2K        [0.8689, 0.1311]], device='cuda:0')5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 72/203 [2m0:04:04 â€¢ 0:08:49[0m [2;4m0.25it/s[0m  
[2KAttention weights: tensor([[0.5584, 0.4416],38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 73/203 [2m0:04:14 â€¢ 0:11:41[0m [2;4m0.19it/s[0m  
        [0.5533, 0.4467],
        [0.5559, 0.4441],
        [0.5550, 0.4450],
        [0.5534, 0.4466],
        [0.5528, 0.4472],
        [0.5539, 0.4461],
        [0.5570, 0.4430],
        [0.5575, 0.4425],
[2K        [0.5541, 0.4459]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 73/203 [2m0:04:14 â€¢ 0:11:41[0m [2;4m0.19it/s[0m  
[2KClass label: GolfSwingâ”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 73/203 [2m0:04:14 â€¢ 0:11:41[0m [2;4m0.19it/s[0m  
[2KAttention weights: tensor([[0.6037, 0.3963]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 73/203 [2m0:04:14 â€¢ 0:11:41[0m [2;4m0.19it/s[0m  
[2KStep 0 - TTA Loss: 0.8315â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 73/203 [2m0:04:14 â€¢ 0:11:41[0m [2;4m0.19it/s[0m  
[2KAttention weights: tensor([[0.6037, 0.3963]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 73/203 [2m0:04:14 â€¢ 0:11:41[0m [2;4m0.19it/s[0m  
[2KAttention weights: tensor([[0.6063, 0.3937]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 73/203 [2m0:04:14 â€¢ 0:11:41[0m [2;4m0.19it/s[0m  
[2KAttention weights: tensor([[0.6154, 0.3846]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 73/203 [2m0:04:14 â€¢ 0:11:41[0m [2;4m0.19it/s[0m  
[2KAttention weights: tensor([[0.6333, 0.3667]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 73/203 [2m0:04:14 â€¢ 0:11:41[0m [2;4m0.19it/s[0m  
[2KAttention weights: tensor([[0.6607, 0.3393]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 73/203 [2m0:04:14 â€¢ 0:11:41[0m [2;4m0.19it/s[0m  
[2KAttention weights: tensor([[0.6950, 0.3050]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 73/203 [2m0:04:14 â€¢ 0:11:41[0m [2;4m0.19it/s[0m  
[2KAttention weights: tensor([[0.7290, 0.2710]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 73/203 [2m0:04:14 â€¢ 0:11:41[0m [2;4m0.19it/s[0m  
[2KAttention weights: tensor([[0.7579, 0.2421]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 73/203 [2m0:04:14 â€¢ 0:11:41[0m [2;4m0.19it/s[0m  
[2KAttention weights: tensor([[0.7728, 0.2272]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 73/203 [2m0:04:14 â€¢ 0:11:41[0m [2;4m0.19it/s[0m  
[2KAttention weights: tensor([[0.5597, 0.4403]], device='cuda:0')37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 73/203 [2m0:04:14 â€¢ 0:11:41[0m [2;4m0.19it/s[0m  
[2KAttention weights: tensor([[0.8429, 0.1571],;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 73/203 [2m0:04:14 â€¢ 0:11:41[0m [2;4m0.19it/s[0m  
        [0.7422, 0.2578],
        [0.8116, 0.1884],
        [0.7752, 0.2248],
        [0.8101, 0.1899],
        [0.8718, 0.1282],
        [0.9101, 0.0899],
        [0.8527, 0.1473],
        [0.8212, 0.1788],
[2K        [0.8258, 0.1742]], device='cuda:0')5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 73/203 [2m0:04:14 â€¢ 0:11:41[0m [2;4m0.19it/s[0m  
[2KAttention weights: tensor([[0.5585, 0.4415],38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 74/203 [2m0:04:16 â€¢ 0:10:22[0m [2;4m0.21it/s[0m  
        [0.5534, 0.4466],
        [0.5560, 0.4440],
        [0.5551, 0.4449],
        [0.5536, 0.4464],
        [0.5529, 0.4471],
        [0.5541, 0.4459],
        [0.5571, 0.4429],
        [0.5576, 0.4424],
[2K        [0.5542, 0.4458]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 74/203 [2m0:04:16 â€¢ 0:10:22[0m [2;4m0.21it/s[0m  
[2KClass label: ThrowDiscusâ”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 74/203 [2m0:04:16 â€¢ 0:10:22[0m [2;4m0.21it/s[0m  
[2KAttention weights: tensor([[0.6202, 0.3798]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 74/203 [2m0:04:16 â€¢ 0:10:22[0m [2;4m0.21it/s[0m  
[2KStep 0 - TTA Loss: 0.8703â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 74/203 [2m0:04:16 â€¢ 0:10:22[0m [2;4m0.21it/s[0m  
[2KAttention weights: tensor([[0.6507, 0.3493]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 74/203 [2m0:04:16 â€¢ 0:10:22[0m [2;4m0.21it/s[0m  
[2KAttention weights: tensor([[0.6789, 0.3211]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 74/203 [2m0:04:16 â€¢ 0:10:22[0m [2;4m0.21it/s[0m  
[2KAttention weights: tensor([[0.7003, 0.2997]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 74/203 [2m0:04:16 â€¢ 0:10:22[0m [2;4m0.21it/s[0m  
[2KAttention weights: tensor([[0.7126, 0.2874]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 74/203 [2m0:04:16 â€¢ 0:10:22[0m [2;4m0.21it/s[0m  
[2KAttention weights: tensor([[0.7109, 0.2891]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 74/203 [2m0:04:16 â€¢ 0:10:22[0m [2;4m0.21it/s[0m  
[2KAttention weights: tensor([[0.6989, 0.3011]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 74/203 [2m0:04:16 â€¢ 0:10:22[0m [2;4m0.21it/s[0m  
[2KAttention weights: tensor([[0.6824, 0.3176]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 74/203 [2m0:04:16 â€¢ 0:10:22[0m [2;4m0.21it/s[0m  
[2KAttention weights: tensor([[0.6683, 0.3317]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 74/203 [2m0:04:16 â€¢ 0:10:22[0m [2;4m0.21it/s[0m  
[2KAttention weights: tensor([[0.6602, 0.3398]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 74/203 [2m0:04:16 â€¢ 0:10:22[0m [2;4m0.21it/s[0m  
[2KAttention weights: tensor([[0.5549, 0.4451]], device='cuda:0')8;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 74/203 [2m0:04:16 â€¢ 0:10:22[0m [2;4m0.21it/s[0m  
[2KAttention weights: tensor([[0.7223, 0.2777],;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 74/203 [2m0:04:16 â€¢ 0:10:22[0m [2;4m0.21it/s[0m  
        [0.6414, 0.3586],
        [0.6824, 0.3176],
        [0.5865, 0.4135],
        [0.6468, 0.3532],
        [0.7402, 0.2598],
        [0.7982, 0.2018],
        [0.7347, 0.2653],
        [0.6931, 0.3069],
[2K        [0.6577, 0.3423]], device='cuda:0')2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 74/203 [2m0:04:16 â€¢ 0:10:22[0m [2;4m0.21it/s[0m  
[2KAttention weights: tensor([[0.5585, 0.4415],38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 75/203 [2m0:04:18 â€¢ 0:10:28[0m [2;4m0.20it/s[0m  
        [0.5534, 0.4466],
        [0.5560, 0.4440],
        [0.5551, 0.4449],
        [0.5536, 0.4464],
        [0.5530, 0.4470],
        [0.5542, 0.4458],
        [0.5571, 0.4429],
        [0.5576, 0.4424],
[2K        [0.5541, 0.4459]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 75/203 [2m0:04:18 â€¢ 0:10:28[0m [2;4m0.20it/s[0m  
[2KClass label: BaseballPitchâ”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 75/203 [2m0:04:18 â€¢ 0:10:28[0m [2;4m0.20it/s[0m  
[2KAttention weights: tensor([[0.6391, 0.3609]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 75/203 [2m0:04:18 â€¢ 0:10:28[0m [2;4m0.20it/s[0m  
[2KStep 0 - TTA Loss: 0.8937â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 75/203 [2m0:04:18 â€¢ 0:10:28[0m [2;4m0.20it/s[0m  
[2KAttention weights: tensor([[0.6391, 0.3609]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 75/203 [2m0:04:18 â€¢ 0:10:28[0m [2;4m0.20it/s[0m  
[2KAttention weights: tensor([[0.6403, 0.3597]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 75/203 [2m0:04:18 â€¢ 0:10:28[0m [2;4m0.20it/s[0m  
[2KAttention weights: tensor([[0.6473, 0.3527]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 75/203 [2m0:04:18 â€¢ 0:10:28[0m [2;4m0.20it/s[0m  
[2KAttention weights: tensor([[0.6666, 0.3334]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 75/203 [2m0:04:18 â€¢ 0:10:28[0m [2;4m0.20it/s[0m  
[2KAttention weights: tensor([[0.7024, 0.2976]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 75/203 [2m0:04:18 â€¢ 0:10:28[0m [2;4m0.20it/s[0m  
[2KAttention weights: tensor([[0.7535, 0.2465]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 75/203 [2m0:04:18 â€¢ 0:10:28[0m [2;4m0.20it/s[0m  
[2KAttention weights: tensor([[0.8039, 0.1961]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 75/203 [2m0:04:18 â€¢ 0:10:28[0m [2;4m0.20it/s[0m  
[2KAttention weights: tensor([[0.8433, 0.1567]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 75/203 [2m0:04:18 â€¢ 0:10:28[0m [2;4m0.20it/s[0m  
[2KAttention weights: tensor([[0.8962, 0.1038]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 75/203 [2m0:04:18 â€¢ 0:10:28[0m [2;4m0.20it/s[0m  
[2KAttention weights: tensor([[0.5688, 0.4312]], device='cuda:0')8;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 75/203 [2m0:04:18 â€¢ 0:10:28[0m [2;4m0.20it/s[0m  
[2KAttention weights: tensor([[0.9709, 0.0291],;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 75/203 [2m0:04:18 â€¢ 0:10:28[0m [2;4m0.20it/s[0m  
        [0.7626, 0.2374],
        [0.6571, 0.3429],
        [0.8143, 0.1857],
        [0.7835, 0.2165],
        [0.7613, 0.2387],
        [0.8092, 0.1908],
        [0.8829, 0.1171],
        [0.8201, 0.1799],
[2K        [0.6044, 0.3956]], device='cuda:0')2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 75/203 [2m0:04:18 â€¢ 0:10:28[0m [2;4m0.20it/s[0m  
[2KAttention weights: tensor([[0.5586, 0.4414],38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 76/203 [2m0:04:20 â€¢ 0:09:29[0m [2;4m0.22it/s[0m  
        [0.5535, 0.4465],
        [0.5560, 0.4440],
        [0.5551, 0.4449],
        [0.5536, 0.4464],
        [0.5530, 0.4470],
        [0.5542, 0.4458],
        [0.5572, 0.4428],
        [0.5576, 0.4424],
[2K        [0.5541, 0.4459]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 76/203 [2m0:04:20 â€¢ 0:09:29[0m [2;4m0.22it/s[0m  
[2KClass label: Billiardsâ”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 76/203 [2m0:04:20 â€¢ 0:09:29[0m [2;4m0.22it/s[0m  
[2KAttention weights: tensor([[0.5912, 0.4088]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 76/203 [2m0:04:20 â€¢ 0:09:29[0m [2;4m0.22it/s[0m  
[2KStep 0 - TTA Loss: 0.5996â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 76/203 [2m0:04:20 â€¢ 0:09:29[0m [2;4m0.22it/s[0m  
[2KAttention weights: tensor([[0.6747, 0.3253]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 76/203 [2m0:04:20 â€¢ 0:09:29[0m [2;4m0.22it/s[0m  
[2KAttention weights: tensor([[0.7359, 0.2641]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 76/203 [2m0:04:20 â€¢ 0:09:29[0m [2;4m0.22it/s[0m  
[2KAttention weights: tensor([[0.7648, 0.2352]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 76/203 [2m0:04:20 â€¢ 0:09:29[0m [2;4m0.22it/s[0m  
[2KAttention weights: tensor([[0.7687, 0.2313]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 76/203 [2m0:04:20 â€¢ 0:09:29[0m [2;4m0.22it/s[0m  
[2KAttention weights: tensor([[0.7618, 0.2382]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 76/203 [2m0:04:20 â€¢ 0:09:29[0m [2;4m0.22it/s[0m  
[2KAttention weights: tensor([[0.7579, 0.2421]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 76/203 [2m0:04:20 â€¢ 0:09:29[0m [2;4m0.22it/s[0m  
[2KAttention weights: tensor([[0.7598, 0.2402]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 76/203 [2m0:04:20 â€¢ 0:09:29[0m [2;4m0.22it/s[0m  
[2KAttention weights: tensor([[0.7641, 0.2359]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 76/203 [2m0:04:20 â€¢ 0:09:29[0m [2;4m0.22it/s[0m  
[2KAttention weights: tensor([[0.7674, 0.2326]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 76/203 [2m0:04:20 â€¢ 0:09:29[0m [2;4m0.22it/s[0m  
[2KAttention weights: tensor([[0.5580, 0.4420]], device='cuda:0')8;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 76/203 [2m0:04:20 â€¢ 0:09:29[0m [2;4m0.22it/s[0m  
[2KAttention weights: tensor([[0.9965, 0.0035],;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 76/203 [2m0:04:20 â€¢ 0:09:29[0m [2;4m0.22it/s[0m  
        [0.7687, 0.2313],
        [0.7797, 0.2203],
        [0.9200, 0.0800],
        [0.9176, 0.0824],
        [0.8736, 0.1264],
        [0.9046, 0.0954],
        [0.9540, 0.0460],
        [0.9172, 0.0828],
[2K        [0.7776, 0.2224]], device='cuda:0')2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 76/203 [2m0:04:20 â€¢ 0:09:29[0m [2;4m0.22it/s[0m  
[2KAttention weights: tensor([[0.5588, 0.4412],[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 77/203 [2m0:04:24 â€¢ 0:09:01[0m [2;4m0.23it/s[0m   
        [0.5535, 0.4465],
        [0.5561, 0.4439],
        [0.5553, 0.4447],
        [0.5537, 0.4463],
        [0.5531, 0.4469],
        [0.5543, 0.4457],
        [0.5573, 0.4427],
        [0.5577, 0.4423],
[2K        [0.5542, 0.4458]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 77/203 [2m0:04:24 â€¢ 0:09:01[0m [2;4m0.23it/s[0m  
[2KClass label: SoccerPenaltyâ”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 77/203 [2m0:04:24 â€¢ 0:09:01[0m [2;4m0.23it/s[0m  
[2KAttention weights: tensor([[0.6407, 0.3593]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 77/203 [2m0:04:24 â€¢ 0:09:01[0m [2;4m0.23it/s[0m  
[2KStep 0 - TTA Loss: 0.6554â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 77/203 [2m0:04:24 â€¢ 0:09:01[0m [2;4m0.23it/s[0m  
[2KAttention weights: tensor([[0.6407, 0.3593]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 77/203 [2m0:04:24 â€¢ 0:09:01[0m [2;4m0.23it/s[0m  
[2KAttention weights: tensor([[0.6429, 0.3571]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 77/203 [2m0:04:24 â€¢ 0:09:01[0m [2;4m0.23it/s[0m  
[2KAttention weights: tensor([[0.6524, 0.3476]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 77/203 [2m0:04:24 â€¢ 0:09:01[0m [2;4m0.23it/s[0m  
[2KAttention weights: tensor([[0.6736, 0.3264]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 77/203 [2m0:04:24 â€¢ 0:09:01[0m [2;4m0.23it/s[0m  
[2KAttention weights: tensor([[0.7094, 0.2906]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 77/203 [2m0:04:24 â€¢ 0:09:01[0m [2;4m0.23it/s[0m  
[2KAttention weights: tensor([[0.7554, 0.2446]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 77/203 [2m0:04:24 â€¢ 0:09:01[0m [2;4m0.23it/s[0m  
[2KAttention weights: tensor([[0.7980, 0.2020]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 77/203 [2m0:04:24 â€¢ 0:09:01[0m [2;4m0.23it/s[0m  
[2KAttention weights: tensor([[0.8301, 0.1699]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 77/203 [2m0:04:24 â€¢ 0:09:01[0m [2;4m0.23it/s[0m  
[2KAttention weights: tensor([[0.8653, 0.1347]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 77/203 [2m0:04:24 â€¢ 0:09:01[0m [2;4m0.23it/s[0m  
[2KAttention weights: tensor([[0.5647, 0.4353]], device='cuda:0')237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 77/203 [2m0:04:24 â€¢ 0:09:01[0m [2;4m0.23it/s[0m  
[2KAttention weights: tensor([[0.9075, 0.0925],5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 77/203 [2m0:04:24 â€¢ 0:09:01[0m [2;4m0.23it/s[0m  
        [0.8076, 0.1924],
        [0.7313, 0.2687],
        [0.8144, 0.1856],
        [0.7908, 0.2092],
        [0.7983, 0.2017],
        [0.7997, 0.2003],
        [0.9166, 0.0834],
        [0.8392, 0.1608],
[2K        [0.7352, 0.2648]], device='cuda:0');5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 77/203 [2m0:04:24 â€¢ 0:09:01[0m [2;4m0.23it/s[0m  
[2KAttention weights: tensor([[0.5588, 0.4412],[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 78/203 [2m0:04:26 â€¢ 0:08:15[0m [2;4m0.25it/s[0m  
        [0.5535, 0.4465],
        [0.5560, 0.4440],
        [0.5553, 0.4447],
        [0.5537, 0.4463],
        [0.5531, 0.4469],
        [0.5543, 0.4457],
        [0.5572, 0.4428],
        [0.5577, 0.4423],
[2K        [0.5542, 0.4458]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 78/203 [2m0:04:26 â€¢ 0:08:15[0m [2;4m0.25it/s[0m  
[2KClass label: PoleVaultâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 78/203 [2m0:04:26 â€¢ 0:08:15[0m [2;4m0.25it/s[0m  
[2KAttention weights: tensor([[0.6121, 0.3879]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 78/203 [2m0:04:26 â€¢ 0:08:15[0m [2;4m0.25it/s[0m  
[2KStep 0 - TTA Loss: 0.6741â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 78/203 [2m0:04:26 â€¢ 0:08:15[0m [2;4m0.25it/s[0m  
[2KAttention weights: tensor([[0.6739, 0.3261]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 78/203 [2m0:04:26 â€¢ 0:08:15[0m [2;4m0.25it/s[0m  
[2KAttention weights: tensor([[0.7330, 0.2670]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 78/203 [2m0:04:26 â€¢ 0:08:15[0m [2;4m0.25it/s[0m  
[2KAttention weights: tensor([[0.7838, 0.2162]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 78/203 [2m0:04:26 â€¢ 0:08:15[0m [2;4m0.25it/s[0m  
[2KAttention weights: tensor([[0.8213, 0.1787]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 78/203 [2m0:04:26 â€¢ 0:08:15[0m [2;4m0.25it/s[0m  
[2KAttention weights: tensor([[0.8454, 0.1546]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 78/203 [2m0:04:26 â€¢ 0:08:15[0m [2;4m0.25it/s[0m  
[2KAttention weights: tensor([[0.8601, 0.1399]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 78/203 [2m0:04:26 â€¢ 0:08:15[0m [2;4m0.25it/s[0m  
[2KAttention weights: tensor([[0.8683, 0.1317]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 78/203 [2m0:04:26 â€¢ 0:08:15[0m [2;4m0.25it/s[0m  
[2KAttention weights: tensor([[0.8722, 0.1278]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 78/203 [2m0:04:26 â€¢ 0:08:15[0m [2;4m0.25it/s[0m  
[2KAttention weights: tensor([[0.8739, 0.1261]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 78/203 [2m0:04:26 â€¢ 0:08:15[0m [2;4m0.25it/s[0m  
[2KAttention weights: tensor([[0.5637, 0.4363]], device='cuda:0')237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 78/203 [2m0:04:26 â€¢ 0:08:15[0m [2;4m0.25it/s[0m  
[2KAttention weights: tensor([[0.9221, 0.0779],5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 78/203 [2m0:04:26 â€¢ 0:08:15[0m [2;4m0.25it/s[0m  
        [0.8348, 0.1652],
        [0.7870, 0.2130],
        [0.8542, 0.1458],
        [0.8547, 0.1453],
        [0.8668, 0.1332],
        [0.8744, 0.1256],
        [0.9530, 0.0470],
        [0.8748, 0.1252],
[2K        [0.7978, 0.2022]], device='cuda:0');5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 78/203 [2m0:04:26 â€¢ 0:08:15[0m [2;4m0.25it/s[0m  
[2KAttention weights: tensor([[0.5589, 0.4411],[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 79/203 [2m0:04:37 â€¢ 0:07:39[0m [2;4m0.27it/s[0m  
        [0.5535, 0.4465],
        [0.5560, 0.4440],
        [0.5553, 0.4447],
        [0.5537, 0.4463],
        [0.5531, 0.4469],
        [0.5543, 0.4457],
        [0.5572, 0.4428],
        [0.5577, 0.4423],
[2K        [0.5542, 0.4458]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 79/203 [2m0:04:37 â€¢ 0:07:39[0m [2;4m0.27it/s[0m  
[2KClass label: PoleVaultâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 79/203 [2m0:04:37 â€¢ 0:07:39[0m [2;4m0.27it/s[0m  
[2KAttention weights: tensor([[0.6141, 0.3859]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 79/203 [2m0:04:37 â€¢ 0:07:39[0m [2;4m0.27it/s[0m  
[2KStep 0 - TTA Loss: 0.5867â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 79/203 [2m0:04:37 â€¢ 0:07:39[0m [2;4m0.27it/s[0m  
[2KAttention weights: tensor([[0.6141, 0.3859]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 79/203 [2m0:04:37 â€¢ 0:07:39[0m [2;4m0.27it/s[0m  
[2KAttention weights: tensor([[0.6143, 0.3857]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 79/203 [2m0:04:37 â€¢ 0:07:39[0m [2;4m0.27it/s[0m  
[2KAttention weights: tensor([[0.6140, 0.3860]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 79/203 [2m0:04:37 â€¢ 0:07:39[0m [2;4m0.27it/s[0m  
[2KAttention weights: tensor([[0.6116, 0.3884]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 79/203 [2m0:04:37 â€¢ 0:07:39[0m [2;4m0.27it/s[0m  
[2KAttention weights: tensor([[0.6050, 0.3950]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 79/203 [2m0:04:37 â€¢ 0:07:39[0m [2;4m0.27it/s[0m  
[2KAttention weights: tensor([[0.5910, 0.4090]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 79/203 [2m0:04:37 â€¢ 0:07:39[0m [2;4m0.27it/s[0m  
[2KAttention weights: tensor([[0.5665, 0.4335]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 79/203 [2m0:04:37 â€¢ 0:07:39[0m [2;4m0.27it/s[0m  
[2KAttention weights: tensor([[0.5359, 0.4641]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 79/203 [2m0:04:37 â€¢ 0:07:39[0m [2;4m0.27it/s[0m  
[2KAttention weights: tensor([[0.5078, 0.4922]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 79/203 [2m0:04:37 â€¢ 0:07:39[0m [2;4m0.27it/s[0m  
[2KAttention weights: tensor([[0.5509, 0.4491]], device='cuda:0')38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 79/203 [2m0:04:37 â€¢ 0:07:39[0m [2;4m0.27it/s[0m  
[2KAttention weights: tensor([[0.6179, 0.3821],2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 79/203 [2m0:04:37 â€¢ 0:07:39[0m [2;4m0.27it/s[0m  
        [0.5818, 0.4182],
        [0.5577, 0.4423],
        [0.5749, 0.4251],
        [0.4759, 0.5241],
        [0.5134, 0.4866],
        [0.4972, 0.5028],
        [0.6261, 0.3739],
        [0.6304, 0.3696],
[2K        [0.5420, 0.4580]], device='cuda:0');2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 79/203 [2m0:04:37 â€¢ 0:07:39[0m [2;4m0.27it/s[0m  
[2KAttention weights: tensor([[0.5588, 0.4412],[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 80/203 [2m0:04:40 â€¢ 0:07:32[0m [2;4m0.27it/s[0m  
        [0.5535, 0.4465],
        [0.5560, 0.4440],
        [0.5552, 0.4448],
        [0.5536, 0.4464],
        [0.5530, 0.4470],
        [0.5541, 0.4459],
        [0.5572, 0.4428],
        [0.5577, 0.4423],
[2K        [0.5541, 0.4459]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 80/203 [2m0:04:40 â€¢ 0:07:32[0m [2;4m0.27it/s[0m  
[2KClass label: BaseballPitchâ”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 80/203 [2m0:04:40 â€¢ 0:07:32[0m [2;4m0.27it/s[0m  
[2KAttention weights: tensor([[0.6434, 0.3566]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 80/203 [2m0:04:40 â€¢ 0:07:32[0m [2;4m0.27it/s[0m  
[2KStep 0 - TTA Loss: 1.0929â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 80/203 [2m0:04:40 â€¢ 0:07:32[0m [2;4m0.27it/s[0m  
[2KAttention weights: tensor([[0.6693, 0.3307]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 80/203 [2m0:04:40 â€¢ 0:07:32[0m [2;4m0.27it/s[0m  
[2KAttention weights: tensor([[0.6926, 0.3074]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 80/203 [2m0:04:40 â€¢ 0:07:32[0m [2;4m0.27it/s[0m  
[2KAttention weights: tensor([[0.7290, 0.2710]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 80/203 [2m0:04:40 â€¢ 0:07:32[0m [2;4m0.27it/s[0m  
[2KAttention weights: tensor([[0.7617, 0.2383]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 80/203 [2m0:04:40 â€¢ 0:07:32[0m [2;4m0.27it/s[0m  
[2KAttention weights: tensor([[0.7868, 0.2132]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 80/203 [2m0:04:40 â€¢ 0:07:32[0m [2;4m0.27it/s[0m  
[2KAttention weights: tensor([[0.8042, 0.1958]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 80/203 [2m0:04:40 â€¢ 0:07:32[0m [2;4m0.27it/s[0m  
[2KAttention weights: tensor([[0.8115, 0.1885]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 80/203 [2m0:04:40 â€¢ 0:07:32[0m [2;4m0.27it/s[0m  
[2KAttention weights: tensor([[0.8125, 0.1875]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 80/203 [2m0:04:40 â€¢ 0:07:32[0m [2;4m0.27it/s[0m  
[2KAttention weights: tensor([[0.8113, 0.1887]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 80/203 [2m0:04:40 â€¢ 0:07:32[0m [2;4m0.27it/s[0m  
[2KAttention weights: tensor([[0.5635, 0.4365]], device='cuda:0')38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 80/203 [2m0:04:40 â€¢ 0:07:32[0m [2;4m0.27it/s[0m  
[2KAttention weights: tensor([[0.5588, 0.4412],[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 81/203 [2m0:04:41 â€¢ 0:06:49[0m [2;4m0.30it/s[0m  
        [0.5534, 0.4466],
        [0.5559, 0.4441],
        [0.5552, 0.4448],
        [0.5535, 0.4465],
        [0.5529, 0.4471],
        [0.5541, 0.4459],
        [0.5571, 0.4429],
        [0.5576, 0.4424],
[2K        [0.5541, 0.4459]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 81/203 [2m0:04:41 â€¢ 0:06:49[0m [2;4m0.30it/s[0m  
[2KClass label: TennisSwingâ”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 81/203 [2m0:04:41 â€¢ 0:06:49[0m [2;4m0.30it/s[0m  
[2KAttention weights: tensor([[0.6647, 0.3353]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 81/203 [2m0:04:41 â€¢ 0:06:49[0m [2;4m0.30it/s[0m  
[2KStep 0 - TTA Loss: 0.8008â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 81/203 [2m0:04:41 â€¢ 0:06:49[0m [2;4m0.30it/s[0m  
[2KAttention weights: tensor([[0.6647, 0.3353]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 81/203 [2m0:04:41 â€¢ 0:06:49[0m [2;4m0.30it/s[0m  
[2KAttention weights: tensor([[0.6641, 0.3359]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 81/203 [2m0:04:41 â€¢ 0:06:49[0m [2;4m0.30it/s[0m  
[2KAttention weights: tensor([[0.6618, 0.3382]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 81/203 [2m0:04:41 â€¢ 0:06:49[0m [2;4m0.30it/s[0m  
[2KAttention weights: tensor([[0.6565, 0.3435]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 81/203 [2m0:04:41 â€¢ 0:06:49[0m [2;4m0.30it/s[0m  
[2KAttention weights: tensor([[0.6483, 0.3517]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 81/203 [2m0:04:41 â€¢ 0:06:49[0m [2;4m0.30it/s[0m  
[2KAttention weights: tensor([[0.6365, 0.3635]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 81/203 [2m0:04:41 â€¢ 0:06:49[0m [2;4m0.30it/s[0m  
[2KAttention weights: tensor([[0.6211, 0.3789]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 81/203 [2m0:04:41 â€¢ 0:06:49[0m [2;4m0.30it/s[0m  
[2KAttention weights: tensor([[0.6011, 0.3989]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 81/203 [2m0:04:41 â€¢ 0:06:49[0m [2;4m0.30it/s[0m  
[2KAttention weights: tensor([[0.5777, 0.4223]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 81/203 [2m0:04:41 â€¢ 0:06:49[0m [2;4m0.30it/s[0m  
[2KAttention weights: tensor([[0.5533, 0.4467]], device='cuda:0')38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 81/203 [2m0:04:41 â€¢ 0:06:49[0m [2;4m0.30it/s[0m  
[2KAttention weights: tensor([[0.4855, 0.5145],2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 81/203 [2m0:04:41 â€¢ 0:06:49[0m [2;4m0.30it/s[0m  
        [0.5312, 0.4688],
        [0.5623, 0.4377],
        [0.5109, 0.4891],
        [0.4428, 0.5572],
        [0.5193, 0.4807],
        [0.5372, 0.4628],
        [0.5418, 0.4582],
        [0.5504, 0.4496],
[2K        [0.5440, 0.4560]], device='cuda:0');2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 81/203 [2m0:04:41 â€¢ 0:06:49[0m [2;4m0.30it/s[0m  
[2KAttention weights: tensor([[0.5587, 0.4413],[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 82/203 [2m0:04:42 â€¢ 0:06:15[0m [2;4m0.32it/s[0m   
        [0.5534, 0.4466],
        [0.5559, 0.4441],
        [0.5551, 0.4449],
        [0.5535, 0.4465],
        [0.5529, 0.4471],
        [0.5540, 0.4460],
        [0.5571, 0.4429],
        [0.5575, 0.4425],
[2K        [0.5540, 0.4460]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 82/203 [2m0:04:42 â€¢ 0:06:15[0m [2;4m0.32it/s[0m  
[2KClass label: SoccerPenaltyâ”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 82/203 [2m0:04:42 â€¢ 0:06:15[0m [2;4m0.32it/s[0m  
[2KAttention weights: tensor([[0.6380, 0.3620]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 82/203 [2m0:04:42 â€¢ 0:06:15[0m [2;4m0.32it/s[0m  
[2KStep 0 - TTA Loss: 0.9079â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 82/203 [2m0:04:42 â€¢ 0:06:15[0m [2;4m0.32it/s[0m  
[2KAttention weights: tensor([[0.6235, 0.3765]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 82/203 [2m0:04:42 â€¢ 0:06:15[0m [2;4m0.32it/s[0m  
[2KAttention weights: tensor([[0.6150, 0.3850]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 82/203 [2m0:04:42 â€¢ 0:06:15[0m [2;4m0.32it/s[0m  
[2KAttention weights: tensor([[0.6086, 0.3914]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 82/203 [2m0:04:42 â€¢ 0:06:15[0m [2;4m0.32it/s[0m  
[2KAttention weights: tensor([[0.6050, 0.3950]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 82/203 [2m0:04:42 â€¢ 0:06:15[0m [2;4m0.32it/s[0m  
[2KAttention weights: tensor([[0.6008, 0.3992]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 82/203 [2m0:04:42 â€¢ 0:06:15[0m [2;4m0.32it/s[0m  
[2KAttention weights: tensor([[0.5986, 0.4014]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 82/203 [2m0:04:42 â€¢ 0:06:15[0m [2;4m0.32it/s[0m  
[2KAttention weights: tensor([[0.5961, 0.4039]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 82/203 [2m0:04:42 â€¢ 0:06:15[0m [2;4m0.32it/s[0m  
[2KAttention weights: tensor([[0.5947, 0.4053]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 82/203 [2m0:04:42 â€¢ 0:06:15[0m [2;4m0.32it/s[0m  
[2KAttention weights: tensor([[0.5941, 0.4059]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 82/203 [2m0:04:42 â€¢ 0:06:15[0m [2;4m0.32it/s[0m  
[2KAttention weights: tensor([[0.5554, 0.4446]], device='cuda:0');237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 82/203 [2m0:04:42 â€¢ 0:06:15[0m [2;4m0.32it/s[0m  
[2KAttention weights: tensor([[0.5472, 0.4528],;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 82/203 [2m0:04:42 â€¢ 0:06:15[0m [2;4m0.32it/s[0m  
        [0.5528, 0.4472],
        [0.5776, 0.4224],
        [0.5427, 0.4573],
        [0.4795, 0.5205],
        [0.5451, 0.4549],
        [0.5646, 0.4354],
        [0.5939, 0.4061],
        [0.5721, 0.4279],
[2K        [0.5622, 0.4378]], device='cuda:0')8;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 82/203 [2m0:04:42 â€¢ 0:06:15[0m [2;4m0.32it/s[0m  
[2KAttention weights: tensor([[0.5586, 0.4414],[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 83/203 [2m0:04:44 â€¢ 0:05:51[0m [2;4m0.34it/s[0m  
        [0.5533, 0.4467],
        [0.5558, 0.4442],
        [0.5551, 0.4449],
        [0.5534, 0.4466],
        [0.5528, 0.4472],
        [0.5539, 0.4461],
        [0.5570, 0.4430],
        [0.5575, 0.4425],
[2K        [0.5540, 0.4460]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 83/203 [2m0:04:44 â€¢ 0:05:51[0m [2;4m0.34it/s[0m  
[2KClass label: PoleVaultâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 83/203 [2m0:04:44 â€¢ 0:05:51[0m [2;4m0.34it/s[0m  
[2KAttention weights: tensor([[0.6093, 0.3907]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 83/203 [2m0:04:44 â€¢ 0:05:51[0m [2;4m0.34it/s[0m  
[2KStep 0 - TTA Loss: 0.6076â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 83/203 [2m0:04:44 â€¢ 0:05:51[0m [2;4m0.34it/s[0m  
[2KAttention weights: tensor([[0.6093, 0.3907]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 83/203 [2m0:04:44 â€¢ 0:05:51[0m [2;4m0.34it/s[0m  
[2KAttention weights: tensor([[0.6100, 0.3900]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 83/203 [2m0:04:44 â€¢ 0:05:51[0m [2;4m0.34it/s[0m  
[2KAttention weights: tensor([[0.6134, 0.3866]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 83/203 [2m0:04:44 â€¢ 0:05:51[0m [2;4m0.34it/s[0m  
[2KAttention weights: tensor([[0.6231, 0.3769]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 83/203 [2m0:04:44 â€¢ 0:05:51[0m [2;4m0.34it/s[0m  
[2KAttention weights: tensor([[0.6423, 0.3577]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 83/203 [2m0:04:44 â€¢ 0:05:51[0m [2;4m0.34it/s[0m  
[2KAttention weights: tensor([[0.6741, 0.3259]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 83/203 [2m0:04:44 â€¢ 0:05:51[0m [2;4m0.34it/s[0m  
[2KAttention weights: tensor([[0.7193, 0.2807]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 83/203 [2m0:04:44 â€¢ 0:05:51[0m [2;4m0.34it/s[0m  
[2KAttention weights: tensor([[0.7696, 0.2304]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 83/203 [2m0:04:44 â€¢ 0:05:51[0m [2;4m0.34it/s[0m  
[2KAttention weights: tensor([[0.8141, 0.1859]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 83/203 [2m0:04:44 â€¢ 0:05:51[0m [2;4m0.34it/s[0m  
[2KAttention weights: tensor([[0.5609, 0.4391]], device='cuda:0');237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 83/203 [2m0:04:44 â€¢ 0:05:51[0m [2;4m0.34it/s[0m  
[2KAttention weights: tensor([[0.7876, 0.2124],;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 83/203 [2m0:04:44 â€¢ 0:05:51[0m [2;4m0.34it/s[0m  
        [0.6991, 0.3009],
        [0.7629, 0.2371],
        [0.7394, 0.2606],
        [0.7408, 0.2592],
        [0.8100, 0.1900],
        [0.8486, 0.1514],
        [0.7984, 0.2016],
        [0.7776, 0.2224],
[2K        [0.7730, 0.2270]], device='cuda:0')8;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 83/203 [2m0:04:44 â€¢ 0:05:51[0m [2;4m0.34it/s[0m  
[2KAttention weights: tensor([[0.5586, 0.4414],[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 84/203 [2m0:04:46 â€¢ 0:05:55[0m [2;4m0.34it/s[0m  
        [0.5534, 0.4466],
        [0.5559, 0.4441],
        [0.5551, 0.4449],
        [0.5534, 0.4466],
        [0.5528, 0.4472],
        [0.5540, 0.4460],
        [0.5570, 0.4430],
        [0.5575, 0.4425],
[2K        [0.5540, 0.4460]], device='cuda:0', grad_fn=<SoftmaxBackward0>)mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 84/203 [2m0:04:46 â€¢ 0:05:55[0m [2;4m0.34it/s[0m  
[2KClass label: PoleVaultâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 84/203 [2m0:04:46 â€¢ 0:05:55[0m [2;4m0.34it/s[0m  
[2KAttention weights: tensor([[0.6105, 0.3895]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 84/203 [2m0:04:46 â€¢ 0:05:55[0m [2;4m0.34it/s[0m  
[2KStep 0 - TTA Loss: 0.6762â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 84/203 [2m0:04:46 â€¢ 0:05:55[0m [2;4m0.34it/s[0m  
[2KAttention weights: tensor([[0.6698, 0.3302]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 84/203 [2m0:04:46 â€¢ 0:05:55[0m [2;4m0.34it/s[0m  
[2KAttention weights: tensor([[0.7240, 0.2760]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 84/203 [2m0:04:46 â€¢ 0:05:55[0m [2;4m0.34it/s[0m  
[2KAttention weights: tensor([[0.7689, 0.2311]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 84/203 [2m0:04:46 â€¢ 0:05:55[0m [2;4m0.34it/s[0m  
[2KAttention weights: tensor([[0.8005, 0.1995]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 84/203 [2m0:04:46 â€¢ 0:05:55[0m [2;4m0.34it/s[0m  
[2KAttention weights: tensor([[0.8194, 0.1806]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 84/203 [2m0:04:46 â€¢ 0:05:55[0m [2;4m0.34it/s[0m  
[2KAttention weights: tensor([[0.8296, 0.1704]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 84/203 [2m0:04:46 â€¢ 0:05:55[0m [2;4m0.34it/s[0m  
[2KAttention weights: tensor([[0.8335, 0.1665]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 84/203 [2m0:04:46 â€¢ 0:05:55[0m [2;4m0.34it/s[0m  
[2KAttention weights: tensor([[0.8346, 0.1654]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 84/203 [2m0:04:46 â€¢ 0:05:55[0m [2;4m0.34it/s[0m  
[2KAttention weights: tensor([[0.8348, 0.1652]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 84/203 [2m0:04:46 â€¢ 0:05:55[0m [2;4m0.34it/s[0m  
[2KAttention weights: tensor([[0.5598, 0.4402]], device='cuda:0')[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 84/203 [2m0:04:46 â€¢ 0:05:55[0m [2;4m0.34it/s[0m  
[2KAttention weights: tensor([[0.7798, 0.2202],;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 84/203 [2m0:04:46 â€¢ 0:05:55[0m [2;4m0.34it/s[0m  
        [0.6950, 0.3050],
        [0.7516, 0.2484],
        [0.7337, 0.2663],
        [0.7291, 0.2709],
        [0.7964, 0.2036],
        [0.8349, 0.1651],
        [0.7900, 0.2100],
        [0.7731, 0.2269],
[2K        [0.7628, 0.2372]], device='cuda:0')8;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 84/203 [2m0:04:46 â€¢ 0:05:55[0m [2;4m0.34it/s[0m  
[2KAttention weights: tensor([[0.5585, 0.4415],[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 85/203 [2m0:04:50 â€¢ 0:06:32[0m [2;4m0.30it/s[0m  
        [0.5533, 0.4467],
        [0.5558, 0.4442],
        [0.5550, 0.4450],
        [0.5534, 0.4466],
        [0.5528, 0.4472],
        [0.5539, 0.4461],
        [0.5570, 0.4430],
        [0.5575, 0.4425],
[2K        [0.5539, 0.4461]], device='cuda:0', grad_fn=<SoftmaxBackward0>)mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 85/203 [2m0:04:50 â€¢ 0:06:32[0m [2;4m0.30it/s[0m  
[2KClass label: TennisSwingâ”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 85/203 [2m0:04:50 â€¢ 0:06:32[0m [2;4m0.30it/s[0m  
[2KAttention weights: tensor([[0.6600, 0.3400]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 85/203 [2m0:04:50 â€¢ 0:06:32[0m [2;4m0.30it/s[0m  
[2KStep 0 - TTA Loss: 0.4701â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 85/203 [2m0:04:50 â€¢ 0:06:32[0m [2;4m0.30it/s[0m  
[2KAttention weights: tensor([[0.6600, 0.3400]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 85/203 [2m0:04:50 â€¢ 0:06:32[0m [2;4m0.30it/s[0m  
[2KAttention weights: tensor([[0.6604, 0.3396]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 85/203 [2m0:04:50 â€¢ 0:06:32[0m [2;4m0.30it/s[0m  
[2KAttention weights: tensor([[0.6627, 0.3373]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 85/203 [2m0:04:50 â€¢ 0:06:32[0m [2;4m0.30it/s[0m  
[2KAttention weights: tensor([[0.6672, 0.3328]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 85/203 [2m0:04:50 â€¢ 0:06:32[0m [2;4m0.30it/s[0m  
[2KAttention weights: tensor([[0.6764, 0.3236]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 85/203 [2m0:04:50 â€¢ 0:06:32[0m [2;4m0.30it/s[0m  
[2KAttention weights: tensor([[0.6886, 0.3114]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 85/203 [2m0:04:50 â€¢ 0:06:32[0m [2;4m0.30it/s[0m  
[2KAttention weights: tensor([[0.7001, 0.2999]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 85/203 [2m0:04:50 â€¢ 0:06:32[0m [2;4m0.30it/s[0m  
[2KAttention weights: tensor([[0.7034, 0.2966]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 85/203 [2m0:04:50 â€¢ 0:06:32[0m [2;4m0.30it/s[0m  
[2KAttention weights: tensor([[0.6993, 0.3007]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 85/203 [2m0:04:50 â€¢ 0:06:32[0m [2;4m0.30it/s[0m  
[2KAttention weights: tensor([[0.5564, 0.4436]], device='cuda:0')[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 85/203 [2m0:04:50 â€¢ 0:06:32[0m [2;4m0.30it/s[0m  
[2KAttention weights: tensor([[0.6573, 0.3427],;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 85/203 [2m0:04:50 â€¢ 0:06:32[0m [2;4m0.30it/s[0m  
        [0.6005, 0.3995],
        [0.6318, 0.3682],
        [0.6173, 0.3827],
        [0.5509, 0.4491],
        [0.6144, 0.3856],
        [0.6238, 0.3762],
        [0.6449, 0.3551],
        [0.6823, 0.3177],
[2K        [0.6277, 0.3723]], device='cuda:0')8;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 85/203 [2m0:04:50 â€¢ 0:06:32[0m [2;4m0.30it/s[0m  
[2KAttention weights: tensor([[0.5585, 0.4415],[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 86/203 [2m0:04:55 â€¢ 0:07:02[0m [2;4m0.28it/s[0m  
        [0.5533, 0.4467],
        [0.5558, 0.4442],
        [0.5551, 0.4449],
        [0.5534, 0.4466],
        [0.5528, 0.4472],
        [0.5539, 0.4461],
        [0.5570, 0.4430],
        [0.5575, 0.4425],
[2K        [0.5539, 0.4461]], device='cuda:0', grad_fn=<SoftmaxBackward0>)mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 86/203 [2m0:04:55 â€¢ 0:07:02[0m [2;4m0.28it/s[0m  
[2KClass label: HammerThrowâ”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 86/203 [2m0:04:55 â€¢ 0:07:02[0m [2;4m0.28it/s[0m  
[2KAttention weights: tensor([[0.5370, 0.4630]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 86/203 [2m0:04:55 â€¢ 0:07:02[0m [2;4m0.28it/s[0m  
[2KStep 0 - TTA Loss: 0.6776â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 86/203 [2m0:04:55 â€¢ 0:07:02[0m [2;4m0.28it/s[0m  
[2KAttention weights: tensor([[0.5633, 0.4367]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 86/203 [2m0:04:55 â€¢ 0:07:02[0m [2;4m0.28it/s[0m  
[2KAttention weights: tensor([[0.6154, 0.3846]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 86/203 [2m0:04:55 â€¢ 0:07:02[0m [2;4m0.28it/s[0m  
[2KAttention weights: tensor([[0.6713, 0.3287]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 86/203 [2m0:04:55 â€¢ 0:07:02[0m [2;4m0.28it/s[0m  
[2KAttention weights: tensor([[0.7148, 0.2852]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 86/203 [2m0:04:55 â€¢ 0:07:02[0m [2;4m0.28it/s[0m  
[2KAttention weights: tensor([[0.7504, 0.2496]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 86/203 [2m0:04:55 â€¢ 0:07:02[0m [2;4m0.28it/s[0m  
[2KAttention weights: tensor([[0.7875, 0.2125]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 86/203 [2m0:04:55 â€¢ 0:07:02[0m [2;4m0.28it/s[0m  
[2KAttention weights: tensor([[0.8233, 0.1767]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 86/203 [2m0:04:55 â€¢ 0:07:02[0m [2;4m0.28it/s[0m  
[2KAttention weights: tensor([[0.8477, 0.1523]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 86/203 [2m0:04:55 â€¢ 0:07:02[0m [2;4m0.28it/s[0m  
[2KAttention weights: tensor([[0.8597, 0.1403]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 86/203 [2m0:04:55 â€¢ 0:07:02[0m [2;4m0.28it/s[0m  
[2KAttention weights: tensor([[0.5634, 0.4366]], device='cuda:0')[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 86/203 [2m0:04:55 â€¢ 0:07:02[0m [2;4m0.28it/s[0m  
[2KAttention weights: tensor([[0.7930, 0.2070],;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 86/203 [2m0:04:55 â€¢ 0:07:02[0m [2;4m0.28it/s[0m  
        [0.6832, 0.3168],
        [0.7507, 0.2493],
        [0.7219, 0.2781],
        [0.8629, 0.1371],
        [0.7689, 0.2311],
        [0.7589, 0.2411],
        [0.7990, 0.2010],
        [0.7510, 0.2490],
[2K        [0.7785, 0.2215]], device='cuda:0')8;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 86/203 [2m0:04:55 â€¢ 0:07:02[0m [2;4m0.28it/s[0m  
[2KAttention weights: tensor([[0.5586, 0.4414],m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 87/203 [2m0:04:59 â€¢ 0:05:18[0m [2;4m0.37it/s[0m   
        [0.5533, 0.4467],
        [0.5559, 0.4441],
        [0.5551, 0.4449],
        [0.5534, 0.4466],
        [0.5528, 0.4472],
        [0.5539, 0.4461],
        [0.5570, 0.4430],
        [0.5575, 0.4425],
[2K        [0.5540, 0.4460]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 87/203 [2m0:04:59 â€¢ 0:05:18[0m [2;4m0.37it/s[0m  
[2KClass label: HighJumpâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 87/203 [2m0:04:59 â€¢ 0:05:18[0m [2;4m0.37it/s[0m  
[2KAttention weights: tensor([[0.6009, 0.3991]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 87/203 [2m0:04:59 â€¢ 0:05:18[0m [2;4m0.37it/s[0m  
[2KStep 0 - TTA Loss: 0.8274â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 87/203 [2m0:04:59 â€¢ 0:05:18[0m [2;4m0.37it/s[0m  
[2KAttention weights: tensor([[0.6009, 0.3991]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 87/203 [2m0:04:59 â€¢ 0:05:18[0m [2;4m0.37it/s[0m  
[2KAttention weights: tensor([[0.6049, 0.3951]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 87/203 [2m0:04:59 â€¢ 0:05:18[0m [2;4m0.37it/s[0m  
[2KAttention weights: tensor([[0.6213, 0.3787]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 87/203 [2m0:04:59 â€¢ 0:05:18[0m [2;4m0.37it/s[0m  
[2KAttention weights: tensor([[0.6579, 0.3421]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 87/203 [2m0:04:59 â€¢ 0:05:18[0m [2;4m0.37it/s[0m  
[2KAttention weights: tensor([[0.7194, 0.2806]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 87/203 [2m0:04:59 â€¢ 0:05:18[0m [2;4m0.37it/s[0m  
[2KAttention weights: tensor([[0.7963, 0.2037]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 87/203 [2m0:04:59 â€¢ 0:05:18[0m [2;4m0.37it/s[0m  
[2KAttention weights: tensor([[0.8732, 0.1268]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 87/203 [2m0:04:59 â€¢ 0:05:18[0m [2;4m0.37it/s[0m  
[2KAttention weights: tensor([[0.9310, 0.0690]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 87/203 [2m0:04:59 â€¢ 0:05:18[0m [2;4m0.37it/s[0m  
[2KAttention weights: tensor([[0.9612, 0.0388]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 87/203 [2m0:04:59 â€¢ 0:05:18[0m [2;4m0.37it/s[0m  
[2KAttention weights: tensor([[0.5687, 0.4313]], device='cuda:0')5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 87/203 [2m0:04:59 â€¢ 0:05:18[0m [2;4m0.37it/s[0m  
[2KAttention weights: tensor([[0.9371, 0.0629],8;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 87/203 [2m0:04:59 â€¢ 0:05:18[0m [2;4m0.37it/s[0m  
        [0.8647, 0.1353],
        [0.9244, 0.0756],
        [0.9096, 0.0904],
        [0.9801, 0.0199],
        [0.9790, 0.0210],
        [0.9476, 0.0524],
        [0.9557, 0.0443],
        [0.9456, 0.0544],
[2K        [0.9515, 0.0485]], device='cuda:0')38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 87/203 [2m0:04:59 â€¢ 0:05:18[0m [2;4m0.37it/s[0m  
[2KAttention weights: tensor([[0.5586, 0.4414],m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 88/203 [2m0:05:06 â€¢ 0:06:21[0m [2;4m0.30it/s[0m  
        [0.5534, 0.4466],
        [0.5559, 0.4441],
        [0.5551, 0.4449],
        [0.5535, 0.4465],
        [0.5529, 0.4471],
        [0.5540, 0.4460],
        [0.5571, 0.4429],
        [0.5576, 0.4424],
[2K        [0.5541, 0.4459]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 88/203 [2m0:05:06 â€¢ 0:06:21[0m [2;4m0.30it/s[0m  
[2KClass label: PoleVaultâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 88/203 [2m0:05:06 â€¢ 0:06:21[0m [2;4m0.30it/s[0m  
[2KAttention weights: tensor([[0.6092, 0.3908]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 88/203 [2m0:05:06 â€¢ 0:06:21[0m [2;4m0.30it/s[0m  
[2KStep 0 - TTA Loss: 0.7122â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 88/203 [2m0:05:06 â€¢ 0:06:21[0m [2;4m0.30it/s[0m  
[2KAttention weights: tensor([[0.7073, 0.2927]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 88/203 [2m0:05:06 â€¢ 0:06:21[0m [2;4m0.30it/s[0m  
[2KAttention weights: tensor([[0.7815, 0.2185]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 88/203 [2m0:05:06 â€¢ 0:06:21[0m [2;4m0.30it/s[0m  
[2KAttention weights: tensor([[0.8322, 0.1678]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 88/203 [2m0:05:06 â€¢ 0:06:21[0m [2;4m0.30it/s[0m  
[2KAttention weights: tensor([[0.8624, 0.1376]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 88/203 [2m0:05:06 â€¢ 0:06:21[0m [2;4m0.30it/s[0m  
[2KAttention weights: tensor([[0.8802, 0.1198]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 88/203 [2m0:05:06 â€¢ 0:06:21[0m [2;4m0.30it/s[0m  
[2KAttention weights: tensor([[0.8883, 0.1117]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 88/203 [2m0:05:06 â€¢ 0:06:21[0m [2;4m0.30it/s[0m  
[2KAttention weights: tensor([[0.8898, 0.1102]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 88/203 [2m0:05:06 â€¢ 0:06:21[0m [2;4m0.30it/s[0m  
[2KAttention weights: tensor([[0.8896, 0.1104]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 88/203 [2m0:05:06 â€¢ 0:06:21[0m [2;4m0.30it/s[0m  
[2KAttention weights: tensor([[0.8889, 0.1111]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 88/203 [2m0:05:06 â€¢ 0:06:21[0m [2;4m0.30it/s[0m  
[2KAttention weights: tensor([[0.5635, 0.4365]], device='cuda:0')5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 88/203 [2m0:05:06 â€¢ 0:06:21[0m [2;4m0.30it/s[0m  
[2KAttention weights: tensor([[0.8792, 0.1208],8;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 88/203 [2m0:05:06 â€¢ 0:06:21[0m [2;4m0.30it/s[0m  
        [0.7977, 0.2023],
        [0.8637, 0.1363],
        [0.8450, 0.1550],
        [0.9357, 0.0643],
        [0.9423, 0.0577],
        [0.8888, 0.1112],
        [0.9052, 0.0948],
        [0.8975, 0.1025],
[2K        [0.8974, 0.1026]], device='cuda:0')38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 88/203 [2m0:05:06 â€¢ 0:06:21[0m [2;4m0.30it/s[0m  
[2KAttention weights: tensor([[0.5587, 0.4413],m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 89/203 [2m0:05:18 â€¢ 0:13:12[0m [2;4m0.14it/s[0m  
        [0.5535, 0.4465],
        [0.5560, 0.4440],
        [0.5552, 0.4448],
        [0.5536, 0.4464],
        [0.5530, 0.4470],
        [0.5541, 0.4459],
        [0.5571, 0.4429],
        [0.5577, 0.4423],
[2K        [0.5542, 0.4458]], device='cuda:0', grad_fn=<SoftmaxBackward0>)7mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 89/203 [2m0:05:18 â€¢ 0:13:12[0m [2;4m0.14it/s[0m  
[2KClass label: PoleVaultâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 89/203 [2m0:05:18 â€¢ 0:13:12[0m [2;4m0.14it/s[0m  
[2KAttention weights: tensor([[0.6107, 0.3893]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 89/203 [2m0:05:18 â€¢ 0:13:12[0m [2;4m0.14it/s[0m  
[2KStep 0 - TTA Loss: 0.6917â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 89/203 [2m0:05:18 â€¢ 0:13:12[0m [2;4m0.14it/s[0m  
[2KAttention weights: tensor([[0.6107, 0.3893]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 89/203 [2m0:05:18 â€¢ 0:13:12[0m [2;4m0.14it/s[0m  
[2KAttention weights: tensor([[0.6105, 0.3895]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 89/203 [2m0:05:18 â€¢ 0:13:12[0m [2;4m0.14it/s[0m  
[2KAttention weights: tensor([[0.6105, 0.3895]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 89/203 [2m0:05:18 â€¢ 0:13:12[0m [2;4m0.14it/s[0m  
[2KAttention weights: tensor([[0.6117, 0.3883]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 89/203 [2m0:05:18 â€¢ 0:13:12[0m [2;4m0.14it/s[0m  
[2KAttention weights: tensor([[0.6150, 0.3850]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 89/203 [2m0:05:18 â€¢ 0:13:12[0m [2;4m0.14it/s[0m  
[2KAttention weights: tensor([[0.6244, 0.3756]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 89/203 [2m0:05:18 â€¢ 0:13:12[0m [2;4m0.14it/s[0m  
[2KAttention weights: tensor([[0.6380, 0.3620]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 89/203 [2m0:05:18 â€¢ 0:13:12[0m [2;4m0.14it/s[0m  
[2KAttention weights: tensor([[0.6642, 0.3358]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 89/203 [2m0:05:18 â€¢ 0:13:12[0m [2;4m0.14it/s[0m  
[2KAttention weights: tensor([[0.6955, 0.3045]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 89/203 [2m0:05:18 â€¢ 0:13:12[0m [2;4m0.14it/s[0m  
[2KAttention weights: tensor([[0.5574, 0.4426]], device='cuda:0')[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 89/203 [2m0:05:18 â€¢ 0:13:12[0m [2;4m0.14it/s[0m  
[2KAttention weights: tensor([[0.7310, 0.2690],8;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 89/203 [2m0:05:18 â€¢ 0:13:12[0m [2;4m0.14it/s[0m  
        [0.6571, 0.3429],
        [0.7050, 0.2950],
        [0.6834, 0.3166],
        [0.6894, 0.3106],
        [0.7376, 0.2624],
        [0.7263, 0.2737],
        [0.7350, 0.2650],
        [0.7437, 0.2563],
[2K        [0.7158, 0.2842]], device='cuda:0')38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 89/203 [2m0:05:18 â€¢ 0:13:12[0m [2;4m0.14it/s[0m  
[2KAttention weights: tensor([[0.5588, 0.4412],m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 90/203 [2m0:05:30 â€¢ 0:22:32[0m [2;4m0.08it/s[0m  
        [0.5535, 0.4465],
        [0.5560, 0.4440],
        [0.5552, 0.4448],
        [0.5537, 0.4463],
        [0.5530, 0.4470],
        [0.5541, 0.4459],
        [0.5572, 0.4428],
        [0.5577, 0.4423],
[2K        [0.5542, 0.4458]], device='cuda:0', grad_fn=<SoftmaxBackward0>)7mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 90/203 [2m0:05:30 â€¢ 0:22:32[0m [2;4m0.08it/s[0m  
[2KClass label: HammerThrowâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 90/203 [2m0:05:30 â€¢ 0:22:32[0m [2;4m0.08it/s[0m  
[2KAttention weights: tensor([[0.5363, 0.4637]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 90/203 [2m0:05:30 â€¢ 0:22:32[0m [2;4m0.08it/s[0m  
[2KStep 0 - TTA Loss: 0.8416â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 90/203 [2m0:05:30 â€¢ 0:22:32[0m [2;4m0.08it/s[0m  
[2KAttention weights: tensor([[0.5757, 0.4243]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 90/203 [2m0:05:30 â€¢ 0:22:32[0m [2;4m0.08it/s[0m  
[2KAttention weights: tensor([[0.6123, 0.3877]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 90/203 [2m0:05:30 â€¢ 0:22:32[0m [2;4m0.08it/s[0m  
[2KAttention weights: tensor([[0.6431, 0.3569]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 90/203 [2m0:05:30 â€¢ 0:22:32[0m [2;4m0.08it/s[0m  
[2KAttention weights: tensor([[0.6609, 0.3391]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 90/203 [2m0:05:30 â€¢ 0:22:32[0m [2;4m0.08it/s[0m  
[2KAttention weights: tensor([[0.6613, 0.3387]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 90/203 [2m0:05:30 â€¢ 0:22:32[0m [2;4m0.08it/s[0m  
[2KAttention weights: tensor([[0.6474, 0.3526]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 90/203 [2m0:05:30 â€¢ 0:22:32[0m [2;4m0.08it/s[0m  
[2KAttention weights: tensor([[0.6314, 0.3686]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 90/203 [2m0:05:30 â€¢ 0:22:32[0m [2;4m0.08it/s[0m  
[2KAttention weights: tensor([[0.6229, 0.3771]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 90/203 [2m0:05:30 â€¢ 0:22:32[0m [2;4m0.08it/s[0m  
[2KAttention weights: tensor([[0.6216, 0.3784]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 90/203 [2m0:05:30 â€¢ 0:22:32[0m [2;4m0.08it/s[0m  
[2KAttention weights: tensor([[0.5560, 0.4440]], device='cuda:0')[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 90/203 [2m0:05:30 â€¢ 0:22:32[0m [2;4m0.08it/s[0m  
[2KAttention weights: tensor([[0.7061, 0.2939],8;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 90/203 [2m0:05:30 â€¢ 0:22:32[0m [2;4m0.08it/s[0m  
        [0.6387, 0.3613],
        [0.6813, 0.3187],
        [0.6633, 0.3367],
        [0.6223, 0.3777],
        [0.7056, 0.2944],
        [0.7140, 0.2860],
        [0.7092, 0.2908],
        [0.7201, 0.2799],
[2K        [0.6857, 0.3143]], device='cuda:0')38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 90/203 [2m0:05:30 â€¢ 0:22:32[0m [2;4m0.08it/s[0m  
[2KAttention weights: tensor([[0.5588, 0.4412],m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 91/203 [2m0:05:33 â€¢ 0:16:31[0m [2;4m0.11it/s[0m  
        [0.5535, 0.4465],
        [0.5560, 0.4440],
        [0.5552, 0.4448],
        [0.5537, 0.4463],
        [0.5530, 0.4470],
        [0.5542, 0.4458],
        [0.5572, 0.4428],
        [0.5577, 0.4423],
[2K        [0.5542, 0.4458]], device='cuda:0', grad_fn=<SoftmaxBackward0>)7mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 91/203 [2m0:05:33 â€¢ 0:16:31[0m [2;4m0.11it/s[0m  
[2KClass label: SoccerPenaltyâ”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 91/203 [2m0:05:33 â€¢ 0:16:31[0m [2;4m0.11it/s[0m  
[2KAttention weights: tensor([[0.6367, 0.3633]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 91/203 [2m0:05:33 â€¢ 0:16:31[0m [2;4m0.11it/s[0m  
[2KStep 0 - TTA Loss: 1.2017â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 91/203 [2m0:05:33 â€¢ 0:16:31[0m [2;4m0.11it/s[0m  
[2KAttention weights: tensor([[0.6367, 0.3633]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 91/203 [2m0:05:33 â€¢ 0:16:31[0m [2;4m0.11it/s[0m  
[2KAttention weights: tensor([[0.6369, 0.3631]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 91/203 [2m0:05:33 â€¢ 0:16:31[0m [2;4m0.11it/s[0m  
[2KAttention weights: tensor([[0.6376, 0.3624]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 91/203 [2m0:05:33 â€¢ 0:16:31[0m [2;4m0.11it/s[0m  
[2KAttention weights: tensor([[0.6385, 0.3615]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 91/203 [2m0:05:33 â€¢ 0:16:31[0m [2;4m0.11it/s[0m  
[2KAttention weights: tensor([[0.6390, 0.3610]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 91/203 [2m0:05:33 â€¢ 0:16:31[0m [2;4m0.11it/s[0m  
[2KAttention weights: tensor([[0.6387, 0.3613]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 91/203 [2m0:05:33 â€¢ 0:16:31[0m [2;4m0.11it/s[0m  
[2KAttention weights: tensor([[0.6393, 0.3607]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 91/203 [2m0:05:33 â€¢ 0:16:31[0m [2;4m0.11it/s[0m  
[2KAttention weights: tensor([[0.6362, 0.3638]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 91/203 [2m0:05:33 â€¢ 0:16:31[0m [2;4m0.11it/s[0m  
[2KAttention weights: tensor([[0.6282, 0.3718]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 91/203 [2m0:05:33 â€¢ 0:16:31[0m [2;4m0.11it/s[0m  
[2KAttention weights: tensor([[0.5560, 0.4440]], device='cuda:0')[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 91/203 [2m0:05:33 â€¢ 0:16:31[0m [2;4m0.11it/s[0m  
[2KAttention weights: tensor([[0.6497, 0.3503],8;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 91/203 [2m0:05:33 â€¢ 0:16:31[0m [2;4m0.11it/s[0m  
        [0.5924, 0.4076],
        [0.6362, 0.3638],
        [0.6082, 0.3918],
        [0.5653, 0.4347],
        [0.6157, 0.3843],
        [0.6286, 0.3714],
        [0.6095, 0.3905],
        [0.6637, 0.3363],
[2K        [0.6344, 0.3656]], device='cuda:0')38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 91/203 [2m0:05:33 â€¢ 0:16:31[0m [2;4m0.11it/s[0m  
[2KAttention weights: tensor([[0.5588, 0.4412],0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 92/203 [2m0:05:34 â€¢ 0:12:40[0m [2;4m0.15it/s[0m   
        [0.5535, 0.4465],
        [0.5560, 0.4440],
        [0.5552, 0.4448],
        [0.5537, 0.4463],
        [0.5530, 0.4470],
        [0.5542, 0.4458],
        [0.5572, 0.4428],
        [0.5577, 0.4423],
[2K        [0.5542, 0.4458]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 92/203 [2m0:05:34 â€¢ 0:12:40[0m [2;4m0.15it/s[0m  
[2KClass label: BaseballPitchâ”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 92/203 [2m0:05:34 â€¢ 0:12:40[0m [2;4m0.15it/s[0m  
[2KAttention weights: tensor([[0.6446, 0.3554]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 92/203 [2m0:05:34 â€¢ 0:12:40[0m [2;4m0.15it/s[0m  
[2KStep 0 - TTA Loss: 1.0101â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 92/203 [2m0:05:34 â€¢ 0:12:40[0m [2;4m0.15it/s[0m  
[2KAttention weights: tensor([[0.6391, 0.3609]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 92/203 [2m0:05:34 â€¢ 0:12:40[0m [2;4m0.15it/s[0m  
[2KAttention weights: tensor([[0.6392, 0.3608]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 92/203 [2m0:05:34 â€¢ 0:12:40[0m [2;4m0.15it/s[0m  
[2KAttention weights: tensor([[0.6353, 0.3647]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 92/203 [2m0:05:34 â€¢ 0:12:40[0m [2;4m0.15it/s[0m  
[2KAttention weights: tensor([[0.6292, 0.3708]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 92/203 [2m0:05:34 â€¢ 0:12:40[0m [2;4m0.15it/s[0m  
[2KAttention weights: tensor([[0.6218, 0.3782]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 92/203 [2m0:05:34 â€¢ 0:12:40[0m [2;4m0.15it/s[0m  
[2KAttention weights: tensor([[0.6146, 0.3854]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 92/203 [2m0:05:34 â€¢ 0:12:40[0m [2;4m0.15it/s[0m  
[2KAttention weights: tensor([[0.6073, 0.3927]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 92/203 [2m0:05:34 â€¢ 0:12:40[0m [2;4m0.15it/s[0m  
[2KAttention weights: tensor([[0.6025, 0.3975]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 92/203 [2m0:05:34 â€¢ 0:12:40[0m [2;4m0.15it/s[0m  
[2KAttention weights: tensor([[0.5999, 0.4001]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 92/203 [2m0:05:34 â€¢ 0:12:40[0m [2;4m0.15it/s[0m  
[2KAttention weights: tensor([[0.5568, 0.4432]], device='cuda:0');5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 92/203 [2m0:05:34 â€¢ 0:12:40[0m [2;4m0.15it/s[0m  
[2KAttention weights: tensor([[0.5588, 0.4412],0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 93/203 [2m0:05:35 â€¢ 0:10:26[0m [2;4m0.18it/s[0m  
        [0.5535, 0.4465],
        [0.5560, 0.4440],
        [0.5552, 0.4448],
        [0.5537, 0.4463],
        [0.5530, 0.4470],
        [0.5542, 0.4458],
        [0.5572, 0.4428],
        [0.5577, 0.4423],
[2K        [0.5542, 0.4458]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 93/203 [2m0:05:35 â€¢ 0:10:26[0m [2;4m0.18it/s[0m  
[2KClass label: SoccerPenaltyâ”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 93/203 [2m0:05:35 â€¢ 0:10:26[0m [2;4m0.18it/s[0m  
[2KAttention weights: tensor([[0.6394, 0.3606]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 93/203 [2m0:05:35 â€¢ 0:10:26[0m [2;4m0.18it/s[0m  
[2KStep 0 - TTA Loss: 0.8277â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 93/203 [2m0:05:35 â€¢ 0:10:26[0m [2;4m0.18it/s[0m  
[2KAttention weights: tensor([[0.6394, 0.3606]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 93/203 [2m0:05:35 â€¢ 0:10:26[0m [2;4m0.18it/s[0m  
[2KAttention weights: tensor([[0.6397, 0.3603]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 93/203 [2m0:05:35 â€¢ 0:10:26[0m [2;4m0.18it/s[0m  
[2KAttention weights: tensor([[0.6422, 0.3578]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 93/203 [2m0:05:35 â€¢ 0:10:26[0m [2;4m0.18it/s[0m  
[2KAttention weights: tensor([[0.6499, 0.3501]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 93/203 [2m0:05:35 â€¢ 0:10:26[0m [2;4m0.18it/s[0m  
[2KAttention weights: tensor([[0.6660, 0.3340]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 93/203 [2m0:05:35 â€¢ 0:10:26[0m [2;4m0.18it/s[0m  
[2KAttention weights: tensor([[0.6923, 0.3077]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 93/203 [2m0:05:35 â€¢ 0:10:26[0m [2;4m0.18it/s[0m  
[2KAttention weights: tensor([[0.7246, 0.2754]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 93/203 [2m0:05:35 â€¢ 0:10:26[0m [2;4m0.18it/s[0m  
[2KAttention weights: tensor([[0.7566, 0.2434]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 93/203 [2m0:05:35 â€¢ 0:10:26[0m [2;4m0.18it/s[0m  
[2KAttention weights: tensor([[0.7814, 0.2186]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 93/203 [2m0:05:35 â€¢ 0:10:26[0m [2;4m0.18it/s[0m  
[2KAttention weights: tensor([[0.5600, 0.4400]], device='cuda:0');5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 93/203 [2m0:05:35 â€¢ 0:10:26[0m [2;4m0.18it/s[0m  
[2KAttention weights: tensor([[0.6828, 0.3172],38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 93/203 [2m0:05:35 â€¢ 0:10:26[0m [2;4m0.18it/s[0m  
        [0.6540, 0.3460],
        [0.6547, 0.3453],
        [0.6634, 0.3366],
        [0.6206, 0.3794],
        [0.6721, 0.3279],
        [0.6703, 0.3297],
        [0.7824, 0.2176],
        [0.7153, 0.2847],
[2K        [0.6515, 0.3485]], device='cuda:0')[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 93/203 [2m0:05:35 â€¢ 0:10:26[0m [2;4m0.18it/s[0m  
[2KAttention weights: tensor([[0.5588, 0.4412],0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 94/203 [2m0:05:37 â€¢ 0:07:04[0m [2;4m0.26it/s[0m  
        [0.5535, 0.4465],
        [0.5560, 0.4440],
        [0.5552, 0.4448],
        [0.5537, 0.4463],
        [0.5530, 0.4470],
        [0.5542, 0.4458],
        [0.5572, 0.4428],
        [0.5577, 0.4423],
[2K        [0.5542, 0.4458]], device='cuda:0', grad_fn=<SoftmaxBackward0>)37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 94/203 [2m0:05:37 â€¢ 0:07:04[0m [2;4m0.26it/s[0m  
[2KClass label: SoccerPenaltyâ”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 94/203 [2m0:05:37 â€¢ 0:07:04[0m [2;4m0.26it/s[0m  
[2KAttention weights: tensor([[0.6312, 0.3688]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 94/203 [2m0:05:37 â€¢ 0:07:04[0m [2;4m0.26it/s[0m  
[2KStep 0 - TTA Loss: 0.7879â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 94/203 [2m0:05:37 â€¢ 0:07:04[0m [2;4m0.26it/s[0m  
[2KAttention weights: tensor([[0.6408, 0.3592]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 94/203 [2m0:05:37 â€¢ 0:07:04[0m [2;4m0.26it/s[0m  
[2KAttention weights: tensor([[0.6433, 0.3567]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 94/203 [2m0:05:37 â€¢ 0:07:04[0m [2;4m0.26it/s[0m  
[2KAttention weights: tensor([[0.6334, 0.3666]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 94/203 [2m0:05:37 â€¢ 0:07:04[0m [2;4m0.26it/s[0m  
[2KAttention weights: tensor([[0.6068, 0.3932]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 94/203 [2m0:05:37 â€¢ 0:07:04[0m [2;4m0.26it/s[0m  
[2KAttention weights: tensor([[0.5727, 0.4273]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 94/203 [2m0:05:37 â€¢ 0:07:04[0m [2;4m0.26it/s[0m  
[2KAttention weights: tensor([[0.5557, 0.4443]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 94/203 [2m0:05:37 â€¢ 0:07:04[0m [2;4m0.26it/s[0m  
[2KAttention weights: tensor([[0.5658, 0.4342]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 94/203 [2m0:05:37 â€¢ 0:07:04[0m [2;4m0.26it/s[0m  
[2KAttention weights: tensor([[0.5833, 0.4167]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 94/203 [2m0:05:37 â€¢ 0:07:04[0m [2;4m0.26it/s[0m  
[2KAttention weights: tensor([[0.5960, 0.4040]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 94/203 [2m0:05:37 â€¢ 0:07:04[0m [2;4m0.26it/s[0m  
[2KAttention weights: tensor([[0.5551, 0.4449]], device='cuda:0')m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 94/203 [2m0:05:37 â€¢ 0:07:04[0m [2;4m0.26it/s[0m  
[2KAttention weights: tensor([[0.5960, 0.4040],38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 94/203 [2m0:05:37 â€¢ 0:07:04[0m [2;4m0.26it/s[0m  
        [0.5746, 0.4254],
        [0.6112, 0.3888],
        [0.5797, 0.4203],
        [0.5150, 0.4850],
        [0.5799, 0.4201],
        [0.5889, 0.4111],
        [0.6000, 0.4000],
        [0.6407, 0.3593],
[2K        [0.6025, 0.3975]], device='cuda:0')[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 94/203 [2m0:05:37 â€¢ 0:07:04[0m [2;4m0.26it/s[0m  
[2KAttention weights: tensor([[0.5588, 0.4412],0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 95/203 [2m0:05:39 â€¢ 0:06:33[0m [2;4m0.28it/s[0m  
        [0.5535, 0.4465],
        [0.5560, 0.4440],
        [0.5552, 0.4448],
        [0.5537, 0.4463],
        [0.5530, 0.4470],
        [0.5542, 0.4458],
        [0.5571, 0.4429],
        [0.5577, 0.4423],
[2K        [0.5542, 0.4458]], device='cuda:0', grad_fn=<SoftmaxBackward0>)37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 95/203 [2m0:05:39 â€¢ 0:06:33[0m [2;4m0.28it/s[0m  
[2KClass label: PoleVaultâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 95/203 [2m0:05:39 â€¢ 0:06:33[0m [2;4m0.28it/s[0m  
[2KAttention weights: tensor([[0.6114, 0.3886]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 95/203 [2m0:05:39 â€¢ 0:06:33[0m [2;4m0.28it/s[0m  
[2KStep 0 - TTA Loss: 0.9082â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 95/203 [2m0:05:39 â€¢ 0:06:33[0m [2;4m0.28it/s[0m  
[2KAttention weights: tensor([[0.6114, 0.3886]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 95/203 [2m0:05:39 â€¢ 0:06:33[0m [2;4m0.28it/s[0m  
[2KAttention weights: tensor([[0.6123, 0.3877]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 95/203 [2m0:05:39 â€¢ 0:06:33[0m [2;4m0.28it/s[0m  
[2KAttention weights: tensor([[0.6151, 0.3849]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 95/203 [2m0:05:39 â€¢ 0:06:33[0m [2;4m0.28it/s[0m  
[2KAttention weights: tensor([[0.6199, 0.3801]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 95/203 [2m0:05:39 â€¢ 0:06:33[0m [2;4m0.28it/s[0m  
[2KAttention weights: tensor([[0.6253, 0.3747]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 95/203 [2m0:05:39 â€¢ 0:06:33[0m [2;4m0.28it/s[0m  
[2KAttention weights: tensor([[0.6264, 0.3736]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 95/203 [2m0:05:39 â€¢ 0:06:33[0m [2;4m0.28it/s[0m  
[2KAttention weights: tensor([[0.6236, 0.3764]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 95/203 [2m0:05:39 â€¢ 0:06:33[0m [2;4m0.28it/s[0m  
[2KAttention weights: tensor([[0.6112, 0.3888]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 95/203 [2m0:05:39 â€¢ 0:06:33[0m [2;4m0.28it/s[0m  
[2KAttention weights: tensor([[0.5843, 0.4157]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 95/203 [2m0:05:39 â€¢ 0:06:33[0m [2;4m0.28it/s[0m  
[2KAttention weights: tensor([[0.5521, 0.4479]], device='cuda:0')m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 95/203 [2m0:05:39 â€¢ 0:06:33[0m [2;4m0.28it/s[0m  
[2KAttention weights: tensor([[0.6829, 0.3171],38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 95/203 [2m0:05:39 â€¢ 0:06:33[0m [2;4m0.28it/s[0m  
        [0.6432, 0.3568],
        [0.5854, 0.4146],
        [0.6450, 0.3550],
        [0.5726, 0.4274],
        [0.5887, 0.4113],
        [0.5509, 0.4491],
        [0.8014, 0.1986],
        [0.6953, 0.3047],
[2K        [0.5765, 0.4235]], device='cuda:0')[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 95/203 [2m0:05:39 â€¢ 0:06:33[0m [2;4m0.28it/s[0m  
[2KAttention weights: tensor([[0.5588, 0.4412],0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 96/203 [2m0:05:45 â€¢ 0:06:59[0m [2;4m0.26it/s[0m  
        [0.5535, 0.4465],
        [0.5560, 0.4440],
        [0.5553, 0.4447],
        [0.5537, 0.4463],
        [0.5530, 0.4470],
        [0.5541, 0.4459],
        [0.5572, 0.4428],
        [0.5577, 0.4423],
[2K        [0.5542, 0.4458]], device='cuda:0', grad_fn=<SoftmaxBackward0>)37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 96/203 [2m0:05:45 â€¢ 0:06:59[0m [2;4m0.26it/s[0m  
[2KClass label: PoleVaultâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 96/203 [2m0:05:45 â€¢ 0:06:59[0m [2;4m0.26it/s[0m  
[2KAttention weights: tensor([[0.6156, 0.3844]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 96/203 [2m0:05:45 â€¢ 0:06:59[0m [2;4m0.26it/s[0m  
[2KStep 0 - TTA Loss: 0.6313â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 96/203 [2m0:05:45 â€¢ 0:06:59[0m [2;4m0.26it/s[0m  
[2KAttention weights: tensor([[0.6020, 0.3980]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 96/203 [2m0:05:45 â€¢ 0:06:59[0m [2;4m0.26it/s[0m  
[2KAttention weights: tensor([[0.6022, 0.3978]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 96/203 [2m0:05:45 â€¢ 0:06:59[0m [2;4m0.26it/s[0m  
[2KAttention weights: tensor([[0.6131, 0.3869]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 96/203 [2m0:05:45 â€¢ 0:06:59[0m [2;4m0.26it/s[0m  
[2KAttention weights: tensor([[0.6256, 0.3744]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 96/203 [2m0:05:45 â€¢ 0:06:59[0m [2;4m0.26it/s[0m  
[2KAttention weights: tensor([[0.6404, 0.3596]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 96/203 [2m0:05:45 â€¢ 0:06:59[0m [2;4m0.26it/s[0m  
[2KAttention weights: tensor([[0.6526, 0.3474]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 96/203 [2m0:05:45 â€¢ 0:06:59[0m [2;4m0.26it/s[0m  
[2KAttention weights: tensor([[0.6583, 0.3417]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 96/203 [2m0:05:45 â€¢ 0:06:59[0m [2;4m0.26it/s[0m  
[2KAttention weights: tensor([[0.6620, 0.3380]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 96/203 [2m0:05:45 â€¢ 0:06:59[0m [2;4m0.26it/s[0m  
[2KAttention weights: tensor([[0.6639, 0.3361]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 96/203 [2m0:05:45 â€¢ 0:06:59[0m [2;4m0.26it/s[0m  
[2KAttention weights: tensor([[0.5549, 0.4451]], device='cuda:0')m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 96/203 [2m0:05:45 â€¢ 0:06:59[0m [2;4m0.26it/s[0m  
[2KAttention weights: tensor([[0.7214, 0.2786],38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 96/203 [2m0:05:45 â€¢ 0:06:59[0m [2;4m0.26it/s[0m  
        [0.6619, 0.3381],
        [0.6526, 0.3474],
        [0.6803, 0.3197],
        [0.6282, 0.3718],
        [0.6680, 0.3320],
        [0.6645, 0.3355],
        [0.7959, 0.2041],
        [0.7275, 0.2725],
[2K        [0.6523, 0.3477]], device='cuda:0')[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 96/203 [2m0:05:45 â€¢ 0:06:59[0m [2;4m0.26it/s[0m  
[2KAttention weights: tensor([[0.5588, 0.4412],[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 97/203 [2m0:05:47 â€¢ 0:06:35[0m [2;4m0.27it/s[0m   
        [0.5535, 0.4465],
        [0.5560, 0.4440],
        [0.5552, 0.4448],
        [0.5537, 0.4463],
        [0.5530, 0.4470],
        [0.5541, 0.4459],
        [0.5572, 0.4428],
        [0.5577, 0.4423],
[2K        [0.5542, 0.4458]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 97/203 [2m0:05:47 â€¢ 0:06:35[0m [2;4m0.27it/s[0m  
[2KClass label: TennisSwingâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 97/203 [2m0:05:47 â€¢ 0:06:35[0m [2;4m0.27it/s[0m  
[2KAttention weights: tensor([[0.6629, 0.3371]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 97/203 [2m0:05:47 â€¢ 0:06:35[0m [2;4m0.27it/s[0m  
[2KStep 0 - TTA Loss: 0.6008â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 97/203 [2m0:05:47 â€¢ 0:06:35[0m [2;4m0.27it/s[0m  
[2KAttention weights: tensor([[0.6629, 0.3371]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 97/203 [2m0:05:47 â€¢ 0:06:35[0m [2;4m0.27it/s[0m  
[2KAttention weights: tensor([[0.6633, 0.3367]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 97/203 [2m0:05:47 â€¢ 0:06:35[0m [2;4m0.27it/s[0m  
[2KAttention weights: tensor([[0.6649, 0.3351]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 97/203 [2m0:05:47 â€¢ 0:06:35[0m [2;4m0.27it/s[0m  
[2KAttention weights: tensor([[0.6684, 0.3316]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 97/203 [2m0:05:47 â€¢ 0:06:35[0m [2;4m0.27it/s[0m  
[2KAttention weights: tensor([[0.6741, 0.3259]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 97/203 [2m0:05:47 â€¢ 0:06:35[0m [2;4m0.27it/s[0m  
[2KAttention weights: tensor([[0.6808, 0.3192]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 97/203 [2m0:05:47 â€¢ 0:06:35[0m [2;4m0.27it/s[0m  
[2KAttention weights: tensor([[0.6895, 0.3105]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 97/203 [2m0:05:47 â€¢ 0:06:35[0m [2;4m0.27it/s[0m  
[2KAttention weights: tensor([[0.7023, 0.2977]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 97/203 [2m0:05:47 â€¢ 0:06:35[0m [2;4m0.27it/s[0m  
[2KAttention weights: tensor([[0.7244, 0.2756]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 97/203 [2m0:05:47 â€¢ 0:06:35[0m [2;4m0.27it/s[0m  
[2KAttention weights: tensor([[0.5590, 0.4410]], device='cuda:0')8;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 97/203 [2m0:05:47 â€¢ 0:06:35[0m [2;4m0.27it/s[0m  
[2KAttention weights: tensor([[0.7137, 0.2863],[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 97/203 [2m0:05:47 â€¢ 0:06:35[0m [2;4m0.27it/s[0m  
        [0.6539, 0.3461],
        [0.6794, 0.3206],
        [0.6821, 0.3179],
        [0.6229, 0.3771],
        [0.6831, 0.3169],
        [0.6858, 0.3142],
        [0.7295, 0.2705],
        [0.7630, 0.2370],
[2K        [0.6865, 0.3135]], device='cuda:0')[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 97/203 [2m0:05:47 â€¢ 0:06:35[0m [2;4m0.27it/s[0m  
[2KAttention weights: tensor([[0.5587, 0.4413],[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 98/203 [2m0:05:50 â€¢ 0:04:19[0m [2;4m0.41it/s[0m  
        [0.5535, 0.4465],
        [0.5560, 0.4440],
        [0.5552, 0.4448],
        [0.5536, 0.4464],
        [0.5530, 0.4470],
        [0.5540, 0.4460],
        [0.5572, 0.4428],
        [0.5577, 0.4423],
[2K        [0.5542, 0.4458]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 98/203 [2m0:05:50 â€¢ 0:04:19[0m [2;4m0.41it/s[0m  
[2KClass label: PoleVaultâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 98/203 [2m0:05:50 â€¢ 0:04:19[0m [2;4m0.41it/s[0m  
[2KAttention weights: tensor([[0.6096, 0.3904]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 98/203 [2m0:05:50 â€¢ 0:04:19[0m [2;4m0.41it/s[0m  
[2KStep 0 - TTA Loss: 1.0398â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 98/203 [2m0:05:50 â€¢ 0:04:19[0m [2;4m0.41it/s[0m  
[2KAttention weights: tensor([[0.6389, 0.3611]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 98/203 [2m0:05:50 â€¢ 0:04:19[0m [2;4m0.41it/s[0m  
[2KAttention weights: tensor([[0.6708, 0.3292]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 98/203 [2m0:05:50 â€¢ 0:04:19[0m [2;4m0.41it/s[0m  
[2KAttention weights: tensor([[0.6998, 0.3002]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 98/203 [2m0:05:50 â€¢ 0:04:19[0m [2;4m0.41it/s[0m  
[2KAttention weights: tensor([[0.7237, 0.2763]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 98/203 [2m0:05:50 â€¢ 0:04:19[0m [2;4m0.41it/s[0m  
[2KAttention weights: tensor([[0.7444, 0.2556]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 98/203 [2m0:05:50 â€¢ 0:04:19[0m [2;4m0.41it/s[0m  
[2KAttention weights: tensor([[0.7590, 0.2410]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 98/203 [2m0:05:50 â€¢ 0:04:19[0m [2;4m0.41it/s[0m  
[2KAttention weights: tensor([[0.7693, 0.2307]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 98/203 [2m0:05:50 â€¢ 0:04:19[0m [2;4m0.41it/s[0m  
[2KAttention weights: tensor([[0.7745, 0.2255]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 98/203 [2m0:05:50 â€¢ 0:04:19[0m [2;4m0.41it/s[0m  
[2KAttention weights: tensor([[0.7772, 0.2228]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 98/203 [2m0:05:50 â€¢ 0:04:19[0m [2;4m0.41it/s[0m  
[2KAttention weights: tensor([[0.5601, 0.4399]], device='cuda:0')8;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 98/203 [2m0:05:50 â€¢ 0:04:19[0m [2;4m0.41it/s[0m  
[2KAttention weights: tensor([[0.7811, 0.2189],[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 98/203 [2m0:05:50 â€¢ 0:04:19[0m [2;4m0.41it/s[0m  
        [0.7052, 0.2948],
        [0.7484, 0.2516],
        [0.7506, 0.2494],
        [0.7110, 0.2890],
        [0.7743, 0.2257],
        [0.7781, 0.2219],
        [0.7922, 0.2078],
        [0.8400, 0.1600],
[2K        [0.7630, 0.2370]], device='cuda:0')[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 98/203 [2m0:05:50 â€¢ 0:04:19[0m [2;4m0.41it/s[0m  
[2KAttention weights: tensor([[0.5587, 0.4413],[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 99/203 [2m0:05:51 â€¢ 0:03:58[0m [2;4m0.44it/s[0m  
        [0.5534, 0.4466],
        [0.5560, 0.4440],
        [0.5552, 0.4448],
        [0.5536, 0.4464],
        [0.5529, 0.4471],
        [0.5540, 0.4460],
        [0.5572, 0.4428],
        [0.5577, 0.4423],
[2K        [0.5541, 0.4459]], device='cuda:0', grad_fn=<SoftmaxBackward0>)237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 99/203 [2m0:05:51 â€¢ 0:03:58[0m [2;4m0.44it/s[0m  
[2KClass label: SoccerPenaltyâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 99/203 [2m0:05:51 â€¢ 0:03:58[0m [2;4m0.44it/s[0m  
[2KAttention weights: tensor([[0.6393, 0.3607]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 99/203 [2m0:05:51 â€¢ 0:03:58[0m [2;4m0.44it/s[0m  
[2KStep 0 - TTA Loss: 0.9707â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 99/203 [2m0:05:51 â€¢ 0:03:58[0m [2;4m0.44it/s[0m  
[2KAttention weights: tensor([[0.6393, 0.3607]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 99/203 [2m0:05:51 â€¢ 0:03:58[0m [2;4m0.44it/s[0m  
[2KAttention weights: tensor([[0.6423, 0.3577]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 99/203 [2m0:05:51 â€¢ 0:03:58[0m [2;4m0.44it/s[0m  
[2KAttention weights: tensor([[0.6566, 0.3434]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 99/203 [2m0:05:51 â€¢ 0:03:58[0m [2;4m0.44it/s[0m  
[2KAttention weights: tensor([[0.6935, 0.3065]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 99/203 [2m0:05:51 â€¢ 0:03:58[0m [2;4m0.44it/s[0m  
[2KAttention weights: tensor([[0.7582, 0.2418]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 99/203 [2m0:05:51 â€¢ 0:03:58[0m [2;4m0.44it/s[0m  
[2KAttention weights: tensor([[0.8436, 0.1564]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 99/203 [2m0:05:51 â€¢ 0:03:58[0m [2;4m0.44it/s[0m  
[2KAttention weights: tensor([[0.9182, 0.0818]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 99/203 [2m0:05:51 â€¢ 0:03:58[0m [2;4m0.44it/s[0m  
[2KAttention weights: tensor([[0.9623, 0.0377]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 99/203 [2m0:05:51 â€¢ 0:03:58[0m [2;4m0.44it/s[0m  
[2KAttention weights: tensor([[0.9902, 0.0098]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 99/203 [2m0:05:51 â€¢ 0:03:58[0m [2;4m0.44it/s[0m  
[2KAttention weights: tensor([[0.5843, 0.4157]], device='cuda:0')0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 99/203 [2m0:05:51 â€¢ 0:03:58[0m [2;4m0.44it/s[0m  
[2KAttention weights: tensor([[9.8569e-01, 1.4311e-02],;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 99/203 [2m0:05:51 â€¢ 0:03:58[0m [2;4m0.44it/s[0m  
        [9.5996e-01, 4.0035e-02],
        [9.0698e-01, 9.3021e-02],
        [9.7373e-01, 2.6268e-02],
        [9.8052e-01, 1.9482e-02],
        [9.7819e-01, 2.1812e-02],
        [9.7137e-01, 2.8631e-02],
        [9.9944e-01, 5.6244e-04],
        [9.7823e-01, 2.1769e-02],
[2K        [9.2224e-01, 7.7755e-02]], device='cuda:0')8;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 99/203 [2m0:05:51 â€¢ 0:03:58[0m [2;4m0.44it/s[0m  
[2KAttention weights: tensor([[0.5588, 0.4412],[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 100/203 [2m0:05:55 â€¢ 0:04:15[0m [2;4m0.40it/s[0m  
        [0.5535, 0.4465],
        [0.5560, 0.4440],
        [0.5553, 0.4447],
        [0.5537, 0.4463],
        [0.5530, 0.4470],
        [0.5540, 0.4460],
        [0.5573, 0.4427],
        [0.5577, 0.4423],
[2K        [0.5542, 0.4458]], device='cuda:0', grad_fn=<SoftmaxBackward0>)237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 100/203 [2m0:05:55 â€¢ 0:04:15[0m [2;4m0.40it/s[0m  
[2KClass label: PoleVaultâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 100/203 [2m0:05:55 â€¢ 0:04:15[0m [2;4m0.40it/s[0m  
[2KAttention weights: tensor([[0.6133, 0.3867]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 100/203 [2m0:05:55 â€¢ 0:04:15[0m [2;4m0.40it/s[0m  
[2KStep 0 - TTA Loss: 0.6616â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 100/203 [2m0:05:55 â€¢ 0:04:15[0m [2;4m0.40it/s[0m  
[2KAttention weights: tensor([[0.8312, 0.1688]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 100/203 [2m0:05:55 â€¢ 0:04:15[0m [2;4m0.40it/s[0m  
[2KAttention weights: tensor([[0.9336, 0.0664]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 100/203 [2m0:05:55 â€¢ 0:04:15[0m [2;4m0.40it/s[0m  
[2KAttention weights: tensor([[0.9795, 0.0205]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 100/203 [2m0:05:55 â€¢ 0:04:15[0m [2;4m0.40it/s[0m  
[2KAttention weights: tensor([[0.9959, 0.0041]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 100/203 [2m0:05:55 â€¢ 0:04:15[0m [2;4m0.40it/s[0m  
[2KAttention weights: tensor([[0.9971, 0.0029]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 100/203 [2m0:05:55 â€¢ 0:04:15[0m [2;4m0.40it/s[0m  
[2KAttention weights: tensor([[0.9971, 0.0029]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 100/203 [2m0:05:55 â€¢ 0:04:15[0m [2;4m0.40it/s[0m  
[2KAttention weights: tensor([[0.9960, 0.0040]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 100/203 [2m0:05:55 â€¢ 0:04:15[0m [2;4m0.40it/s[0m  
[2KAttention weights: tensor([[0.9949, 0.0051]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 100/203 [2m0:05:55 â€¢ 0:04:15[0m [2;4m0.40it/s[0m  
[2KAttention weights: tensor([[0.9940, 0.0060]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 100/203 [2m0:05:55 â€¢ 0:04:15[0m [2;4m0.40it/s[0m  
[2KAttention weights: tensor([[0.5835, 0.4165]], device='cuda:0')0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 100/203 [2m0:05:55 â€¢ 0:04:15[0m [2;4m0.40it/s[0m  
[2KAttention weights: tensor([[9.9817e-01, 1.8288e-03],;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 100/203 [2m0:05:55 â€¢ 0:04:15[0m [2;4m0.40it/s[0m  
        [9.9155e-01, 8.4524e-03],
        [9.5886e-01, 4.1144e-02],
        [9.9542e-01, 4.5767e-03],
        [9.9758e-01, 2.4240e-03],
        [9.9636e-01, 3.6383e-03],
        [9.9374e-01, 6.2566e-03],
        [9.9999e-01, 8.5966e-06],
        [9.9588e-01, 4.1211e-03],
[2K        [9.6923e-01, 3.0767e-02]], device='cuda:0')8;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 100/203 [2m0:05:55 â€¢ 0:04:15[0m [2;4m0.40it/s[0m  
[2KAttention weights: tensor([[0.5590, 0.4410],[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 101/203 [2m0:06:00 â€¢ 0:04:39[0m [2;4m0.37it/s[0m  
        [0.5537, 0.4463],
        [0.5562, 0.4438],
        [0.5554, 0.4446],
        [0.5538, 0.4462],
        [0.5532, 0.4468],
        [0.5542, 0.4458],
        [0.5576, 0.4424],
        [0.5579, 0.4421],
[2K        [0.5543, 0.4457]], device='cuda:0', grad_fn=<SoftmaxBackward0>)237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 101/203 [2m0:06:00 â€¢ 0:04:39[0m [2;4m0.37it/s[0m  
[2KClass label: Billiardsâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 101/203 [2m0:06:00 â€¢ 0:04:39[0m [2;4m0.37it/s[0m  
[2KAttention weights: tensor([[0.5983, 0.4017]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 101/203 [2m0:06:00 â€¢ 0:04:39[0m [2;4m0.37it/s[0m  
[2KStep 0 - TTA Loss: 0.7213â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 101/203 [2m0:06:00 â€¢ 0:04:39[0m [2;4m0.37it/s[0m  
[2KAttention weights: tensor([[0.5983, 0.4017]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 101/203 [2m0:06:00 â€¢ 0:04:39[0m [2;4m0.37it/s[0m  
[2KAttention weights: tensor([[0.5942, 0.4058]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 101/203 [2m0:06:00 â€¢ 0:04:39[0m [2;4m0.37it/s[0m  
[2KAttention weights: tensor([[0.5771, 0.4229]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 101/203 [2m0:06:00 â€¢ 0:04:39[0m [2;4m0.37it/s[0m  
[2KAttention weights: tensor([[0.5378, 0.4622]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 101/203 [2m0:06:00 â€¢ 0:04:39[0m [2;4m0.37it/s[0m  
[2KAttention weights: tensor([[0.4673, 0.5327]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 101/203 [2m0:06:00 â€¢ 0:04:39[0m [2;4m0.37it/s[0m  
[2KAttention weights: tensor([[0.3648, 0.6352]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 101/203 [2m0:06:00 â€¢ 0:04:39[0m [2;4m0.37it/s[0m  
[2KAttention weights: tensor([[0.2564, 0.7436]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 101/203 [2m0:06:00 â€¢ 0:04:39[0m [2;4m0.37it/s[0m  
[2KAttention weights: tensor([[0.1784, 0.8216]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 101/203 [2m0:06:00 â€¢ 0:04:39[0m [2;4m0.37it/s[0m  
[2KAttention weights: tensor([[0.1340, 0.8660]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 101/203 [2m0:06:00 â€¢ 0:04:39[0m [2;4m0.37it/s[0m  
[2KAttention weights: tensor([[0.5422, 0.4578]], device='cuda:0')0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 101/203 [2m0:06:00 â€¢ 0:04:39[0m [2;4m0.37it/s[0m  
[2KAttention weights: tensor([[0.1244, 0.8756],[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 101/203 [2m0:06:00 â€¢ 0:04:39[0m [2;4m0.37it/s[0m  
        [0.1107, 0.8893],
        [0.1090, 0.8910],
        [0.1459, 0.8541],
        [0.0562, 0.9438],
        [0.0350, 0.9650],
        [0.0148, 0.9852],
        [0.2119, 0.7881],
        [0.1865, 0.8135],
[2K        [0.0816, 0.9184]], device='cuda:0')[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 101/203 [2m0:06:00 â€¢ 0:04:39[0m [2;4m0.37it/s[0m  
[2KAttention weights: tensor([[0.5589, 0.4411],[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 102/203 [2m0:06:04 â€¢ 0:05:29[0m [2;4m0.31it/s[0m   
        [0.5536, 0.4464],
        [0.5561, 0.4439],
        [0.5554, 0.4446],
        [0.5538, 0.4462],
        [0.5531, 0.4469],
        [0.5541, 0.4459],
        [0.5576, 0.4424],
        [0.5579, 0.4421],
[2K        [0.5543, 0.4457]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 102/203 [2m0:06:04 â€¢ 0:05:29[0m [2;4m0.31it/s[0m  
[2KClass label: CleanAndJerkâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 102/203 [2m0:06:04 â€¢ 0:05:29[0m [2;4m0.31it/s[0m  
[2KAttention weights: tensor([[0.6222, 0.3778]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 102/203 [2m0:06:04 â€¢ 0:05:29[0m [2;4m0.31it/s[0m  
[2KStep 0 - TTA Loss: 0.7644â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 102/203 [2m0:06:04 â€¢ 0:05:29[0m [2;4m0.31it/s[0m  
[2KAttention weights: tensor([[0.5459, 0.4541]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 102/203 [2m0:06:04 â€¢ 0:05:29[0m [2;4m0.31it/s[0m  
[2KAttention weights: tensor([[0.4854, 0.5146]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 102/203 [2m0:06:04 â€¢ 0:05:29[0m [2;4m0.31it/s[0m  
[2KAttention weights: tensor([[0.4411, 0.5589]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 102/203 [2m0:06:04 â€¢ 0:05:29[0m [2;4m0.31it/s[0m  
[2KAttention weights: tensor([[0.4106, 0.5894]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 102/203 [2m0:06:04 â€¢ 0:05:29[0m [2;4m0.31it/s[0m  
[2KAttention weights: tensor([[0.3896, 0.6104]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 102/203 [2m0:06:04 â€¢ 0:05:29[0m [2;4m0.31it/s[0m  
[2KAttention weights: tensor([[0.3772, 0.6228]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 102/203 [2m0:06:04 â€¢ 0:05:29[0m [2;4m0.31it/s[0m  
[2KAttention weights: tensor([[0.3703, 0.6297]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 102/203 [2m0:06:04 â€¢ 0:05:29[0m [2;4m0.31it/s[0m  
[2KAttention weights: tensor([[0.3668, 0.6332]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 102/203 [2m0:06:04 â€¢ 0:05:29[0m [2;4m0.31it/s[0m  
[2KAttention weights: tensor([[0.3656, 0.6344]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 102/203 [2m0:06:04 â€¢ 0:05:29[0m [2;4m0.31it/s[0m  
[2KAttention weights: tensor([[0.5479, 0.4521]], device='cuda:0')38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 102/203 [2m0:06:04 â€¢ 0:05:29[0m [2;4m0.31it/s[0m  
[2KAttention weights: tensor([[0.3222, 0.6778],[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 102/203 [2m0:06:04 â€¢ 0:05:29[0m [2;4m0.31it/s[0m  
        [0.4055, 0.5945],
        [0.3653, 0.6347],
        [0.3494, 0.6506],
        [0.2031, 0.7969],
        [0.1634, 0.8366],
        [0.0952, 0.9048],
        [0.4276, 0.5724],
        [0.4253, 0.5747],
[2K        [0.2771, 0.7229]], device='cuda:0')m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 102/203 [2m0:06:04 â€¢ 0:05:29[0m [2;4m0.31it/s[0m  
[2KAttention weights: tensor([[0.5589, 0.4411],[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 103/203 [2m0:06:06 â€¢ 0:05:26[0m [2;4m0.31it/s[0m  
        [0.5536, 0.4464],
        [0.5561, 0.4439],
        [0.5554, 0.4446],
        [0.5538, 0.4462],
        [0.5531, 0.4469],
        [0.5540, 0.4460],
        [0.5576, 0.4424],
        [0.5578, 0.4422],
[2K        [0.5543, 0.4457]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 103/203 [2m0:06:06 â€¢ 0:05:26[0m [2;4m0.31it/s[0m  
[2KClass label: TennisSwingâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 103/203 [2m0:06:06 â€¢ 0:05:26[0m [2;4m0.31it/s[0m  
[2KAttention weights: tensor([[0.6594, 0.3406]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 103/203 [2m0:06:06 â€¢ 0:05:26[0m [2;4m0.31it/s[0m  
[2KStep 0 - TTA Loss: 0.4591â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 103/203 [2m0:06:06 â€¢ 0:05:26[0m [2;4m0.31it/s[0m  
[2KAttention weights: tensor([[0.6594, 0.3406]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 103/203 [2m0:06:06 â€¢ 0:05:26[0m [2;4m0.31it/s[0m  
[2KAttention weights: tensor([[0.6596, 0.3404]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 103/203 [2m0:06:06 â€¢ 0:05:26[0m [2;4m0.31it/s[0m  
[2KAttention weights: tensor([[0.6614, 0.3386]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 103/203 [2m0:06:06 â€¢ 0:05:26[0m [2;4m0.31it/s[0m  
[2KAttention weights: tensor([[0.6668, 0.3332]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 103/203 [2m0:06:06 â€¢ 0:05:26[0m [2;4m0.31it/s[0m  
[2KAttention weights: tensor([[0.6774, 0.3226]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 103/203 [2m0:06:06 â€¢ 0:05:26[0m [2;4m0.31it/s[0m  
[2KAttention weights: tensor([[0.6934, 0.3066]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 103/203 [2m0:06:06 â€¢ 0:05:26[0m [2;4m0.31it/s[0m  
[2KAttention weights: tensor([[0.7126, 0.2874]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 103/203 [2m0:06:06 â€¢ 0:05:26[0m [2;4m0.31it/s[0m  
[2KAttention weights: tensor([[0.7335, 0.2665]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 103/203 [2m0:06:06 â€¢ 0:05:26[0m [2;4m0.31it/s[0m  
[2KAttention weights: tensor([[0.7522, 0.2478]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 103/203 [2m0:06:06 â€¢ 0:05:26[0m [2;4m0.31it/s[0m  
[2KAttention weights: tensor([[0.5602, 0.4398]], device='cuda:0')38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 103/203 [2m0:06:06 â€¢ 0:05:26[0m [2;4m0.31it/s[0m  
[2KAttention weights: tensor([[0.6629, 0.3371],[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 103/203 [2m0:06:06 â€¢ 0:05:26[0m [2;4m0.31it/s[0m  
        [0.6237, 0.3763],
        [0.6669, 0.3331],
        [0.6516, 0.3484],
        [0.5574, 0.4426],
        [0.6035, 0.3965],
        [0.5532, 0.4468],
        [0.6772, 0.3228],
        [0.7699, 0.2301],
[2K        [0.6523, 0.3477]], device='cuda:0')m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 103/203 [2m0:06:06 â€¢ 0:05:26[0m [2;4m0.31it/s[0m  
[2KAttention weights: tensor([[0.5589, 0.4411],[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 104/203 [2m0:06:07 â€¢ 0:04:55[0m [2;4m0.34it/s[0m  
        [0.5536, 0.4464],
        [0.5561, 0.4439],
        [0.5554, 0.4446],
        [0.5537, 0.4463],
        [0.5530, 0.4470],
        [0.5540, 0.4460],
        [0.5576, 0.4424],
        [0.5578, 0.4422],
[2K        [0.5543, 0.4457]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 104/203 [2m0:06:07 â€¢ 0:04:55[0m [2;4m0.34it/s[0m  
[2KClass label: PoleVaultâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 104/203 [2m0:06:07 â€¢ 0:04:55[0m [2;4m0.34it/s[0m  
[2KAttention weights: tensor([[0.6106, 0.3894]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 104/203 [2m0:06:07 â€¢ 0:04:55[0m [2;4m0.34it/s[0m  
[2KStep 0 - TTA Loss: 0.6426â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 104/203 [2m0:06:07 â€¢ 0:04:55[0m [2;4m0.34it/s[0m  
[2KAttention weights: tensor([[0.6108, 0.3892]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 104/203 [2m0:06:07 â€¢ 0:04:55[0m [2;4m0.34it/s[0m  
[2KAttention weights: tensor([[0.6213, 0.3787]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 104/203 [2m0:06:07 â€¢ 0:04:55[0m [2;4m0.34it/s[0m  
[2KAttention weights: tensor([[0.6351, 0.3649]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 104/203 [2m0:06:07 â€¢ 0:04:55[0m [2;4m0.34it/s[0m  
[2KAttention weights: tensor([[0.6494, 0.3506]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 104/203 [2m0:06:07 â€¢ 0:04:55[0m [2;4m0.34it/s[0m  
[2KAttention weights: tensor([[0.6617, 0.3383]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 104/203 [2m0:06:07 â€¢ 0:04:55[0m [2;4m0.34it/s[0m  
[2KAttention weights: tensor([[0.6716, 0.3284]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 104/203 [2m0:06:07 â€¢ 0:04:55[0m [2;4m0.34it/s[0m  
[2KAttention weights: tensor([[0.6781, 0.3219]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 104/203 [2m0:06:07 â€¢ 0:04:55[0m [2;4m0.34it/s[0m  
[2KAttention weights: tensor([[0.6807, 0.3193]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 104/203 [2m0:06:07 â€¢ 0:04:55[0m [2;4m0.34it/s[0m  
[2KAttention weights: tensor([[0.6817, 0.3183]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 104/203 [2m0:06:07 â€¢ 0:04:55[0m [2;4m0.34it/s[0m  
[2KAttention weights: tensor([[0.5563, 0.4437]], device='cuda:0')38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 104/203 [2m0:06:07 â€¢ 0:04:55[0m [2;4m0.34it/s[0m  
[2KAttention weights: tensor([[0.7222, 0.2778],[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 104/203 [2m0:06:07 â€¢ 0:04:55[0m [2;4m0.34it/s[0m  
        [0.6568, 0.3432],
        [0.7090, 0.2910],
        [0.6966, 0.3034],
        [0.6350, 0.3650],
        [0.6917, 0.3083],
        [0.6820, 0.3180],
        [0.7330, 0.2670],
        [0.7840, 0.2160],
[2K        [0.7052, 0.2948]], device='cuda:0')m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 104/203 [2m0:06:07 â€¢ 0:04:55[0m [2;4m0.34it/s[0m  
[2KAttention weights: tensor([[0.5589, 0.4411],[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 105/203 [2m0:06:14 â€¢ 0:05:15[0m [2;4m0.31it/s[0m  
        [0.5535, 0.4465],
        [0.5561, 0.4439],
        [0.5553, 0.4447],
        [0.5537, 0.4463],
        [0.5530, 0.4470],
        [0.5540, 0.4460],
        [0.5575, 0.4425],
        [0.5578, 0.4422],
[2K        [0.5542, 0.4458]], device='cuda:0', grad_fn=<SoftmaxBackward0>);237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 105/203 [2m0:06:14 â€¢ 0:05:15[0m [2;4m0.31it/s[0m  
[2KClass label: HighJumpâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 105/203 [2m0:06:14 â€¢ 0:05:15[0m [2;4m0.31it/s[0m  
[2KAttention weights: tensor([[0.6010, 0.3990]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 105/203 [2m0:06:14 â€¢ 0:05:15[0m [2;4m0.31it/s[0m  
[2KStep 0 - TTA Loss: 0.7803â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 105/203 [2m0:06:14 â€¢ 0:05:15[0m [2;4m0.31it/s[0m  
[2KAttention weights: tensor([[0.6010, 0.3990]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 105/203 [2m0:06:14 â€¢ 0:05:15[0m [2;4m0.31it/s[0m  
[2KAttention weights: tensor([[0.6021, 0.3979]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 105/203 [2m0:06:14 â€¢ 0:05:15[0m [2;4m0.31it/s[0m  
[2KAttention weights: tensor([[0.6083, 0.3917]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 105/203 [2m0:06:14 â€¢ 0:05:15[0m [2;4m0.31it/s[0m  
[2KAttention weights: tensor([[0.6245, 0.3755]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 105/203 [2m0:06:14 â€¢ 0:05:15[0m [2;4m0.31it/s[0m  
[2KAttention weights: tensor([[0.6542, 0.3458]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 105/203 [2m0:06:14 â€¢ 0:05:15[0m [2;4m0.31it/s[0m  
[2KAttention weights: tensor([[0.6982, 0.3018]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 105/203 [2m0:06:14 â€¢ 0:05:15[0m [2;4m0.31it/s[0m  
[2KAttention weights: tensor([[0.7576, 0.2424]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 105/203 [2m0:06:14 â€¢ 0:05:15[0m [2;4m0.31it/s[0m  
[2KAttention weights: tensor([[0.8185, 0.1815]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 105/203 [2m0:06:14 â€¢ 0:05:15[0m [2;4m0.31it/s[0m  
[2KAttention weights: tensor([[0.8670, 0.1330]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 105/203 [2m0:06:14 â€¢ 0:05:15[0m [2;4m0.31it/s[0m  
[2KAttention weights: tensor([[0.5622, 0.4378]], device='cuda:0')[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 105/203 [2m0:06:14 â€¢ 0:05:15[0m [2;4m0.31it/s[0m  
[2KAttention weights: tensor([[0.8145, 0.1855],[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 105/203 [2m0:06:14 â€¢ 0:05:15[0m [2;4m0.31it/s[0m  
        [0.7485, 0.2515],
        [0.8079, 0.1921],
        [0.7933, 0.2067],
        [0.8083, 0.1917],
        [0.9101, 0.0899],
        [0.8434, 0.1566],
        [0.8452, 0.1548],
        [0.8629, 0.1371],
[2K        [0.8367, 0.1633]], device='cuda:0')m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 105/203 [2m0:06:14 â€¢ 0:05:15[0m [2;4m0.31it/s[0m  
[2KAttention weights: tensor([[0.5589, 0.4411],[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 106/203 [2m0:06:19 â€¢ 0:05:54[0m [2;4m0.27it/s[0m  
        [0.5536, 0.4464],
        [0.5561, 0.4439],
        [0.5554, 0.4446],
        [0.5537, 0.4463],
        [0.5531, 0.4469],
        [0.5540, 0.4460],
        [0.5576, 0.4424],
        [0.5578, 0.4422],
[2K        [0.5543, 0.4457]], device='cuda:0', grad_fn=<SoftmaxBackward0>);237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 106/203 [2m0:06:19 â€¢ 0:05:54[0m [2;4m0.27it/s[0m  
[2KClass label: TennisSwingâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 106/203 [2m0:06:19 â€¢ 0:05:54[0m [2;4m0.27it/s[0m  
[2KAttention weights: tensor([[0.6608, 0.3392]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 106/203 [2m0:06:19 â€¢ 0:05:54[0m [2;4m0.27it/s[0m  
[2KStep 0 - TTA Loss: 0.7412â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 106/203 [2m0:06:19 â€¢ 0:05:54[0m [2;4m0.27it/s[0m  
[2KAttention weights: tensor([[0.6801, 0.3199]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 106/203 [2m0:06:19 â€¢ 0:05:54[0m [2;4m0.27it/s[0m  
[2KAttention weights: tensor([[0.6524, 0.3476]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 106/203 [2m0:06:19 â€¢ 0:05:54[0m [2;4m0.27it/s[0m  
[2KAttention weights: tensor([[0.5783, 0.4217]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 106/203 [2m0:06:19 â€¢ 0:05:54[0m [2;4m0.27it/s[0m  
[2KAttention weights: tensor([[0.4804, 0.5196]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 106/203 [2m0:06:19 â€¢ 0:05:54[0m [2;4m0.27it/s[0m  
[2KAttention weights: tensor([[0.3932, 0.6068]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 106/203 [2m0:06:19 â€¢ 0:05:54[0m [2;4m0.27it/s[0m  
[2KAttention weights: tensor([[0.3374, 0.6626]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 106/203 [2m0:06:19 â€¢ 0:05:54[0m [2;4m0.27it/s[0m  
[2KAttention weights: tensor([[0.3103, 0.6897]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 106/203 [2m0:06:19 â€¢ 0:05:54[0m [2;4m0.27it/s[0m  
[2KAttention weights: tensor([[0.3008, 0.6992]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 106/203 [2m0:06:19 â€¢ 0:05:54[0m [2;4m0.27it/s[0m  
[2KAttention weights: tensor([[0.2989, 0.7011]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 106/203 [2m0:06:19 â€¢ 0:05:54[0m [2;4m0.27it/s[0m  
[2KAttention weights: tensor([[0.5476, 0.4524]], device='cuda:0')[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 106/203 [2m0:06:19 â€¢ 0:05:54[0m [2;4m0.27it/s[0m  
[2KAttention weights: tensor([[0.5456, 0.4544],[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 106/203 [2m0:06:19 â€¢ 0:05:54[0m [2;4m0.27it/s[0m  
        [0.5165, 0.4835],
        [0.5487, 0.4513],
        [0.4554, 0.5446],
        [0.5284, 0.4716],
        [0.6909, 0.3091],
        [0.6617, 0.3383],
        [0.5878, 0.4122],
        [0.2990, 0.7010],
[2K        [0.5395, 0.4605]], device='cuda:0')m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 106/203 [2m0:06:19 â€¢ 0:05:54[0m [2;4m0.27it/s[0m  
[2KAttention weights: tensor([[0.5589, 0.4411],â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 107/203 [2m0:06:23 â€¢ 0:06:22[0m [2;4m0.25it/s[0m   
        [0.5535, 0.4465],
        [0.5561, 0.4439],
        [0.5553, 0.4447],
        [0.5537, 0.4463],
        [0.5531, 0.4469],
        [0.5540, 0.4460],
        [0.5576, 0.4424],
        [0.5578, 0.4422],
[2K        [0.5543, 0.4457]], device='cuda:0', grad_fn=<SoftmaxBackward0>)mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 107/203 [2m0:06:23 â€¢ 0:06:22[0m [2;4m0.25it/s[0m  
[2KClass label: PoleVaultâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 107/203 [2m0:06:23 â€¢ 0:06:22[0m [2;4m0.25it/s[0m  
[2KAttention weights: tensor([[0.6175, 0.3825]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 107/203 [2m0:06:23 â€¢ 0:06:22[0m [2;4m0.25it/s[0m  
[2KStep 0 - TTA Loss: 0.7229â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 107/203 [2m0:06:23 â€¢ 0:06:22[0m [2;4m0.25it/s[0m  
[2KAttention weights: tensor([[0.6175, 0.3825]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 107/203 [2m0:06:23 â€¢ 0:06:22[0m [2;4m0.25it/s[0m  
[2KAttention weights: tensor([[0.6190, 0.3810]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 107/203 [2m0:06:23 â€¢ 0:06:22[0m [2;4m0.25it/s[0m  
[2KAttention weights: tensor([[0.6268, 0.3732]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 107/203 [2m0:06:23 â€¢ 0:06:22[0m [2;4m0.25it/s[0m  
[2KAttention weights: tensor([[0.6469, 0.3531]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 107/203 [2m0:06:23 â€¢ 0:06:22[0m [2;4m0.25it/s[0m  
[2KAttention weights: tensor([[0.6842, 0.3158]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 107/203 [2m0:06:23 â€¢ 0:06:22[0m [2;4m0.25it/s[0m  
[2KAttention weights: tensor([[0.7430, 0.2570]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 107/203 [2m0:06:23 â€¢ 0:06:22[0m [2;4m0.25it/s[0m  
[2KAttention weights: tensor([[0.8174, 0.1826]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 107/203 [2m0:06:23 â€¢ 0:06:22[0m [2;4m0.25it/s[0m  
[2KAttention weights: tensor([[0.8906, 0.1094]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 107/203 [2m0:06:23 â€¢ 0:06:22[0m [2;4m0.25it/s[0m  
[2KAttention weights: tensor([[0.9452, 0.0548]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 107/203 [2m0:06:23 â€¢ 0:06:22[0m [2;4m0.25it/s[0m  
[2KAttention weights: tensor([[0.5729, 0.4271]], device='cuda:0')[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 107/203 [2m0:06:23 â€¢ 0:06:22[0m [2;4m0.25it/s[0m  
[2KAttention weights: tensor([[0.9277, 0.0723],m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 107/203 [2m0:06:23 â€¢ 0:06:22[0m [2;4m0.25it/s[0m  
        [0.8304, 0.1696],
        [0.9048, 0.0952],
        [0.8895, 0.1105],
        [0.9225, 0.0775],
        [0.9595, 0.0405],
        [0.9747, 0.0253],
        [0.9359, 0.0641],
        [0.9049, 0.0951],
[2K        [0.9205, 0.0795]], device='cuda:0')0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 107/203 [2m0:06:23 â€¢ 0:06:22[0m [2;4m0.25it/s[0m  
[2KAttention weights: tensor([[0.5589, 0.4411],â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 108/203 [2m0:06:30 â€¢ 0:06:39[0m [2;4m0.24it/s[0m  
        [0.5536, 0.4464],
        [0.5562, 0.4438],
        [0.5554, 0.4446],
        [0.5538, 0.4462],
        [0.5531, 0.4469],
        [0.5541, 0.4459],
        [0.5576, 0.4424],
        [0.5578, 0.4422],
[2K        [0.5543, 0.4457]], device='cuda:0', grad_fn=<SoftmaxBackward0>)mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 108/203 [2m0:06:30 â€¢ 0:06:39[0m [2;4m0.24it/s[0m  
[2KClass label: CleanAndJerkâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 108/203 [2m0:06:30 â€¢ 0:06:39[0m [2;4m0.24it/s[0m  
[2KAttention weights: tensor([[0.6169, 0.3831]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 108/203 [2m0:06:30 â€¢ 0:06:39[0m [2;4m0.24it/s[0m  
[2KStep 0 - TTA Loss: 0.6173â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 108/203 [2m0:06:30 â€¢ 0:06:39[0m [2;4m0.24it/s[0m  
[2KAttention weights: tensor([[0.7112, 0.2888]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 108/203 [2m0:06:30 â€¢ 0:06:39[0m [2;4m0.24it/s[0m  
[2KAttention weights: tensor([[0.7850, 0.2150]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 108/203 [2m0:06:30 â€¢ 0:06:39[0m [2;4m0.24it/s[0m  
[2KAttention weights: tensor([[0.8347, 0.1653]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 108/203 [2m0:06:30 â€¢ 0:06:39[0m [2;4m0.24it/s[0m  
[2KAttention weights: tensor([[0.8668, 0.1332]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 108/203 [2m0:06:30 â€¢ 0:06:39[0m [2;4m0.24it/s[0m  
[2KAttention weights: tensor([[0.8851, 0.1149]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 108/203 [2m0:06:30 â€¢ 0:06:39[0m [2;4m0.24it/s[0m  
[2KAttention weights: tensor([[0.8937, 0.1063]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 108/203 [2m0:06:30 â€¢ 0:06:39[0m [2;4m0.24it/s[0m  
[2KAttention weights: tensor([[0.8940, 0.1060]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 108/203 [2m0:06:30 â€¢ 0:06:39[0m [2;4m0.24it/s[0m  
[2KAttention weights: tensor([[0.8909, 0.1091]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 108/203 [2m0:06:30 â€¢ 0:06:39[0m [2;4m0.24it/s[0m  
[2KAttention weights: tensor([[0.8882, 0.1118]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 108/203 [2m0:06:30 â€¢ 0:06:39[0m [2;4m0.24it/s[0m  
[2KAttention weights: tensor([[0.5656, 0.4344]], device='cuda:0')[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 108/203 [2m0:06:30 â€¢ 0:06:39[0m [2;4m0.24it/s[0m  
[2KAttention weights: tensor([[0.9225, 0.0775],m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 108/203 [2m0:06:30 â€¢ 0:06:39[0m [2;4m0.24it/s[0m  
        [0.8243, 0.1757],
        [0.8872, 0.1128],
        [0.8806, 0.1194],
        [0.9134, 0.0866],
        [0.9531, 0.0469],
        [0.9715, 0.0285],
        [0.9307, 0.0693],
        [0.8958, 0.1042],
[2K        [0.9098, 0.0902]], device='cuda:0')0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 108/203 [2m0:06:30 â€¢ 0:06:39[0m [2;4m0.24it/s[0m  
[2KAttention weights: tensor([[0.5590, 0.4410],â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 109/203 [2m0:06:35 â€¢ 0:07:36[0m [2;4m0.21it/s[0m  
        [0.5536, 0.4464],
        [0.5562, 0.4438],
        [0.5554, 0.4446],
        [0.5539, 0.4461],
        [0.5532, 0.4468],
        [0.5542, 0.4458],
        [0.5577, 0.4423],
        [0.5579, 0.4421],
[2K        [0.5544, 0.4456]], device='cuda:0', grad_fn=<SoftmaxBackward0>)mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 109/203 [2m0:06:35 â€¢ 0:07:36[0m [2;4m0.21it/s[0m  
[2KClass label: ThrowDiscusâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 109/203 [2m0:06:35 â€¢ 0:07:36[0m [2;4m0.21it/s[0m  
[2KAttention weights: tensor([[0.6170, 0.3830]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 109/203 [2m0:06:35 â€¢ 0:07:36[0m [2;4m0.21it/s[0m  
[2KStep 0 - TTA Loss: 0.7837â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 109/203 [2m0:06:35 â€¢ 0:07:36[0m [2;4m0.21it/s[0m  
[2KAttention weights: tensor([[0.6170, 0.3830]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 109/203 [2m0:06:35 â€¢ 0:07:36[0m [2;4m0.21it/s[0m  
[2KAttention weights: tensor([[0.6163, 0.3837]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 109/203 [2m0:06:35 â€¢ 0:07:36[0m [2;4m0.21it/s[0m  
[2KAttention weights: tensor([[0.6137, 0.3863]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 109/203 [2m0:06:35 â€¢ 0:07:36[0m [2;4m0.21it/s[0m  
[2KAttention weights: tensor([[0.6101, 0.3899]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 109/203 [2m0:06:35 â€¢ 0:07:36[0m [2;4m0.21it/s[0m  
[2KAttention weights: tensor([[0.6054, 0.3946]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 109/203 [2m0:06:35 â€¢ 0:07:36[0m [2;4m0.21it/s[0m  
[2KAttention weights: tensor([[0.5992, 0.4008]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 109/203 [2m0:06:35 â€¢ 0:07:36[0m [2;4m0.21it/s[0m  
[2KAttention weights: tensor([[0.5919, 0.4081]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 109/203 [2m0:06:35 â€¢ 0:07:36[0m [2;4m0.21it/s[0m  
[2KAttention weights: tensor([[0.5801, 0.4199]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 109/203 [2m0:06:35 â€¢ 0:07:36[0m [2;4m0.21it/s[0m  
[2KAttention weights: tensor([[0.5582, 0.4418]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 109/203 [2m0:06:35 â€¢ 0:07:36[0m [2;4m0.21it/s[0m  
[2KAttention weights: tensor([[0.5515, 0.4485]], device='cuda:0')[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 109/203 [2m0:06:35 â€¢ 0:07:36[0m [2;4m0.21it/s[0m  
[2KAttention weights: tensor([[0.6619, 0.3381],m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 109/203 [2m0:06:35 â€¢ 0:07:36[0m [2;4m0.21it/s[0m  
        [0.5864, 0.4136],
        [0.4140, 0.5860],
        [0.5976, 0.4024],
        [0.5173, 0.4827],
        [0.6114, 0.3886],
        [0.6543, 0.3457],
        [0.6624, 0.3376],
        [0.6213, 0.3787],
[2K        [0.5275, 0.4725]], device='cuda:0')0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 109/203 [2m0:06:35 â€¢ 0:07:36[0m [2;4m0.21it/s[0m  
[2KAttention weights: tensor([[0.5590, 0.4410],â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 110/203 [2m0:06:40 â€¢ 0:08:02[0m [2;4m0.19it/s[0m  
        [0.5537, 0.4463],
        [0.5563, 0.4437],
        [0.5554, 0.4446],
        [0.5539, 0.4461],
        [0.5533, 0.4467],
        [0.5542, 0.4458],
        [0.5577, 0.4423],
        [0.5579, 0.4421],
[2K        [0.5544, 0.4456]], device='cuda:0', grad_fn=<SoftmaxBackward0>)5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 110/203 [2m0:06:40 â€¢ 0:08:02[0m [2;4m0.19it/s[0m  
[2KClass label: HighJumpâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 110/203 [2m0:06:40 â€¢ 0:08:02[0m [2;4m0.19it/s[0m  
[2KAttention weights: tensor([[0.6000, 0.4000]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 110/203 [2m0:06:40 â€¢ 0:08:02[0m [2;4m0.19it/s[0m  
[2KStep 0 - TTA Loss: 0.7680â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 110/203 [2m0:06:40 â€¢ 0:08:02[0m [2;4m0.19it/s[0m  
[2KAttention weights: tensor([[0.6046, 0.3954]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 110/203 [2m0:06:40 â€¢ 0:08:02[0m [2;4m0.19it/s[0m  
[2KAttention weights: tensor([[0.6270, 0.3730]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 110/203 [2m0:06:40 â€¢ 0:08:02[0m [2;4m0.19it/s[0m  
[2KAttention weights: tensor([[0.6489, 0.3511]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 110/203 [2m0:06:40 â€¢ 0:08:02[0m [2;4m0.19it/s[0m  
[2KAttention weights: tensor([[0.6662, 0.3338]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 110/203 [2m0:06:40 â€¢ 0:08:02[0m [2;4m0.19it/s[0m  
[2KAttention weights: tensor([[0.6806, 0.3194]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 110/203 [2m0:06:40 â€¢ 0:08:02[0m [2;4m0.19it/s[0m  
[2KAttention weights: tensor([[0.6889, 0.3111]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 110/203 [2m0:06:40 â€¢ 0:08:02[0m [2;4m0.19it/s[0m  
[2KAttention weights: tensor([[0.6926, 0.3074]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 110/203 [2m0:06:40 â€¢ 0:08:02[0m [2;4m0.19it/s[0m  
[2KAttention weights: tensor([[0.6933, 0.3067]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 110/203 [2m0:06:40 â€¢ 0:08:02[0m [2;4m0.19it/s[0m  
[2KAttention weights: tensor([[0.6931, 0.3069]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 110/203 [2m0:06:40 â€¢ 0:08:02[0m [2;4m0.19it/s[0m  
[2KAttention weights: tensor([[0.5558, 0.4442]], device='cuda:0')[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 110/203 [2m0:06:40 â€¢ 0:08:02[0m [2;4m0.19it/s[0m  
[2KAttention weights: tensor([[0.6855, 0.3145],m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 110/203 [2m0:06:40 â€¢ 0:08:02[0m [2;4m0.19it/s[0m  
        [0.6223, 0.3777],
        [0.5028, 0.4972],
        [0.6288, 0.3712],
        [0.5722, 0.4278],
        [0.6931, 0.3069],
        [0.6876, 0.3124],
        [0.7004, 0.2996],
        [0.6729, 0.3271],
[2K        [0.5715, 0.4285]], device='cuda:0')0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 110/203 [2m0:06:40 â€¢ 0:08:02[0m [2;4m0.19it/s[0m  
[2KAttention weights: tensor([[0.5590, 0.4410],â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 111/203 [2m0:06:42 â€¢ 0:07:17[0m [2;4m0.21it/s[0m  
        [0.5537, 0.4463],
        [0.5562, 0.4438],
        [0.5554, 0.4446],
        [0.5539, 0.4461],
        [0.5533, 0.4467],
        [0.5542, 0.4458],
        [0.5577, 0.4423],
        [0.5579, 0.4421],
[2K        [0.5544, 0.4456]], device='cuda:0', grad_fn=<SoftmaxBackward0>)5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 111/203 [2m0:06:42 â€¢ 0:07:17[0m [2;4m0.21it/s[0m  
[2KClass label: PoleVaultâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 111/203 [2m0:06:42 â€¢ 0:07:17[0m [2;4m0.21it/s[0m  
[2KAttention weights: tensor([[0.6163, 0.3837]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 111/203 [2m0:06:42 â€¢ 0:07:17[0m [2;4m0.21it/s[0m  
[2KStep 0 - TTA Loss: 0.5396â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 111/203 [2m0:06:42 â€¢ 0:07:17[0m [2;4m0.21it/s[0m  
[2KAttention weights: tensor([[0.6163, 0.3837]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 111/203 [2m0:06:42 â€¢ 0:07:17[0m [2;4m0.21it/s[0m  
[2KAttention weights: tensor([[0.6167, 0.3833]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 111/203 [2m0:06:42 â€¢ 0:07:17[0m [2;4m0.21it/s[0m  
[2KAttention weights: tensor([[0.6186, 0.3814]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 111/203 [2m0:06:42 â€¢ 0:07:17[0m [2;4m0.21it/s[0m  
[2KAttention weights: tensor([[0.6237, 0.3763]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 111/203 [2m0:06:42 â€¢ 0:07:17[0m [2;4m0.21it/s[0m  
[2KAttention weights: tensor([[0.6333, 0.3667]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 111/203 [2m0:06:42 â€¢ 0:07:17[0m [2;4m0.21it/s[0m  
[2KAttention weights: tensor([[0.6468, 0.3532]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 111/203 [2m0:06:42 â€¢ 0:07:17[0m [2;4m0.21it/s[0m  
[2KAttention weights: tensor([[0.6620, 0.3380]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 111/203 [2m0:06:42 â€¢ 0:07:17[0m [2;4m0.21it/s[0m  
[2KAttention weights: tensor([[0.6789, 0.3211]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 111/203 [2m0:06:42 â€¢ 0:07:17[0m [2;4m0.21it/s[0m  
[2KAttention weights: tensor([[0.7066, 0.2934]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 111/203 [2m0:06:42 â€¢ 0:07:17[0m [2;4m0.21it/s[0m  
[2KAttention weights: tensor([[0.5577, 0.4423]], device='cuda:0')[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 111/203 [2m0:06:42 â€¢ 0:07:17[0m [2;4m0.21it/s[0m  
[2KAttention weights: tensor([[0.7305, 0.2695],m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 111/203 [2m0:06:42 â€¢ 0:07:17[0m [2;4m0.21it/s[0m  
        [0.6507, 0.3493],
        [0.6720, 0.3280],
        [0.6807, 0.3193],
        [0.6446, 0.3554],
        [0.7172, 0.2828],
        [0.7540, 0.2460],
        [0.7310, 0.2690],
        [0.7234, 0.2766],
[2K        [0.6852, 0.3148]], device='cuda:0')0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 111/203 [2m0:06:42 â€¢ 0:07:17[0m [2;4m0.21it/s[0m  
[2KAttention weights: tensor([[0.5590, 0.4410],â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 112/203 [2m0:06:49 â€¢ 0:08:04[0m [2;4m0.19it/s[0m   
        [0.5537, 0.4463],
        [0.5562, 0.4438],
        [0.5554, 0.4446],
        [0.5539, 0.4461],
        [0.5533, 0.4467],
        [0.5543, 0.4457],
        [0.5577, 0.4423],
        [0.5579, 0.4421],
[2K        [0.5544, 0.4456]], device='cuda:0', grad_fn=<SoftmaxBackward0>)7mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 112/203 [2m0:06:49 â€¢ 0:08:04[0m [2;4m0.19it/s[0m  
[2KClass label: GolfSwingâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 112/203 [2m0:06:49 â€¢ 0:08:04[0m [2;4m0.19it/s[0m  
[2KAttention weights: tensor([[0.6066, 0.3934]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 112/203 [2m0:06:49 â€¢ 0:08:04[0m [2;4m0.19it/s[0m  
[2KStep 0 - TTA Loss: 0.9372â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 112/203 [2m0:06:49 â€¢ 0:08:04[0m [2;4m0.19it/s[0m  
[2KAttention weights: tensor([[0.6355, 0.3645]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 112/203 [2m0:06:49 â€¢ 0:08:04[0m [2;4m0.19it/s[0m  
[2KAttention weights: tensor([[0.6615, 0.3385]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 112/203 [2m0:06:49 â€¢ 0:08:04[0m [2;4m0.19it/s[0m  
[2KAttention weights: tensor([[0.6813, 0.3187]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 112/203 [2m0:06:49 â€¢ 0:08:04[0m [2;4m0.19it/s[0m  
[2KAttention weights: tensor([[0.6945, 0.3055]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 112/203 [2m0:06:49 â€¢ 0:08:04[0m [2;4m0.19it/s[0m  
[2KAttention weights: tensor([[0.7005, 0.2995]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 112/203 [2m0:06:49 â€¢ 0:08:04[0m [2;4m0.19it/s[0m  
[2KAttention weights: tensor([[0.7017, 0.2983]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 112/203 [2m0:06:49 â€¢ 0:08:04[0m [2;4m0.19it/s[0m  
[2KAttention weights: tensor([[0.6993, 0.3007]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 112/203 [2m0:06:49 â€¢ 0:08:04[0m [2;4m0.19it/s[0m  
[2KAttention weights: tensor([[0.6956, 0.3044]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 112/203 [2m0:06:49 â€¢ 0:08:04[0m [2;4m0.19it/s[0m  
[2KAttention weights: tensor([[0.6931, 0.3069]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 112/203 [2m0:06:49 â€¢ 0:08:04[0m [2;4m0.19it/s[0m  
[2KAttention weights: tensor([[0.5580, 0.4420]], device='cuda:0')[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 112/203 [2m0:06:49 â€¢ 0:08:04[0m [2;4m0.19it/s[0m  
[2KAttention weights: tensor([[0.7542, 0.2458],0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 112/203 [2m0:06:49 â€¢ 0:08:04[0m [2;4m0.19it/s[0m  
        [0.6695, 0.3305],
        [0.7112, 0.2888],
        [0.6922, 0.3078],
        [0.6850, 0.3150],
        [0.7589, 0.2411],
        [0.7978, 0.2022],
        [0.7572, 0.2428],
        [0.7437, 0.2563],
[2K        [0.7222, 0.2778]], device='cuda:0')[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 112/203 [2m0:06:49 â€¢ 0:08:04[0m [2;4m0.19it/s[0m  
[2KAttention weights: tensor([[0.5590, 0.4410],â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 113/203 [2m0:06:53 â€¢ 0:07:26[0m [2;4m0.20it/s[0m  
        [0.5537, 0.4463],
        [0.5563, 0.4437],
        [0.5555, 0.4445],
        [0.5539, 0.4461],
        [0.5533, 0.4467],
        [0.5543, 0.4457],
        [0.5577, 0.4423],
        [0.5579, 0.4421],
[2K        [0.5544, 0.4456]], device='cuda:0', grad_fn=<SoftmaxBackward0>)7mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 113/203 [2m0:06:53 â€¢ 0:07:26[0m [2;4m0.20it/s[0m  
[2KClass label: TennisSwingâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 113/203 [2m0:06:53 â€¢ 0:07:26[0m [2;4m0.20it/s[0m  
[2KAttention weights: tensor([[0.6603, 0.3397]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 113/203 [2m0:06:53 â€¢ 0:07:26[0m [2;4m0.20it/s[0m  
[2KStep 0 - TTA Loss: 0.4682â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 113/203 [2m0:06:53 â€¢ 0:07:26[0m [2;4m0.20it/s[0m  
[2KAttention weights: tensor([[0.6603, 0.3397]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 113/203 [2m0:06:53 â€¢ 0:07:26[0m [2;4m0.20it/s[0m  
[2KAttention weights: tensor([[0.6601, 0.3399]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 113/203 [2m0:06:53 â€¢ 0:07:26[0m [2;4m0.20it/s[0m  
[2KAttention weights: tensor([[0.6597, 0.3403]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 113/203 [2m0:06:53 â€¢ 0:07:26[0m [2;4m0.20it/s[0m  
[2KAttention weights: tensor([[0.6602, 0.3398]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 113/203 [2m0:06:53 â€¢ 0:07:26[0m [2;4m0.20it/s[0m  
[2KAttention weights: tensor([[0.6622, 0.3378]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 113/203 [2m0:06:53 â€¢ 0:07:26[0m [2;4m0.20it/s[0m  
[2KAttention weights: tensor([[0.6656, 0.3344]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 113/203 [2m0:06:53 â€¢ 0:07:26[0m [2;4m0.20it/s[0m  
[2KAttention weights: tensor([[0.6669, 0.3331]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 113/203 [2m0:06:53 â€¢ 0:07:26[0m [2;4m0.20it/s[0m  
[2KAttention weights: tensor([[0.6628, 0.3372]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 113/203 [2m0:06:53 â€¢ 0:07:26[0m [2;4m0.20it/s[0m  
[2KAttention weights: tensor([[0.6480, 0.3520]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 113/203 [2m0:06:53 â€¢ 0:07:26[0m [2;4m0.20it/s[0m  
[2KAttention weights: tensor([[0.5557, 0.4443]], device='cuda:0')[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 113/203 [2m0:06:53 â€¢ 0:07:26[0m [2;4m0.20it/s[0m  
[2KAttention weights: tensor([[0.6223, 0.3777],0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 113/203 [2m0:06:53 â€¢ 0:07:26[0m [2;4m0.20it/s[0m  
        [0.5771, 0.4229],
        [0.6078, 0.3922],
        [0.5265, 0.4735],
        [0.5292, 0.4708],
        [0.5977, 0.4023],
        [0.6208, 0.3792],
        [0.6169, 0.3831],
        [0.6356, 0.3644],
[2K        [0.6008, 0.3992]], device='cuda:0')[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 113/203 [2m0:06:53 â€¢ 0:07:26[0m [2;4m0.20it/s[0m  
[2KAttention weights: tensor([[0.5590, 0.4410],â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 114/203 [2m0:06:58 â€¢ 0:07:04[0m [2;4m0.21it/s[0m  
        [0.5537, 0.4463],
        [0.5563, 0.4437],
        [0.5555, 0.4445],
        [0.5539, 0.4461],
        [0.5533, 0.4467],
        [0.5543, 0.4457],
        [0.5577, 0.4423],
        [0.5579, 0.4421],
[2K        [0.5544, 0.4456]], device='cuda:0', grad_fn=<SoftmaxBackward0>)7mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 114/203 [2m0:06:58 â€¢ 0:07:04[0m [2;4m0.21it/s[0m  
[2KClass label: PoleVaultâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 114/203 [2m0:06:58 â€¢ 0:07:04[0m [2;4m0.21it/s[0m  
[2KAttention weights: tensor([[0.6108, 0.3892]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 114/203 [2m0:06:58 â€¢ 0:07:04[0m [2;4m0.21it/s[0m  
[2KStep 0 - TTA Loss: 0.7261â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 114/203 [2m0:06:58 â€¢ 0:07:04[0m [2;4m0.21it/s[0m  
[2KAttention weights: tensor([[0.6265, 0.3735]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 114/203 [2m0:06:58 â€¢ 0:07:04[0m [2;4m0.21it/s[0m  
[2KAttention weights: tensor([[0.6580, 0.3420]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 114/203 [2m0:06:58 â€¢ 0:07:04[0m [2;4m0.21it/s[0m  
[2KAttention weights: tensor([[0.6965, 0.3035]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 114/203 [2m0:06:58 â€¢ 0:07:04[0m [2;4m0.21it/s[0m  
[2KAttention weights: tensor([[0.7367, 0.2633]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 114/203 [2m0:06:58 â€¢ 0:07:04[0m [2;4m0.21it/s[0m  
[2KAttention weights: tensor([[0.7709, 0.2291]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 114/203 [2m0:06:58 â€¢ 0:07:04[0m [2;4m0.21it/s[0m  
[2KAttention weights: tensor([[0.7953, 0.2047]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 114/203 [2m0:06:58 â€¢ 0:07:04[0m [2;4m0.21it/s[0m  
[2KAttention weights: tensor([[0.8113, 0.1887]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 114/203 [2m0:06:58 â€¢ 0:07:04[0m [2;4m0.21it/s[0m  
[2KAttention weights: tensor([[0.8197, 0.1803]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 114/203 [2m0:06:58 â€¢ 0:07:04[0m [2;4m0.21it/s[0m  
[2KAttention weights: tensor([[0.8233, 0.1767]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 114/203 [2m0:06:58 â€¢ 0:07:04[0m [2;4m0.21it/s[0m  
[2KAttention weights: tensor([[0.5620, 0.4380]], device='cuda:0')[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 114/203 [2m0:06:58 â€¢ 0:07:04[0m [2;4m0.21it/s[0m  
[2KAttention weights: tensor([[0.7609, 0.2391],0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 114/203 [2m0:06:58 â€¢ 0:07:04[0m [2;4m0.21it/s[0m  
        [0.6663, 0.3337],
        [0.7325, 0.2675],
        [0.6697, 0.3303],
        [0.7055, 0.2945],
        [0.7776, 0.2224],
        [0.8243, 0.1757],
        [0.7653, 0.2347],
        [0.7329, 0.2671],
[2K        [0.7375, 0.2625]], device='cuda:0')[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 114/203 [2m0:06:58 â€¢ 0:07:04[0m [2;4m0.21it/s[0m  
[2KAttention weights: tensor([[0.5590, 0.4410],â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 115/203 [2m0:07:23 â€¢ 0:36:31[0m [2;4m0.04it/s[0m  
        [0.5537, 0.4463],
        [0.5563, 0.4437],
        [0.5555, 0.4445],
        [0.5539, 0.4461],
        [0.5533, 0.4467],
        [0.5543, 0.4457],
        [0.5577, 0.4423],
        [0.5579, 0.4421],
[2K        [0.5544, 0.4456]], device='cuda:0', grad_fn=<SoftmaxBackward0>);5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 115/203 [2m0:07:23 â€¢ 0:36:31[0m [2;4m0.04it/s[0m  
[2KClass label: ThrowDiscusâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 115/203 [2m0:07:23 â€¢ 0:36:31[0m [2;4m0.04it/s[0m  
[2KAttention weights: tensor([[0.6110, 0.3890]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 115/203 [2m0:07:23 â€¢ 0:36:31[0m [2;4m0.04it/s[0m  
[2KStep 0 - TTA Loss: 0.9255â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 115/203 [2m0:07:23 â€¢ 0:36:31[0m [2;4m0.04it/s[0m  
[2KAttention weights: tensor([[0.6110, 0.3890]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 115/203 [2m0:07:23 â€¢ 0:36:31[0m [2;4m0.04it/s[0m  
[2KAttention weights: tensor([[0.6121, 0.3879]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 115/203 [2m0:07:23 â€¢ 0:36:31[0m [2;4m0.04it/s[0m  
[2KAttention weights: tensor([[0.6176, 0.3824]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 115/203 [2m0:07:23 â€¢ 0:36:31[0m [2;4m0.04it/s[0m  
[2KAttention weights: tensor([[0.6301, 0.3699]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 115/203 [2m0:07:23 â€¢ 0:36:31[0m [2;4m0.04it/s[0m  
[2KAttention weights: tensor([[0.6518, 0.3482]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 115/203 [2m0:07:23 â€¢ 0:36:31[0m [2;4m0.04it/s[0m  
[2KAttention weights: tensor([[0.6815, 0.3185]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 115/203 [2m0:07:23 â€¢ 0:36:31[0m [2;4m0.04it/s[0m  
[2KAttention weights: tensor([[0.7155, 0.2845]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 115/203 [2m0:07:23 â€¢ 0:36:31[0m [2;4m0.04it/s[0m  
[2KAttention weights: tensor([[0.7525, 0.2475]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 115/203 [2m0:07:23 â€¢ 0:36:31[0m [2;4m0.04it/s[0m  
[2KAttention weights: tensor([[0.7907, 0.2093]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 115/203 [2m0:07:23 â€¢ 0:36:31[0m [2;4m0.04it/s[0m  
[2KAttention weights: tensor([[0.5605, 0.4395]], device='cuda:0')â•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 115/203 [2m0:07:23 â€¢ 0:36:31[0m [2;4m0.04it/s[0m  
[2KAttention weights: tensor([[0.7496, 0.2504],0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 115/203 [2m0:07:23 â€¢ 0:36:31[0m [2;4m0.04it/s[0m  
        [0.6682, 0.3318],
        [0.7667, 0.2333],
        [0.7126, 0.2874],
        [0.7124, 0.2876],
        [0.7620, 0.2380],
        [0.7759, 0.2241],
        [0.7433, 0.2567],
        [0.7726, 0.2274],
[2K        [0.8107, 0.1893]], device='cuda:0')[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 115/203 [2m0:07:23 â€¢ 0:36:31[0m [2;4m0.04it/s[0m  
[2KAttention weights: tensor([[0.5591, 0.4409],â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 116/203 [2m0:07:25 â€¢ 0:19:05[0m [2;4m0.08it/s[0m  
        [0.5537, 0.4463],
        [0.5563, 0.4437],
        [0.5555, 0.4445],
        [0.5540, 0.4460],
        [0.5533, 0.4467],
        [0.5543, 0.4457],
        [0.5577, 0.4423],
        [0.5579, 0.4421],
[2K        [0.5545, 0.4455]], device='cuda:0', grad_fn=<SoftmaxBackward0>);5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 116/203 [2m0:07:25 â€¢ 0:19:05[0m [2;4m0.08it/s[0m  
[2KClass label: HammerThrowâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 116/203 [2m0:07:25 â€¢ 0:19:05[0m [2;4m0.08it/s[0m  
[2KAttention weights: tensor([[0.5363, 0.4637]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 116/203 [2m0:07:25 â€¢ 0:19:05[0m [2;4m0.08it/s[0m  
[2KStep 0 - TTA Loss: 0.6559â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 116/203 [2m0:07:25 â€¢ 0:19:05[0m [2;4m0.08it/s[0m  
[2KAttention weights: tensor([[0.5720, 0.4280]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 116/203 [2m0:07:25 â€¢ 0:19:05[0m [2;4m0.08it/s[0m  
[2KAttention weights: tensor([[0.6186, 0.3814]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 116/203 [2m0:07:25 â€¢ 0:19:05[0m [2;4m0.08it/s[0m  
[2KAttention weights: tensor([[0.6659, 0.3341]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 116/203 [2m0:07:25 â€¢ 0:19:05[0m [2;4m0.08it/s[0m  
[2KAttention weights: tensor([[0.6993, 0.3007]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 116/203 [2m0:07:25 â€¢ 0:19:05[0m [2;4m0.08it/s[0m  
[2KAttention weights: tensor([[0.7221, 0.2779]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 116/203 [2m0:07:25 â€¢ 0:19:05[0m [2;4m0.08it/s[0m  
[2KAttention weights: tensor([[0.7483, 0.2517]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 116/203 [2m0:07:25 â€¢ 0:19:05[0m [2;4m0.08it/s[0m  
[2KAttention weights: tensor([[0.7759, 0.2241]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 116/203 [2m0:07:25 â€¢ 0:19:05[0m [2;4m0.08it/s[0m  
[2KAttention weights: tensor([[0.7967, 0.2033]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 116/203 [2m0:07:25 â€¢ 0:19:05[0m [2;4m0.08it/s[0m  
[2KAttention weights: tensor([[0.8070, 0.1930]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 116/203 [2m0:07:25 â€¢ 0:19:05[0m [2;4m0.08it/s[0m  
[2KAttention weights: tensor([[0.5620, 0.4380]], device='cuda:0')â•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 116/203 [2m0:07:25 â€¢ 0:19:05[0m [2;4m0.08it/s[0m  
[2KAttention weights: tensor([[0.7880, 0.2120],0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 116/203 [2m0:07:25 â€¢ 0:19:05[0m [2;4m0.08it/s[0m  
        [0.6901, 0.3099],
        [0.7726, 0.2274],
        [0.7379, 0.2621],
        [0.8100, 0.1900],
        [0.7840, 0.2160],
        [0.7851, 0.2149],
        [0.7875, 0.2125],
        [0.7891, 0.2109],
[2K        [0.8046, 0.1954]], device='cuda:0')[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 116/203 [2m0:07:25 â€¢ 0:19:05[0m [2;4m0.08it/s[0m  
[2KAttention weights: tensor([[0.5591, 0.4409],â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 117/203 [2m0:07:27 â€¢ 0:13:35[0m [2;4m0.11it/s[0m   
        [0.5537, 0.4463],
        [0.5563, 0.4437],
        [0.5555, 0.4445],
        [0.5540, 0.4460],
        [0.5533, 0.4467],
        [0.5544, 0.4456],
        [0.5577, 0.4423],
        [0.5580, 0.4420],
[2K        [0.5545, 0.4455]], device='cuda:0', grad_fn=<SoftmaxBackward0>)37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 117/203 [2m0:07:27 â€¢ 0:13:35[0m [2;4m0.11it/s[0m  
[2KClass label: HammerThrowâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 117/203 [2m0:07:27 â€¢ 0:13:35[0m [2;4m0.11it/s[0m  
[2KAttention weights: tensor([[0.5405, 0.4595]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 117/203 [2m0:07:27 â€¢ 0:13:35[0m [2;4m0.11it/s[0m  
[2KStep 0 - TTA Loss: 0.8778â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 117/203 [2m0:07:27 â€¢ 0:13:35[0m [2;4m0.11it/s[0m  
[2KAttention weights: tensor([[0.5405, 0.4595]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 117/203 [2m0:07:27 â€¢ 0:13:35[0m [2;4m0.11it/s[0m  
[2KAttention weights: tensor([[0.5459, 0.4541]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 117/203 [2m0:07:27 â€¢ 0:13:35[0m [2;4m0.11it/s[0m  
[2KAttention weights: tensor([[0.5683, 0.4317]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 117/203 [2m0:07:27 â€¢ 0:13:35[0m [2;4m0.11it/s[0m  
[2KAttention weights: tensor([[0.6173, 0.3827]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 117/203 [2m0:07:27 â€¢ 0:13:35[0m [2;4m0.11it/s[0m  
[2KAttention weights: tensor([[0.6985, 0.3015]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 117/203 [2m0:07:27 â€¢ 0:13:35[0m [2;4m0.11it/s[0m  
[2KAttention weights: tensor([[0.8025, 0.1975]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 117/203 [2m0:07:27 â€¢ 0:13:35[0m [2;4m0.11it/s[0m  
[2KAttention weights: tensor([[0.9012, 0.0988]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 117/203 [2m0:07:27 â€¢ 0:13:35[0m [2;4m0.11it/s[0m  
[2KAttention weights: tensor([[0.9672, 0.0328]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 117/203 [2m0:07:27 â€¢ 0:13:35[0m [2;4m0.11it/s[0m  
[2KAttention weights: tensor([[0.9927, 0.0073]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 117/203 [2m0:07:27 â€¢ 0:13:35[0m [2;4m0.11it/s[0m  
[2KAttention weights: tensor([[0.5821, 0.4179]], device='cuda:0')m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 117/203 [2m0:07:27 â€¢ 0:13:35[0m [2;4m0.11it/s[0m  
[2KAttention weights: tensor([[0.9793, 0.0207],[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 117/203 [2m0:07:27 â€¢ 0:13:35[0m [2;4m0.11it/s[0m  
        [0.9013, 0.0987],
        [0.9622, 0.0378],
        [0.9512, 0.0488],
        [0.9987, 0.0013],
        [0.9786, 0.0214],
        [0.9651, 0.0349],
        [0.9817, 0.0183],
        [0.9671, 0.0329],
[2K        [0.9803, 0.0197]], device='cuda:0')[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 117/203 [2m0:07:27 â€¢ 0:13:35[0m [2;4m0.11it/s[0m  
[2KAttention weights: tensor([[0.5591, 0.4409],â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 118/203 [2m0:07:30 â€¢ 0:03:22[0m [2;4m0.42it/s[0m  
        [0.5538, 0.4462],
        [0.5564, 0.4436],
        [0.5555, 0.4445],
        [0.5541, 0.4459],
        [0.5534, 0.4466],
        [0.5544, 0.4456],
        [0.5578, 0.4422],
        [0.5580, 0.4420],
[2K        [0.5546, 0.4454]], device='cuda:0', grad_fn=<SoftmaxBackward0>)37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 118/203 [2m0:07:30 â€¢ 0:03:22[0m [2;4m0.42it/s[0m  
[2KClass label: Billiardsâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 118/203 [2m0:07:30 â€¢ 0:03:22[0m [2;4m0.42it/s[0m  
[2KAttention weights: tensor([[0.5933, 0.4067]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 118/203 [2m0:07:30 â€¢ 0:03:22[0m [2;4m0.42it/s[0m  
[2KStep 0 - TTA Loss: 0.4512â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 118/203 [2m0:07:30 â€¢ 0:03:22[0m [2;4m0.42it/s[0m  
[2KAttention weights: tensor([[0.7158, 0.2842]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 118/203 [2m0:07:30 â€¢ 0:03:22[0m [2;4m0.42it/s[0m  
[2KAttention weights: tensor([[0.8122, 0.1878]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 118/203 [2m0:07:30 â€¢ 0:03:22[0m [2;4m0.42it/s[0m  
[2KAttention weights: tensor([[0.8714, 0.1286]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 118/203 [2m0:07:30 â€¢ 0:03:22[0m [2;4m0.42it/s[0m  
[2KAttention weights: tensor([[0.9067, 0.0933]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 118/203 [2m0:07:30 â€¢ 0:03:22[0m [2;4m0.42it/s[0m  
[2KAttention weights: tensor([[0.9308, 0.0692]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 118/203 [2m0:07:30 â€¢ 0:03:22[0m [2;4m0.42it/s[0m  
[2KAttention weights: tensor([[0.9511, 0.0489]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 118/203 [2m0:07:30 â€¢ 0:03:22[0m [2;4m0.42it/s[0m  
[2KAttention weights: tensor([[0.9645, 0.0355]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 118/203 [2m0:07:30 â€¢ 0:03:22[0m [2;4m0.42it/s[0m  
[2KAttention weights: tensor([[0.9724, 0.0276]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 118/203 [2m0:07:30 â€¢ 0:03:22[0m [2;4m0.42it/s[0m  
[2KAttention weights: tensor([[0.9758, 0.0242]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 118/203 [2m0:07:30 â€¢ 0:03:22[0m [2;4m0.42it/s[0m  
[2KAttention weights: tensor([[0.5757, 0.4243]], device='cuda:0')m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 118/203 [2m0:07:30 â€¢ 0:03:22[0m [2;4m0.42it/s[0m  
[2KAttention weights: tensor([[9.8780e-01, 1.2199e-02],5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 118/203 [2m0:07:30 â€¢ 0:03:22[0m [2;4m0.42it/s[0m  
        [9.7670e-01, 2.3299e-02],
        [9.7352e-01, 2.6483e-02],
        [9.7095e-01, 2.9053e-02],
        [9.9931e-01, 6.8820e-04],
        [9.8687e-01, 1.3126e-02],
        [9.7631e-01, 2.3686e-02],
        [9.9025e-01, 9.7501e-03],
        [9.8043e-01, 1.9568e-02],
[2K        [9.8651e-01, 1.3490e-02]], device='cuda:0');5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 118/203 [2m0:07:30 â€¢ 0:03:22[0m [2;4m0.42it/s[0m  
[2KAttention weights: tensor([[0.5592, 0.4408],â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 119/203 [2m0:07:42 â€¢ 0:06:43[0m [2;4m0.21it/s[0m  
        [0.5538, 0.4462],
        [0.5564, 0.4436],
        [0.5556, 0.4444],
        [0.5542, 0.4458],
        [0.5535, 0.4465],
        [0.5545, 0.4455],
        [0.5578, 0.4422],
        [0.5581, 0.4419],
[2K        [0.5547, 0.4453]], device='cuda:0', grad_fn=<SoftmaxBackward0>)37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 119/203 [2m0:07:42 â€¢ 0:06:43[0m [2;4m0.21it/s[0m  
[2KClass label: PoleVaultâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 119/203 [2m0:07:42 â€¢ 0:06:43[0m [2;4m0.21it/s[0m  
[2KAttention weights: tensor([[0.6162, 0.3838]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 119/203 [2m0:07:42 â€¢ 0:06:43[0m [2;4m0.21it/s[0m  
[2KStep 0 - TTA Loss: 0.7192â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 119/203 [2m0:07:42 â€¢ 0:06:43[0m [2;4m0.21it/s[0m  
[2KAttention weights: tensor([[0.6162, 0.3838]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 119/203 [2m0:07:42 â€¢ 0:06:43[0m [2;4m0.21it/s[0m  
[2KAttention weights: tensor([[0.6193, 0.3807]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 119/203 [2m0:07:42 â€¢ 0:06:43[0m [2;4m0.21it/s[0m  
[2KAttention weights: tensor([[0.6310, 0.3690]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 119/203 [2m0:07:42 â€¢ 0:06:43[0m [2;4m0.21it/s[0m  
[2KAttention weights: tensor([[0.6560, 0.3440]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 119/203 [2m0:07:42 â€¢ 0:06:43[0m [2;4m0.21it/s[0m  
[2KAttention weights: tensor([[0.6962, 0.3038]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 119/203 [2m0:07:42 â€¢ 0:06:43[0m [2;4m0.21it/s[0m  
[2KAttention weights: tensor([[0.7482, 0.2518]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 119/203 [2m0:07:42 â€¢ 0:06:43[0m [2;4m0.21it/s[0m  
[2KAttention weights: tensor([[0.8064, 0.1936]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 119/203 [2m0:07:42 â€¢ 0:06:43[0m [2;4m0.21it/s[0m  
[2KAttention weights: tensor([[0.8635, 0.1365]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 119/203 [2m0:07:42 â€¢ 0:06:43[0m [2;4m0.21it/s[0m  
[2KAttention weights: tensor([[0.9053, 0.0947]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 119/203 [2m0:07:42 â€¢ 0:06:43[0m [2;4m0.21it/s[0m  
[2KAttention weights: tensor([[0.5676, 0.4324]], device='cuda:0')m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 119/203 [2m0:07:42 â€¢ 0:06:43[0m [2;4m0.21it/s[0m  
[2KAttention weights: tensor([[0.9338, 0.0662],[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 119/203 [2m0:07:42 â€¢ 0:06:43[0m [2;4m0.21it/s[0m  
        [0.9791, 0.0209],
        [0.8898, 0.1102],
        [0.9101, 0.0899],
        [0.9461, 0.0539],
        [0.9346, 0.0654],
        [0.9341, 0.0659],
        [0.9472, 0.0528],
        [0.9280, 0.0720],
[2K        [0.9057, 0.0943]], device='cuda:0')[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 119/203 [2m0:07:42 â€¢ 0:06:43[0m [2;4m0.21it/s[0m  
[2KAttention weights: tensor([[0.5593, 0.4407],â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 120/203 [2m0:07:52 â€¢ 0:08:00[0m [2;4m0.17it/s[0m  
        [0.5539, 0.4461],
        [0.5565, 0.4435],
        [0.5557, 0.4443],
        [0.5543, 0.4457],
        [0.5535, 0.4465],
        [0.5546, 0.4454],
        [0.5579, 0.4421],
        [0.5581, 0.4419],
[2K        [0.5547, 0.4453]], device='cuda:0', grad_fn=<SoftmaxBackward0>)8;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 120/203 [2m0:07:52 â€¢ 0:08:00[0m [2;4m0.17it/s[0m  
[2KClass label: SoccerPenaltyâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 120/203 [2m0:07:52 â€¢ 0:08:00[0m [2;4m0.17it/s[0m  
[2KAttention weights: tensor([[0.6333, 0.3667]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 120/203 [2m0:07:52 â€¢ 0:08:00[0m [2;4m0.17it/s[0m  
[2KStep 0 - TTA Loss: 1.0452â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 120/203 [2m0:07:52 â€¢ 0:08:00[0m [2;4m0.17it/s[0m  
[2KAttention weights: tensor([[0.7269, 0.2731]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 120/203 [2m0:07:52 â€¢ 0:08:00[0m [2;4m0.17it/s[0m  
[2KAttention weights: tensor([[0.8070, 0.1930]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 120/203 [2m0:07:52 â€¢ 0:08:00[0m [2;4m0.17it/s[0m  
[2KAttention weights: tensor([[0.8670, 0.1330]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 120/203 [2m0:07:52 â€¢ 0:08:00[0m [2;4m0.17it/s[0m  
[2KAttention weights: tensor([[0.9011, 0.0989]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 120/203 [2m0:07:52 â€¢ 0:08:00[0m [2;4m0.17it/s[0m  
[2KAttention weights: tensor([[0.9145, 0.0855]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 120/203 [2m0:07:52 â€¢ 0:08:00[0m [2;4m0.17it/s[0m  
[2KAttention weights: tensor([[0.9131, 0.0869]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 120/203 [2m0:07:52 â€¢ 0:08:00[0m [2;4m0.17it/s[0m  
[2KAttention weights: tensor([[0.9124, 0.0876]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 120/203 [2m0:07:52 â€¢ 0:08:00[0m [2;4m0.17it/s[0m  
[2KAttention weights: tensor([[0.9131, 0.0869]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 120/203 [2m0:07:52 â€¢ 0:08:00[0m [2;4m0.17it/s[0m  
[2KAttention weights: tensor([[0.9139, 0.0861]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 120/203 [2m0:07:52 â€¢ 0:08:00[0m [2;4m0.17it/s[0m  
[2KAttention weights: tensor([[0.5685, 0.4315]], device='cuda:0')mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 120/203 [2m0:07:52 â€¢ 0:08:00[0m [2;4m0.17it/s[0m  
[2KAttention weights: tensor([[0.8922, 0.1078],[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 120/203 [2m0:07:52 â€¢ 0:08:00[0m [2;4m0.17it/s[0m  
        [0.9407, 0.0593],
        [0.8376, 0.1624],
        [0.8604, 0.1396],
        [0.8929, 0.1071],
        [0.8876, 0.1124],
        [0.8895, 0.1105],
        [0.9143, 0.0857],
        [0.8852, 0.1148],
[2K        [0.8537, 0.1463]], device='cuda:0')[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 120/203 [2m0:07:52 â€¢ 0:08:00[0m [2;4m0.17it/s[0m  
[2KAttention weights: tensor([[0.5593, 0.4407],â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 121/203 [2m0:07:53 â€¢ 0:06:49[0m [2;4m0.20it/s[0m  
        [0.5540, 0.4460],
        [0.5566, 0.4434],
        [0.5557, 0.4443],
        [0.5544, 0.4456],
        [0.5536, 0.4464],
        [0.5546, 0.4454],
        [0.5579, 0.4421],
        [0.5582, 0.4418],
[2K        [0.5548, 0.4452]], device='cuda:0', grad_fn=<SoftmaxBackward0>)8;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 121/203 [2m0:07:53 â€¢ 0:06:49[0m [2;4m0.20it/s[0m  
[2KClass label: SoccerPenaltyâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 121/203 [2m0:07:53 â€¢ 0:06:49[0m [2;4m0.20it/s[0m  
[2KAttention weights: tensor([[0.6364, 0.3636]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 121/203 [2m0:07:53 â€¢ 0:06:49[0m [2;4m0.20it/s[0m  
[2KStep 0 - TTA Loss: 0.9155â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 121/203 [2m0:07:53 â€¢ 0:06:49[0m [2;4m0.20it/s[0m  
[2KAttention weights: tensor([[0.6364, 0.3636]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 121/203 [2m0:07:53 â€¢ 0:06:49[0m [2;4m0.20it/s[0m  
[2KAttention weights: tensor([[0.6383, 0.3617]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 121/203 [2m0:07:53 â€¢ 0:06:49[0m [2;4m0.20it/s[0m  
[2KAttention weights: tensor([[0.6467, 0.3533]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 121/203 [2m0:07:53 â€¢ 0:06:49[0m [2;4m0.20it/s[0m  
[2KAttention weights: tensor([[0.6668, 0.3332]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 121/203 [2m0:07:53 â€¢ 0:06:49[0m [2;4m0.20it/s[0m  
[2KAttention weights: tensor([[0.7031, 0.2969]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 121/203 [2m0:07:53 â€¢ 0:06:49[0m [2;4m0.20it/s[0m  
[2KAttention weights: tensor([[0.7547, 0.2453]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 121/203 [2m0:07:53 â€¢ 0:06:49[0m [2;4m0.20it/s[0m  
[2KAttention weights: tensor([[0.8117, 0.1883]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 121/203 [2m0:07:53 â€¢ 0:06:49[0m [2;4m0.20it/s[0m  
[2KAttention weights: tensor([[0.8600, 0.1400]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 121/203 [2m0:07:53 â€¢ 0:06:49[0m [2;4m0.20it/s[0m  
[2KAttention weights: tensor([[0.8880, 0.1120]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 121/203 [2m0:07:53 â€¢ 0:06:49[0m [2;4m0.20it/s[0m  
[2KAttention weights: tensor([[0.5648, 0.4352]], device='cuda:0')mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 121/203 [2m0:07:53 â€¢ 0:06:49[0m [2;4m0.20it/s[0m  
[2KAttention weights: tensor([[0.8205, 0.1795],[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 121/203 [2m0:07:53 â€¢ 0:06:49[0m [2;4m0.20it/s[0m  
        [0.7894, 0.2106],
        [0.7338, 0.2662],
        [0.7779, 0.2221],
        [0.7618, 0.2382],
        [0.7864, 0.2136],
        [0.7803, 0.2197],
        [0.8974, 0.1026],
        [0.8136, 0.1864],
[2K        [0.7383, 0.2617]], device='cuda:0')[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 121/203 [2m0:07:53 â€¢ 0:06:49[0m [2;4m0.20it/s[0m  
[2KAttention weights: tensor([[0.5594, 0.4406],â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 122/203 [2m0:07:53 â€¢ 0:06:32[0m [2;4m0.21it/s[0m   
        [0.5540, 0.4460],
        [0.5566, 0.4434],
        [0.5557, 0.4443],
        [0.5544, 0.4456],
        [0.5536, 0.4464],
        [0.5547, 0.4453],
        [0.5579, 0.4421],
        [0.5582, 0.4418],
[2K        [0.5548, 0.4452]], device='cuda:0', grad_fn=<SoftmaxBackward0>)237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 122/203 [2m0:07:53 â€¢ 0:06:32[0m [2;4m0.21it/s[0m  
[2KClass label: SoccerPenaltyâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 122/203 [2m0:07:53 â€¢ 0:06:32[0m [2;4m0.21it/s[0m  
[2KAttention weights: tensor([[0.6340, 0.3660]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 122/203 [2m0:07:53 â€¢ 0:06:32[0m [2;4m0.21it/s[0m  
[2KStep 0 - TTA Loss: 0.4121â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 122/203 [2m0:07:53 â€¢ 0:06:32[0m [2;4m0.21it/s[0m  
[2KAttention weights: tensor([[0.6696, 0.3304]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 122/203 [2m0:07:53 â€¢ 0:06:32[0m [2;4m0.21it/s[0m  
[2KAttention weights: tensor([[0.7044, 0.2956]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 122/203 [2m0:07:53 â€¢ 0:06:32[0m [2;4m0.21it/s[0m  
[2KAttention weights: tensor([[0.7320, 0.2680]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 122/203 [2m0:07:53 â€¢ 0:06:32[0m [2;4m0.21it/s[0m  
[2KAttention weights: tensor([[0.7514, 0.2486]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 122/203 [2m0:07:53 â€¢ 0:06:32[0m [2;4m0.21it/s[0m  
[2KAttention weights: tensor([[0.7684, 0.2316]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 122/203 [2m0:07:53 â€¢ 0:06:32[0m [2;4m0.21it/s[0m  
[2KAttention weights: tensor([[0.7861, 0.2139]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 122/203 [2m0:07:53 â€¢ 0:06:32[0m [2;4m0.21it/s[0m  
[2KAttention weights: tensor([[0.8031, 0.1969]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 122/203 [2m0:07:53 â€¢ 0:06:32[0m [2;4m0.21it/s[0m  
[2KAttention weights: tensor([[0.8160, 0.1840]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 122/203 [2m0:07:53 â€¢ 0:06:32[0m [2;4m0.21it/s[0m  
[2KAttention weights: tensor([[0.8233, 0.1767]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 122/203 [2m0:07:53 â€¢ 0:06:32[0m [2;4m0.21it/s[0m  
[2KAttention weights: tensor([[0.5616, 0.4384]], device='cuda:0')0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 122/203 [2m0:07:53 â€¢ 0:06:32[0m [2;4m0.21it/s[0m  
[2KAttention weights: tensor([[0.7609, 0.2391],[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 122/203 [2m0:07:53 â€¢ 0:06:32[0m [2;4m0.21it/s[0m  
        [0.7234, 0.2766],
        [0.6917, 0.3083],
        [0.7208, 0.2792],
        [0.6884, 0.3116],
        [0.7223, 0.2777],
        [0.7246, 0.2754],
        [0.8254, 0.1746],
        [0.7618, 0.2382],
[2K        [0.6953, 0.3047]], device='cuda:0')â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 122/203 [2m0:07:53 â€¢ 0:06:32[0m [2;4m0.21it/s[0m  
[2KAttention weights: tensor([[0.5594, 0.4406],â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 123/203 [2m0:07:56 â€¢ 0:06:30[0m [2;4m0.21it/s[0m  
        [0.5540, 0.4460],
        [0.5566, 0.4434],
        [0.5558, 0.4442],
        [0.5544, 0.4456],
        [0.5537, 0.4463],
        [0.5547, 0.4453],
        [0.5580, 0.4420],
        [0.5582, 0.4418],
[2K        [0.5548, 0.4452]], device='cuda:0', grad_fn=<SoftmaxBackward0>)237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 123/203 [2m0:07:56 â€¢ 0:06:30[0m [2;4m0.21it/s[0m  
[2KClass label: TennisSwingâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 123/203 [2m0:07:56 â€¢ 0:06:30[0m [2;4m0.21it/s[0m  
[2KAttention weights: tensor([[0.6628, 0.3372]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 123/203 [2m0:07:56 â€¢ 0:06:30[0m [2;4m0.21it/s[0m  
[2KStep 0 - TTA Loss: 0.5863â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 123/203 [2m0:07:56 â€¢ 0:06:30[0m [2;4m0.21it/s[0m  
[2KAttention weights: tensor([[0.6628, 0.3372]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 123/203 [2m0:07:56 â€¢ 0:06:30[0m [2;4m0.21it/s[0m  
[2KAttention weights: tensor([[0.6658, 0.3342]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 123/203 [2m0:07:56 â€¢ 0:06:30[0m [2;4m0.21it/s[0m  
[2KAttention weights: tensor([[0.6805, 0.3195]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 123/203 [2m0:07:56 â€¢ 0:06:30[0m [2;4m0.21it/s[0m  
[2KAttention weights: tensor([[0.7160, 0.2840]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 123/203 [2m0:07:56 â€¢ 0:06:30[0m [2;4m0.21it/s[0m  
[2KAttention weights: tensor([[0.7738, 0.2262]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 123/203 [2m0:07:56 â€¢ 0:06:30[0m [2;4m0.21it/s[0m  
[2KAttention weights: tensor([[0.8532, 0.1468]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 123/203 [2m0:07:56 â€¢ 0:06:30[0m [2;4m0.21it/s[0m  
[2KAttention weights: tensor([[0.9277, 0.0723]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 123/203 [2m0:07:56 â€¢ 0:06:30[0m [2;4m0.21it/s[0m  
[2KAttention weights: tensor([[0.9729, 0.0271]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 123/203 [2m0:07:56 â€¢ 0:06:30[0m [2;4m0.21it/s[0m  
[2KAttention weights: tensor([[0.9904, 0.0096]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 123/203 [2m0:07:56 â€¢ 0:06:30[0m [2;4m0.21it/s[0m  
[2KAttention weights: tensor([[0.5805, 0.4195]], device='cuda:0')0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 123/203 [2m0:07:56 â€¢ 0:06:30[0m [2;4m0.21it/s[0m  
[2KAttention weights: tensor([[0.9640, 0.0360],[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 123/203 [2m0:07:56 â€¢ 0:06:30[0m [2;4m0.21it/s[0m  
        [0.9264, 0.0736],
        [0.9366, 0.0634],
        [0.9676, 0.0324],
        [0.9439, 0.0561],
        [0.9612, 0.0388],
        [0.9223, 0.0777],
        [0.9795, 0.0205],
        [0.9961, 0.0039],
[2K        [0.9556, 0.0444]], device='cuda:0')â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 123/203 [2m0:07:56 â€¢ 0:06:30[0m [2;4m0.21it/s[0m  
[2KAttention weights: tensor([[0.5595, 0.4405],â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 124/203 [2m0:08:01 â€¢ 0:04:59[0m [2;4m0.26it/s[0m  
        [0.5541, 0.4459],
        [0.5566, 0.4434],
        [0.5558, 0.4442],
        [0.5545, 0.4455],
        [0.5537, 0.4463],
        [0.5547, 0.4453],
        [0.5580, 0.4420],
        [0.5583, 0.4417],
[2K        [0.5549, 0.4451]], device='cuda:0', grad_fn=<SoftmaxBackward0>)237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 124/203 [2m0:08:01 â€¢ 0:04:59[0m [2;4m0.26it/s[0m  
[2KClass label: SoccerPenaltyâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 124/203 [2m0:08:01 â€¢ 0:04:59[0m [2;4m0.26it/s[0m  
[2KAttention weights: tensor([[0.6345, 0.3655]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 124/203 [2m0:08:01 â€¢ 0:04:59[0m [2;4m0.26it/s[0m  
[2KStep 0 - TTA Loss: 0.8000â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 124/203 [2m0:08:01 â€¢ 0:04:59[0m [2;4m0.26it/s[0m  
[2KAttention weights: tensor([[0.7638, 0.2362]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 124/203 [2m0:08:01 â€¢ 0:04:59[0m [2;4m0.26it/s[0m  
[2KAttention weights: tensor([[0.8586, 0.1414]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 124/203 [2m0:08:01 â€¢ 0:04:59[0m [2;4m0.26it/s[0m  
[2KAttention weights: tensor([[0.9129, 0.0871]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 124/203 [2m0:08:01 â€¢ 0:04:59[0m [2;4m0.26it/s[0m  
[2KAttention weights: tensor([[0.9344, 0.0656]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 124/203 [2m0:08:01 â€¢ 0:04:59[0m [2;4m0.26it/s[0m  
[2KAttention weights: tensor([[0.9341, 0.0659]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 124/203 [2m0:08:01 â€¢ 0:04:59[0m [2;4m0.26it/s[0m  
[2KAttention weights: tensor([[0.9198, 0.0802]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 124/203 [2m0:08:01 â€¢ 0:04:59[0m [2;4m0.26it/s[0m  
[2KAttention weights: tensor([[0.8945, 0.1055]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 124/203 [2m0:08:01 â€¢ 0:04:59[0m [2;4m0.26it/s[0m  
[2KAttention weights: tensor([[0.8730, 0.1270]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 124/203 [2m0:08:01 â€¢ 0:04:59[0m [2;4m0.26it/s[0m  
[2KAttention weights: tensor([[0.8616, 0.1384]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 124/203 [2m0:08:01 â€¢ 0:04:59[0m [2;4m0.26it/s[0m  
[2KAttention weights: tensor([[0.5635, 0.4365]], device='cuda:0')0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 124/203 [2m0:08:01 â€¢ 0:04:59[0m [2;4m0.26it/s[0m  
[2KAttention weights: tensor([[0.8760, 0.1240],[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 124/203 [2m0:08:01 â€¢ 0:04:59[0m [2;4m0.26it/s[0m  
        [0.8186, 0.1814],
        [0.8588, 0.1412],
        [0.8882, 0.1118],
        [0.8158, 0.1842],
        [0.8702, 0.1298],
        [0.8099, 0.1901],
        [0.8585, 0.1415],
        [0.9759, 0.0241],
[2K        [0.8856, 0.1144]], device='cuda:0')â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 124/203 [2m0:08:01 â€¢ 0:04:59[0m [2;4m0.26it/s[0m  
[2KAttention weights: tensor([[0.5594, 0.4406],â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 125/203 [2m0:08:03 â€¢ 0:04:34[0m [2;4m0.29it/s[0m  
        [0.5541, 0.4459],
        [0.5566, 0.4434],
        [0.5558, 0.4442],
        [0.5544, 0.4456],
        [0.5537, 0.4463],
        [0.5547, 0.4453],
        [0.5580, 0.4420],
        [0.5583, 0.4417],
[2K        [0.5549, 0.4451]], device='cuda:0', grad_fn=<SoftmaxBackward0>)38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 125/203 [2m0:08:03 â€¢ 0:04:34[0m [2;4m0.29it/s[0m  
[2KClass label: Billiardsâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 125/203 [2m0:08:03 â€¢ 0:04:34[0m [2;4m0.29it/s[0m  
[2KAttention weights: tensor([[0.5963, 0.4037]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 125/203 [2m0:08:03 â€¢ 0:04:34[0m [2;4m0.29it/s[0m  
[2KStep 0 - TTA Loss: 0.6613â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 125/203 [2m0:08:03 â€¢ 0:04:34[0m [2;4m0.29it/s[0m  
[2KAttention weights: tensor([[0.5963, 0.4037]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 125/203 [2m0:08:03 â€¢ 0:04:34[0m [2;4m0.29it/s[0m  
[2KAttention weights: tensor([[0.5953, 0.4047]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 125/203 [2m0:08:03 â€¢ 0:04:34[0m [2;4m0.29it/s[0m  
[2KAttention weights: tensor([[0.5932, 0.4068]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 125/203 [2m0:08:03 â€¢ 0:04:34[0m [2;4m0.29it/s[0m  
[2KAttention weights: tensor([[0.5920, 0.4080]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 125/203 [2m0:08:03 â€¢ 0:04:34[0m [2;4m0.29it/s[0m  
[2KAttention weights: tensor([[0.5938, 0.4062]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 125/203 [2m0:08:03 â€¢ 0:04:34[0m [2;4m0.29it/s[0m  
[2KAttention weights: tensor([[0.5995, 0.4005]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 125/203 [2m0:08:03 â€¢ 0:04:34[0m [2;4m0.29it/s[0m  
[2KAttention weights: tensor([[0.6060, 0.3940]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 125/203 [2m0:08:03 â€¢ 0:04:34[0m [2;4m0.29it/s[0m  
[2KAttention weights: tensor([[0.6080, 0.3920]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 125/203 [2m0:08:03 â€¢ 0:04:34[0m [2;4m0.29it/s[0m  
[2KAttention weights: tensor([[0.6111, 0.3889]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 125/203 [2m0:08:03 â€¢ 0:04:34[0m [2;4m0.29it/s[0m  
[2KAttention weights: tensor([[0.5540, 0.4460]], device='cuda:0')4mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 125/203 [2m0:08:03 â€¢ 0:04:34[0m [2;4m0.29it/s[0m  
[2KAttention weights: tensor([[0.4572, 0.5428],[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 125/203 [2m0:08:03 â€¢ 0:04:34[0m [2;4m0.29it/s[0m  
        [0.6296, 0.3704],
        [0.5848, 0.4152],
        [0.4824, 0.5176],
        [0.3473, 0.6527],
        [0.4515, 0.5485],
        [0.4615, 0.5385],
        [0.2076, 0.7924],
        [0.6130, 0.3870],
[2K        [0.5716, 0.4284]], device='cuda:0')â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 125/203 [2m0:08:03 â€¢ 0:04:34[0m [2;4m0.29it/s[0m  
[2KAttention weights: tensor([[0.5594, 0.4406],â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 126/203 [2m0:08:08 â€¢ 0:04:45[0m [2;4m0.27it/s[0m  
        [0.5540, 0.4460],
        [0.5566, 0.4434],
        [0.5558, 0.4442],
        [0.5544, 0.4456],
        [0.5536, 0.4464],
        [0.5547, 0.4453],
        [0.5579, 0.4421],
        [0.5583, 0.4417],
[2K        [0.5548, 0.4452]], device='cuda:0', grad_fn=<SoftmaxBackward0>)38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 126/203 [2m0:08:08 â€¢ 0:04:45[0m [2;4m0.27it/s[0m  
[2KClass label: BaseballPitchâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 126/203 [2m0:08:08 â€¢ 0:04:45[0m [2;4m0.27it/s[0m  
[2KAttention weights: tensor([[0.6437, 0.3563]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 126/203 [2m0:08:08 â€¢ 0:04:45[0m [2;4m0.27it/s[0m  
[2KStep 0 - TTA Loss: 0.6158â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 126/203 [2m0:08:08 â€¢ 0:04:45[0m [2;4m0.27it/s[0m  
[2KAttention weights: tensor([[0.6557, 0.3443]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 126/203 [2m0:08:08 â€¢ 0:04:45[0m [2;4m0.27it/s[0m  
[2KAttention weights: tensor([[0.6948, 0.3052]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 126/203 [2m0:08:08 â€¢ 0:04:45[0m [2;4m0.27it/s[0m  
[2KAttention weights: tensor([[0.7444, 0.2556]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 126/203 [2m0:08:08 â€¢ 0:04:45[0m [2;4m0.27it/s[0m  
[2KAttention weights: tensor([[0.7892, 0.2108]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 126/203 [2m0:08:08 â€¢ 0:04:45[0m [2;4m0.27it/s[0m  
[2KAttention weights: tensor([[0.8242, 0.1758]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 126/203 [2m0:08:08 â€¢ 0:04:45[0m [2;4m0.27it/s[0m  
[2KAttention weights: tensor([[0.8449, 0.1551]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 126/203 [2m0:08:08 â€¢ 0:04:45[0m [2;4m0.27it/s[0m  
[2KAttention weights: tensor([[0.8561, 0.1439]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 126/203 [2m0:08:08 â€¢ 0:04:45[0m [2;4m0.27it/s[0m  
[2KAttention weights: tensor([[0.8617, 0.1383]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 126/203 [2m0:08:08 â€¢ 0:04:45[0m [2;4m0.27it/s[0m  
[2KAttention weights: tensor([[0.8660, 0.1340]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 126/203 [2m0:08:08 â€¢ 0:04:45[0m [2;4m0.27it/s[0m  
[2KAttention weights: tensor([[0.5656, 0.4344]], device='cuda:0')4mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 126/203 [2m0:08:08 â€¢ 0:04:45[0m [2;4m0.27it/s[0m  
[2KAttention weights: tensor([[0.8670, 0.1330],[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 126/203 [2m0:08:08 â€¢ 0:04:45[0m [2;4m0.27it/s[0m  
        [0.7696, 0.2304],
        [0.6987, 0.3013],
        [0.7244, 0.2756],
        [0.6322, 0.3678],
        [0.6665, 0.3335],
        [0.6794, 0.3206],
        [0.5678, 0.4322],
        [0.7887, 0.2113],
[2K        [0.7057, 0.2943]], device='cuda:0')â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 126/203 [2m0:08:08 â€¢ 0:04:45[0m [2;4m0.27it/s[0m  
[2KAttention weights: tensor([[0.5594, 0.4406],â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 127/203 [2m0:08:12 â€¢ 0:04:39[0m [2;4m0.27it/s[0m   
        [0.5540, 0.4460],
        [0.5566, 0.4434],
        [0.5558, 0.4442],
        [0.5544, 0.4456],
        [0.5536, 0.4464],
        [0.5547, 0.4453],
        [0.5579, 0.4421],
        [0.5583, 0.4417],
[2K        [0.5548, 0.4452]], device='cuda:0', grad_fn=<SoftmaxBackward0>);237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 127/203 [2m0:08:12 â€¢ 0:04:39[0m [2;4m0.27it/s[0m  
[2KClass label: PoleVaultâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 127/203 [2m0:08:12 â€¢ 0:04:39[0m [2;4m0.27it/s[0m  
[2KAttention weights: tensor([[0.6121, 0.3879]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 127/203 [2m0:08:12 â€¢ 0:04:39[0m [2;4m0.27it/s[0m  
[2KStep 0 - TTA Loss: 0.7385â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 127/203 [2m0:08:12 â€¢ 0:04:39[0m [2;4m0.27it/s[0m  
[2KAttention weights: tensor([[0.6121, 0.3879]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 127/203 [2m0:08:12 â€¢ 0:04:39[0m [2;4m0.27it/s[0m  
[2KAttention weights: tensor([[0.6132, 0.3868]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 127/203 [2m0:08:12 â€¢ 0:04:39[0m [2;4m0.27it/s[0m  
[2KAttention weights: tensor([[0.6174, 0.3826]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 127/203 [2m0:08:12 â€¢ 0:04:39[0m [2;4m0.27it/s[0m  
[2KAttention weights: tensor([[0.6271, 0.3729]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 127/203 [2m0:08:12 â€¢ 0:04:39[0m [2;4m0.27it/s[0m  
[2KAttention weights: tensor([[0.6453, 0.3547]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 127/203 [2m0:08:12 â€¢ 0:04:39[0m [2;4m0.27it/s[0m  
[2KAttention weights: tensor([[0.6772, 0.3228]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 127/203 [2m0:08:12 â€¢ 0:04:39[0m [2;4m0.27it/s[0m  
[2KAttention weights: tensor([[0.7249, 0.2751]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 127/203 [2m0:08:12 â€¢ 0:04:39[0m [2;4m0.27it/s[0m  
[2KAttention weights: tensor([[0.7871, 0.2129]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 127/203 [2m0:08:12 â€¢ 0:04:39[0m [2;4m0.27it/s[0m  
[2KAttention weights: tensor([[0.8529, 0.1471]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 127/203 [2m0:08:12 â€¢ 0:04:39[0m [2;4m0.27it/s[0m  
[2KAttention weights: tensor([[0.5677, 0.4323]], device='cuda:0')[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 127/203 [2m0:08:12 â€¢ 0:04:39[0m [2;4m0.27it/s[0m  
[2KAttention weights: tensor([[0.9116, 0.0884],â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 127/203 [2m0:08:12 â€¢ 0:04:39[0m [2;4m0.27it/s[0m  
        [0.7866, 0.2134],
        [0.8259, 0.1741],
        [0.8322, 0.1678],
        [0.8374, 0.1626],
        [0.8790, 0.1210],
        [0.9118, 0.0882],
        [0.8638, 0.1362],
        [0.8584, 0.1416],
[2K        [0.8420, 0.1580]], device='cuda:0')â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 127/203 [2m0:08:12 â€¢ 0:04:39[0m [2;4m0.27it/s[0m  
[2KAttention weights: tensor([[0.5594, 0.4406],â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 128/203 [2m0:08:18 â€¢ 0:04:03[0m [2;4m0.31it/s[0m  
        [0.5540, 0.4460],
        [0.5566, 0.4434],
        [0.5558, 0.4442],
        [0.5544, 0.4456],
        [0.5537, 0.4463],
        [0.5547, 0.4453],
        [0.5579, 0.4421],
        [0.5583, 0.4417],
[2K        [0.5548, 0.4452]], device='cuda:0', grad_fn=<SoftmaxBackward0>);237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 128/203 [2m0:08:18 â€¢ 0:04:03[0m [2;4m0.31it/s[0m  
[2KClass label: Billiardsâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 128/203 [2m0:08:18 â€¢ 0:04:03[0m [2;4m0.31it/s[0m  
[2KAttention weights: tensor([[0.5960, 0.4040]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 128/203 [2m0:08:18 â€¢ 0:04:03[0m [2;4m0.31it/s[0m  
[2KStep 0 - TTA Loss: 0.4428â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 128/203 [2m0:08:18 â€¢ 0:04:03[0m [2;4m0.31it/s[0m  
[2KAttention weights: tensor([[0.6671, 0.3329]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 128/203 [2m0:08:18 â€¢ 0:04:03[0m [2;4m0.31it/s[0m  
[2KAttention weights: tensor([[0.7319, 0.2681]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 128/203 [2m0:08:18 â€¢ 0:04:03[0m [2;4m0.31it/s[0m  
[2KAttention weights: tensor([[0.7790, 0.2210]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 128/203 [2m0:08:18 â€¢ 0:04:03[0m [2;4m0.31it/s[0m  
[2KAttention weights: tensor([[0.8086, 0.1914]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 128/203 [2m0:08:18 â€¢ 0:04:03[0m [2;4m0.31it/s[0m  
[2KAttention weights: tensor([[0.8294, 0.1706]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 128/203 [2m0:08:18 â€¢ 0:04:03[0m [2;4m0.31it/s[0m  
[2KAttention weights: tensor([[0.8452, 0.1548]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 128/203 [2m0:08:18 â€¢ 0:04:03[0m [2;4m0.31it/s[0m  
[2KAttention weights: tensor([[0.8569, 0.1431]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 128/203 [2m0:08:18 â€¢ 0:04:03[0m [2;4m0.31it/s[0m  
[2KAttention weights: tensor([[0.8657, 0.1343]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 128/203 [2m0:08:18 â€¢ 0:04:03[0m [2;4m0.31it/s[0m  
[2KAttention weights: tensor([[0.8711, 0.1289]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 128/203 [2m0:08:18 â€¢ 0:04:03[0m [2;4m0.31it/s[0m  
[2KAttention weights: tensor([[0.5629, 0.4371]], device='cuda:0')[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 128/203 [2m0:08:18 â€¢ 0:04:03[0m [2;4m0.31it/s[0m  
[2KAttention weights: tensor([[0.9258, 0.0742],â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 128/203 [2m0:08:18 â€¢ 0:04:03[0m [2;4m0.31it/s[0m  
        [0.8726, 0.1274],
        [0.8643, 0.1357],
        [0.8712, 0.1288],
        [0.8804, 0.1196],
        [0.9192, 0.0808],
        [0.9444, 0.0556],
        [0.9065, 0.0935],
        [0.8901, 0.1099],
[2K        [0.8792, 0.1208]], device='cuda:0')â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 128/203 [2m0:08:18 â€¢ 0:04:03[0m [2;4m0.31it/s[0m  
[2KAttention weights: tensor([[0.5594, 0.4406],â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 129/203 [2m0:08:24 â€¢ 0:05:54[0m [2;4m0.21it/s[0m  
        [0.5541, 0.4459],
        [0.5566, 0.4434],
        [0.5558, 0.4442],
        [0.5544, 0.4456],
        [0.5537, 0.4463],
        [0.5547, 0.4453],
        [0.5579, 0.4421],
        [0.5583, 0.4417],
[2K        [0.5549, 0.4451]], device='cuda:0', grad_fn=<SoftmaxBackward0>);237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 129/203 [2m0:08:24 â€¢ 0:05:54[0m [2;4m0.21it/s[0m  
[2KClass label: Billiardsâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 129/203 [2m0:08:24 â€¢ 0:05:54[0m [2;4m0.21it/s[0m  
[2KAttention weights: tensor([[0.5929, 0.4071]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 129/203 [2m0:08:24 â€¢ 0:05:54[0m [2;4m0.21it/s[0m  
[2KStep 0 - TTA Loss: 0.6145â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 129/203 [2m0:08:24 â€¢ 0:05:54[0m [2;4m0.21it/s[0m  
[2KAttention weights: tensor([[0.5929, 0.4071]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 129/203 [2m0:08:24 â€¢ 0:05:54[0m [2;4m0.21it/s[0m  
[2KAttention weights: tensor([[0.5956, 0.4044]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 129/203 [2m0:08:24 â€¢ 0:05:54[0m [2;4m0.21it/s[0m  
[2KAttention weights: tensor([[0.6058, 0.3942]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 129/203 [2m0:08:24 â€¢ 0:05:54[0m [2;4m0.21it/s[0m  
[2KAttention weights: tensor([[0.6263, 0.3737]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 129/203 [2m0:08:24 â€¢ 0:05:54[0m [2;4m0.21it/s[0m  
[2KAttention weights: tensor([[0.6569, 0.3431]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 129/203 [2m0:08:24 â€¢ 0:05:54[0m [2;4m0.21it/s[0m  
[2KAttention weights: tensor([[0.6888, 0.3112]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 129/203 [2m0:08:24 â€¢ 0:05:54[0m [2;4m0.21it/s[0m  
[2KAttention weights: tensor([[0.7142, 0.2858]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 129/203 [2m0:08:24 â€¢ 0:05:54[0m [2;4m0.21it/s[0m  
[2KAttention weights: tensor([[0.7453, 0.2547]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 129/203 [2m0:08:24 â€¢ 0:05:54[0m [2;4m0.21it/s[0m  
[2KAttention weights: tensor([[0.8214, 0.1786]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 129/203 [2m0:08:24 â€¢ 0:05:54[0m [2;4m0.21it/s[0m  
[2KAttention weights: tensor([[0.5640, 0.4360]], device='cuda:0')[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 129/203 [2m0:08:24 â€¢ 0:05:54[0m [2;4m0.21it/s[0m  
[2KAttention weights: tensor([[0.8172, 0.1828],â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 129/203 [2m0:08:24 â€¢ 0:05:54[0m [2;4m0.21it/s[0m  
        [0.9344, 0.0656],
        [0.7530, 0.2470],
        [0.7893, 0.2107],
        [0.7346, 0.2654],
        [0.7897, 0.2103],
        [0.7919, 0.2081],
        [0.8267, 0.1733],
        [0.8233, 0.1767],
[2K        [0.7538, 0.2462]], device='cuda:0')â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 129/203 [2m0:08:24 â€¢ 0:05:54[0m [2;4m0.21it/s[0m  
[2KAttention weights: tensor([[0.5594, 0.4406],â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 130/203 [2m0:08:30 â€¢ 0:05:52[0m [2;4m0.21it/s[0m  
        [0.5541, 0.4459],
        [0.5566, 0.4434],
        [0.5558, 0.4442],
        [0.5544, 0.4456],
        [0.5537, 0.4463],
        [0.5547, 0.4453],
        [0.5579, 0.4421],
        [0.5583, 0.4417],
[2K        [0.5549, 0.4451]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 130/203 [2m0:08:30 â€¢ 0:05:52[0m [2;4m0.21it/s[0m  
[2KClass label: PoleVaultâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 130/203 [2m0:08:30 â€¢ 0:05:52[0m [2;4m0.21it/s[0m  
[2KAttention weights: tensor([[0.6083, 0.3917]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 130/203 [2m0:08:30 â€¢ 0:05:52[0m [2;4m0.21it/s[0m  
[2KStep 0 - TTA Loss: 0.7815â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 130/203 [2m0:08:30 â€¢ 0:05:52[0m [2;4m0.21it/s[0m  
[2KAttention weights: tensor([[0.6726, 0.3274]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 130/203 [2m0:08:30 â€¢ 0:05:52[0m [2;4m0.21it/s[0m  
[2KAttention weights: tensor([[0.7215, 0.2785]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 130/203 [2m0:08:30 â€¢ 0:05:52[0m [2;4m0.21it/s[0m  
[2KAttention weights: tensor([[0.7566, 0.2434]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 130/203 [2m0:08:30 â€¢ 0:05:52[0m [2;4m0.21it/s[0m  
[2KAttention weights: tensor([[0.7799, 0.2201]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 130/203 [2m0:08:30 â€¢ 0:05:52[0m [2;4m0.21it/s[0m  
[2KAttention weights: tensor([[0.7935, 0.2065]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 130/203 [2m0:08:30 â€¢ 0:05:52[0m [2;4m0.21it/s[0m  
[2KAttention weights: tensor([[0.8008, 0.1992]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 130/203 [2m0:08:30 â€¢ 0:05:52[0m [2;4m0.21it/s[0m  
[2KAttention weights: tensor([[0.8036, 0.1964]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 130/203 [2m0:08:30 â€¢ 0:05:52[0m [2;4m0.21it/s[0m  
[2KAttention weights: tensor([[0.8044, 0.1956]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 130/203 [2m0:08:30 â€¢ 0:05:52[0m [2;4m0.21it/s[0m  
[2KAttention weights: tensor([[0.8043, 0.1957]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 130/203 [2m0:08:30 â€¢ 0:05:52[0m [2;4m0.21it/s[0m  
[2KAttention weights: tensor([[0.5616, 0.4384]], device='cuda:0')24mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 130/203 [2m0:08:30 â€¢ 0:05:52[0m [2;4m0.21it/s[0m  
[2KAttention weights: tensor([[0.8642, 0.1358],â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 130/203 [2m0:08:30 â€¢ 0:05:52[0m [2;4m0.21it/s[0m  
        [0.9910, 0.0090],
        [0.7855, 0.2145],
        [0.8596, 0.1404],
        [0.7818, 0.2182],
        [0.8277, 0.1723],
        [0.8043, 0.1957],
        [0.8896, 0.1104],
        [0.8820, 0.1180],
[2K        [0.7825, 0.2175]], device='cuda:0')â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 130/203 [2m0:08:30 â€¢ 0:05:52[0m [2;4m0.21it/s[0m  
[2KAttention weights: tensor([[0.5594, 0.4406],â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 131/203 [2m0:08:33 â€¢ 0:06:00[0m [2;4m0.20it/s[0m  
        [0.5542, 0.4458],
        [0.5567, 0.4433],
        [0.5559, 0.4441],
        [0.5545, 0.4455],
        [0.5537, 0.4463],
        [0.5548, 0.4452],
        [0.5579, 0.4421],
        [0.5583, 0.4417],
[2K        [0.5549, 0.4451]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 131/203 [2m0:08:33 â€¢ 0:06:00[0m [2;4m0.20it/s[0m  
[2KClass label: CleanAndJerkâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 131/203 [2m0:08:33 â€¢ 0:06:00[0m [2;4m0.20it/s[0m  
[2KAttention weights: tensor([[0.6224, 0.3776]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 131/203 [2m0:08:33 â€¢ 0:06:00[0m [2;4m0.20it/s[0m  
[2KStep 0 - TTA Loss: 0.5563â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 131/203 [2m0:08:33 â€¢ 0:06:00[0m [2;4m0.20it/s[0m  
[2KAttention weights: tensor([[0.6224, 0.3776]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 131/203 [2m0:08:33 â€¢ 0:06:00[0m [2;4m0.20it/s[0m  
[2KAttention weights: tensor([[0.6235, 0.3765]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 131/203 [2m0:08:33 â€¢ 0:06:00[0m [2;4m0.20it/s[0m  
[2KAttention weights: tensor([[0.6301, 0.3699]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 131/203 [2m0:08:33 â€¢ 0:06:00[0m [2;4m0.20it/s[0m  
[2KAttention weights: tensor([[0.6472, 0.3528]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 131/203 [2m0:08:33 â€¢ 0:06:00[0m [2;4m0.20it/s[0m  
[2KAttention weights: tensor([[0.6793, 0.3207]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 131/203 [2m0:08:33 â€¢ 0:06:00[0m [2;4m0.20it/s[0m  
[2KAttention weights: tensor([[0.7264, 0.2736]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 131/203 [2m0:08:33 â€¢ 0:06:00[0m [2;4m0.20it/s[0m  
[2KAttention weights: tensor([[0.7807, 0.2193]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 131/203 [2m0:08:33 â€¢ 0:06:00[0m [2;4m0.20it/s[0m  
[2KAttention weights: tensor([[0.8311, 0.1689]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 131/203 [2m0:08:33 â€¢ 0:06:00[0m [2;4m0.20it/s[0m  
[2KAttention weights: tensor([[0.8765, 0.1235]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 131/203 [2m0:08:33 â€¢ 0:06:00[0m [2;4m0.20it/s[0m  
[2KAttention weights: tensor([[0.5661, 0.4339]], device='cuda:0')24mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 131/203 [2m0:08:33 â€¢ 0:06:00[0m [2;4m0.20it/s[0m  
[2KAttention weights: tensor([[0.7690, 0.2310],â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 131/203 [2m0:08:33 â€¢ 0:06:00[0m [2;4m0.20it/s[0m  
        [0.8252, 0.1748],
        [0.9252, 0.0748],
        [0.7694, 0.2306],
        [0.7534, 0.2466],
        [0.7807, 0.2193],
        [0.7588, 0.2412],
        [0.7704, 0.2296],
        [0.8405, 0.1595],
[2K        [0.8554, 0.1446]], device='cuda:0')â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 131/203 [2m0:08:33 â€¢ 0:06:00[0m [2;4m0.20it/s[0m  
[2KAttention weights: tensor([[0.5595, 0.4405],â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m 132/203 [2m0:08:36 â€¢ 0:05:35[0m [2;4m0.21it/s[0m   
        [0.5542, 0.4458],
        [0.5567, 0.4433],
        [0.5559, 0.4441],
        [0.5545, 0.4455],
        [0.5537, 0.4463],
        [0.5548, 0.4452],
        [0.5579, 0.4421],
        [0.5584, 0.4416],
[2K        [0.5549, 0.4451]], device='cuda:0', grad_fn=<SoftmaxBackward0>)5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m 132/203 [2m0:08:36 â€¢ 0:05:35[0m [2;4m0.21it/s[0m  
[2KClass label: Billiardsâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m 132/203 [2m0:08:36 â€¢ 0:05:35[0m [2;4m0.21it/s[0m  
[2KAttention weights: tensor([[0.5968, 0.4032]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 132/203 [2m0:08:36 â€¢ 0:05:35[0m [2;4m0.21it/s[0m  
[2KStep 0 - TTA Loss: 0.6415â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m 132/203 [2m0:08:36 â€¢ 0:05:35[0m [2;4m0.21it/s[0m  
[2KAttention weights: tensor([[0.6749, 0.3251]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 132/203 [2m0:08:36 â€¢ 0:05:35[0m [2;4m0.21it/s[0m  
[2KAttention weights: tensor([[0.7517, 0.2483]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 132/203 [2m0:08:36 â€¢ 0:05:35[0m [2;4m0.21it/s[0m  
[2KAttention weights: tensor([[0.8073, 0.1927]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 132/203 [2m0:08:36 â€¢ 0:05:35[0m [2;4m0.21it/s[0m  
[2KAttention weights: tensor([[0.8427, 0.1573]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 132/203 [2m0:08:36 â€¢ 0:05:35[0m [2;4m0.21it/s[0m  
[2KAttention weights: tensor([[0.8704, 0.1296]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 132/203 [2m0:08:36 â€¢ 0:05:35[0m [2;4m0.21it/s[0m  
[2KAttention weights: tensor([[0.8996, 0.1004]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 132/203 [2m0:08:36 â€¢ 0:05:35[0m [2;4m0.21it/s[0m  
[2KAttention weights: tensor([[0.9236, 0.0764]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 132/203 [2m0:08:36 â€¢ 0:05:35[0m [2;4m0.21it/s[0m  
[2KAttention weights: tensor([[0.9402, 0.0598]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 132/203 [2m0:08:36 â€¢ 0:05:35[0m [2;4m0.21it/s[0m  
[2KAttention weights: tensor([[0.9483, 0.0517]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 132/203 [2m0:08:36 â€¢ 0:05:35[0m [2;4m0.21it/s[0m  
[2KAttention weights: tensor([[0.5696, 0.4304]], device='cuda:0')[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m 132/203 [2m0:08:36 â€¢ 0:05:35[0m [2;4m0.21it/s[0m  
[2KAttention weights: tensor([[0.8414, 0.1586],â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m 132/203 [2m0:08:36 â€¢ 0:05:35[0m [2;4m0.21it/s[0m  
        [0.9506, 0.0494],
        [0.9516, 0.0484],
        [0.8481, 0.1519],
        [0.8299, 0.1701],
        [0.8533, 0.1467],
        [0.8277, 0.1723],
        [0.8543, 0.1457],
        [0.8975, 0.1025],
[2K        [0.8986, 0.1014]], device='cuda:0')â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m 132/203 [2m0:08:36 â€¢ 0:05:35[0m [2;4m0.21it/s[0m  
[2KAttention weights: tensor([[0.5595, 0.4405],â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m 133/203 [2m0:08:42 â€¢ 0:05:42[0m [2;4m0.20it/s[0m  
        [0.5543, 0.4457],
        [0.5567, 0.4433],
        [0.5559, 0.4441],
        [0.5545, 0.4455],
        [0.5538, 0.4462],
        [0.5548, 0.4452],
        [0.5580, 0.4420],
        [0.5584, 0.4416],
[2K        [0.5550, 0.4450]], device='cuda:0', grad_fn=<SoftmaxBackward0>)5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m 133/203 [2m0:08:42 â€¢ 0:05:42[0m [2;4m0.20it/s[0m  
[2KClass label: TennisSwingâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m 133/203 [2m0:08:42 â€¢ 0:05:42[0m [2;4m0.20it/s[0m  
[2KAttention weights: tensor([[0.6646, 0.3354]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 133/203 [2m0:08:42 â€¢ 0:05:42[0m [2;4m0.20it/s[0m  
[2KStep 0 - TTA Loss: 0.7408â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m 133/203 [2m0:08:42 â€¢ 0:05:42[0m [2;4m0.20it/s[0m  
[2KAttention weights: tensor([[0.6646, 0.3354]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 133/203 [2m0:08:42 â€¢ 0:05:42[0m [2;4m0.20it/s[0m  
[2KAttention weights: tensor([[0.6668, 0.3332]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 133/203 [2m0:08:42 â€¢ 0:05:42[0m [2;4m0.20it/s[0m  
[2KAttention weights: tensor([[0.6734, 0.3266]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 133/203 [2m0:08:42 â€¢ 0:05:42[0m [2;4m0.20it/s[0m  
[2KAttention weights: tensor([[0.6825, 0.3175]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 133/203 [2m0:08:42 â€¢ 0:05:42[0m [2;4m0.20it/s[0m  
[2KAttention weights: tensor([[0.6891, 0.3109]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 133/203 [2m0:08:42 â€¢ 0:05:42[0m [2;4m0.20it/s[0m  
[2KAttention weights: tensor([[0.6847, 0.3153]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 133/203 [2m0:08:42 â€¢ 0:05:42[0m [2;4m0.20it/s[0m  
[2KAttention weights: tensor([[0.6584, 0.3416]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 133/203 [2m0:08:42 â€¢ 0:05:42[0m [2;4m0.20it/s[0m  
[2KAttention weights: tensor([[0.6094, 0.3906]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 133/203 [2m0:08:42 â€¢ 0:05:42[0m [2;4m0.20it/s[0m  
[2KAttention weights: tensor([[0.5699, 0.4301]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 133/203 [2m0:08:42 â€¢ 0:05:42[0m [2;4m0.20it/s[0m  
[2KAttention weights: tensor([[0.5547, 0.4453]], device='cuda:0')[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m 133/203 [2m0:08:42 â€¢ 0:05:42[0m [2;4m0.20it/s[0m  
[2KAttention weights: tensor([[0.7214, 0.2786],â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m 133/203 [2m0:08:42 â€¢ 0:05:42[0m [2;4m0.20it/s[0m  
        [0.9757, 0.0243],
        [0.7021, 0.2979],
        [0.6920, 0.3080],
        [0.6257, 0.3743],
        [0.6679, 0.3321],
        [0.6962, 0.3038],
        [0.7632, 0.2368],
        [0.5752, 0.4248],
[2K        [0.6318, 0.3682]], device='cuda:0')â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m 133/203 [2m0:08:42 â€¢ 0:05:42[0m [2;4m0.20it/s[0m  
[2KAttention weights: tensor([[0.5595, 0.4405],â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m 134/203 [2m0:08:57 â€¢ 0:07:53[0m [2;4m0.15it/s[0m  
        [0.5543, 0.4457],
        [0.5568, 0.4432],
        [0.5559, 0.4441],
        [0.5545, 0.4455],
        [0.5538, 0.4462],
        [0.5548, 0.4452],
        [0.5580, 0.4420],
        [0.5584, 0.4416],
[2K        [0.5549, 0.4451]], device='cuda:0', grad_fn=<SoftmaxBackward0>)5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m 134/203 [2m0:08:57 â€¢ 0:07:53[0m [2;4m0.15it/s[0m  
[2KClass label: HighJumpâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m 134/203 [2m0:08:57 â€¢ 0:07:53[0m [2;4m0.15it/s[0m  
[2KAttention weights: tensor([[0.6026, 0.3974]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 134/203 [2m0:08:57 â€¢ 0:07:53[0m [2;4m0.15it/s[0m  
[2KStep 0 - TTA Loss: 0.7032â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m 134/203 [2m0:08:57 â€¢ 0:07:53[0m [2;4m0.15it/s[0m  
[2KAttention weights: tensor([[0.6370, 0.3630]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 134/203 [2m0:08:57 â€¢ 0:07:53[0m [2;4m0.15it/s[0m  
[2KAttention weights: tensor([[0.6747, 0.3253]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 134/203 [2m0:08:57 â€¢ 0:07:53[0m [2;4m0.15it/s[0m  
[2KAttention weights: tensor([[0.7145, 0.2855]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 134/203 [2m0:08:57 â€¢ 0:07:53[0m [2;4m0.15it/s[0m  
[2KAttention weights: tensor([[0.7529, 0.2471]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 134/203 [2m0:08:57 â€¢ 0:07:53[0m [2;4m0.15it/s[0m  
[2KAttention weights: tensor([[0.7807, 0.2193]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 134/203 [2m0:08:57 â€¢ 0:07:53[0m [2;4m0.15it/s[0m  
[2KAttention weights: tensor([[0.7990, 0.2010]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 134/203 [2m0:08:57 â€¢ 0:07:53[0m [2;4m0.15it/s[0m  
[2KAttention weights: tensor([[0.8086, 0.1914]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 134/203 [2m0:08:57 â€¢ 0:07:53[0m [2;4m0.15it/s[0m  
[2KAttention weights: tensor([[0.8124, 0.1876]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 134/203 [2m0:08:57 â€¢ 0:07:53[0m [2;4m0.15it/s[0m  
[2KAttention weights: tensor([[0.8135, 0.1865]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 134/203 [2m0:08:57 â€¢ 0:07:53[0m [2;4m0.15it/s[0m  
[2KAttention weights: tensor([[0.5599, 0.4401]], device='cuda:0')[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m 134/203 [2m0:08:57 â€¢ 0:07:53[0m [2;4m0.15it/s[0m  
[2KAttention weights: tensor([[0.7839, 0.2161],â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m 134/203 [2m0:08:57 â€¢ 0:07:53[0m [2;4m0.15it/s[0m  
        [0.9486, 0.0514],
        [0.7681, 0.2319],
        [0.7655, 0.2345],
        [0.7316, 0.2684],
        [0.8136, 0.1864],
        [0.7786, 0.2214],
        [0.8195, 0.1805],
        [0.7625, 0.2375],
[2K        [0.7497, 0.2503]], device='cuda:0')â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m 134/203 [2m0:08:57 â€¢ 0:07:53[0m [2;4m0.15it/s[0m  
[2KAttention weights: tensor([[0.5595, 0.4405],â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m 135/203 [2m0:09:02 â€¢ 0:08:11[0m [2;4m0.14it/s[0m  
        [0.5543, 0.4457],
        [0.5568, 0.4432],
        [0.5559, 0.4441],
        [0.5545, 0.4455],
        [0.5538, 0.4462],
        [0.5548, 0.4452],
        [0.5580, 0.4420],
        [0.5583, 0.4417],
[2K        [0.5549, 0.4451]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m 135/203 [2m0:09:02 â€¢ 0:08:11[0m [2;4m0.14it/s[0m  
[2KClass label: CleanAndJerkâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m 135/203 [2m0:09:02 â€¢ 0:08:11[0m [2;4m0.14it/s[0m  
[2KAttention weights: tensor([[0.6188, 0.3812]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 135/203 [2m0:09:02 â€¢ 0:08:11[0m [2;4m0.14it/s[0m  
[2KStep 0 - TTA Loss: 0.5635â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m 135/203 [2m0:09:02 â€¢ 0:08:11[0m [2;4m0.14it/s[0m  
[2KAttention weights: tensor([[0.6188, 0.3812]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 135/203 [2m0:09:02 â€¢ 0:08:11[0m [2;4m0.14it/s[0m  
[2KAttention weights: tensor([[0.6197, 0.3803]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 135/203 [2m0:09:02 â€¢ 0:08:11[0m [2;4m0.14it/s[0m  
[2KAttention weights: tensor([[0.6241, 0.3759]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 135/203 [2m0:09:02 â€¢ 0:08:11[0m [2;4m0.14it/s[0m  
[2KAttention weights: tensor([[0.6358, 0.3642]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 135/203 [2m0:09:02 â€¢ 0:08:11[0m [2;4m0.14it/s[0m  
[2KAttention weights: tensor([[0.6567, 0.3433]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 135/203 [2m0:09:02 â€¢ 0:08:11[0m [2;4m0.14it/s[0m  
[2KAttention weights: tensor([[0.6854, 0.3146]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 135/203 [2m0:09:02 â€¢ 0:08:11[0m [2;4m0.14it/s[0m  
[2KAttention weights: tensor([[0.7168, 0.2832]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 135/203 [2m0:09:02 â€¢ 0:08:11[0m [2;4m0.14it/s[0m  
[2KAttention weights: tensor([[0.7442, 0.2558]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 135/203 [2m0:09:02 â€¢ 0:08:11[0m [2;4m0.14it/s[0m  
[2KAttention weights: tensor([[0.7694, 0.2306]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 135/203 [2m0:09:02 â€¢ 0:08:11[0m [2;4m0.14it/s[0m  
[2KAttention weights: tensor([[0.5598, 0.4402]], device='cuda:0')224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m 135/203 [2m0:09:02 â€¢ 0:08:11[0m [2;4m0.14it/s[0m  
[2KAttention weights: tensor([[0.7022, 0.2978],â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m 135/203 [2m0:09:02 â€¢ 0:08:11[0m [2;4m0.14it/s[0m  
        [0.7274, 0.2726],
        [0.8049, 0.1951],
        [0.6833, 0.3167],
        [0.6432, 0.3568],
        [0.6886, 0.3114],
        [0.6924, 0.3076],
        [0.7020, 0.2980],
        [0.7397, 0.2603],
[2K        [0.7405, 0.2595]], device='cuda:0')â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m 135/203 [2m0:09:02 â€¢ 0:08:11[0m [2;4m0.14it/s[0m  
[2KAttention weights: tensor([[0.5595, 0.4405],â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m 136/203 [2m0:09:09 â€¢ 0:10:00[0m [2;4m0.11it/s[0m  
        [0.5543, 0.4457],
        [0.5567, 0.4433],
        [0.5559, 0.4441],
        [0.5545, 0.4455],
        [0.5537, 0.4463],
        [0.5548, 0.4452],
        [0.5579, 0.4421],
        [0.5583, 0.4417],
[2K        [0.5549, 0.4451]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m 136/203 [2m0:09:09 â€¢ 0:10:00[0m [2;4m0.11it/s[0m  
[2KClass label: GolfSwingâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m 136/203 [2m0:09:09 â€¢ 0:10:00[0m [2;4m0.11it/s[0m  
[2KAttention weights: tensor([[0.6073, 0.3927]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 136/203 [2m0:09:09 â€¢ 0:10:00[0m [2;4m0.11it/s[0m  
[2KStep 0 - TTA Loss: 0.5963â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m 136/203 [2m0:09:09 â€¢ 0:10:00[0m [2;4m0.11it/s[0m  
[2KAttention weights: tensor([[0.6462, 0.3538]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 136/203 [2m0:09:09 â€¢ 0:10:00[0m [2;4m0.11it/s[0m  
[2KAttention weights: tensor([[0.6972, 0.3028]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 136/203 [2m0:09:09 â€¢ 0:10:00[0m [2;4m0.11it/s[0m  
[2KAttention weights: tensor([[0.7475, 0.2525]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 136/203 [2m0:09:09 â€¢ 0:10:00[0m [2;4m0.11it/s[0m  
[2KAttention weights: tensor([[0.7866, 0.2134]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 136/203 [2m0:09:09 â€¢ 0:10:00[0m [2;4m0.11it/s[0m  
[2KAttention weights: tensor([[0.8122, 0.1878]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 136/203 [2m0:09:09 â€¢ 0:10:00[0m [2;4m0.11it/s[0m  
[2KAttention weights: tensor([[0.8292, 0.1708]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 136/203 [2m0:09:09 â€¢ 0:10:00[0m [2;4m0.11it/s[0m  
[2KAttention weights: tensor([[0.8398, 0.1602]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 136/203 [2m0:09:09 â€¢ 0:10:00[0m [2;4m0.11it/s[0m  
[2KAttention weights: tensor([[0.8457, 0.1543]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 136/203 [2m0:09:09 â€¢ 0:10:00[0m [2;4m0.11it/s[0m  
[2KAttention weights: tensor([[0.8485, 0.1515]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 136/203 [2m0:09:09 â€¢ 0:10:00[0m [2;4m0.11it/s[0m  
[2KAttention weights: tensor([[0.5634, 0.4366]], device='cuda:0')224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m 136/203 [2m0:09:09 â€¢ 0:10:00[0m [2;4m0.11it/s[0m  
[2KAttention weights: tensor([[0.7917, 0.2083],â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m 136/203 [2m0:09:09 â€¢ 0:10:00[0m [2;4m0.11it/s[0m  
        [0.7691, 0.2309],
        [0.8370, 0.1630],
        [0.8492, 0.1508],
        [0.7258, 0.2742],
        [0.7612, 0.2388],
        [0.7563, 0.2437],
        [0.7862, 0.2138],
        [0.8239, 0.1761],
[2K        [0.8008, 0.1992]], device='cuda:0')â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m 136/203 [2m0:09:09 â€¢ 0:10:00[0m [2;4m0.11it/s[0m  
[2KAttention weights: tensor([[0.5595, 0.4405],â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m 137/203 [2m0:09:13 â€¢ 0:05:46[0m [2;4m0.19it/s[0m  
        [0.5543, 0.4457],
        [0.5567, 0.4433],
        [0.5558, 0.4442],
        [0.5544, 0.4456],
        [0.5537, 0.4463],
        [0.5547, 0.4453],
        [0.5579, 0.4421],
        [0.5583, 0.4417],
[2K        [0.5549, 0.4451]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m 137/203 [2m0:09:13 â€¢ 0:05:46[0m [2;4m0.19it/s[0m  
[2KClass label: SoccerPenaltyâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m 137/203 [2m0:09:13 â€¢ 0:05:46[0m [2;4m0.19it/s[0m  
[2KAttention weights: tensor([[0.6300, 0.3700]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 137/203 [2m0:09:13 â€¢ 0:05:46[0m [2;4m0.19it/s[0m  
[2KStep 0 - TTA Loss: 0.7707â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m 137/203 [2m0:09:13 â€¢ 0:05:46[0m [2;4m0.19it/s[0m  
[2KAttention weights: tensor([[0.6300, 0.3700]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 137/203 [2m0:09:13 â€¢ 0:05:46[0m [2;4m0.19it/s[0m  
[2KAttention weights: tensor([[0.6304, 0.3696]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 137/203 [2m0:09:13 â€¢ 0:05:46[0m [2;4m0.19it/s[0m  
[2KAttention weights: tensor([[0.6320, 0.3680]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 137/203 [2m0:09:13 â€¢ 0:05:46[0m [2;4m0.19it/s[0m  
[2KAttention weights: tensor([[0.6348, 0.3652]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 137/203 [2m0:09:13 â€¢ 0:05:46[0m [2;4m0.19it/s[0m  
[2KAttention weights: tensor([[0.6383, 0.3617]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 137/203 [2m0:09:13 â€¢ 0:05:46[0m [2;4m0.19it/s[0m  
[2KAttention weights: tensor([[0.6395, 0.3605]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 137/203 [2m0:09:13 â€¢ 0:05:46[0m [2;4m0.19it/s[0m  
[2KAttention weights: tensor([[0.6342, 0.3658]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 137/203 [2m0:09:13 â€¢ 0:05:46[0m [2;4m0.19it/s[0m  
[2KAttention weights: tensor([[0.6141, 0.3859]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 137/203 [2m0:09:13 â€¢ 0:05:46[0m [2;4m0.19it/s[0m  
[2KAttention weights: tensor([[0.5757, 0.4243]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 137/203 [2m0:09:13 â€¢ 0:05:46[0m [2;4m0.19it/s[0m  
[2KAttention weights: tensor([[0.5543, 0.4457]], device='cuda:0')224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m 137/203 [2m0:09:13 â€¢ 0:05:46[0m [2;4m0.19it/s[0m  
[2KAttention weights: tensor([[0.6189, 0.3811],â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m 137/203 [2m0:09:13 â€¢ 0:05:46[0m [2;4m0.19it/s[0m  
        [0.5874, 0.4126],
        [0.6472, 0.3528],
        [0.6428, 0.3572],
        [0.5073, 0.4927],
        [0.5744, 0.4256],
        [0.5876, 0.4124],
        [0.5276, 0.4724],
        [0.6593, 0.3407],
[2K        [0.6316, 0.3684]], device='cuda:0')â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m 137/203 [2m0:09:13 â€¢ 0:05:46[0m [2;4m0.19it/s[0m  
[2KAttention weights: tensor([[0.5594, 0.4406],â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”[0m 138/203 [2m0:09:15 â€¢ 0:04:50[0m [2;4m0.22it/s[0m   
        [0.5543, 0.4457],
        [0.5567, 0.4433],
        [0.5558, 0.4442],
        [0.5544, 0.4456],
        [0.5537, 0.4463],
        [0.5547, 0.4453],
        [0.5579, 0.4421],
        [0.5583, 0.4417],
[2K        [0.5549, 0.4451]], device='cuda:0', grad_fn=<SoftmaxBackward0>);5;237mâ”â”â”â”â”â”â”â”â”â”â”â”[0m 138/203 [2m0:09:15 â€¢ 0:04:50[0m [2;4m0.22it/s[0m  
[2KClass label: PoleVaultâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”[0m 138/203 [2m0:09:15 â€¢ 0:04:50[0m [2;4m0.22it/s[0m  
[2KAttention weights: tensor([[0.6159, 0.3841]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 138/203 [2m0:09:15 â€¢ 0:04:50[0m [2;4m0.22it/s[0m  
[2KStep 0 - TTA Loss: 0.7420â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”[0m 138/203 [2m0:09:15 â€¢ 0:04:50[0m [2;4m0.22it/s[0m  
[2KAttention weights: tensor([[0.6257, 0.3743]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 138/203 [2m0:09:15 â€¢ 0:04:50[0m [2;4m0.22it/s[0m  
[2KAttention weights: tensor([[0.6546, 0.3454]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 138/203 [2m0:09:15 â€¢ 0:04:50[0m [2;4m0.22it/s[0m  
[2KAttention weights: tensor([[0.6985, 0.3015]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 138/203 [2m0:09:15 â€¢ 0:04:50[0m [2;4m0.22it/s[0m  
[2KAttention weights: tensor([[0.7456, 0.2544]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 138/203 [2m0:09:15 â€¢ 0:04:50[0m [2;4m0.22it/s[0m  
[2KAttention weights: tensor([[0.7869, 0.2131]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 138/203 [2m0:09:15 â€¢ 0:04:50[0m [2;4m0.22it/s[0m  
[2KAttention weights: tensor([[0.8162, 0.1838]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 138/203 [2m0:09:15 â€¢ 0:04:50[0m [2;4m0.22it/s[0m  
[2KAttention weights: tensor([[0.8343, 0.1657]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 138/203 [2m0:09:15 â€¢ 0:04:50[0m [2;4m0.22it/s[0m  
[2KAttention weights: tensor([[0.8435, 0.1565]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 138/203 [2m0:09:15 â€¢ 0:04:50[0m [2;4m0.22it/s[0m  
[2KAttention weights: tensor([[0.8470, 0.1530]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 138/203 [2m0:09:15 â€¢ 0:04:50[0m [2;4m0.22it/s[0m  
[2KAttention weights: tensor([[0.5631, 0.4369]], device='cuda:0')â•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”[0m 138/203 [2m0:09:15 â€¢ 0:04:50[0m [2;4m0.22it/s[0m  
[2KAttention weights: tensor([[0.7725, 0.2275],â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”[0m 138/203 [2m0:09:15 â€¢ 0:04:50[0m [2;4m0.22it/s[0m  
        [0.6816, 0.3184],
        [0.7826, 0.2174],
        [0.7516, 0.2484],
        [0.7126, 0.2874],
        [0.7994, 0.2006],
        [0.8480, 0.1520],
        [0.6896, 0.3104],
        [0.7754, 0.2246],
[2K        [0.7880, 0.2120]], device='cuda:0')â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”[0m 138/203 [2m0:09:15 â€¢ 0:04:50[0m [2;4m0.22it/s[0m  
[2KAttention weights: tensor([[0.5594, 0.4406],â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”[0m 139/203 [2m0:09:24 â€¢ 0:05:45[0m [2;4m0.19it/s[0m  
        [0.5543, 0.4457],
        [0.5567, 0.4433],
        [0.5558, 0.4442],
        [0.5544, 0.4456],
        [0.5537, 0.4463],
        [0.5547, 0.4453],
        [0.5579, 0.4421],
        [0.5583, 0.4417],
[2K        [0.5549, 0.4451]], device='cuda:0', grad_fn=<SoftmaxBackward0>);5;237mâ”â”â”â”â”â”â”â”â”â”â”â”[0m 139/203 [2m0:09:24 â€¢ 0:05:45[0m [2;4m0.19it/s[0m  
[2KClass label: PoleVaultâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”[0m 139/203 [2m0:09:24 â€¢ 0:05:45[0m [2;4m0.19it/s[0m  
[2KAttention weights: tensor([[0.6105, 0.3895]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 139/203 [2m0:09:24 â€¢ 0:05:45[0m [2;4m0.19it/s[0m  
[2KStep 0 - TTA Loss: 0.7665â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”[0m 139/203 [2m0:09:24 â€¢ 0:05:45[0m [2;4m0.19it/s[0m  
[2KAttention weights: tensor([[0.6105, 0.3895]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 139/203 [2m0:09:24 â€¢ 0:05:45[0m [2;4m0.19it/s[0m  
[2KAttention weights: tensor([[0.6122, 0.3878]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 139/203 [2m0:09:24 â€¢ 0:05:45[0m [2;4m0.19it/s[0m  
[2KAttention weights: tensor([[0.6192, 0.3808]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 139/203 [2m0:09:24 â€¢ 0:05:45[0m [2;4m0.19it/s[0m  
[2KAttention weights: tensor([[0.6350, 0.3650]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 139/203 [2m0:09:24 â€¢ 0:05:45[0m [2;4m0.19it/s[0m  
[2KAttention weights: tensor([[0.6605, 0.3395]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 139/203 [2m0:09:24 â€¢ 0:05:45[0m [2;4m0.19it/s[0m  
[2KAttention weights: tensor([[0.6948, 0.3052]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 139/203 [2m0:09:24 â€¢ 0:05:45[0m [2;4m0.19it/s[0m  
[2KAttention weights: tensor([[0.7437, 0.2563]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 139/203 [2m0:09:24 â€¢ 0:05:45[0m [2;4m0.19it/s[0m  
[2KAttention weights: tensor([[0.8038, 0.1962]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 139/203 [2m0:09:24 â€¢ 0:05:45[0m [2;4m0.19it/s[0m  
[2KAttention weights: tensor([[0.8650, 0.1350]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 139/203 [2m0:09:24 â€¢ 0:05:45[0m [2;4m0.19it/s[0m  
[2KAttention weights: tensor([[0.5685, 0.4315]], device='cuda:0')â•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”[0m 139/203 [2m0:09:24 â€¢ 0:05:45[0m [2;4m0.19it/s[0m  
[2KAttention weights: tensor([[0.8539, 0.1461],â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”[0m 139/203 [2m0:09:24 â€¢ 0:05:45[0m [2;4m0.19it/s[0m  
        [0.7491, 0.2509],
        [0.8254, 0.1746],
        [0.8085, 0.1915],
        [0.8177, 0.1823],
        [0.8795, 0.1205],
        [0.9159, 0.0841],
        [0.8491, 0.1509],
        [0.8347, 0.1653],
[2K        [0.8406, 0.1594]], device='cuda:0')â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”[0m 139/203 [2m0:09:24 â€¢ 0:05:45[0m [2;4m0.19it/s[0m  
[2KAttention weights: tensor([[0.5594, 0.4406],â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”[0m 140/203 [2m0:09:28 â€¢ 0:05:25[0m [2;4m0.19it/s[0m  
        [0.5543, 0.4457],
        [0.5567, 0.4433],
        [0.5558, 0.4442],
        [0.5544, 0.4456],
        [0.5537, 0.4463],
        [0.5548, 0.4452],
        [0.5579, 0.4421],
        [0.5583, 0.4417],
[2K        [0.5549, 0.4451]], device='cuda:0', grad_fn=<SoftmaxBackward0>)m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”[0m 140/203 [2m0:09:28 â€¢ 0:05:25[0m [2;4m0.19it/s[0m  
[2KClass label: PoleVaultâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”[0m 140/203 [2m0:09:28 â€¢ 0:05:25[0m [2;4m0.19it/s[0m  
[2KAttention weights: tensor([[0.6104, 0.3896]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 140/203 [2m0:09:28 â€¢ 0:05:25[0m [2;4m0.19it/s[0m  
[2KStep 0 - TTA Loss: 0.7489â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”[0m 140/203 [2m0:09:28 â€¢ 0:05:25[0m [2;4m0.19it/s[0m  
[2KAttention weights: tensor([[0.7198, 0.2802]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 140/203 [2m0:09:28 â€¢ 0:05:25[0m [2;4m0.19it/s[0m  
[2KAttention weights: tensor([[0.8002, 0.1998]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 140/203 [2m0:09:28 â€¢ 0:05:25[0m [2;4m0.19it/s[0m  
[2KAttention weights: tensor([[0.8510, 0.1490]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 140/203 [2m0:09:28 â€¢ 0:05:25[0m [2;4m0.19it/s[0m  
[2KAttention weights: tensor([[0.8853, 0.1147]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 140/203 [2m0:09:28 â€¢ 0:05:25[0m [2;4m0.19it/s[0m  
[2KAttention weights: tensor([[0.9050, 0.0950]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 140/203 [2m0:09:28 â€¢ 0:05:25[0m [2;4m0.19it/s[0m  
[2KAttention weights: tensor([[0.9108, 0.0892]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 140/203 [2m0:09:28 â€¢ 0:05:25[0m [2;4m0.19it/s[0m  
[2KAttention weights: tensor([[0.9094, 0.0906]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 140/203 [2m0:09:28 â€¢ 0:05:25[0m [2;4m0.19it/s[0m  
[2KAttention weights: tensor([[0.9061, 0.0939]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 140/203 [2m0:09:28 â€¢ 0:05:25[0m [2;4m0.19it/s[0m  
[2KAttention weights: tensor([[0.9032, 0.0968]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 140/203 [2m0:09:28 â€¢ 0:05:25[0m [2;4m0.19it/s[0m  
[2KAttention weights: tensor([[0.5656, 0.4344]], device='cuda:0');224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”[0m 140/203 [2m0:09:28 â€¢ 0:05:25[0m [2;4m0.19it/s[0m  
[2KAttention weights: tensor([[0.8433, 0.1567],â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”[0m 140/203 [2m0:09:28 â€¢ 0:05:25[0m [2;4m0.19it/s[0m  
        [0.7397, 0.2603],
        [0.8113, 0.1887],
        [0.7938, 0.2062],
        [0.8035, 0.1965],
        [0.8657, 0.1343],
        [0.9024, 0.0976],
        [0.8411, 0.1589],
        [0.8248, 0.1752],
[2K        [0.8264, 0.1736]], device='cuda:0')â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”[0m 140/203 [2m0:09:28 â€¢ 0:05:25[0m [2;4m0.19it/s[0m  
[2KAttention weights: tensor([[0.5594, 0.4406],â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”[0m 141/203 [2m0:09:30 â€¢ 0:04:49[0m [2;4m0.22it/s[0m  
        [0.5543, 0.4457],
        [0.5566, 0.4434],
        [0.5558, 0.4442],
        [0.5544, 0.4456],
        [0.5537, 0.4463],
        [0.5547, 0.4453],
        [0.5578, 0.4422],
        [0.5583, 0.4417],
[2K        [0.5549, 0.4451]], device='cuda:0', grad_fn=<SoftmaxBackward0>)m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”[0m 141/203 [2m0:09:30 â€¢ 0:04:49[0m [2;4m0.22it/s[0m  
[2KClass label: TennisSwingâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”[0m 141/203 [2m0:09:30 â€¢ 0:04:49[0m [2;4m0.22it/s[0m  
[2KAttention weights: tensor([[0.6595, 0.3405]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 141/203 [2m0:09:30 â€¢ 0:04:49[0m [2;4m0.22it/s[0m  
[2KStep 0 - TTA Loss: 1.0564â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”[0m 141/203 [2m0:09:30 â€¢ 0:04:49[0m [2;4m0.22it/s[0m  
[2KAttention weights: tensor([[0.6595, 0.3405]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 141/203 [2m0:09:30 â€¢ 0:04:49[0m [2;4m0.22it/s[0m  
[2KAttention weights: tensor([[0.6578, 0.3422]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 141/203 [2m0:09:30 â€¢ 0:04:49[0m [2;4m0.22it/s[0m  
[2KAttention weights: tensor([[0.6512, 0.3488]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 141/203 [2m0:09:30 â€¢ 0:04:49[0m [2;4m0.22it/s[0m  
[2KAttention weights: tensor([[0.6355, 0.3645]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 141/203 [2m0:09:30 â€¢ 0:04:49[0m [2;4m0.22it/s[0m  
[2KAttention weights: tensor([[0.6063, 0.3937]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 141/203 [2m0:09:30 â€¢ 0:04:49[0m [2;4m0.22it/s[0m  
[2KAttention weights: tensor([[0.5680, 0.4320]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 141/203 [2m0:09:30 â€¢ 0:04:49[0m [2;4m0.22it/s[0m  
[2KAttention weights: tensor([[0.5048, 0.4952]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 141/203 [2m0:09:30 â€¢ 0:04:49[0m [2;4m0.22it/s[0m  
[2KAttention weights: tensor([[0.4280, 0.5720]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 141/203 [2m0:09:30 â€¢ 0:04:49[0m [2;4m0.22it/s[0m  
[2KAttention weights: tensor([[0.3459, 0.6541]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 141/203 [2m0:09:30 â€¢ 0:04:49[0m [2;4m0.22it/s[0m  
[2KAttention weights: tensor([[0.5479, 0.4521]], device='cuda:0');224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”[0m 141/203 [2m0:09:30 â€¢ 0:04:49[0m [2;4m0.22it/s[0m  
[2KAttention weights: tensor([[0.3803, 0.6197],â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”[0m 141/203 [2m0:09:30 â€¢ 0:04:49[0m [2;4m0.22it/s[0m  
        [0.4114, 0.5886],
        [0.3883, 0.6117],
        [0.3441, 0.6559],
        [0.2725, 0.7275],
        [0.2903, 0.7097],
        [0.3084, 0.6916],
        [0.3629, 0.6371],
        [0.2949, 0.7051],
[2K        [0.3448, 0.6552]], device='cuda:0')â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”[0m 141/203 [2m0:09:30 â€¢ 0:04:49[0m [2;4m0.22it/s[0m  
[2KAttention weights: tensor([[0.5594, 0.4406],â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”[0m 142/203 [2m0:09:31 â€¢ 0:04:15[0m [2;4m0.24it/s[0m  
        [0.5542, 0.4458],
        [0.5566, 0.4434],
        [0.5558, 0.4442],
        [0.5543, 0.4457],
        [0.5536, 0.4464],
        [0.5546, 0.4454],
        [0.5578, 0.4422],
        [0.5582, 0.4418],
[2K        [0.5548, 0.4452]], device='cuda:0', grad_fn=<SoftmaxBackward0>)m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”[0m 142/203 [2m0:09:31 â€¢ 0:04:15[0m [2;4m0.24it/s[0m  
[2KClass label: PoleVaultâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”[0m 142/203 [2m0:09:31 â€¢ 0:04:15[0m [2;4m0.24it/s[0m  
[2KAttention weights: tensor([[0.6142, 0.3858]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 142/203 [2m0:09:31 â€¢ 0:04:15[0m [2;4m0.24it/s[0m  
[2KStep 0 - TTA Loss: 0.7666â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”[0m 142/203 [2m0:09:31 â€¢ 0:04:15[0m [2;4m0.24it/s[0m  
[2KAttention weights: tensor([[0.5880, 0.4120]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 142/203 [2m0:09:31 â€¢ 0:04:15[0m [2;4m0.24it/s[0m  
[2KAttention weights: tensor([[0.5812, 0.4188]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 142/203 [2m0:09:31 â€¢ 0:04:15[0m [2;4m0.24it/s[0m  
[2KAttention weights: tensor([[0.5877, 0.4123]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 142/203 [2m0:09:31 â€¢ 0:04:15[0m [2;4m0.24it/s[0m  
[2KAttention weights: tensor([[0.5992, 0.4008]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 142/203 [2m0:09:31 â€¢ 0:04:15[0m [2;4m0.24it/s[0m  
[2KAttention weights: tensor([[0.6110, 0.3890]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 142/203 [2m0:09:31 â€¢ 0:04:15[0m [2;4m0.24it/s[0m  
[2KAttention weights: tensor([[0.6200, 0.3800]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 142/203 [2m0:09:31 â€¢ 0:04:15[0m [2;4m0.24it/s[0m  
[2KAttention weights: tensor([[0.6277, 0.3723]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 142/203 [2m0:09:31 â€¢ 0:04:15[0m [2;4m0.24it/s[0m  
[2KAttention weights: tensor([[0.6336, 0.3664]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 142/203 [2m0:09:31 â€¢ 0:04:15[0m [2;4m0.24it/s[0m  
[2KAttention weights: tensor([[0.6371, 0.3629]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 142/203 [2m0:09:31 â€¢ 0:04:15[0m [2;4m0.24it/s[0m  
[2KAttention weights: tensor([[0.5551, 0.4449]], device='cuda:0');224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”[0m 142/203 [2m0:09:31 â€¢ 0:04:15[0m [2;4m0.24it/s[0m  
[2KAttention weights: tensor([[0.6192, 0.3808],â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”[0m 142/203 [2m0:09:31 â€¢ 0:04:15[0m [2;4m0.24it/s[0m  
        [0.5638, 0.4362],
        [0.5981, 0.4019],
        [0.5614, 0.4386],
        [0.5258, 0.4742],
        [0.5879, 0.4121],
        [0.6382, 0.3618],
        [0.6152, 0.3848],
        [0.5525, 0.4475],
[2K        [0.5854, 0.4146]], device='cuda:0')â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”[0m 142/203 [2m0:09:31 â€¢ 0:04:15[0m [2;4m0.24it/s[0m  
[2KAttention weights: tensor([[0.5593, 0.4407],â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”[0m 143/203 [2m0:09:35 â€¢ 0:03:39[0m [2;4m0.27it/s[0m   
        [0.5542, 0.4458],
        [0.5566, 0.4434],
        [0.5557, 0.4443],
        [0.5543, 0.4457],
        [0.5536, 0.4464],
        [0.5546, 0.4454],
        [0.5578, 0.4422],
        [0.5582, 0.4418],
[2K        [0.5548, 0.4452]], device='cuda:0', grad_fn=<SoftmaxBackward0>)8;5;237mâ”â”â”â”â”â”â”â”â”â”â”[0m 143/203 [2m0:09:35 â€¢ 0:03:39[0m [2;4m0.27it/s[0m  
[2KClass label: HammerThrowâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”[0m 143/203 [2m0:09:35 â€¢ 0:03:39[0m [2;4m0.27it/s[0m  
[2KAttention weights: tensor([[0.5399, 0.4601]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 143/203 [2m0:09:35 â€¢ 0:03:39[0m [2;4m0.27it/s[0m  
[2KStep 0 - TTA Loss: 0.6752â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”[0m 143/203 [2m0:09:35 â€¢ 0:03:39[0m [2;4m0.27it/s[0m  
[2KAttention weights: tensor([[0.5399, 0.4601]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 143/203 [2m0:09:35 â€¢ 0:03:39[0m [2;4m0.27it/s[0m  
[2KAttention weights: tensor([[0.5423, 0.4577]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 143/203 [2m0:09:35 â€¢ 0:03:39[0m [2;4m0.27it/s[0m  
[2KAttention weights: tensor([[0.5541, 0.4459]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 143/203 [2m0:09:35 â€¢ 0:03:39[0m [2;4m0.27it/s[0m  
[2KAttention weights: tensor([[0.5849, 0.4151]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 143/203 [2m0:09:35 â€¢ 0:03:39[0m [2;4m0.27it/s[0m  
[2KAttention weights: tensor([[0.6429, 0.3571]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 143/203 [2m0:09:35 â€¢ 0:03:39[0m [2;4m0.27it/s[0m  
[2KAttention weights: tensor([[0.7292, 0.2708]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 143/203 [2m0:09:35 â€¢ 0:03:39[0m [2;4m0.27it/s[0m  
[2KAttention weights: tensor([[0.8307, 0.1693]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 143/203 [2m0:09:35 â€¢ 0:03:39[0m [2;4m0.27it/s[0m  
[2KAttention weights: tensor([[0.9201, 0.0799]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 143/203 [2m0:09:35 â€¢ 0:03:39[0m [2;4m0.27it/s[0m  
[2KAttention weights: tensor([[0.9689, 0.0311]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 143/203 [2m0:09:35 â€¢ 0:03:39[0m [2;4m0.27it/s[0m  
[2KAttention weights: tensor([[0.5748, 0.4252]], device='cuda:0')mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”[0m 143/203 [2m0:09:35 â€¢ 0:03:39[0m [2;4m0.27it/s[0m  
[2KAttention weights: tensor([[0.9458, 0.0542],â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”[0m 143/203 [2m0:09:35 â€¢ 0:03:39[0m [2;4m0.27it/s[0m  
        [0.8376, 0.1624],
        [0.9160, 0.0840],
        [0.8976, 0.1024],
        [0.9892, 0.0108],
        [0.9443, 0.0557],
        [0.9324, 0.0676],
        [0.9482, 0.0518],
        [0.9202, 0.0798],
[2K        [0.9441, 0.0559]], device='cuda:0')â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”[0m 143/203 [2m0:09:35 â€¢ 0:03:39[0m [2;4m0.27it/s[0m  
[2KAttention weights: tensor([[0.5594, 0.4406],â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”[0m 144/203 [2m0:09:49 â€¢ 0:04:49[0m [2;4m0.20it/s[0m  
        [0.5542, 0.4458],
        [0.5566, 0.4434],
        [0.5558, 0.4442],
        [0.5544, 0.4456],
        [0.5536, 0.4464],
        [0.5546, 0.4454],
        [0.5578, 0.4422],
        [0.5582, 0.4418],
[2K        [0.5548, 0.4452]], device='cuda:0', grad_fn=<SoftmaxBackward0>)8;5;237mâ”â”â”â”â”â”â”â”â”â”â”[0m 144/203 [2m0:09:49 â€¢ 0:04:49[0m [2;4m0.20it/s[0m  
[2KClass label: PoleVaultâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”[0m 144/203 [2m0:09:49 â€¢ 0:04:49[0m [2;4m0.20it/s[0m  
[2KAttention weights: tensor([[0.6157, 0.3843]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 144/203 [2m0:09:49 â€¢ 0:04:49[0m [2;4m0.20it/s[0m  
[2KStep 0 - TTA Loss: 0.7165â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”[0m 144/203 [2m0:09:49 â€¢ 0:04:49[0m [2;4m0.20it/s[0m  
[2KAttention weights: tensor([[0.7378, 0.2622]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 144/203 [2m0:09:49 â€¢ 0:04:49[0m [2;4m0.20it/s[0m  
[2KAttention weights: tensor([[0.8407, 0.1593]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 144/203 [2m0:09:49 â€¢ 0:04:49[0m [2;4m0.20it/s[0m  
[2KAttention weights: tensor([[0.9138, 0.0862]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 144/203 [2m0:09:49 â€¢ 0:04:49[0m [2;4m0.20it/s[0m  
[2KAttention weights: tensor([[0.9566, 0.0434]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 144/203 [2m0:09:49 â€¢ 0:04:49[0m [2;4m0.20it/s[0m  
[2KAttention weights: tensor([[0.9772, 0.0228]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 144/203 [2m0:09:49 â€¢ 0:04:49[0m [2;4m0.20it/s[0m  
[2KAttention weights: tensor([[0.9867, 0.0133]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 144/203 [2m0:09:49 â€¢ 0:04:49[0m [2;4m0.20it/s[0m  
[2KAttention weights: tensor([[0.9907, 0.0093]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 144/203 [2m0:09:49 â€¢ 0:04:49[0m [2;4m0.20it/s[0m  
[2KAttention weights: tensor([[0.9925, 0.0075]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 144/203 [2m0:09:49 â€¢ 0:04:49[0m [2;4m0.20it/s[0m  
[2KAttention weights: tensor([[0.9931, 0.0069]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 144/203 [2m0:09:49 â€¢ 0:04:49[0m [2;4m0.20it/s[0m  
[2KAttention weights: tensor([[0.5818, 0.4182]], device='cuda:0')mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”[0m 144/203 [2m0:09:49 â€¢ 0:04:49[0m [2;4m0.20it/s[0m  
[2KAttention weights: tensor([[0.9872, 0.0128],â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”[0m 144/203 [2m0:09:49 â€¢ 0:04:49[0m [2;4m0.20it/s[0m  
        [0.9278, 0.0722],
        [0.9747, 0.0253],
        [0.9680, 0.0320],
        [0.9979, 0.0021],
        [0.9919, 0.0081],
        [0.9933, 0.0067],
        [0.9890, 0.0110],
        [0.9747, 0.0253],
[2K        [0.9861, 0.0139]], device='cuda:0')â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”[0m 144/203 [2m0:09:49 â€¢ 0:04:49[0m [2;4m0.20it/s[0m  
[2KAttention weights: tensor([[0.5595, 0.4405],â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”[0m 145/203 [2m0:10:04 â€¢ 0:14:21[0m [2;4m0.07it/s[0m  
        [0.5543, 0.4457],
        [0.5567, 0.4433],
        [0.5558, 0.4442],
        [0.5545, 0.4455],
        [0.5537, 0.4463],
        [0.5547, 0.4453],
        [0.5579, 0.4421],
        [0.5583, 0.4417],
[2K        [0.5549, 0.4451]], device='cuda:0', grad_fn=<SoftmaxBackward0>)0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”[0m 145/203 [2m0:10:04 â€¢ 0:14:21[0m [2;4m0.07it/s[0m  
[2KClass label: TennisSwingâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”[0m 145/203 [2m0:10:04 â€¢ 0:14:21[0m [2;4m0.07it/s[0m  
[2KAttention weights: tensor([[0.6614, 0.3386]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 145/203 [2m0:10:04 â€¢ 0:14:21[0m [2;4m0.07it/s[0m  
[2KStep 0 - TTA Loss: 0.6638â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”[0m 145/203 [2m0:10:04 â€¢ 0:14:21[0m [2;4m0.07it/s[0m  
[2KAttention weights: tensor([[0.6614, 0.3386]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 145/203 [2m0:10:04 â€¢ 0:14:21[0m [2;4m0.07it/s[0m  
[2KAttention weights: tensor([[0.6642, 0.3358]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 145/203 [2m0:10:04 â€¢ 0:14:21[0m [2;4m0.07it/s[0m  
[2KAttention weights: tensor([[0.6747, 0.3253]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 145/203 [2m0:10:04 â€¢ 0:14:21[0m [2;4m0.07it/s[0m  
[2KAttention weights: tensor([[0.6936, 0.3064]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 145/203 [2m0:10:04 â€¢ 0:14:21[0m [2;4m0.07it/s[0m  
[2KAttention weights: tensor([[0.7197, 0.2803]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 145/203 [2m0:10:04 â€¢ 0:14:21[0m [2;4m0.07it/s[0m  
[2KAttention weights: tensor([[0.7548, 0.2452]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 145/203 [2m0:10:04 â€¢ 0:14:21[0m [2;4m0.07it/s[0m  
[2KAttention weights: tensor([[0.7885, 0.2115]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 145/203 [2m0:10:04 â€¢ 0:14:21[0m [2;4m0.07it/s[0m  
[2KAttention weights: tensor([[0.8112, 0.1888]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 145/203 [2m0:10:04 â€¢ 0:14:21[0m [2;4m0.07it/s[0m  
[2KAttention weights: tensor([[0.8302, 0.1698]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 145/203 [2m0:10:04 â€¢ 0:14:21[0m [2;4m0.07it/s[0m  
[2KAttention weights: tensor([[0.5628, 0.4372]], device='cuda:0')6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”[0m 145/203 [2m0:10:04 â€¢ 0:14:21[0m [2;4m0.07it/s[0m  
[2KAttention weights: tensor([[0.8664, 0.1336],â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”[0m 145/203 [2m0:10:04 â€¢ 0:14:21[0m [2;4m0.07it/s[0m  
        [0.7578, 0.2422],
        [0.8309, 0.1691],
        [0.8129, 0.1871],
        [0.8741, 0.1259],
        [0.8808, 0.1192],
        [0.9036, 0.0964],
        [0.8698, 0.1302],
        [0.8440, 0.1560],
[2K        [0.8513, 0.1487]], device='cuda:0')â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”[0m 145/203 [2m0:10:04 â€¢ 0:14:21[0m [2;4m0.07it/s[0m  
[2KAttention weights: tensor([[0.5594, 0.4406],â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”[0m 146/203 [2m0:10:07 â€¢ 0:08:49[0m [2;4m0.11it/s[0m  
        [0.5543, 0.4457],
        [0.5567, 0.4433],
        [0.5558, 0.4442],
        [0.5545, 0.4455],
        [0.5537, 0.4463],
        [0.5547, 0.4453],
        [0.5579, 0.4421],
        [0.5582, 0.4418],
[2K        [0.5549, 0.4451]], device='cuda:0', grad_fn=<SoftmaxBackward0>)0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”[0m 146/203 [2m0:10:07 â€¢ 0:08:49[0m [2;4m0.11it/s[0m  
[2KClass label: HammerThrowâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”[0m 146/203 [2m0:10:07 â€¢ 0:08:49[0m [2;4m0.11it/s[0m  
[2KAttention weights: tensor([[0.5405, 0.4595]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 146/203 [2m0:10:07 â€¢ 0:08:49[0m [2;4m0.11it/s[0m  
[2KStep 0 - TTA Loss: 0.5403â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”[0m 146/203 [2m0:10:07 â€¢ 0:08:49[0m [2;4m0.11it/s[0m  
[2KAttention weights: tensor([[0.6109, 0.3891]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 146/203 [2m0:10:07 â€¢ 0:08:49[0m [2;4m0.11it/s[0m  
[2KAttention weights: tensor([[0.6810, 0.3190]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 146/203 [2m0:10:07 â€¢ 0:08:49[0m [2;4m0.11it/s[0m  
[2KAttention weights: tensor([[0.7588, 0.2412]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 146/203 [2m0:10:07 â€¢ 0:08:49[0m [2;4m0.11it/s[0m  
[2KAttention weights: tensor([[0.8167, 0.1833]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 146/203 [2m0:10:07 â€¢ 0:08:49[0m [2;4m0.11it/s[0m  
[2KAttention weights: tensor([[0.8641, 0.1359]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 146/203 [2m0:10:07 â€¢ 0:08:49[0m [2;4m0.11it/s[0m  
[2KAttention weights: tensor([[0.8938, 0.1062]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 146/203 [2m0:10:07 â€¢ 0:08:49[0m [2;4m0.11it/s[0m  
[2KAttention weights: tensor([[0.9117, 0.0883]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 146/203 [2m0:10:07 â€¢ 0:08:49[0m [2;4m0.11it/s[0m  
[2KAttention weights: tensor([[0.9212, 0.0788]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 146/203 [2m0:10:07 â€¢ 0:08:49[0m [2;4m0.11it/s[0m  
[2KAttention weights: tensor([[0.9256, 0.0744]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 146/203 [2m0:10:07 â€¢ 0:08:49[0m [2;4m0.11it/s[0m  
[2KAttention weights: tensor([[0.5688, 0.4312]], device='cuda:0')6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”[0m 146/203 [2m0:10:07 â€¢ 0:08:49[0m [2;4m0.11it/s[0m  
[2KAttention weights: tensor([[0.8774, 0.1226],â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”[0m 146/203 [2m0:10:07 â€¢ 0:08:49[0m [2;4m0.11it/s[0m  
        [0.7603, 0.2397],
        [0.8354, 0.1646],
        [0.8128, 0.1872],
        [0.9266, 0.0734],
        [0.8800, 0.1200],
        [0.8904, 0.1096],
        [0.8821, 0.1179],
        [0.8319, 0.1681],
[2K        [0.8640, 0.1360]], device='cuda:0')â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”[0m 146/203 [2m0:10:07 â€¢ 0:08:49[0m [2;4m0.11it/s[0m  
[2KAttention weights: tensor([[0.5594, 0.4406],â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”[0m 147/203 [2m0:10:11 â€¢ 0:07:03[0m [2;4m0.13it/s[0m  
        [0.5543, 0.4457],
        [0.5566, 0.4434],
        [0.5558, 0.4442],
        [0.5545, 0.4455],
        [0.5536, 0.4464],
        [0.5547, 0.4453],
        [0.5578, 0.4422],
        [0.5582, 0.4418],
[2K        [0.5549, 0.4451]], device='cuda:0', grad_fn=<SoftmaxBackward0>)0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”[0m 147/203 [2m0:10:11 â€¢ 0:07:03[0m [2;4m0.13it/s[0m  
[2KClass label: GolfSwingâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”[0m 147/203 [2m0:10:11 â€¢ 0:07:03[0m [2;4m0.13it/s[0m  
[2KAttention weights: tensor([[0.6046, 0.3954]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 147/203 [2m0:10:11 â€¢ 0:07:03[0m [2;4m0.13it/s[0m  
[2KStep 0 - TTA Loss: 0.4150â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”[0m 147/203 [2m0:10:11 â€¢ 0:07:03[0m [2;4m0.13it/s[0m  
[2KAttention weights: tensor([[0.6046, 0.3954]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 147/203 [2m0:10:11 â€¢ 0:07:03[0m [2;4m0.13it/s[0m  
[2KAttention weights: tensor([[0.6061, 0.3939]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 147/203 [2m0:10:11 â€¢ 0:07:03[0m [2;4m0.13it/s[0m  
[2KAttention weights: tensor([[0.6114, 0.3886]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 147/203 [2m0:10:11 â€¢ 0:07:03[0m [2;4m0.13it/s[0m  
[2KAttention weights: tensor([[0.6243, 0.3757]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 147/203 [2m0:10:11 â€¢ 0:07:03[0m [2;4m0.13it/s[0m  
[2KAttention weights: tensor([[0.6461, 0.3539]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 147/203 [2m0:10:11 â€¢ 0:07:03[0m [2;4m0.13it/s[0m  
[2KAttention weights: tensor([[0.6764, 0.3236]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 147/203 [2m0:10:11 â€¢ 0:07:03[0m [2;4m0.13it/s[0m  
[2KAttention weights: tensor([[0.7059, 0.2941]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 147/203 [2m0:10:11 â€¢ 0:07:03[0m [2;4m0.13it/s[0m  
[2KAttention weights: tensor([[0.7340, 0.2660]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 147/203 [2m0:10:11 â€¢ 0:07:03[0m [2;4m0.13it/s[0m  
[2KAttention weights: tensor([[0.7596, 0.2404]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 147/203 [2m0:10:11 â€¢ 0:07:03[0m [2;4m0.13it/s[0m  
[2KAttention weights: tensor([[0.5605, 0.4395]], device='cuda:0')6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”[0m 147/203 [2m0:10:11 â€¢ 0:07:03[0m [2;4m0.13it/s[0m  
[2KAttention weights: tensor([[0.8109, 0.1891],â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”[0m 147/203 [2m0:10:11 â€¢ 0:07:03[0m [2;4m0.13it/s[0m  
        [0.7065, 0.2935],
        [0.7624, 0.2376],
        [0.7938, 0.2062],
        [0.8239, 0.1761],
        [0.7815, 0.2185],
        [0.7778, 0.2222],
        [0.8073, 0.1927],
        [0.7993, 0.2007],
[2K        [0.7860, 0.2140]], device='cuda:0')â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”[0m 147/203 [2m0:10:11 â€¢ 0:07:03[0m [2;4m0.13it/s[0m  
[2KAttention weights: tensor([[0.5594, 0.4406],â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”[0m 148/203 [2m0:10:15 â€¢ 0:06:01[0m [2;4m0.15it/s[0m   
        [0.5543, 0.4457],
        [0.5566, 0.4434],
        [0.5558, 0.4442],
        [0.5545, 0.4455],
        [0.5536, 0.4464],
        [0.5547, 0.4453],
        [0.5578, 0.4422],
        [0.5582, 0.4418],
[2K        [0.5549, 0.4451]], device='cuda:0', grad_fn=<SoftmaxBackward0>)38;5;237mâ”â”â”â”â”â”â”â”â”â”[0m 148/203 [2m0:10:15 â€¢ 0:06:01[0m [2;4m0.15it/s[0m  
[2KClass label: SoccerPenaltyâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”[0m 148/203 [2m0:10:15 â€¢ 0:06:01[0m [2;4m0.15it/s[0m  
[2KAttention weights: tensor([[0.6341, 0.3659]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 148/203 [2m0:10:15 â€¢ 0:06:01[0m [2;4m0.15it/s[0m  
[2KStep 0 - TTA Loss: 0.8533â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”[0m 148/203 [2m0:10:15 â€¢ 0:06:01[0m [2;4m0.15it/s[0m  
[2KAttention weights: tensor([[0.6902, 0.3098]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 148/203 [2m0:10:15 â€¢ 0:06:01[0m [2;4m0.15it/s[0m  
[2KAttention weights: tensor([[0.7612, 0.2388]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 148/203 [2m0:10:15 â€¢ 0:06:01[0m [2;4m0.15it/s[0m  
[2KAttention weights: tensor([[0.8344, 0.1656]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 148/203 [2m0:10:15 â€¢ 0:06:01[0m [2;4m0.15it/s[0m  
[2KAttention weights: tensor([[0.8919, 0.1081]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 148/203 [2m0:10:15 â€¢ 0:06:01[0m [2;4m0.15it/s[0m  
[2KAttention weights: tensor([[0.9240, 0.0760]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 148/203 [2m0:10:15 â€¢ 0:06:01[0m [2;4m0.15it/s[0m  
[2KAttention weights: tensor([[0.9356, 0.0644]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 148/203 [2m0:10:15 â€¢ 0:06:01[0m [2;4m0.15it/s[0m  
[2KAttention weights: tensor([[0.9336, 0.0664]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 148/203 [2m0:10:15 â€¢ 0:06:01[0m [2;4m0.15it/s[0m  
[2KAttention weights: tensor([[0.9262, 0.0738]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 148/203 [2m0:10:15 â€¢ 0:06:01[0m [2;4m0.15it/s[0m  
[2KAttention weights: tensor([[0.9203, 0.0797]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 148/203 [2m0:10:15 â€¢ 0:06:01[0m [2;4m0.15it/s[0m  
[2KAttention weights: tensor([[0.5682, 0.4318]], device='cuda:0')7mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”[0m 148/203 [2m0:10:15 â€¢ 0:06:01[0m [2;4m0.15it/s[0m  
[2KAttention weights: tensor([[0.8653, 0.1347],â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”[0m 148/203 [2m0:10:15 â€¢ 0:06:01[0m [2;4m0.15it/s[0m  
        [0.7751, 0.2249],
        [0.7769, 0.2231],
        [0.8491, 0.1509],
        [0.8533, 0.1467],
        [0.8294, 0.1706],
        [0.8191, 0.1809],
        [0.9181, 0.0819],
        [0.8495, 0.1505],
[2K        [0.8002, 0.1998]], device='cuda:0')â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”[0m 148/203 [2m0:10:15 â€¢ 0:06:01[0m [2;4m0.15it/s[0m  
[2KAttention weights: tensor([[0.5594, 0.4406],â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”[0m 149/203 [2m0:10:19 â€¢ 0:05:22[0m [2;4m0.17it/s[0m  
        [0.5542, 0.4458],
        [0.5566, 0.4434],
        [0.5558, 0.4442],
        [0.5545, 0.4455],
        [0.5536, 0.4464],
        [0.5546, 0.4454],
        [0.5578, 0.4422],
        [0.5582, 0.4418],
[2K        [0.5549, 0.4451]], device='cuda:0', grad_fn=<SoftmaxBackward0>)38;5;237mâ”â”â”â”â”â”â”â”â”â”[0m 149/203 [2m0:10:19 â€¢ 0:05:22[0m [2;4m0.17it/s[0m  
[2KClass label: HighJumpâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”[0m 149/203 [2m0:10:19 â€¢ 0:05:22[0m [2;4m0.17it/s[0m  
[2KAttention weights: tensor([[0.6036, 0.3964]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 149/203 [2m0:10:19 â€¢ 0:05:22[0m [2;4m0.17it/s[0m  
[2KStep 0 - TTA Loss: 0.7188â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”[0m 149/203 [2m0:10:19 â€¢ 0:05:22[0m [2;4m0.17it/s[0m  
[2KAttention weights: tensor([[0.6036, 0.3964]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 149/203 [2m0:10:19 â€¢ 0:05:22[0m [2;4m0.17it/s[0m  
[2KAttention weights: tensor([[0.6015, 0.3985]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 149/203 [2m0:10:19 â€¢ 0:05:22[0m [2;4m0.17it/s[0m  
[2KAttention weights: tensor([[0.5947, 0.4053]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 149/203 [2m0:10:19 â€¢ 0:05:22[0m [2;4m0.17it/s[0m  
[2KAttention weights: tensor([[0.5827, 0.4173]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 149/203 [2m0:10:19 â€¢ 0:05:22[0m [2;4m0.17it/s[0m  
[2KAttention weights: tensor([[0.5672, 0.4328]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 149/203 [2m0:10:19 â€¢ 0:05:22[0m [2;4m0.17it/s[0m  
[2KAttention weights: tensor([[0.5492, 0.4508]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 149/203 [2m0:10:19 â€¢ 0:05:22[0m [2;4m0.17it/s[0m  
[2KAttention weights: tensor([[0.5330, 0.4670]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 149/203 [2m0:10:19 â€¢ 0:05:22[0m [2;4m0.17it/s[0m  
[2KAttention weights: tensor([[0.5182, 0.4818]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 149/203 [2m0:10:19 â€¢ 0:05:22[0m [2;4m0.17it/s[0m  
[2KAttention weights: tensor([[0.5009, 0.4991]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 149/203 [2m0:10:19 â€¢ 0:05:22[0m [2;4m0.17it/s[0m  
[2KAttention weights: tensor([[0.5501, 0.4499]], device='cuda:0')7mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”[0m 149/203 [2m0:10:19 â€¢ 0:05:22[0m [2;4m0.17it/s[0m  
[2KAttention weights: tensor([[0.4120, 0.5880],â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”[0m 149/203 [2m0:10:19 â€¢ 0:05:22[0m [2;4m0.17it/s[0m  
        [0.4244, 0.5756],
        [0.5630, 0.4370],
        [0.4240, 0.5760],
        [0.3483, 0.6517],
        [0.4780, 0.5220],
        [0.4678, 0.5322],
        [0.1804, 0.8196],
        [0.5058, 0.4942],
[2K        [0.5610, 0.4390]], device='cuda:0')â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”[0m 149/203 [2m0:10:19 â€¢ 0:05:22[0m [2;4m0.17it/s[0m  
[2KAttention weights: tensor([[0.5593, 0.4407],â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”[0m 150/203 [2m0:10:23 â€¢ 0:03:23[0m [2;4m0.26it/s[0m  
        [0.5542, 0.4458],
        [0.5566, 0.4434],
        [0.5557, 0.4443],
        [0.5544, 0.4456],
        [0.5536, 0.4464],
        [0.5546, 0.4454],
        [0.5577, 0.4423],
        [0.5581, 0.4419],
[2K        [0.5549, 0.4451]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”[0m 150/203 [2m0:10:23 â€¢ 0:03:23[0m [2;4m0.26it/s[0m  
[2KClass label: BaseballPitchâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”[0m 150/203 [2m0:10:23 â€¢ 0:03:23[0m [2;4m0.26it/s[0m  
[2KAttention weights: tensor([[0.6479, 0.3521]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 150/203 [2m0:10:23 â€¢ 0:03:23[0m [2;4m0.26it/s[0m  
[2KStep 0 - TTA Loss: 0.7036â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”[0m 150/203 [2m0:10:23 â€¢ 0:03:23[0m [2;4m0.26it/s[0m  
[2KAttention weights: tensor([[0.6596, 0.3404]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 150/203 [2m0:10:23 â€¢ 0:03:23[0m [2;4m0.26it/s[0m  
[2KAttention weights: tensor([[0.6991, 0.3009]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 150/203 [2m0:10:23 â€¢ 0:03:23[0m [2;4m0.26it/s[0m  
[2KAttention weights: tensor([[0.7408, 0.2592]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 150/203 [2m0:10:23 â€¢ 0:03:23[0m [2;4m0.26it/s[0m  
[2KAttention weights: tensor([[0.7717, 0.2283]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 150/203 [2m0:10:23 â€¢ 0:03:23[0m [2;4m0.26it/s[0m  
[2KAttention weights: tensor([[0.7912, 0.2088]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 150/203 [2m0:10:23 â€¢ 0:03:23[0m [2;4m0.26it/s[0m  
[2KAttention weights: tensor([[0.8047, 0.1953]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 150/203 [2m0:10:23 â€¢ 0:03:23[0m [2;4m0.26it/s[0m  
[2KAttention weights: tensor([[0.8130, 0.1870]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 150/203 [2m0:10:23 â€¢ 0:03:23[0m [2;4m0.26it/s[0m  
[2KAttention weights: tensor([[0.8183, 0.1817]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 150/203 [2m0:10:23 â€¢ 0:03:23[0m [2;4m0.26it/s[0m  
[2KAttention weights: tensor([[0.8205, 0.1795]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 150/203 [2m0:10:23 â€¢ 0:03:23[0m [2;4m0.26it/s[0m  
[2KAttention weights: tensor([[0.5643, 0.4357]], device='cuda:0');6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”[0m 150/203 [2m0:10:23 â€¢ 0:03:23[0m [2;4m0.26it/s[0m  
[2KAttention weights: tensor([[0.8211, 0.1789],â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”[0m 150/203 [2m0:10:23 â€¢ 0:03:23[0m [2;4m0.26it/s[0m  
        [0.5979, 0.4021],
        [0.6623, 0.3377],
        [0.6552, 0.3448],
        [0.5970, 0.4030],
        [0.6481, 0.3519],
        [0.6558, 0.3442],
        [0.4951, 0.5049],
        [0.7048, 0.2952],
[2K        [0.6739, 0.3261]], device='cuda:0')â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”[0m 150/203 [2m0:10:23 â€¢ 0:03:23[0m [2;4m0.26it/s[0m  
[2KAttention weights: tensor([[0.5593, 0.4407],â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”[0m 151/203 [2m0:10:25 â€¢ 0:03:00[0m [2;4m0.29it/s[0m  
        [0.5542, 0.4458],
        [0.5566, 0.4434],
        [0.5557, 0.4443],
        [0.5544, 0.4456],
        [0.5536, 0.4464],
        [0.5546, 0.4454],
        [0.5577, 0.4423],
        [0.5581, 0.4419],
[2K        [0.5549, 0.4451]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”[0m 151/203 [2m0:10:25 â€¢ 0:03:00[0m [2;4m0.29it/s[0m  
[2KClass label: GolfSwingâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”[0m 151/203 [2m0:10:25 â€¢ 0:03:00[0m [2;4m0.29it/s[0m  
[2KAttention weights: tensor([[0.6096, 0.3904]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 151/203 [2m0:10:25 â€¢ 0:03:00[0m [2;4m0.29it/s[0m  
[2KStep 0 - TTA Loss: 0.8462â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”[0m 151/203 [2m0:10:25 â€¢ 0:03:00[0m [2;4m0.29it/s[0m  
[2KAttention weights: tensor([[0.6096, 0.3904]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 151/203 [2m0:10:25 â€¢ 0:03:00[0m [2;4m0.29it/s[0m  
[2KAttention weights: tensor([[0.6106, 0.3894]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 151/203 [2m0:10:25 â€¢ 0:03:00[0m [2;4m0.29it/s[0m  
[2KAttention weights: tensor([[0.6158, 0.3842]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 151/203 [2m0:10:25 â€¢ 0:03:00[0m [2;4m0.29it/s[0m  
[2KAttention weights: tensor([[0.6298, 0.3702]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 151/203 [2m0:10:25 â€¢ 0:03:00[0m [2;4m0.29it/s[0m  
[2KAttention weights: tensor([[0.6560, 0.3440]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 151/203 [2m0:10:25 â€¢ 0:03:00[0m [2;4m0.29it/s[0m  
[2KAttention weights: tensor([[0.6967, 0.3033]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 151/203 [2m0:10:25 â€¢ 0:03:00[0m [2;4m0.29it/s[0m  
[2KAttention weights: tensor([[0.7470, 0.2530]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 151/203 [2m0:10:25 â€¢ 0:03:00[0m [2;4m0.29it/s[0m  
[2KAttention weights: tensor([[0.8000, 0.2000]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 151/203 [2m0:10:25 â€¢ 0:03:00[0m [2;4m0.29it/s[0m  
[2KAttention weights: tensor([[0.8465, 0.1535]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 151/203 [2m0:10:25 â€¢ 0:03:00[0m [2;4m0.29it/s[0m  
[2KAttention weights: tensor([[0.5647, 0.4353]], device='cuda:0');6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”[0m 151/203 [2m0:10:25 â€¢ 0:03:00[0m [2;4m0.29it/s[0m  
[2KAttention weights: tensor([[0.8410, 0.1590],â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”[0m 151/203 [2m0:10:25 â€¢ 0:03:00[0m [2;4m0.29it/s[0m  
        [0.7241, 0.2759],
        [0.7365, 0.2635],
        [0.8826, 0.1174],
        [0.7100, 0.2900],
        [0.7463, 0.2537],
        [0.7449, 0.2551],
        [0.7751, 0.2249],
        [0.8244, 0.1756],
[2K        [0.7592, 0.2408]], device='cuda:0')â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”[0m 151/203 [2m0:10:25 â€¢ 0:03:00[0m [2;4m0.29it/s[0m  
[2KAttention weights: tensor([[0.5594, 0.4406],â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”[0m 152/203 [2m0:10:28 â€¢ 0:02:50[0m [2;4m0.30it/s[0m  
        [0.5542, 0.4458],
        [0.5566, 0.4434],
        [0.5557, 0.4443],
        [0.5544, 0.4456],
        [0.5536, 0.4464],
        [0.5546, 0.4454],
        [0.5577, 0.4423],
        [0.5581, 0.4419],
[2K        [0.5549, 0.4451]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”[0m 152/203 [2m0:10:28 â€¢ 0:02:50[0m [2;4m0.30it/s[0m  
[2KClass label: PoleVaultâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”[0m 152/203 [2m0:10:28 â€¢ 0:02:50[0m [2;4m0.30it/s[0m  
[2KAttention weights: tensor([[0.6167, 0.3833]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 152/203 [2m0:10:28 â€¢ 0:02:50[0m [2;4m0.30it/s[0m  
[2KStep 0 - TTA Loss: 0.5875â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”[0m 152/203 [2m0:10:28 â€¢ 0:02:50[0m [2;4m0.30it/s[0m  
[2KAttention weights: tensor([[0.6493, 0.3507]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 152/203 [2m0:10:28 â€¢ 0:02:50[0m [2;4m0.30it/s[0m  
[2KAttention weights: tensor([[0.6840, 0.3160]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 152/203 [2m0:10:28 â€¢ 0:02:50[0m [2;4m0.30it/s[0m  
[2KAttention weights: tensor([[0.7146, 0.2854]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 152/203 [2m0:10:28 â€¢ 0:02:50[0m [2;4m0.30it/s[0m  
[2KAttention weights: tensor([[0.7370, 0.2630]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 152/203 [2m0:10:28 â€¢ 0:02:50[0m [2;4m0.30it/s[0m  
[2KAttention weights: tensor([[0.7501, 0.2499]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 152/203 [2m0:10:28 â€¢ 0:02:50[0m [2;4m0.30it/s[0m  
[2KAttention weights: tensor([[0.7567, 0.2433]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 152/203 [2m0:10:28 â€¢ 0:02:50[0m [2;4m0.30it/s[0m  
[2KAttention weights: tensor([[0.7595, 0.2405]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 152/203 [2m0:10:28 â€¢ 0:02:50[0m [2;4m0.30it/s[0m  
[2KAttention weights: tensor([[0.7605, 0.2395]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 152/203 [2m0:10:28 â€¢ 0:02:50[0m [2;4m0.30it/s[0m  
[2KAttention weights: tensor([[0.7607, 0.2393]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 152/203 [2m0:10:28 â€¢ 0:02:50[0m [2;4m0.30it/s[0m  
[2KAttention weights: tensor([[0.5595, 0.4405]], device='cuda:0');6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”[0m 152/203 [2m0:10:28 â€¢ 0:02:50[0m [2;4m0.30it/s[0m  
[2KAttention weights: tensor([[0.8220, 0.1780],â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”[0m 152/203 [2m0:10:28 â€¢ 0:02:50[0m [2;4m0.30it/s[0m  
        [0.7148, 0.2852],
        [0.7339, 0.2661],
        [0.8537, 0.1463],
        [0.7067, 0.2933],
        [0.7532, 0.2468],
        [0.7608, 0.2392],
        [0.7755, 0.2245],
        [0.8104, 0.1896],
[2K        [0.7541, 0.2459]], device='cuda:0')â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”[0m 152/203 [2m0:10:28 â€¢ 0:02:50[0m [2;4m0.30it/s[0m  
[2KAttention weights: tensor([[0.5594, 0.4406],â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”[0m 153/203 [2m0:10:58 â€¢ -:--:--[0m [2;4m0.00it/s[0m   
        [0.5542, 0.4458],
        [0.5566, 0.4434],
        [0.5558, 0.4442],
        [0.5544, 0.4456],
        [0.5536, 0.4464],
        [0.5546, 0.4454],
        [0.5577, 0.4423],
        [0.5582, 0.4418],
[2K        [0.5549, 0.4451]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[38;5;237mâ”â”â”â”â”â”â”â”â”[0m 153/203 [2m0:10:58 â€¢ -:--:--[0m [2;4m0.00it/s[0m  
[2KClass label: HighJumpâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”[0m 153/203 [2m0:10:58 â€¢ -:--:--[0m [2;4m0.00it/s[0m  
[2KAttention weights: tensor([[0.6036, 0.3964]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 153/203 [2m0:10:58 â€¢ -:--:--[0m [2;4m0.00it/s[0m  
[2KStep 0 - TTA Loss: 0.7809â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”[0m 153/203 [2m0:10:58 â€¢ -:--:--[0m [2;4m0.00it/s[0m  
[2KAttention weights: tensor([[0.6036, 0.3964]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 153/203 [2m0:10:58 â€¢ -:--:--[0m [2;4m0.00it/s[0m  
[2KAttention weights: tensor([[0.6053, 0.3947]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 153/203 [2m0:10:58 â€¢ -:--:--[0m [2;4m0.00it/s[0m  
[2KAttention weights: tensor([[0.6148, 0.3852]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 153/203 [2m0:10:58 â€¢ -:--:--[0m [2;4m0.00it/s[0m  
[2KAttention weights: tensor([[0.6401, 0.3599]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 153/203 [2m0:10:58 â€¢ -:--:--[0m [2;4m0.00it/s[0m  
[2KAttention weights: tensor([[0.6872, 0.3128]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 153/203 [2m0:10:58 â€¢ -:--:--[0m [2;4m0.00it/s[0m  
[2KAttention weights: tensor([[0.7574, 0.2426]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 153/203 [2m0:10:58 â€¢ -:--:--[0m [2;4m0.00it/s[0m  
[2KAttention weights: tensor([[0.8442, 0.1558]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 153/203 [2m0:10:58 â€¢ -:--:--[0m [2;4m0.00it/s[0m  
[2KAttention weights: tensor([[0.9259, 0.0741]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 153/203 [2m0:10:58 â€¢ -:--:--[0m [2;4m0.00it/s[0m  
[2KAttention weights: tensor([[0.9780, 0.0220]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 153/203 [2m0:10:58 â€¢ -:--:--[0m [2;4m0.00it/s[0m  
[2KAttention weights: tensor([[0.5805, 0.4195]], device='cuda:0')37mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”[0m 153/203 [2m0:10:58 â€¢ -:--:--[0m [2;4m0.00it/s[0m  
[2KAttention weights: tensor([[0.9484, 0.0516],â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”[0m 153/203 [2m0:10:58 â€¢ -:--:--[0m [2;4m0.00it/s[0m  
        [0.9035, 0.0965],
        [0.9459, 0.0541],
        [0.9455, 0.0545],
        [0.9680, 0.0320],
        [0.9952, 0.0048],
        [0.9735, 0.0265],
        [0.9687, 0.0313],
        [0.9719, 0.0281],
[2K        [0.9685, 0.0315]], device='cuda:0')â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”[0m 153/203 [2m0:10:58 â€¢ -:--:--[0m [2;4m0.00it/s[0m  
[2KAttention weights: tensor([[0.5594, 0.4406],â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”[0m 154/203 [2m0:11:02 â€¢ 0:02:33[0m [2;4m0.32it/s[0m  
        [0.5542, 0.4458],
        [0.5566, 0.4434],
        [0.5558, 0.4442],
        [0.5545, 0.4455],
        [0.5537, 0.4463],
        [0.5547, 0.4453],
        [0.5577, 0.4423],
        [0.5582, 0.4418],
[2K        [0.5549, 0.4451]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[38;5;237mâ”â”â”â”â”â”â”â”â”[0m 154/203 [2m0:11:02 â€¢ 0:02:33[0m [2;4m0.32it/s[0m  
[2KClass label: PoleVaultâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”[0m 154/203 [2m0:11:02 â€¢ 0:02:33[0m [2;4m0.32it/s[0m  
[2KAttention weights: tensor([[0.6141, 0.3859]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 154/203 [2m0:11:02 â€¢ 0:02:33[0m [2;4m0.32it/s[0m  
[2KStep 0 - TTA Loss: 0.7265â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”[0m 154/203 [2m0:11:02 â€¢ 0:02:33[0m [2;4m0.32it/s[0m  
[2KAttention weights: tensor([[0.8039, 0.1961]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 154/203 [2m0:11:02 â€¢ 0:02:33[0m [2;4m0.32it/s[0m  
[2KAttention weights: tensor([[0.9206, 0.0794]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 154/203 [2m0:11:02 â€¢ 0:02:33[0m [2;4m0.32it/s[0m  
[2KAttention weights: tensor([[0.9770, 0.0230]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 154/203 [2m0:11:02 â€¢ 0:02:33[0m [2;4m0.32it/s[0m  
[2KAttention weights: tensor([[0.9945, 0.0055]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 154/203 [2m0:11:02 â€¢ 0:02:33[0m [2;4m0.32it/s[0m  
[2KAttention weights: tensor([[0.9939, 0.0061]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 154/203 [2m0:11:02 â€¢ 0:02:33[0m [2;4m0.32it/s[0m  
[2KAttention weights: tensor([[0.9913, 0.0087]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 154/203 [2m0:11:02 â€¢ 0:02:33[0m [2;4m0.32it/s[0m  
[2KAttention weights: tensor([[0.9864, 0.0136]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 154/203 [2m0:11:02 â€¢ 0:02:33[0m [2;4m0.32it/s[0m  
[2KAttention weights: tensor([[0.9812, 0.0188]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 154/203 [2m0:11:02 â€¢ 0:02:33[0m [2;4m0.32it/s[0m  
[2KAttention weights: tensor([[0.9778, 0.0222]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 154/203 [2m0:11:02 â€¢ 0:02:33[0m [2;4m0.32it/s[0m  
[2KAttention weights: tensor([[0.5753, 0.4247]], device='cuda:0')37mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”[0m 154/203 [2m0:11:02 â€¢ 0:02:33[0m [2;4m0.32it/s[0m  
[2KAttention weights: tensor([[0.9544, 0.0456],â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”[0m 154/203 [2m0:11:02 â€¢ 0:02:33[0m [2;4m0.32it/s[0m  
        [0.9156, 0.0844],
        [0.9551, 0.0449],
        [0.9530, 0.0470],
        [0.9765, 0.0235],
        [0.9974, 0.0026],
        [0.9769, 0.0231],
        [0.9755, 0.0245],
        [0.9793, 0.0207],
[2K        [0.9761, 0.0239]], device='cuda:0')â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”[0m 154/203 [2m0:11:02 â€¢ 0:02:33[0m [2;4m0.32it/s[0m  
[2KAttention weights: tensor([[0.5595, 0.4405],â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”[0m 155/203 [2m0:11:05 â€¢ 0:02:32[0m [2;4m0.32it/s[0m  
        [0.5543, 0.4457],
        [0.5567, 0.4433],
        [0.5558, 0.4442],
        [0.5546, 0.4454],
        [0.5538, 0.4462],
        [0.5548, 0.4452],
        [0.5578, 0.4422],
        [0.5582, 0.4418],
[2K        [0.5550, 0.4450]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m[38;5;237mâ”â”â”â”â”â”â”â”â”[0m 155/203 [2m0:11:05 â€¢ 0:02:32[0m [2;4m0.32it/s[0m  
[2KClass label: PoleVaultâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”[0m 155/203 [2m0:11:05 â€¢ 0:02:32[0m [2;4m0.32it/s[0m  
[2KAttention weights: tensor([[0.6106, 0.3894]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 155/203 [2m0:11:05 â€¢ 0:02:32[0m [2;4m0.32it/s[0m  
[2KStep 0 - TTA Loss: 0.5226â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”[0m 155/203 [2m0:11:05 â€¢ 0:02:32[0m [2;4m0.32it/s[0m  
[2KAttention weights: tensor([[0.6106, 0.3894]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 155/203 [2m0:11:05 â€¢ 0:02:32[0m [2;4m0.32it/s[0m  
[2KAttention weights: tensor([[0.6025, 0.3975]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 155/203 [2m0:11:05 â€¢ 0:02:32[0m [2;4m0.32it/s[0m  
[2KAttention weights: tensor([[0.5740, 0.4260]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 155/203 [2m0:11:05 â€¢ 0:02:32[0m [2;4m0.32it/s[0m  
[2KAttention weights: tensor([[0.5184, 0.4816]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 155/203 [2m0:11:05 â€¢ 0:02:32[0m [2;4m0.32it/s[0m  
[2KAttention weights: tensor([[0.4355, 0.5645]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 155/203 [2m0:11:05 â€¢ 0:02:32[0m [2;4m0.32it/s[0m  
[2KAttention weights: tensor([[0.3353, 0.6647]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 155/203 [2m0:11:05 â€¢ 0:02:32[0m [2;4m0.32it/s[0m  
[2KAttention weights: tensor([[0.2367, 0.7633]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 155/203 [2m0:11:05 â€¢ 0:02:32[0m [2;4m0.32it/s[0m  
[2KAttention weights: tensor([[0.1540, 0.8460]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 155/203 [2m0:11:05 â€¢ 0:02:32[0m [2;4m0.32it/s[0m  
[2KAttention weights: tensor([[0.0952, 0.9048]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 155/203 [2m0:11:05 â€¢ 0:02:32[0m [2;4m0.32it/s[0m  
[2KAttention weights: tensor([[0.5351, 0.4649]], device='cuda:0')8;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”[0m 155/203 [2m0:11:05 â€¢ 0:02:32[0m [2;4m0.32it/s[0m  
[2KAttention weights: tensor([[0.2026, 0.7974],â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”[0m 155/203 [2m0:11:05 â€¢ 0:02:32[0m [2;4m0.32it/s[0m  
        [0.3246, 0.6754],
        [0.2459, 0.7541],
        [0.2477, 0.7523],
        [0.1264, 0.8736],
        [0.1432, 0.8568],
        [0.0568, 0.9432],
        [0.1927, 0.8073],
        [0.3340, 0.6660],
[2K        [0.2151, 0.7849]], device='cuda:0')â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”[0m 155/203 [2m0:11:05 â€¢ 0:02:32[0m [2;4m0.32it/s[0m  
[2KAttention weights: tensor([[0.5594, 0.4406],â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”[0m 156/203 [2m0:11:13 â€¢ 0:03:47[0m [2;4m0.21it/s[0m  
        [0.5543, 0.4457],
        [0.5567, 0.4433],
        [0.5558, 0.4442],
        [0.5545, 0.4455],
        [0.5538, 0.4462],
        [0.5548, 0.4452],
        [0.5578, 0.4422],
        [0.5582, 0.4418],
[2K        [0.5550, 0.4450]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m[38;5;237mâ”â”â”â”â”â”â”â”â”[0m 156/203 [2m0:11:13 â€¢ 0:03:47[0m [2;4m0.21it/s[0m  
[2KClass label: CleanAndJerkâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”[0m 156/203 [2m0:11:13 â€¢ 0:03:47[0m [2;4m0.21it/s[0m  
[2KAttention weights: tensor([[0.6208, 0.3792]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 156/203 [2m0:11:13 â€¢ 0:03:47[0m [2;4m0.21it/s[0m  
[2KStep 0 - TTA Loss: 0.5999â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”[0m 156/203 [2m0:11:13 â€¢ 0:03:47[0m [2;4m0.21it/s[0m  
[2KAttention weights: tensor([[0.5800, 0.4200]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 156/203 [2m0:11:13 â€¢ 0:03:47[0m [2;4m0.21it/s[0m  
[2KAttention weights: tensor([[0.5588, 0.4412]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 156/203 [2m0:11:13 â€¢ 0:03:47[0m [2;4m0.21it/s[0m  
[2KAttention weights: tensor([[0.5486, 0.4514]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 156/203 [2m0:11:13 â€¢ 0:03:47[0m [2;4m0.21it/s[0m  
[2KAttention weights: tensor([[0.5442, 0.4558]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 156/203 [2m0:11:13 â€¢ 0:03:47[0m [2;4m0.21it/s[0m  
[2KAttention weights: tensor([[0.5414, 0.4586]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 156/203 [2m0:11:13 â€¢ 0:03:47[0m [2;4m0.21it/s[0m  
[2KAttention weights: tensor([[0.5396, 0.4604]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 156/203 [2m0:11:13 â€¢ 0:03:47[0m [2;4m0.21it/s[0m  
[2KAttention weights: tensor([[0.5386, 0.4614]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 156/203 [2m0:11:13 â€¢ 0:03:47[0m [2;4m0.21it/s[0m  
[2KAttention weights: tensor([[0.5384, 0.4616]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 156/203 [2m0:11:13 â€¢ 0:03:47[0m [2;4m0.21it/s[0m  
[2KAttention weights: tensor([[0.5385, 0.4615]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 156/203 [2m0:11:13 â€¢ 0:03:47[0m [2;4m0.21it/s[0m  
[2KAttention weights: tensor([[0.5537, 0.4463]], device='cuda:0')8;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”[0m 156/203 [2m0:11:13 â€¢ 0:03:47[0m [2;4m0.21it/s[0m  
[2KAttention weights: tensor([[0.3660, 0.6340],â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”[0m 156/203 [2m0:11:13 â€¢ 0:03:47[0m [2;4m0.21it/s[0m  
        [0.4472, 0.5528],
        [0.5385, 0.4615],
        [0.4071, 0.5929],
        [0.2860, 0.7140],
        [0.3172, 0.6828],
        [0.1880, 0.8120],
        [0.3559, 0.6441],
        [0.5175, 0.4825],
[2K        [0.4398, 0.5602]], device='cuda:0')â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”[0m 156/203 [2m0:11:13 â€¢ 0:03:47[0m [2;4m0.21it/s[0m  
[2KAttention weights: tensor([[0.5594, 0.4406],â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”[0m 157/203 [2m0:11:22 â€¢ 0:04:35[0m [2;4m0.17it/s[0m  
        [0.5543, 0.4457],
        [0.5567, 0.4433],
        [0.5558, 0.4442],
        [0.5545, 0.4455],
        [0.5538, 0.4462],
        [0.5547, 0.4453],
        [0.5578, 0.4422],
        [0.5582, 0.4418],
[2K        [0.5550, 0.4450]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m[38;5;237mâ”â”â”â”â”â”â”â”â”[0m 157/203 [2m0:11:22 â€¢ 0:04:35[0m [2;4m0.17it/s[0m  
[2KClass label: GolfSwingâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”[0m 157/203 [2m0:11:22 â€¢ 0:04:35[0m [2;4m0.17it/s[0m  
[2KAttention weights: tensor([[0.6078, 0.3922]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 157/203 [2m0:11:22 â€¢ 0:04:35[0m [2;4m0.17it/s[0m  
[2KStep 0 - TTA Loss: 0.7206â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”[0m 157/203 [2m0:11:22 â€¢ 0:04:35[0m [2;4m0.17it/s[0m  
[2KAttention weights: tensor([[0.6078, 0.3922]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 157/203 [2m0:11:22 â€¢ 0:04:35[0m [2;4m0.17it/s[0m  
[2KAttention weights: tensor([[0.6078, 0.3922]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 157/203 [2m0:11:22 â€¢ 0:04:35[0m [2;4m0.17it/s[0m  
[2KAttention weights: tensor([[0.6080, 0.3920]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 157/203 [2m0:11:22 â€¢ 0:04:35[0m [2;4m0.17it/s[0m  
[2KAttention weights: tensor([[0.6086, 0.3914]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 157/203 [2m0:11:22 â€¢ 0:04:35[0m [2;4m0.17it/s[0m  
[2KAttention weights: tensor([[0.6101, 0.3899]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 157/203 [2m0:11:22 â€¢ 0:04:35[0m [2;4m0.17it/s[0m  
[2KAttention weights: tensor([[0.6106, 0.3894]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 157/203 [2m0:11:22 â€¢ 0:04:35[0m [2;4m0.17it/s[0m  
[2KAttention weights: tensor([[0.6053, 0.3947]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 157/203 [2m0:11:22 â€¢ 0:04:35[0m [2;4m0.17it/s[0m  
[2KAttention weights: tensor([[0.5946, 0.4054]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 157/203 [2m0:11:22 â€¢ 0:04:35[0m [2;4m0.17it/s[0m  
[2KAttention weights: tensor([[0.5692, 0.4308]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 157/203 [2m0:11:22 â€¢ 0:04:35[0m [2;4m0.17it/s[0m  
[2KAttention weights: tensor([[0.5535, 0.4465]], device='cuda:0')8;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”[0m 157/203 [2m0:11:22 â€¢ 0:04:35[0m [2;4m0.17it/s[0m  
[2KAttention weights: tensor([[0.5788, 0.4212],â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”[0m 157/203 [2m0:11:22 â€¢ 0:04:35[0m [2;4m0.17it/s[0m  
        [0.5585, 0.4415],
        [0.6181, 0.3819],
        [0.5347, 0.4653],
        [0.4843, 0.5157],
        [0.5415, 0.4585],
        [0.5217, 0.4783],
        [0.5730, 0.4270],
        [0.6284, 0.3716],
[2K        [0.5865, 0.4135]], device='cuda:0')â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”[0m 157/203 [2m0:11:22 â€¢ 0:04:35[0m [2;4m0.17it/s[0m  
[2KAttention weights: tensor([[0.5594, 0.4406],â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”[0m 158/203 [2m0:11:27 â€¢ 0:04:18[0m [2;4m0.17it/s[0m   
        [0.5543, 0.4457],
        [0.5567, 0.4433],
        [0.5558, 0.4442],
        [0.5545, 0.4455],
        [0.5538, 0.4462],
        [0.5547, 0.4453],
        [0.5578, 0.4422],
        [0.5582, 0.4418],
[2K        [0.5550, 0.4450]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[38;5;237mâ”â”â”â”â”â”â”â”[0m 158/203 [2m0:11:27 â€¢ 0:04:18[0m [2;4m0.17it/s[0m  
[2KClass label: BaseballPitchâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”[0m 158/203 [2m0:11:27 â€¢ 0:04:18[0m [2;4m0.17it/s[0m  
[2KAttention weights: tensor([[0.6457, 0.3543]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 158/203 [2m0:11:27 â€¢ 0:04:18[0m [2;4m0.17it/s[0m  
[2KStep 0 - TTA Loss: 0.6791â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”[0m 158/203 [2m0:11:27 â€¢ 0:04:18[0m [2;4m0.17it/s[0m  
[2KAttention weights: tensor([[0.6548, 0.3452]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 158/203 [2m0:11:27 â€¢ 0:04:18[0m [2;4m0.17it/s[0m  
[2KAttention weights: tensor([[0.6863, 0.3137]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 158/203 [2m0:11:27 â€¢ 0:04:18[0m [2;4m0.17it/s[0m  
[2KAttention weights: tensor([[0.7320, 0.2680]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 158/203 [2m0:11:27 â€¢ 0:04:18[0m [2;4m0.17it/s[0m  
[2KAttention weights: tensor([[0.7772, 0.2228]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 158/203 [2m0:11:27 â€¢ 0:04:18[0m [2;4m0.17it/s[0m  
[2KAttention weights: tensor([[0.8124, 0.1876]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 158/203 [2m0:11:27 â€¢ 0:04:18[0m [2;4m0.17it/s[0m  
[2KAttention weights: tensor([[0.8357, 0.1643]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 158/203 [2m0:11:27 â€¢ 0:04:18[0m [2;4m0.17it/s[0m  
[2KAttention weights: tensor([[0.8489, 0.1511]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 158/203 [2m0:11:27 â€¢ 0:04:18[0m [2;4m0.17it/s[0m  
[2KAttention weights: tensor([[0.8547, 0.1453]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 158/203 [2m0:11:27 â€¢ 0:04:18[0m [2;4m0.17it/s[0m  
[2KAttention weights: tensor([[0.8572, 0.1428]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 158/203 [2m0:11:27 â€¢ 0:04:18[0m [2;4m0.17it/s[0m  
[2KAttention weights: tensor([[0.5661, 0.4339]], device='cuda:0')237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”[0m 158/203 [2m0:11:27 â€¢ 0:04:18[0m [2;4m0.17it/s[0m  
[2KAttention weights: tensor([[0.8577, 0.1423],â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”[0m 158/203 [2m0:11:27 â€¢ 0:04:18[0m [2;4m0.17it/s[0m  
        [0.6485, 0.3515],
        [0.6707, 0.3293],
        [0.6434, 0.3566],
        [0.6512, 0.3488],
        [0.6536, 0.3464],
        [0.6561, 0.3439],
        [0.7302, 0.2698],
        [0.7335, 0.2665],
[2K        [0.6593, 0.3407]], device='cuda:0')â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”[0m 158/203 [2m0:11:27 â€¢ 0:04:18[0m [2;4m0.17it/s[0m  
[2KAttention weights: tensor([[0.5594, 0.4406],â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”[0m 159/203 [2m0:11:28 â€¢ 0:03:37[0m [2;4m0.20it/s[0m  
        [0.5543, 0.4457],
        [0.5567, 0.4433],
        [0.5558, 0.4442],
        [0.5545, 0.4455],
        [0.5538, 0.4462],
        [0.5547, 0.4453],
        [0.5578, 0.4422],
        [0.5582, 0.4418],
[2K        [0.5550, 0.4450]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[38;5;237mâ”â”â”â”â”â”â”â”[0m 159/203 [2m0:11:28 â€¢ 0:03:37[0m [2;4m0.20it/s[0m  
[2KClass label: Billiardsâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”[0m 159/203 [2m0:11:28 â€¢ 0:03:37[0m [2;4m0.20it/s[0m  
[2KAttention weights: tensor([[0.5957, 0.4043]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 159/203 [2m0:11:28 â€¢ 0:03:37[0m [2;4m0.20it/s[0m  
[2KStep 0 - TTA Loss: 0.5672â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”[0m 159/203 [2m0:11:28 â€¢ 0:03:37[0m [2;4m0.20it/s[0m  
[2KAttention weights: tensor([[0.5957, 0.4043]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 159/203 [2m0:11:28 â€¢ 0:03:37[0m [2;4m0.20it/s[0m  
[2KAttention weights: tensor([[0.5968, 0.4032]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 159/203 [2m0:11:28 â€¢ 0:03:37[0m [2;4m0.20it/s[0m  
[2KAttention weights: tensor([[0.6025, 0.3975]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 159/203 [2m0:11:28 â€¢ 0:03:37[0m [2;4m0.20it/s[0m  
[2KAttention weights: tensor([[0.6177, 0.3823]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 159/203 [2m0:11:28 â€¢ 0:03:37[0m [2;4m0.20it/s[0m  
[2KAttention weights: tensor([[0.6447, 0.3553]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 159/203 [2m0:11:28 â€¢ 0:03:37[0m [2;4m0.20it/s[0m  
[2KAttention weights: tensor([[0.6835, 0.3165]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 159/203 [2m0:11:28 â€¢ 0:03:37[0m [2;4m0.20it/s[0m  
[2KAttention weights: tensor([[0.7285, 0.2715]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 159/203 [2m0:11:28 â€¢ 0:03:37[0m [2;4m0.20it/s[0m  
[2KAttention weights: tensor([[0.7686, 0.2314]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 159/203 [2m0:11:28 â€¢ 0:03:37[0m [2;4m0.20it/s[0m  
[2KAttention weights: tensor([[0.7991, 0.2009]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 159/203 [2m0:11:28 â€¢ 0:03:37[0m [2;4m0.20it/s[0m  
[2KAttention weights: tensor([[0.5592, 0.4408]], device='cuda:0')237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”[0m 159/203 [2m0:11:28 â€¢ 0:03:37[0m [2;4m0.20it/s[0m  
[2KAttention weights: tensor([[0.7724, 0.2276],â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”[0m 159/203 [2m0:11:28 â€¢ 0:03:37[0m [2;4m0.20it/s[0m  
        [0.8215, 0.1785],
        [0.6811, 0.3189],
        [0.6988, 0.3012],
        [0.6377, 0.3623],
        [0.6824, 0.3176],
        [0.6817, 0.3183],
        [0.7432, 0.2568],
        [0.7501, 0.2499],
[2K        [0.6725, 0.3275]], device='cuda:0')â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”[0m 159/203 [2m0:11:28 â€¢ 0:03:37[0m [2;4m0.20it/s[0m  
[2KAttention weights: tensor([[0.5595, 0.4405],â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”[0m 160/203 [2m0:11:30 â€¢ 0:03:23[0m [2;4m0.21it/s[0m  
        [0.5543, 0.4457],
        [0.5567, 0.4433],
        [0.5558, 0.4442],
        [0.5545, 0.4455],
        [0.5538, 0.4462],
        [0.5547, 0.4453],
        [0.5578, 0.4422],
        [0.5582, 0.4418],
[2K        [0.5550, 0.4450]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”[0m 160/203 [2m0:11:30 â€¢ 0:03:23[0m [2;4m0.21it/s[0m  
[2KClass label: Billiardsâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”[0m 160/203 [2m0:11:30 â€¢ 0:03:23[0m [2;4m0.21it/s[0m  
[2KAttention weights: tensor([[0.5989, 0.4011]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 160/203 [2m0:11:30 â€¢ 0:03:23[0m [2;4m0.21it/s[0m  
[2KStep 0 - TTA Loss: 0.7927â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”[0m 160/203 [2m0:11:30 â€¢ 0:03:23[0m [2;4m0.21it/s[0m  
[2KAttention weights: tensor([[0.6420, 0.3580]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 160/203 [2m0:11:30 â€¢ 0:03:23[0m [2;4m0.21it/s[0m  
[2KAttention weights: tensor([[0.6812, 0.3188]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 160/203 [2m0:11:30 â€¢ 0:03:23[0m [2;4m0.21it/s[0m  
[2KAttention weights: tensor([[0.7084, 0.2916]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 160/203 [2m0:11:30 â€¢ 0:03:23[0m [2;4m0.21it/s[0m  
[2KAttention weights: tensor([[0.7219, 0.2781]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 160/203 [2m0:11:30 â€¢ 0:03:23[0m [2;4m0.21it/s[0m  
[2KAttention weights: tensor([[0.7263, 0.2737]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 160/203 [2m0:11:30 â€¢ 0:03:23[0m [2;4m0.21it/s[0m  
[2KAttention weights: tensor([[0.7288, 0.2712]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 160/203 [2m0:11:30 â€¢ 0:03:23[0m [2;4m0.21it/s[0m  
[2KAttention weights: tensor([[0.7324, 0.2676]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 160/203 [2m0:11:30 â€¢ 0:03:23[0m [2;4m0.21it/s[0m  
[2KAttention weights: tensor([[0.7384, 0.2616]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 160/203 [2m0:11:30 â€¢ 0:03:23[0m [2;4m0.21it/s[0m  
[2KAttention weights: tensor([[0.7424, 0.2576]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 160/203 [2m0:11:30 â€¢ 0:03:23[0m [2;4m0.21it/s[0m  
[2KAttention weights: tensor([[0.5569, 0.4431]], device='cuda:0')98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”[0m 160/203 [2m0:11:30 â€¢ 0:03:23[0m [2;4m0.21it/s[0m  
[2KAttention weights: tensor([[0.7268, 0.2732],â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”[0m 160/203 [2m0:11:30 â€¢ 0:03:23[0m [2;4m0.21it/s[0m  
        [0.7440, 0.2560],
        [0.6563, 0.3437],
        [0.6620, 0.3380],
        [0.5973, 0.4027],
        [0.6503, 0.3497],
        [0.6522, 0.3478],
        [0.7038, 0.2962],
        [0.7171, 0.2829],
[2K        [0.6497, 0.3503]], device='cuda:0')â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”[0m 160/203 [2m0:11:30 â€¢ 0:03:23[0m [2;4m0.21it/s[0m  
[2KAttention weights: tensor([[0.5595, 0.4405],â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”[0m 161/203 [2m0:11:32 â€¢ 0:03:13[0m [2;4m0.22it/s[0m  
        [0.5543, 0.4457],
        [0.5567, 0.4433],
        [0.5558, 0.4442],
        [0.5545, 0.4455],
        [0.5538, 0.4462],
        [0.5547, 0.4453],
        [0.5578, 0.4422],
        [0.5582, 0.4418],
[2K        [0.5550, 0.4450]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”[0m 161/203 [2m0:11:32 â€¢ 0:03:13[0m [2;4m0.22it/s[0m  
[2KClass label: Billiardsâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”[0m 161/203 [2m0:11:32 â€¢ 0:03:13[0m [2;4m0.22it/s[0m  
[2KAttention weights: tensor([[0.5960, 0.4040]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 161/203 [2m0:11:32 â€¢ 0:03:13[0m [2;4m0.22it/s[0m  
[2KStep 0 - TTA Loss: 0.7699â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”[0m 161/203 [2m0:11:32 â€¢ 0:03:13[0m [2;4m0.22it/s[0m  
[2KAttention weights: tensor([[0.5960, 0.4040]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 161/203 [2m0:11:32 â€¢ 0:03:13[0m [2;4m0.22it/s[0m  
[2KAttention weights: tensor([[0.5983, 0.4017]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 161/203 [2m0:11:32 â€¢ 0:03:13[0m [2;4m0.22it/s[0m  
[2KAttention weights: tensor([[0.6078, 0.3922]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 161/203 [2m0:11:32 â€¢ 0:03:13[0m [2;4m0.22it/s[0m  
[2KAttention weights: tensor([[0.6288, 0.3712]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 161/203 [2m0:11:32 â€¢ 0:03:13[0m [2;4m0.22it/s[0m  
[2KAttention weights: tensor([[0.6642, 0.3358]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 161/203 [2m0:11:32 â€¢ 0:03:13[0m [2;4m0.22it/s[0m  
[2KAttention weights: tensor([[0.7081, 0.2919]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 161/203 [2m0:11:32 â€¢ 0:03:13[0m [2;4m0.22it/s[0m  
[2KAttention weights: tensor([[0.7646, 0.2354]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 161/203 [2m0:11:32 â€¢ 0:03:13[0m [2;4m0.22it/s[0m  
[2KAttention weights: tensor([[0.8590, 0.1410]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 161/203 [2m0:11:32 â€¢ 0:03:13[0m [2;4m0.22it/s[0m  
[2KAttention weights: tensor([[0.9592, 0.0408]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 161/203 [2m0:11:32 â€¢ 0:03:13[0m [2;4m0.22it/s[0m  
[2KAttention weights: tensor([[0.5785, 0.4215]], device='cuda:0')98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”[0m 161/203 [2m0:11:32 â€¢ 0:03:13[0m [2;4m0.22it/s[0m  
[2KAttention weights: tensor([[0.8861, 0.1139],â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”[0m 161/203 [2m0:11:32 â€¢ 0:03:13[0m [2;4m0.22it/s[0m  
        [0.9957, 0.0043],
        [0.8102, 0.1898],
        [0.8853, 0.1147],
        [0.8153, 0.1847],
        [0.8557, 0.1443],
        [0.8301, 0.1699],
        [0.9148, 0.0852],
        [0.9045, 0.0955],
[2K        [0.8070, 0.1930]], device='cuda:0')â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”[0m 161/203 [2m0:11:32 â€¢ 0:03:13[0m [2;4m0.22it/s[0m  
[2KAttention weights: tensor([[0.5595, 0.4405],â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”[0m 162/203 [2m0:11:35 â€¢ 0:02:32[0m [2;4m0.27it/s[0m  
        [0.5543, 0.4457],
        [0.5567, 0.4433],
        [0.5559, 0.4441],
        [0.5545, 0.4455],
        [0.5538, 0.4462],
        [0.5548, 0.4452],
        [0.5578, 0.4422],
        [0.5583, 0.4417],
[2K        [0.5550, 0.4450]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”[0m 162/203 [2m0:11:35 â€¢ 0:02:32[0m [2;4m0.27it/s[0m  
[2KClass label: PoleVaultâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”[0m 162/203 [2m0:11:35 â€¢ 0:02:32[0m [2;4m0.27it/s[0m  
[2KAttention weights: tensor([[0.6157, 0.3843]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 162/203 [2m0:11:35 â€¢ 0:02:32[0m [2;4m0.27it/s[0m  
[2KStep 0 - TTA Loss: 0.5437â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”[0m 162/203 [2m0:11:35 â€¢ 0:02:32[0m [2;4m0.27it/s[0m  
[2KAttention weights: tensor([[0.7296, 0.2704]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 162/203 [2m0:11:35 â€¢ 0:02:32[0m [2;4m0.27it/s[0m  
[2KAttention weights: tensor([[0.8234, 0.1766]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 162/203 [2m0:11:35 â€¢ 0:02:32[0m [2;4m0.27it/s[0m  
[2KAttention weights: tensor([[0.8911, 0.1089]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 162/203 [2m0:11:35 â€¢ 0:02:32[0m [2;4m0.27it/s[0m  
[2KAttention weights: tensor([[0.9350, 0.0650]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 162/203 [2m0:11:35 â€¢ 0:02:32[0m [2;4m0.27it/s[0m  
[2KAttention weights: tensor([[0.9587, 0.0413]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 162/203 [2m0:11:35 â€¢ 0:02:32[0m [2;4m0.27it/s[0m  
[2KAttention weights: tensor([[0.9749, 0.0251]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 162/203 [2m0:11:35 â€¢ 0:02:32[0m [2;4m0.27it/s[0m  
[2KAttention weights: tensor([[0.9829, 0.0171]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 162/203 [2m0:11:35 â€¢ 0:02:32[0m [2;4m0.27it/s[0m  
[2KAttention weights: tensor([[0.9866, 0.0134]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 162/203 [2m0:11:35 â€¢ 0:02:32[0m [2;4m0.27it/s[0m  
[2KAttention weights: tensor([[0.9879, 0.0121]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 162/203 [2m0:11:35 â€¢ 0:02:32[0m [2;4m0.27it/s[0m  
[2KAttention weights: tensor([[0.5816, 0.4184]], device='cuda:0')98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”[0m 162/203 [2m0:11:35 â€¢ 0:02:32[0m [2;4m0.27it/s[0m  
[2KAttention weights: tensor([[9.8795e-01, 1.2049e-02],[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”[0m 162/203 [2m0:11:35 â€¢ 0:02:32[0m [2;4m0.27it/s[0m  
        [9.9996e-01, 3.9828e-05],
        [9.6288e-01, 3.7119e-02],
        [9.8687e-01, 1.3133e-02],
        [9.8054e-01, 1.9458e-02],
        [9.8868e-01, 1.1318e-02],
        [9.8824e-01, 1.1762e-02],
        [9.9390e-01, 6.1014e-03],
        [9.8855e-01, 1.1454e-02],
[2K        [9.6682e-01, 3.3179e-02]], device='cuda:0')[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”[0m 162/203 [2m0:11:35 â€¢ 0:02:32[0m [2;4m0.27it/s[0m  
[2KAttention weights: tensor([[0.5596, 0.4404],â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”[0m 163/203 [2m0:11:43 â€¢ 0:02:19[0m [2;4m0.29it/s[0m   
        [0.5545, 0.4455],
        [0.5568, 0.4432],
        [0.5560, 0.4440],
        [0.5546, 0.4454],
        [0.5539, 0.4461],
        [0.5549, 0.4451],
        [0.5579, 0.4421],
        [0.5584, 0.4416],
[2K        [0.5551, 0.4449]], device='cuda:0', grad_fn=<SoftmaxBackward0>)m[38;5;237mâ”â”â”â”â”â”â”[0m 163/203 [2m0:11:43 â€¢ 0:02:19[0m [2;4m0.29it/s[0m  
[2KClass label: BaseballPitchâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”[0m 163/203 [2m0:11:43 â€¢ 0:02:19[0m [2;4m0.29it/s[0m  
[2KAttention weights: tensor([[0.6419, 0.3581]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 163/203 [2m0:11:43 â€¢ 0:02:19[0m [2;4m0.29it/s[0m  
[2KStep 0 - TTA Loss: 0.6635â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”[0m 163/203 [2m0:11:43 â€¢ 0:02:19[0m [2;4m0.29it/s[0m  
[2KAttention weights: tensor([[0.6419, 0.3581]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 163/203 [2m0:11:43 â€¢ 0:02:19[0m [2;4m0.29it/s[0m  
[2KAttention weights: tensor([[0.6463, 0.3537]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 163/203 [2m0:11:43 â€¢ 0:02:19[0m [2;4m0.29it/s[0m  
[2KAttention weights: tensor([[0.6644, 0.3356]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 163/203 [2m0:11:43 â€¢ 0:02:19[0m [2;4m0.29it/s[0m  
[2KAttention weights: tensor([[0.7036, 0.2964]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 163/203 [2m0:11:43 â€¢ 0:02:19[0m [2;4m0.29it/s[0m  
[2KAttention weights: tensor([[0.7654, 0.2346]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 163/203 [2m0:11:43 â€¢ 0:02:19[0m [2;4m0.29it/s[0m  
[2KAttention weights: tensor([[0.8382, 0.1618]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 163/203 [2m0:11:43 â€¢ 0:02:19[0m [2;4m0.29it/s[0m  
[2KAttention weights: tensor([[0.9011, 0.0989]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 163/203 [2m0:11:43 â€¢ 0:02:19[0m [2;4m0.29it/s[0m  
[2KAttention weights: tensor([[0.9501, 0.0499]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 163/203 [2m0:11:43 â€¢ 0:02:19[0m [2;4m0.29it/s[0m  
[2KAttention weights: tensor([[0.9746, 0.0254]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 163/203 [2m0:11:43 â€¢ 0:02:19[0m [2;4m0.29it/s[0m  
[2KAttention weights: tensor([[0.5764, 0.4236]], device='cuda:0');237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”[0m 163/203 [2m0:11:43 â€¢ 0:02:19[0m [2;4m0.29it/s[0m  
[2KAttention weights: tensor([[0.9842, 0.0158],â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”[0m 163/203 [2m0:11:43 â€¢ 0:02:19[0m [2;4m0.29it/s[0m  
        [0.9633, 0.0367],
        [0.8945, 0.1055],
        [0.9390, 0.0610],
        [0.9389, 0.0611],
        [0.9474, 0.0526],
        [0.9596, 0.0404],
        [0.9626, 0.0374],
        [0.9450, 0.0550],
[2K        [0.9102, 0.0898]], device='cuda:0')â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”[0m 163/203 [2m0:11:43 â€¢ 0:02:19[0m [2;4m0.29it/s[0m  
[2KAttention weights: tensor([[0.5596, 0.4404],â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”[0m 164/203 [2m0:11:45 â€¢ 0:02:06[0m [2;4m0.31it/s[0m  
        [0.5545, 0.4455],
        [0.5568, 0.4432],
        [0.5560, 0.4440],
        [0.5546, 0.4454],
        [0.5539, 0.4461],
        [0.5549, 0.4451],
        [0.5579, 0.4421],
        [0.5584, 0.4416],
[2K        [0.5551, 0.4449]], device='cuda:0', grad_fn=<SoftmaxBackward0>)m[38;5;237mâ”â”â”â”â”â”â”[0m 164/203 [2m0:11:45 â€¢ 0:02:06[0m [2;4m0.31it/s[0m  
[2KClass label: Billiardsâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”[0m 164/203 [2m0:11:45 â€¢ 0:02:06[0m [2;4m0.31it/s[0m  
[2KAttention weights: tensor([[0.5954, 0.4046]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 164/203 [2m0:11:45 â€¢ 0:02:06[0m [2;4m0.31it/s[0m  
[2KStep 0 - TTA Loss: 0.8440â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”[0m 164/203 [2m0:11:45 â€¢ 0:02:06[0m [2;4m0.31it/s[0m  
[2KAttention weights: tensor([[0.6970, 0.3030]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 164/203 [2m0:11:45 â€¢ 0:02:06[0m [2;4m0.31it/s[0m  
[2KAttention weights: tensor([[0.7789, 0.2211]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 164/203 [2m0:11:45 â€¢ 0:02:06[0m [2;4m0.31it/s[0m  
[2KAttention weights: tensor([[0.8316, 0.1684]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 164/203 [2m0:11:45 â€¢ 0:02:06[0m [2;4m0.31it/s[0m  
[2KAttention weights: tensor([[0.8574, 0.1426]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 164/203 [2m0:11:45 â€¢ 0:02:06[0m [2;4m0.31it/s[0m  
[2KAttention weights: tensor([[0.8637, 0.1363]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 164/203 [2m0:11:45 â€¢ 0:02:06[0m [2;4m0.31it/s[0m  
[2KAttention weights: tensor([[0.8561, 0.1439]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 164/203 [2m0:11:45 â€¢ 0:02:06[0m [2;4m0.31it/s[0m  
[2KAttention weights: tensor([[0.8431, 0.1569]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 164/203 [2m0:11:45 â€¢ 0:02:06[0m [2;4m0.31it/s[0m  
[2KAttention weights: tensor([[0.8311, 0.1689]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 164/203 [2m0:11:45 â€¢ 0:02:06[0m [2;4m0.31it/s[0m  
[2KAttention weights: tensor([[0.8238, 0.1762]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 164/203 [2m0:11:45 â€¢ 0:02:06[0m [2;4m0.31it/s[0m  
[2KAttention weights: tensor([[0.5607, 0.4393]], device='cuda:0');237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”[0m 164/203 [2m0:11:45 â€¢ 0:02:06[0m [2;4m0.31it/s[0m  
[2KAttention weights: tensor([[0.9088, 0.0912],â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”[0m 164/203 [2m0:11:45 â€¢ 0:02:06[0m [2;4m0.31it/s[0m  
        [0.8217, 0.1783],
        [0.7978, 0.2022],
        [0.8246, 0.1754],
        [0.8155, 0.1845],
        [0.8488, 0.1512],
        [0.8746, 0.1254],
        [0.8698, 0.1302],
        [0.8498, 0.1502],
[2K        [0.8113, 0.1887]], device='cuda:0')â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”[0m 164/203 [2m0:11:45 â€¢ 0:02:06[0m [2;4m0.31it/s[0m  
[2KAttention weights: tensor([[0.5594, 0.4406],â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”[0m 165/203 [2m0:11:49 â€¢ 0:02:09[0m [2;4m0.30it/s[0m  
        [0.5545, 0.4455],
        [0.5567, 0.4433],
        [0.5559, 0.4441],
        [0.5545, 0.4455],
        [0.5538, 0.4462],
        [0.5548, 0.4452],
        [0.5578, 0.4422],
        [0.5583, 0.4417],
[2K        [0.5550, 0.4450]], device='cuda:0', grad_fn=<SoftmaxBackward0>)mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”[0m 165/203 [2m0:11:49 â€¢ 0:02:09[0m [2;4m0.30it/s[0m  
[2KClass label: BaseballPitchâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”[0m 165/203 [2m0:11:49 â€¢ 0:02:09[0m [2;4m0.30it/s[0m  
[2KAttention weights: tensor([[0.6379, 0.3621]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 165/203 [2m0:11:49 â€¢ 0:02:09[0m [2;4m0.30it/s[0m  
[2KStep 0 - TTA Loss: 0.4732â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”[0m 165/203 [2m0:11:49 â€¢ 0:02:09[0m [2;4m0.30it/s[0m  
[2KAttention weights: tensor([[0.6379, 0.3621]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 165/203 [2m0:11:49 â€¢ 0:02:09[0m [2;4m0.30it/s[0m  
[2KAttention weights: tensor([[0.6382, 0.3618]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 165/203 [2m0:11:49 â€¢ 0:02:09[0m [2;4m0.30it/s[0m  
[2KAttention weights: tensor([[0.6389, 0.3611]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 165/203 [2m0:11:49 â€¢ 0:02:09[0m [2;4m0.30it/s[0m  
[2KAttention weights: tensor([[0.6422, 0.3578]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 165/203 [2m0:11:49 â€¢ 0:02:09[0m [2;4m0.30it/s[0m  
[2KAttention weights: tensor([[0.6498, 0.3502]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 165/203 [2m0:11:49 â€¢ 0:02:09[0m [2;4m0.30it/s[0m  
[2KAttention weights: tensor([[0.6627, 0.3373]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 165/203 [2m0:11:49 â€¢ 0:02:09[0m [2;4m0.30it/s[0m  
[2KAttention weights: tensor([[0.6767, 0.3233]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 165/203 [2m0:11:49 â€¢ 0:02:09[0m [2;4m0.30it/s[0m  
[2KAttention weights: tensor([[0.6928, 0.3072]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 165/203 [2m0:11:49 â€¢ 0:02:09[0m [2;4m0.30it/s[0m  
[2KAttention weights: tensor([[0.7217, 0.2783]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 165/203 [2m0:11:49 â€¢ 0:02:09[0m [2;4m0.30it/s[0m  
[2KAttention weights: tensor([[0.5614, 0.4386]], device='cuda:0');98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”[0m 165/203 [2m0:11:49 â€¢ 0:02:09[0m [2;4m0.30it/s[0m  
[2KAttention weights: tensor([[0.7709, 0.2291],â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”[0m 165/203 [2m0:11:49 â€¢ 0:02:09[0m [2;4m0.30it/s[0m  
        [0.3487, 0.6513],
        [0.6360, 0.3640],
        [0.6288, 0.3712],
        [0.5955, 0.4045],
        [0.6272, 0.3728],
        [0.6644, 0.3356],
        [0.6593, 0.3407],
        [0.6730, 0.3270],
[2K        [0.6422, 0.3578]], device='cuda:0')â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”[0m 165/203 [2m0:11:49 â€¢ 0:02:09[0m [2;4m0.30it/s[0m  
[2KAttention weights: tensor([[0.5594, 0.4406],â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”[0m 166/203 [2m0:11:53 â€¢ 0:02:02[0m [2;4m0.30it/s[0m  
        [0.5544, 0.4456],
        [0.5567, 0.4433],
        [0.5558, 0.4442],
        [0.5545, 0.4455],
        [0.5538, 0.4462],
        [0.5548, 0.4452],
        [0.5578, 0.4422],
        [0.5582, 0.4418],
[2K        [0.5550, 0.4450]], device='cuda:0', grad_fn=<SoftmaxBackward0>)mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”[0m 166/203 [2m0:11:53 â€¢ 0:02:02[0m [2;4m0.30it/s[0m  
[2KClass label: TennisSwingâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”[0m 166/203 [2m0:11:53 â€¢ 0:02:02[0m [2;4m0.30it/s[0m  
[2KAttention weights: tensor([[0.6652, 0.3348]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 166/203 [2m0:11:53 â€¢ 0:02:02[0m [2;4m0.30it/s[0m  
[2KStep 0 - TTA Loss: 1.0085â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”[0m 166/203 [2m0:11:53 â€¢ 0:02:02[0m [2;4m0.30it/s[0m  
[2KAttention weights: tensor([[0.7020, 0.2980]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 166/203 [2m0:11:53 â€¢ 0:02:02[0m [2;4m0.30it/s[0m  
[2KAttention weights: tensor([[0.7562, 0.2438]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 166/203 [2m0:11:53 â€¢ 0:02:02[0m [2;4m0.30it/s[0m  
[2KAttention weights: tensor([[0.8120, 0.1880]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 166/203 [2m0:11:53 â€¢ 0:02:02[0m [2;4m0.30it/s[0m  
[2KAttention weights: tensor([[0.8563, 0.1437]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 166/203 [2m0:11:53 â€¢ 0:02:02[0m [2;4m0.30it/s[0m  
[2KAttention weights: tensor([[0.8849, 0.1151]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 166/203 [2m0:11:53 â€¢ 0:02:02[0m [2;4m0.30it/s[0m  
[2KAttention weights: tensor([[0.9001, 0.0999]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 166/203 [2m0:11:53 â€¢ 0:02:02[0m [2;4m0.30it/s[0m  
[2KAttention weights: tensor([[0.9082, 0.0918]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 166/203 [2m0:11:53 â€¢ 0:02:02[0m [2;4m0.30it/s[0m  
[2KAttention weights: tensor([[0.9114, 0.0886]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 166/203 [2m0:11:53 â€¢ 0:02:02[0m [2;4m0.30it/s[0m  
[2KAttention weights: tensor([[0.9164, 0.0836]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 166/203 [2m0:11:53 â€¢ 0:02:02[0m [2;4m0.30it/s[0m  
[2KAttention weights: tensor([[0.5674, 0.4326]], device='cuda:0');98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”[0m 166/203 [2m0:11:53 â€¢ 0:02:02[0m [2;4m0.30it/s[0m  
[2KAttention weights: tensor([[0.9100, 0.0900],â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”[0m 166/203 [2m0:11:53 â€¢ 0:02:02[0m [2;4m0.30it/s[0m  
        [0.6146, 0.3854],
        [0.7873, 0.2127],
        [0.8293, 0.1707],
        [0.7861, 0.2139],
        [0.8107, 0.1893],
        [0.7945, 0.2055],
        [0.8390, 0.1610],
        [0.9178, 0.0822],
[2K        [0.8138, 0.1862]], device='cuda:0')â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”[0m 166/203 [2m0:11:53 â€¢ 0:02:02[0m [2;4m0.30it/s[0m  
[2KAttention weights: tensor([[0.5594, 0.4406],â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”[0m 167/203 [2m0:11:56 â€¢ 0:01:57[0m [2;4m0.31it/s[0m  
        [0.5544, 0.4456],
        [0.5567, 0.4433],
        [0.5559, 0.4441],
        [0.5545, 0.4455],
        [0.5538, 0.4462],
        [0.5548, 0.4452],
        [0.5578, 0.4422],
        [0.5583, 0.4417],
[2K        [0.5550, 0.4450]], device='cuda:0', grad_fn=<SoftmaxBackward0>)mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”[0m 167/203 [2m0:11:56 â€¢ 0:01:57[0m [2;4m0.31it/s[0m  
[2KClass label: BaseballPitchâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”[0m 167/203 [2m0:11:56 â€¢ 0:01:57[0m [2;4m0.31it/s[0m  
[2KAttention weights: tensor([[0.6454, 0.3546]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 167/203 [2m0:11:56 â€¢ 0:01:57[0m [2;4m0.31it/s[0m  
[2KStep 0 - TTA Loss: 0.5835â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”[0m 167/203 [2m0:11:56 â€¢ 0:01:57[0m [2;4m0.31it/s[0m  
[2KAttention weights: tensor([[0.6454, 0.3546]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 167/203 [2m0:11:56 â€¢ 0:01:57[0m [2;4m0.31it/s[0m  
[2KAttention weights: tensor([[0.6488, 0.3512]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 167/203 [2m0:11:56 â€¢ 0:01:57[0m [2;4m0.31it/s[0m  
[2KAttention weights: tensor([[0.6636, 0.3364]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 167/203 [2m0:11:56 â€¢ 0:01:57[0m [2;4m0.31it/s[0m  
[2KAttention weights: tensor([[0.6972, 0.3028]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 167/203 [2m0:11:56 â€¢ 0:01:57[0m [2;4m0.31it/s[0m  
[2KAttention weights: tensor([[0.7517, 0.2483]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 167/203 [2m0:11:56 â€¢ 0:01:57[0m [2;4m0.31it/s[0m  
[2KAttention weights: tensor([[0.8183, 0.1817]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 167/203 [2m0:11:56 â€¢ 0:01:57[0m [2;4m0.31it/s[0m  
[2KAttention weights: tensor([[0.8802, 0.1198]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 167/203 [2m0:11:56 â€¢ 0:01:57[0m [2;4m0.31it/s[0m  
[2KAttention weights: tensor([[0.9262, 0.0738]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 167/203 [2m0:11:56 â€¢ 0:01:57[0m [2;4m0.31it/s[0m  
[2KAttention weights: tensor([[0.9579, 0.0421]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 167/203 [2m0:11:56 â€¢ 0:01:57[0m [2;4m0.31it/s[0m  
[2KAttention weights: tensor([[0.5756, 0.4244]], device='cuda:0');98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”[0m 167/203 [2m0:11:56 â€¢ 0:01:57[0m [2;4m0.31it/s[0m  
[2KAttention weights: tensor([[0.9811, 0.0189],â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”[0m 167/203 [2m0:11:56 â€¢ 0:01:57[0m [2;4m0.31it/s[0m  
        [0.8288, 0.1712],
        [0.8545, 0.1455],
        [0.9215, 0.0785],
        [0.8968, 0.1032],
        [0.8913, 0.1087],
        [0.8793, 0.1207],
        [0.9317, 0.0683],
        [0.9615, 0.0385],
[2K        [0.8803, 0.1197]], device='cuda:0')â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”[0m 167/203 [2m0:11:56 â€¢ 0:01:57[0m [2;4m0.31it/s[0m  
[2KAttention weights: tensor([[0.5594, 0.4406],â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”[0m 168/203 [2m0:12:00 â€¢ 0:02:11[0m [2;4m0.27it/s[0m   
        [0.5544, 0.4456],
        [0.5567, 0.4433],
        [0.5559, 0.4441],
        [0.5546, 0.4454],
        [0.5539, 0.4461],
        [0.5548, 0.4452],
        [0.5578, 0.4422],
        [0.5583, 0.4417],
[2K        [0.5550, 0.4450]], device='cuda:0', grad_fn=<SoftmaxBackward0>)0m[38;5;237mâ”â”â”â”â”â”[0m 168/203 [2m0:12:00 â€¢ 0:02:11[0m [2;4m0.27it/s[0m  
[2KClass label: SoccerPenaltyâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”[0m 168/203 [2m0:12:00 â€¢ 0:02:11[0m [2;4m0.27it/s[0m  
[2KAttention weights: tensor([[0.6357, 0.3643]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 168/203 [2m0:12:00 â€¢ 0:02:11[0m [2;4m0.27it/s[0m  
[2KStep 0 - TTA Loss: 0.7574â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”[0m 168/203 [2m0:12:00 â€¢ 0:02:11[0m [2;4m0.27it/s[0m  
[2KAttention weights: tensor([[0.7583, 0.2417]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 168/203 [2m0:12:00 â€¢ 0:02:11[0m [2;4m0.27it/s[0m  
[2KAttention weights: tensor([[0.8594, 0.1406]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 168/203 [2m0:12:00 â€¢ 0:02:11[0m [2;4m0.27it/s[0m  
[2KAttention weights: tensor([[0.9235, 0.0765]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 168/203 [2m0:12:00 â€¢ 0:02:11[0m [2;4m0.27it/s[0m  
[2KAttention weights: tensor([[0.9500, 0.0500]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 168/203 [2m0:12:00 â€¢ 0:02:11[0m [2;4m0.27it/s[0m  
[2KAttention weights: tensor([[0.9646, 0.0354]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 168/203 [2m0:12:00 â€¢ 0:02:11[0m [2;4m0.27it/s[0m  
[2KAttention weights: tensor([[0.9723, 0.0277]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 168/203 [2m0:12:00 â€¢ 0:02:11[0m [2;4m0.27it/s[0m  
[2KAttention weights: tensor([[0.9751, 0.0249]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 168/203 [2m0:12:00 â€¢ 0:02:11[0m [2;4m0.27it/s[0m  
[2KAttention weights: tensor([[0.9766, 0.0234]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 168/203 [2m0:12:00 â€¢ 0:02:11[0m [2;4m0.27it/s[0m  
[2KAttention weights: tensor([[0.9772, 0.0228]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 168/203 [2m0:12:00 â€¢ 0:02:11[0m [2;4m0.27it/s[0m  
[2KAttention weights: tensor([[0.5751, 0.4249]], device='cuda:0')5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”[0m 168/203 [2m0:12:00 â€¢ 0:02:11[0m [2;4m0.27it/s[0m  
[2KAttention weights: tensor([[0.9891, 0.0109],â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”[0m 168/203 [2m0:12:00 â€¢ 0:02:11[0m [2;4m0.27it/s[0m  
        [0.8787, 0.1213],
        [0.8676, 0.1324],
        [0.9443, 0.0557],
        [0.9356, 0.0644],
        [0.9241, 0.0759],
        [0.9155, 0.0845],
        [0.9773, 0.0227],
        [0.9656, 0.0344],
[2K        [0.8918, 0.1082]], device='cuda:0')â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”[0m 168/203 [2m0:12:00 â€¢ 0:02:11[0m [2;4m0.27it/s[0m  
[2KAttention weights: tensor([[0.5595, 0.4405],â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”[0m 169/203 [2m0:12:01 â€¢ 0:02:03[0m [2;4m0.28it/s[0m  
        [0.5545, 0.4455],
        [0.5568, 0.4432],
        [0.5560, 0.4440],
        [0.5546, 0.4454],
        [0.5539, 0.4461],
        [0.5549, 0.4451],
        [0.5579, 0.4421],
        [0.5584, 0.4416],
[2K        [0.5551, 0.4449]], device='cuda:0', grad_fn=<SoftmaxBackward0>)0m[38;5;237mâ”â”â”â”â”â”[0m 169/203 [2m0:12:01 â€¢ 0:02:03[0m [2;4m0.28it/s[0m  
[2KClass label: HammerThrowâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”[0m 169/203 [2m0:12:01 â€¢ 0:02:03[0m [2;4m0.28it/s[0m  
[2KAttention weights: tensor([[0.5397, 0.4603]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 169/203 [2m0:12:01 â€¢ 0:02:03[0m [2;4m0.28it/s[0m  
[2KStep 0 - TTA Loss: 0.5358â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”[0m 169/203 [2m0:12:01 â€¢ 0:02:03[0m [2;4m0.28it/s[0m  
[2KAttention weights: tensor([[0.5397, 0.4603]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 169/203 [2m0:12:01 â€¢ 0:02:03[0m [2;4m0.28it/s[0m  
[2KAttention weights: tensor([[0.5404, 0.4596]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 169/203 [2m0:12:01 â€¢ 0:02:03[0m [2;4m0.28it/s[0m  
[2KAttention weights: tensor([[0.5434, 0.4566]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 169/203 [2m0:12:01 â€¢ 0:02:03[0m [2;4m0.28it/s[0m  
[2KAttention weights: tensor([[0.5500, 0.4500]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 169/203 [2m0:12:01 â€¢ 0:02:03[0m [2;4m0.28it/s[0m  
[2KAttention weights: tensor([[0.5638, 0.4362]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 169/203 [2m0:12:01 â€¢ 0:02:03[0m [2;4m0.28it/s[0m  
[2KAttention weights: tensor([[0.5809, 0.4191]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 169/203 [2m0:12:01 â€¢ 0:02:03[0m [2;4m0.28it/s[0m  
[2KAttention weights: tensor([[0.5991, 0.4009]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 169/203 [2m0:12:01 â€¢ 0:02:03[0m [2;4m0.28it/s[0m  
[2KAttention weights: tensor([[0.6201, 0.3799]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 169/203 [2m0:12:01 â€¢ 0:02:03[0m [2;4m0.28it/s[0m  
[2KAttention weights: tensor([[0.6471, 0.3529]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 169/203 [2m0:12:01 â€¢ 0:02:03[0m [2;4m0.28it/s[0m  
[2KAttention weights: tensor([[0.5580, 0.4420]], device='cuda:0')5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”[0m 169/203 [2m0:12:01 â€¢ 0:02:03[0m [2;4m0.28it/s[0m  
[2KAttention weights: tensor([[0.7849, 0.2151],â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”[0m 169/203 [2m0:12:01 â€¢ 0:02:03[0m [2;4m0.28it/s[0m  
        [0.6526, 0.3474],
        [0.6963, 0.3037],
        [0.7010, 0.2990],
        [0.6889, 0.3111],
        [0.6931, 0.3069],
        [0.6920, 0.3080],
        [0.7154, 0.2846],
        [0.7630, 0.2370],
[2K        [0.7058, 0.2942]], device='cuda:0')â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”[0m 169/203 [2m0:12:01 â€¢ 0:02:03[0m [2;4m0.28it/s[0m  
[2KAttention weights: tensor([[0.5595, 0.4405],â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”[0m 170/203 [2m0:12:07 â€¢ 0:01:53[0m [2;4m0.29it/s[0m  
        [0.5545, 0.4455],
        [0.5568, 0.4432],
        [0.5559, 0.4441],
        [0.5546, 0.4454],
        [0.5539, 0.4461],
        [0.5549, 0.4451],
        [0.5578, 0.4422],
        [0.5584, 0.4416],
[2K        [0.5551, 0.4449]], device='cuda:0', grad_fn=<SoftmaxBackward0>)0m[38;5;237mâ”â”â”â”â”â”[0m 170/203 [2m0:12:07 â€¢ 0:01:53[0m [2;4m0.29it/s[0m  
[2KClass label: HighJumpâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”[0m 170/203 [2m0:12:07 â€¢ 0:01:53[0m [2;4m0.29it/s[0m  
[2KAttention weights: tensor([[0.6070, 0.3930]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 170/203 [2m0:12:07 â€¢ 0:01:53[0m [2;4m0.29it/s[0m  
[2KStep 0 - TTA Loss: 0.8555â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”[0m 170/203 [2m0:12:07 â€¢ 0:01:53[0m [2;4m0.29it/s[0m  
[2KAttention weights: tensor([[0.6586, 0.3414]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 170/203 [2m0:12:07 â€¢ 0:01:53[0m [2;4m0.29it/s[0m  
[2KAttention weights: tensor([[0.7231, 0.2769]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 170/203 [2m0:12:07 â€¢ 0:01:53[0m [2;4m0.29it/s[0m  
[2KAttention weights: tensor([[0.7885, 0.2115]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 170/203 [2m0:12:07 â€¢ 0:01:53[0m [2;4m0.29it/s[0m  
[2KAttention weights: tensor([[0.8441, 0.1559]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 170/203 [2m0:12:07 â€¢ 0:01:53[0m [2;4m0.29it/s[0m  
[2KAttention weights: tensor([[0.8835, 0.1165]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 170/203 [2m0:12:07 â€¢ 0:01:53[0m [2;4m0.29it/s[0m  
[2KAttention weights: tensor([[0.9063, 0.0937]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 170/203 [2m0:12:07 â€¢ 0:01:53[0m [2;4m0.29it/s[0m  
[2KAttention weights: tensor([[0.9193, 0.0807]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 170/203 [2m0:12:07 â€¢ 0:01:53[0m [2;4m0.29it/s[0m  
[2KAttention weights: tensor([[0.9272, 0.0728]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 170/203 [2m0:12:07 â€¢ 0:01:53[0m [2;4m0.29it/s[0m  
[2KAttention weights: tensor([[0.9310, 0.0690]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 170/203 [2m0:12:07 â€¢ 0:01:53[0m [2;4m0.29it/s[0m  
[2KAttention weights: tensor([[0.5662, 0.4338]], device='cuda:0')5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”[0m 170/203 [2m0:12:07 â€¢ 0:01:53[0m [2;4m0.29it/s[0m  
[2KAttention weights: tensor([[0.8832, 0.1168],â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”[0m 170/203 [2m0:12:07 â€¢ 0:01:53[0m [2;4m0.29it/s[0m  
        [0.7808, 0.2192],
        [0.8464, 0.1536],
        [0.8384, 0.1616],
        [0.8884, 0.1116],
        [0.9321, 0.0679],
        [0.8783, 0.1217],
        [0.8808, 0.1192],
        [0.8952, 0.1048],
[2K        [0.8771, 0.1229]], device='cuda:0')â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”[0m 170/203 [2m0:12:07 â€¢ 0:01:53[0m [2;4m0.29it/s[0m  
[2KAttention weights: tensor([[0.5595, 0.4405],â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”[0m 171/203 [2m0:12:11 â€¢ 0:01:54[0m [2;4m0.28it/s[0m  
        [0.5545, 0.4455],
        [0.5568, 0.4432],
        [0.5560, 0.4440],
        [0.5546, 0.4454],
        [0.5539, 0.4461],
        [0.5549, 0.4451],
        [0.5578, 0.4422],
        [0.5584, 0.4416],
[2K        [0.5551, 0.4449]], device='cuda:0', grad_fn=<SoftmaxBackward0>)4mâ•¸[0m[38;5;237mâ”â”â”â”â”â”[0m 171/203 [2m0:12:11 â€¢ 0:01:54[0m [2;4m0.28it/s[0m  
[2KClass label: BaseballPitchâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”[0m 171/203 [2m0:12:11 â€¢ 0:01:54[0m [2;4m0.28it/s[0m  
[2KAttention weights: tensor([[0.6426, 0.3574]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 171/203 [2m0:12:11 â€¢ 0:01:54[0m [2;4m0.28it/s[0m  
[2KStep 0 - TTA Loss: 0.9700â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”[0m 171/203 [2m0:12:11 â€¢ 0:01:54[0m [2;4m0.28it/s[0m  
[2KAttention weights: tensor([[0.6426, 0.3574]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 171/203 [2m0:12:11 â€¢ 0:01:54[0m [2;4m0.28it/s[0m  
[2KAttention weights: tensor([[0.6452, 0.3548]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 171/203 [2m0:12:11 â€¢ 0:01:54[0m [2;4m0.28it/s[0m  
[2KAttention weights: tensor([[0.6561, 0.3439]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 171/203 [2m0:12:11 â€¢ 0:01:54[0m [2;4m0.28it/s[0m  
[2KAttention weights: tensor([[0.6806, 0.3194]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 171/203 [2m0:12:11 â€¢ 0:01:54[0m [2;4m0.28it/s[0m  
[2KAttention weights: tensor([[0.7231, 0.2769]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 171/203 [2m0:12:11 â€¢ 0:01:54[0m [2;4m0.28it/s[0m  
[2KAttention weights: tensor([[0.7829, 0.2171]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 171/203 [2m0:12:11 â€¢ 0:01:54[0m [2;4m0.28it/s[0m  
[2KAttention weights: tensor([[0.8499, 0.1501]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 171/203 [2m0:12:11 â€¢ 0:01:54[0m [2;4m0.28it/s[0m  
[2KAttention weights: tensor([[0.9080, 0.0920]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 171/203 [2m0:12:11 â€¢ 0:01:54[0m [2;4m0.28it/s[0m  
[2KAttention weights: tensor([[0.9465, 0.0535]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 171/203 [2m0:12:11 â€¢ 0:01:54[0m [2;4m0.28it/s[0m  
[2KAttention weights: tensor([[0.5724, 0.4276]], device='cuda:0')2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”[0m 171/203 [2m0:12:11 â€¢ 0:01:54[0m [2;4m0.28it/s[0m  
[2KAttention weights: tensor([[0.9681, 0.0319],â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”[0m 171/203 [2m0:12:11 â€¢ 0:01:54[0m [2;4m0.28it/s[0m  
        [0.8189, 0.1811],
        [0.8362, 0.1638],
        [0.8849, 0.1151],
        [0.8949, 0.1051],
        [0.9186, 0.0814],
        [0.8907, 0.1093],
        [0.9188, 0.0812],
        [0.9101, 0.0899],
[2K        [0.8648, 0.1352]], device='cuda:0')â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”[0m 171/203 [2m0:12:11 â€¢ 0:01:54[0m [2;4m0.28it/s[0m  
[2KAttention weights: tensor([[0.5595, 0.4405],â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”[0m 172/203 [2m0:12:13 â€¢ 0:01:44[0m [2;4m0.30it/s[0m  
        [0.5545, 0.4455],
        [0.5568, 0.4432],
        [0.5559, 0.4441],
        [0.5546, 0.4454],
        [0.5539, 0.4461],
        [0.5549, 0.4451],
        [0.5578, 0.4422],
        [0.5584, 0.4416],
[2K        [0.5551, 0.4449]], device='cuda:0', grad_fn=<SoftmaxBackward0>)4mâ•¸[0m[38;5;237mâ”â”â”â”â”â”[0m 172/203 [2m0:12:13 â€¢ 0:01:44[0m [2;4m0.30it/s[0m  
[2KClass label: PoleVaultâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”[0m 172/203 [2m0:12:13 â€¢ 0:01:44[0m [2;4m0.30it/s[0m  
[2KAttention weights: tensor([[0.6109, 0.3891]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 172/203 [2m0:12:13 â€¢ 0:01:44[0m [2;4m0.30it/s[0m  
[2KStep 0 - TTA Loss: 0.8335â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”[0m 172/203 [2m0:12:13 â€¢ 0:01:44[0m [2;4m0.30it/s[0m  
[2KAttention weights: tensor([[0.6883, 0.3117]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 172/203 [2m0:12:13 â€¢ 0:01:44[0m [2;4m0.30it/s[0m  
[2KAttention weights: tensor([[0.7694, 0.2306]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 172/203 [2m0:12:13 â€¢ 0:01:44[0m [2;4m0.30it/s[0m  
[2KAttention weights: tensor([[0.8382, 0.1618]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 172/203 [2m0:12:13 â€¢ 0:01:44[0m [2;4m0.30it/s[0m  
[2KAttention weights: tensor([[0.8934, 0.1066]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 172/203 [2m0:12:13 â€¢ 0:01:44[0m [2;4m0.30it/s[0m  
[2KAttention weights: tensor([[0.9325, 0.0675]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 172/203 [2m0:12:13 â€¢ 0:01:44[0m [2;4m0.30it/s[0m  
[2KAttention weights: tensor([[0.9554, 0.0446]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 172/203 [2m0:12:13 â€¢ 0:01:44[0m [2;4m0.30it/s[0m  
[2KAttention weights: tensor([[0.9665, 0.0335]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 172/203 [2m0:12:13 â€¢ 0:01:44[0m [2;4m0.30it/s[0m  
[2KAttention weights: tensor([[0.9719, 0.0281]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 172/203 [2m0:12:13 â€¢ 0:01:44[0m [2;4m0.30it/s[0m  
[2KAttention weights: tensor([[0.9740, 0.0260]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 172/203 [2m0:12:13 â€¢ 0:01:44[0m [2;4m0.30it/s[0m  
[2KAttention weights: tensor([[0.5756, 0.4244]], device='cuda:0')2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”[0m 172/203 [2m0:12:13 â€¢ 0:01:44[0m [2;4m0.30it/s[0m  
[2KAttention weights: tensor([[0.9809, 0.0191],â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”[0m 172/203 [2m0:12:13 â€¢ 0:01:44[0m [2;4m0.30it/s[0m  
        [0.8755, 0.1245],
        [0.9155, 0.0845],
        [0.9340, 0.0660],
        [0.9532, 0.0468],
        [0.9705, 0.0295],
        [0.9745, 0.0255],
        [0.9625, 0.0375],
        [0.9460, 0.0540],
[2K        [0.9357, 0.0643]], device='cuda:0')â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”[0m 172/203 [2m0:12:13 â€¢ 0:01:44[0m [2;4m0.30it/s[0m  
[2KAttention weights: tensor([[0.5595, 0.4405],â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”[0m 173/203 [2m0:12:19 â€¢ 0:01:50[0m [2;4m0.27it/s[0m   
        [0.5545, 0.4455],
        [0.5568, 0.4432],
        [0.5559, 0.4441],
        [0.5546, 0.4454],
        [0.5540, 0.4460],
        [0.5549, 0.4451],
        [0.5578, 0.4422],
        [0.5584, 0.4416],
[2K        [0.5551, 0.4449]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m[38;5;237mâ”â”â”â”â”[0m 173/203 [2m0:12:19 â€¢ 0:01:50[0m [2;4m0.27it/s[0m  
[2KClass label: HammerThrowâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”[0m 173/203 [2m0:12:19 â€¢ 0:01:50[0m [2;4m0.27it/s[0m  
[2KAttention weights: tensor([[0.5392, 0.4608]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 173/203 [2m0:12:19 â€¢ 0:01:50[0m [2;4m0.27it/s[0m  
[2KStep 0 - TTA Loss: 0.5750â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”[0m 173/203 [2m0:12:19 â€¢ 0:01:50[0m [2;4m0.27it/s[0m  
[2KAttention weights: tensor([[0.5392, 0.4608]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 173/203 [2m0:12:19 â€¢ 0:01:50[0m [2;4m0.27it/s[0m  
[2KAttention weights: tensor([[0.5434, 0.4566]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 173/203 [2m0:12:19 â€¢ 0:01:50[0m [2;4m0.27it/s[0m  
[2KAttention weights: tensor([[0.5604, 0.4396]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 173/203 [2m0:12:19 â€¢ 0:01:50[0m [2;4m0.27it/s[0m  
[2KAttention weights: tensor([[0.5983, 0.4017]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 173/203 [2m0:12:19 â€¢ 0:01:50[0m [2;4m0.27it/s[0m  
[2KAttention weights: tensor([[0.6627, 0.3373]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 173/203 [2m0:12:19 â€¢ 0:01:50[0m [2;4m0.27it/s[0m  
[2KAttention weights: tensor([[0.7513, 0.2487]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 173/203 [2m0:12:19 â€¢ 0:01:50[0m [2;4m0.27it/s[0m  
[2KAttention weights: tensor([[0.8464, 0.1536]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 173/203 [2m0:12:19 â€¢ 0:01:50[0m [2;4m0.27it/s[0m  
[2KAttention weights: tensor([[0.9210, 0.0790]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 173/203 [2m0:12:19 â€¢ 0:01:50[0m [2;4m0.27it/s[0m  
[2KAttention weights: tensor([[0.9630, 0.0370]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 173/203 [2m0:12:19 â€¢ 0:01:50[0m [2;4m0.27it/s[0m  
[2KAttention weights: tensor([[0.5737, 0.4263]], device='cuda:0');5;237mâ•º[0m[38;5;237mâ”â”â”â”â”[0m 173/203 [2m0:12:19 â€¢ 0:01:50[0m [2;4m0.27it/s[0m  
[2KAttention weights: tensor([[0.9593, 0.0407],â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”[0m 173/203 [2m0:12:19 â€¢ 0:01:50[0m [2;4m0.27it/s[0m  
        [0.8589, 0.1411],
        [0.9264, 0.0736],
        [0.9168, 0.0832],
        [0.9836, 0.0164],
        [0.9608, 0.0392],
        [0.9608, 0.0392],
        [0.9580, 0.0420],
        [0.9369, 0.0631],
[2K        [0.9488, 0.0512]], device='cuda:0')â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”[0m 173/203 [2m0:12:19 â€¢ 0:01:50[0m [2;4m0.27it/s[0m  
[2KAttention weights: tensor([[0.5595, 0.4405],â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”[0m 174/203 [2m0:12:22 â€¢ 0:01:43[0m [2;4m0.28it/s[0m  
        [0.5545, 0.4455],
        [0.5568, 0.4432],
        [0.5559, 0.4441],
        [0.5546, 0.4454],
        [0.5540, 0.4460],
        [0.5549, 0.4451],
        [0.5578, 0.4422],
        [0.5584, 0.4416],
[2K        [0.5551, 0.4449]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m[38;5;237mâ”â”â”â”â”[0m 174/203 [2m0:12:22 â€¢ 0:01:43[0m [2;4m0.28it/s[0m  
[2KClass label: TennisSwingâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”[0m 174/203 [2m0:12:22 â€¢ 0:01:43[0m [2;4m0.28it/s[0m  
[2KAttention weights: tensor([[0.6611, 0.3389]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 174/203 [2m0:12:22 â€¢ 0:01:43[0m [2;4m0.28it/s[0m  
[2KStep 0 - TTA Loss: 0.7813â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”[0m 174/203 [2m0:12:22 â€¢ 0:01:43[0m [2;4m0.28it/s[0m  
[2KAttention weights: tensor([[0.7352, 0.2648]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 174/203 [2m0:12:22 â€¢ 0:01:43[0m [2;4m0.28it/s[0m  
[2KAttention weights: tensor([[0.7866, 0.2134]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 174/203 [2m0:12:22 â€¢ 0:01:43[0m [2;4m0.28it/s[0m  
[2KAttention weights: tensor([[0.8190, 0.1810]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 174/203 [2m0:12:22 â€¢ 0:01:43[0m [2;4m0.28it/s[0m  
[2KAttention weights: tensor([[0.8320, 0.1680]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 174/203 [2m0:12:22 â€¢ 0:01:43[0m [2;4m0.28it/s[0m  
[2KAttention weights: tensor([[0.8271, 0.1729]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 174/203 [2m0:12:22 â€¢ 0:01:43[0m [2;4m0.28it/s[0m  
[2KAttention weights: tensor([[0.8146, 0.1854]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 174/203 [2m0:12:22 â€¢ 0:01:43[0m [2;4m0.28it/s[0m  
[2KAttention weights: tensor([[0.8007, 0.1993]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 174/203 [2m0:12:22 â€¢ 0:01:43[0m [2;4m0.28it/s[0m  
[2KAttention weights: tensor([[0.7894, 0.2106]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 174/203 [2m0:12:22 â€¢ 0:01:43[0m [2;4m0.28it/s[0m  
[2KAttention weights: tensor([[0.7830, 0.2170]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 174/203 [2m0:12:22 â€¢ 0:01:43[0m [2;4m0.28it/s[0m  
[2KAttention weights: tensor([[0.5614, 0.4386]], device='cuda:0');5;237mâ•º[0m[38;5;237mâ”â”â”â”â”[0m 174/203 [2m0:12:22 â€¢ 0:01:43[0m [2;4m0.28it/s[0m  
[2KAttention weights: tensor([[0.8955, 0.1045],â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”[0m 174/203 [2m0:12:22 â€¢ 0:01:43[0m [2;4m0.28it/s[0m  
        [0.7551, 0.2449],
        [0.8410, 0.1590],
        [0.8061, 0.1939],
        [0.9508, 0.0492],
        [0.8876, 0.1124],
        [0.8998, 0.1002],
        [0.8923, 0.1077],
        [0.7811, 0.2189],
[2K        [0.8701, 0.1299]], device='cuda:0')â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”[0m 174/203 [2m0:12:22 â€¢ 0:01:43[0m [2;4m0.28it/s[0m  
[2KAttention weights: tensor([[0.5595, 0.4405],â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”[0m 175/203 [2m0:12:27 â€¢ 0:01:50[0m [2;4m0.26it/s[0m  
        [0.5545, 0.4455],
        [0.5568, 0.4432],
        [0.5559, 0.4441],
        [0.5546, 0.4454],
        [0.5539, 0.4461],
        [0.5549, 0.4451],
        [0.5578, 0.4422],
        [0.5583, 0.4417],
[2K        [0.5551, 0.4449]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m[38;5;237mâ”â”â”â”â”[0m 175/203 [2m0:12:27 â€¢ 0:01:50[0m [2;4m0.26it/s[0m  
[2KClass label: BaseballPitchâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”[0m 175/203 [2m0:12:27 â€¢ 0:01:50[0m [2;4m0.26it/s[0m  
[2KAttention weights: tensor([[0.6408, 0.3592]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 175/203 [2m0:12:27 â€¢ 0:01:50[0m [2;4m0.26it/s[0m  
[2KStep 0 - TTA Loss: 0.7253â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”[0m 175/203 [2m0:12:27 â€¢ 0:01:50[0m [2;4m0.26it/s[0m  
[2KAttention weights: tensor([[0.6408, 0.3592]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 175/203 [2m0:12:27 â€¢ 0:01:50[0m [2;4m0.26it/s[0m  
[2KAttention weights: tensor([[0.6432, 0.3568]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 175/203 [2m0:12:27 â€¢ 0:01:50[0m [2;4m0.26it/s[0m  
[2KAttention weights: tensor([[0.6567, 0.3433]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 175/203 [2m0:12:27 â€¢ 0:01:50[0m [2;4m0.26it/s[0m  
[2KAttention weights: tensor([[0.6926, 0.3074]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 175/203 [2m0:12:27 â€¢ 0:01:50[0m [2;4m0.26it/s[0m  
[2KAttention weights: tensor([[0.7602, 0.2398]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 175/203 [2m0:12:27 â€¢ 0:01:50[0m [2;4m0.26it/s[0m  
[2KAttention weights: tensor([[0.8511, 0.1489]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 175/203 [2m0:12:27 â€¢ 0:01:50[0m [2;4m0.26it/s[0m  
[2KAttention weights: tensor([[0.9306, 0.0694]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 175/203 [2m0:12:27 â€¢ 0:01:50[0m [2;4m0.26it/s[0m  
[2KAttention weights: tensor([[0.9717, 0.0283]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 175/203 [2m0:12:27 â€¢ 0:01:50[0m [2;4m0.26it/s[0m  
[2KAttention weights: tensor([[0.9876, 0.0124]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 175/203 [2m0:12:27 â€¢ 0:01:50[0m [2;4m0.26it/s[0m  
[2KAttention weights: tensor([[0.5812, 0.4188]], device='cuda:0');5;237mâ•º[0m[38;5;237mâ”â”â”â”â”[0m 175/203 [2m0:12:27 â€¢ 0:01:50[0m [2;4m0.26it/s[0m  
[2KAttention weights: tensor([[0.9963, 0.0037],â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”[0m 175/203 [2m0:12:27 â€¢ 0:01:50[0m [2;4m0.26it/s[0m  
        [0.8473, 0.1527],
        [0.8170, 0.1830],
        [0.9227, 0.0773],
        [0.9426, 0.0574],
        [0.8876, 0.1124],
        [0.9183, 0.0817],
        [0.9542, 0.0458],
        [0.8718, 0.1282],
[2K        [0.8419, 0.1581]], device='cuda:0')â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”[0m 175/203 [2m0:12:27 â€¢ 0:01:50[0m [2;4m0.26it/s[0m  
[2KAttention weights: tensor([[0.5595, 0.4405],â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”[0m 176/203 [2m0:12:29 â€¢ 0:01:40[0m [2;4m0.27it/s[0m  
        [0.5545, 0.4455],
        [0.5568, 0.4432],
        [0.5559, 0.4441],
        [0.5547, 0.4453],
        [0.5540, 0.4460],
        [0.5549, 0.4451],
        [0.5578, 0.4422],
        [0.5583, 0.4417],
[2K        [0.5551, 0.4449]], device='cuda:0', grad_fn=<SoftmaxBackward0>)24mâ•¸[0m[38;5;237mâ”â”â”â”â”[0m 176/203 [2m0:12:29 â€¢ 0:01:40[0m [2;4m0.27it/s[0m  
[2KClass label: BaseballPitchâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”[0m 176/203 [2m0:12:29 â€¢ 0:01:40[0m [2;4m0.27it/s[0m  
[2KAttention weights: tensor([[0.6431, 0.3569]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 176/203 [2m0:12:29 â€¢ 0:01:40[0m [2;4m0.27it/s[0m  
[2KStep 0 - TTA Loss: 0.6929â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”[0m 176/203 [2m0:12:29 â€¢ 0:01:40[0m [2;4m0.27it/s[0m  
[2KAttention weights: tensor([[0.8688, 0.1312]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 176/203 [2m0:12:29 â€¢ 0:01:40[0m [2;4m0.27it/s[0m  
[2KAttention weights: tensor([[0.9690, 0.0310]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 176/203 [2m0:12:29 â€¢ 0:01:40[0m [2;4m0.27it/s[0m  
[2KAttention weights: tensor([[0.9931, 0.0069]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 176/203 [2m0:12:29 â€¢ 0:01:40[0m [2;4m0.27it/s[0m  
[2KAttention weights: tensor([[0.9982, 0.0018]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 176/203 [2m0:12:29 â€¢ 0:01:40[0m [2;4m0.27it/s[0m  
[2KAttention weights: tensor([[9.9930e-01, 6.9616e-04]], device='cuda:0', grad_fn=<SoftmaxBackward0>)m 176/203 [2m0:12:29 â€¢ 0:01:40[0m [2;4m0.27it/s[0m  
[2KAttention weights: tensor([[9.9963e-01, 3.6882e-04]], device='cuda:0', grad_fn=<SoftmaxBackward0>)m 176/203 [2m0:12:29 â€¢ 0:01:40[0m [2;4m0.27it/s[0m  
[2KAttention weights: tensor([[9.9975e-01, 2.5225e-04]], device='cuda:0', grad_fn=<SoftmaxBackward0>)m 176/203 [2m0:12:29 â€¢ 0:01:40[0m [2;4m0.27it/s[0m  
[2KAttention weights: tensor([[9.9979e-01, 2.0578e-04]], device='cuda:0', grad_fn=<SoftmaxBackward0>)m 176/203 [2m0:12:29 â€¢ 0:01:40[0m [2;4m0.27it/s[0m  
[2KAttention weights: tensor([[9.9981e-01, 1.8907e-04]], device='cuda:0', grad_fn=<SoftmaxBackward0>)m 176/203 [2m0:12:29 â€¢ 0:01:40[0m [2;4m0.27it/s[0m  
[2KAttention weights: tensor([[0.5948, 0.4052]], device='cuda:0');2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”[0m 176/203 [2m0:12:29 â€¢ 0:01:40[0m [2;4m0.27it/s[0m  
[2KAttention weights: tensor([[9.9981e-01, 1.8523e-04],â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”[0m 176/203 [2m0:12:29 â€¢ 0:01:40[0m [2;4m0.27it/s[0m  
        [9.3571e-01, 6.4287e-02],
        [9.0645e-01, 9.3548e-02],
        [9.8139e-01, 1.8612e-02],
        [9.8573e-01, 1.4271e-02],
        [9.6000e-01, 3.9997e-02],
        [9.7157e-01, 2.8433e-02],
        [9.9020e-01, 9.8008e-03],
        [9.6908e-01, 3.0915e-02],
[2K        [9.2994e-01, 7.0057e-02]], device='cuda:0')â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”[0m 176/203 [2m0:12:29 â€¢ 0:01:40[0m [2;4m0.27it/s[0m  
[2KAttention weights: tensor([[0.5596, 0.4404],â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”[0m 177/203 [2m0:12:34 â€¢ 0:01:42[0m [2;4m0.26it/s[0m  
        [0.5545, 0.4455],
        [0.5568, 0.4432],
        [0.5560, 0.4440],
        [0.5547, 0.4453],
        [0.5540, 0.4460],
        [0.5549, 0.4451],
        [0.5579, 0.4421],
        [0.5584, 0.4416],
[2K        [0.5551, 0.4449]], device='cuda:0', grad_fn=<SoftmaxBackward0>)24mâ•¸[0m[38;5;237mâ”â”â”â”â”[0m 177/203 [2m0:12:34 â€¢ 0:01:42[0m [2;4m0.26it/s[0m  
[2KClass label: PoleVaultâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”[0m 177/203 [2m0:12:34 â€¢ 0:01:42[0m [2;4m0.26it/s[0m  
[2KAttention weights: tensor([[0.6169, 0.3831]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 177/203 [2m0:12:34 â€¢ 0:01:42[0m [2;4m0.26it/s[0m  
[2KStep 0 - TTA Loss: 0.6917â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”[0m 177/203 [2m0:12:34 â€¢ 0:01:42[0m [2;4m0.26it/s[0m  
[2KAttention weights: tensor([[0.6169, 0.3831]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 177/203 [2m0:12:34 â€¢ 0:01:42[0m [2;4m0.26it/s[0m  
[2KAttention weights: tensor([[0.6196, 0.3804]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 177/203 [2m0:12:34 â€¢ 0:01:42[0m [2;4m0.26it/s[0m  
[2KAttention weights: tensor([[0.6318, 0.3682]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 177/203 [2m0:12:34 â€¢ 0:01:42[0m [2;4m0.26it/s[0m  
[2KAttention weights: tensor([[0.6612, 0.3388]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 177/203 [2m0:12:34 â€¢ 0:01:42[0m [2;4m0.26it/s[0m  
[2KAttention weights: tensor([[0.7139, 0.2861]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 177/203 [2m0:12:34 â€¢ 0:01:42[0m [2;4m0.26it/s[0m  
[2KAttention weights: tensor([[0.7878, 0.2122]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 177/203 [2m0:12:34 â€¢ 0:01:42[0m [2;4m0.26it/s[0m  
[2KAttention weights: tensor([[0.8730, 0.1270]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 177/203 [2m0:12:34 â€¢ 0:01:42[0m [2;4m0.26it/s[0m  
[2KAttention weights: tensor([[0.9421, 0.0579]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 177/203 [2m0:12:34 â€¢ 0:01:42[0m [2;4m0.26it/s[0m  
[2KAttention weights: tensor([[0.9814, 0.0186]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 177/203 [2m0:12:34 â€¢ 0:01:42[0m [2;4m0.26it/s[0m  
[2KAttention weights: tensor([[0.5829, 0.4171]], device='cuda:0');2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”[0m 177/203 [2m0:12:34 â€¢ 0:01:42[0m [2;4m0.26it/s[0m  
[2KAttention weights: tensor([[0.9921, 0.0079],â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”[0m 177/203 [2m0:12:34 â€¢ 0:01:42[0m [2;4m0.26it/s[0m  
        [0.9227, 0.0773],
        [0.9596, 0.0404],
        [0.9666, 0.0334],
        [0.9818, 0.0182],
        [0.9890, 0.0110],
        [0.9952, 0.0048],
        [0.9854, 0.0146],
        [0.9673, 0.0327],
[2K        [0.9709, 0.0291]], device='cuda:0')â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”[0m 177/203 [2m0:12:34 â€¢ 0:01:42[0m [2;4m0.26it/s[0m  
[2KAttention weights: tensor([[0.5596, 0.4404],â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”[0m 178/203 [2m0:12:39 â€¢ 0:01:39[0m [2;4m0.25it/s[0m   
        [0.5545, 0.4455],
        [0.5568, 0.4432],
        [0.5560, 0.4440],
        [0.5547, 0.4453],
        [0.5540, 0.4460],
        [0.5550, 0.4450],
        [0.5578, 0.4422],
        [0.5583, 0.4417],
[2K        [0.5551, 0.4449]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m[38;5;237mâ”â”â”â”[0m 178/203 [2m0:12:39 â€¢ 0:01:39[0m [2;4m0.25it/s[0m  
[2KClass label: PoleVaultâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”[0m 178/203 [2m0:12:39 â€¢ 0:01:39[0m [2;4m0.25it/s[0m  
[2KAttention weights: tensor([[0.6108, 0.3892]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 178/203 [2m0:12:39 â€¢ 0:01:39[0m [2;4m0.25it/s[0m  
[2KStep 0 - TTA Loss: 0.6427â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”[0m 178/203 [2m0:12:39 â€¢ 0:01:39[0m [2;4m0.25it/s[0m  
[2KAttention weights: tensor([[0.8543, 0.1457]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 178/203 [2m0:12:39 â€¢ 0:01:39[0m [2;4m0.25it/s[0m  
[2KAttention weights: tensor([[0.9593, 0.0407]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 178/203 [2m0:12:39 â€¢ 0:01:39[0m [2;4m0.25it/s[0m  
[2KAttention weights: tensor([[0.9917, 0.0083]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 178/203 [2m0:12:39 â€¢ 0:01:39[0m [2;4m0.25it/s[0m  
[2KAttention weights: tensor([[0.9974, 0.0026]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 178/203 [2m0:12:39 â€¢ 0:01:39[0m [2;4m0.25it/s[0m  
[2KAttention weights: tensor([[0.9986, 0.0014]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 178/203 [2m0:12:39 â€¢ 0:01:39[0m [2;4m0.25it/s[0m  
[2KAttention weights: tensor([[0.9989, 0.0011]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 178/203 [2m0:12:39 â€¢ 0:01:39[0m [2;4m0.25it/s[0m  
[2KAttention weights: tensor([[0.9990, 0.0010]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 178/203 [2m0:12:39 â€¢ 0:01:39[0m [2;4m0.25it/s[0m  
[2KAttention weights: tensor([[0.9990, 0.0010]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 178/203 [2m0:12:39 â€¢ 0:01:39[0m [2;4m0.25it/s[0m  
[2KAttention weights: tensor([[0.9990, 0.0010]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 178/203 [2m0:12:39 â€¢ 0:01:39[0m [2;4m0.25it/s[0m  
[2KAttention weights: tensor([[0.5909, 0.4091]], device='cuda:0')8;5;237mâ•º[0m[38;5;237mâ”â”â”â”[0m 178/203 [2m0:12:39 â€¢ 0:01:39[0m [2;4m0.25it/s[0m  
[2KAttention weights: tensor([[0.9953, 0.0047],â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”[0m 178/203 [2m0:12:39 â€¢ 0:01:39[0m [2;4m0.25it/s[0m  
        [0.9525, 0.0475],
        [0.9824, 0.0176],
        [0.9824, 0.0176],
        [0.9931, 0.0069],
        [0.9969, 0.0031],
        [0.9990, 0.0010],
        [0.9939, 0.0061],
        [0.9831, 0.0169],
[2K        [0.9886, 0.0114]], device='cuda:0')â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”[0m 178/203 [2m0:12:39 â€¢ 0:01:39[0m [2;4m0.25it/s[0m  
[2KAttention weights: tensor([[0.5595, 0.4405],â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”[0m 179/203 [2m0:12:59 â€¢ 0:03:59[0m [2;4m0.10it/s[0m  
        [0.5545, 0.4455],
        [0.5568, 0.4432],
        [0.5560, 0.4440],
        [0.5547, 0.4453],
        [0.5540, 0.4460],
        [0.5550, 0.4450],
        [0.5578, 0.4422],
        [0.5584, 0.4416],
[2K        [0.5551, 0.4449]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m[38;5;237mâ”â”â”â”[0m 179/203 [2m0:12:59 â€¢ 0:03:59[0m [2;4m0.10it/s[0m  
[2KClass label: PoleVaultâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”[0m 179/203 [2m0:12:59 â€¢ 0:03:59[0m [2;4m0.10it/s[0m  
[2KAttention weights: tensor([[0.6111, 0.3889]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 179/203 [2m0:12:59 â€¢ 0:03:59[0m [2;4m0.10it/s[0m  
[2KStep 0 - TTA Loss: 0.4655â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”[0m 179/203 [2m0:12:59 â€¢ 0:03:59[0m [2;4m0.10it/s[0m  
[2KAttention weights: tensor([[0.6111, 0.3889]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 179/203 [2m0:12:59 â€¢ 0:03:59[0m [2;4m0.10it/s[0m  
[2KAttention weights: tensor([[0.6107, 0.3893]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 179/203 [2m0:12:59 â€¢ 0:03:59[0m [2;4m0.10it/s[0m  
[2KAttention weights: tensor([[0.6101, 0.3899]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 179/203 [2m0:12:59 â€¢ 0:03:59[0m [2;4m0.10it/s[0m  
[2KAttention weights: tensor([[0.6120, 0.3880]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 179/203 [2m0:12:59 â€¢ 0:03:59[0m [2;4m0.10it/s[0m  
[2KAttention weights: tensor([[0.6185, 0.3815]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 179/203 [2m0:12:59 â€¢ 0:03:59[0m [2;4m0.10it/s[0m  
[2KAttention weights: tensor([[0.6314, 0.3686]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 179/203 [2m0:12:59 â€¢ 0:03:59[0m [2;4m0.10it/s[0m  
[2KAttention weights: tensor([[0.6499, 0.3501]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 179/203 [2m0:12:59 â€¢ 0:03:59[0m [2;4m0.10it/s[0m  
[2KAttention weights: tensor([[0.6722, 0.3278]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 179/203 [2m0:12:59 â€¢ 0:03:59[0m [2;4m0.10it/s[0m  
[2KAttention weights: tensor([[0.6964, 0.3036]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 179/203 [2m0:12:59 â€¢ 0:03:59[0m [2;4m0.10it/s[0m  
[2KAttention weights: tensor([[0.5576, 0.4424]], device='cuda:0')8;5;237mâ•º[0m[38;5;237mâ”â”â”â”[0m 179/203 [2m0:12:59 â€¢ 0:03:59[0m [2;4m0.10it/s[0m  
[2KAttention weights: tensor([[0.7399, 0.2601],â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”[0m 179/203 [2m0:12:59 â€¢ 0:03:59[0m [2;4m0.10it/s[0m  
        [0.6442, 0.3558],
        [0.6822, 0.3178],
        [0.6744, 0.3256],
        [0.6332, 0.3668],
        [0.6932, 0.3068],
        [0.7203, 0.2797],
        [0.7187, 0.2813],
        [0.7202, 0.2798],
[2K        [0.6839, 0.3161]], device='cuda:0')â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”[0m 179/203 [2m0:12:59 â€¢ 0:03:59[0m [2;4m0.10it/s[0m  
[2KAttention weights: tensor([[0.5595, 0.4405],â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”[0m 180/203 [2m0:13:05 â€¢ 0:05:03[0m [2;4m0.08it/s[0m  
        [0.5545, 0.4455],
        [0.5568, 0.4432],
        [0.5559, 0.4441],
        [0.5547, 0.4453],
        [0.5540, 0.4460],
        [0.5550, 0.4450],
        [0.5578, 0.4422],
        [0.5583, 0.4417],
[2K        [0.5551, 0.4449]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m[38;5;237mâ”â”â”â”[0m 180/203 [2m0:13:05 â€¢ 0:05:03[0m [2;4m0.08it/s[0m  
[2KClass label: CleanAndJerkâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”[0m 180/203 [2m0:13:05 â€¢ 0:05:03[0m [2;4m0.08it/s[0m  
[2KAttention weights: tensor([[0.6194, 0.3806]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 180/203 [2m0:13:05 â€¢ 0:05:03[0m [2;4m0.08it/s[0m  
[2KStep 0 - TTA Loss: 0.4801â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”[0m 180/203 [2m0:13:05 â€¢ 0:05:03[0m [2;4m0.08it/s[0m  
[2KAttention weights: tensor([[0.6607, 0.3393]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 180/203 [2m0:13:05 â€¢ 0:05:03[0m [2;4m0.08it/s[0m  
[2KAttention weights: tensor([[0.7130, 0.2870]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 180/203 [2m0:13:05 â€¢ 0:05:03[0m [2;4m0.08it/s[0m  
[2KAttention weights: tensor([[0.7587, 0.2413]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 180/203 [2m0:13:05 â€¢ 0:05:03[0m [2;4m0.08it/s[0m  
[2KAttention weights: tensor([[0.7895, 0.2105]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 180/203 [2m0:13:05 â€¢ 0:05:03[0m [2;4m0.08it/s[0m  
[2KAttention weights: tensor([[0.8111, 0.1889]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 180/203 [2m0:13:05 â€¢ 0:05:03[0m [2;4m0.08it/s[0m  
[2KAttention weights: tensor([[0.8302, 0.1698]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 180/203 [2m0:13:05 â€¢ 0:05:03[0m [2;4m0.08it/s[0m  
[2KAttention weights: tensor([[0.8474, 0.1526]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 180/203 [2m0:13:05 â€¢ 0:05:03[0m [2;4m0.08it/s[0m  
[2KAttention weights: tensor([[0.8603, 0.1397]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 180/203 [2m0:13:05 â€¢ 0:05:03[0m [2;4m0.08it/s[0m  
[2KAttention weights: tensor([[0.8675, 0.1325]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 180/203 [2m0:13:05 â€¢ 0:05:03[0m [2;4m0.08it/s[0m  
[2KAttention weights: tensor([[0.5643, 0.4357]], device='cuda:0')8;5;237mâ•º[0m[38;5;237mâ”â”â”â”[0m 180/203 [2m0:13:05 â€¢ 0:05:03[0m [2;4m0.08it/s[0m  
[2KAttention weights: tensor([[0.7792, 0.2208],â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”[0m 180/203 [2m0:13:05 â€¢ 0:05:03[0m [2;4m0.08it/s[0m  
        [0.6957, 0.3043],
        [0.8697, 0.1303],
        [0.7427, 0.2573],
        [0.7337, 0.2663],
        [0.7789, 0.2211],
        [0.7901, 0.2099],
        [0.7647, 0.2353],
        [0.8035, 0.1965],
[2K        [0.8163, 0.1837]], device='cuda:0')â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”[0m 180/203 [2m0:13:05 â€¢ 0:05:03[0m [2;4m0.08it/s[0m  
[2KAttention weights: tensor([[0.5595, 0.4405],â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”[0m 181/203 [2m0:13:11 â€¢ 0:02:11[0m [2;4m0.17it/s[0m  
        [0.5545, 0.4455],
        [0.5568, 0.4432],
        [0.5559, 0.4441],
        [0.5547, 0.4453],
        [0.5540, 0.4460],
        [0.5550, 0.4450],
        [0.5578, 0.4422],
        [0.5583, 0.4417],
[2K        [0.5551, 0.4449]], device='cuda:0', grad_fn=<SoftmaxBackward0>)224mâ•¸[0m[38;5;237mâ”â”â”â”[0m 181/203 [2m0:13:11 â€¢ 0:02:11[0m [2;4m0.17it/s[0m  
[2KClass label: GolfSwingâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”[0m 181/203 [2m0:13:11 â€¢ 0:02:11[0m [2;4m0.17it/s[0m  
[2KAttention weights: tensor([[0.6056, 0.3944]], device='cuda:0', grad_fn=<SoftmaxBackward0>)mâ”â”â”â”[0m 181/203 [2m0:13:11 â€¢ 0:02:11[0m [2;4m0.17it/s[0m  
[2KStep 0 - TTA Loss: 0.4599â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”[0m 181/203 [2m0:13:11 â€¢ 0:02:11[0m [2;4m0.17it/s[0m  
[2KAttention weights: tensor([[0.6056, 0.3944]], device='cuda:0', grad_fn=<SoftmaxBackward0>)mâ”â”â”â”[0m 181/203 [2m0:13:11 â€¢ 0:02:11[0m [2;4m0.17it/s[0m  
[2KAttention weights: tensor([[0.6077, 0.3923]], device='cuda:0', grad_fn=<SoftmaxBackward0>)mâ”â”â”â”[0m 181/203 [2m0:13:11 â€¢ 0:02:11[0m [2;4m0.17it/s[0m  
[2KAttention weights: tensor([[0.6168, 0.3832]], device='cuda:0', grad_fn=<SoftmaxBackward0>)mâ”â”â”â”[0m 181/203 [2m0:13:11 â€¢ 0:02:11[0m [2;4m0.17it/s[0m  
[2KAttention weights: tensor([[0.6378, 0.3622]], device='cuda:0', grad_fn=<SoftmaxBackward0>)mâ”â”â”â”[0m 181/203 [2m0:13:11 â€¢ 0:02:11[0m [2;4m0.17it/s[0m  
[2KAttention weights: tensor([[0.6736, 0.3264]], device='cuda:0', grad_fn=<SoftmaxBackward0>)mâ”â”â”â”[0m 181/203 [2m0:13:11 â€¢ 0:02:11[0m [2;4m0.17it/s[0m  
[2KAttention weights: tensor([[0.7210, 0.2790]], device='cuda:0', grad_fn=<SoftmaxBackward0>)mâ”â”â”â”[0m 181/203 [2m0:13:11 â€¢ 0:02:11[0m [2;4m0.17it/s[0m  
[2KAttention weights: tensor([[0.7725, 0.2275]], device='cuda:0', grad_fn=<SoftmaxBackward0>)mâ”â”â”â”[0m 181/203 [2m0:13:11 â€¢ 0:02:11[0m [2;4m0.17it/s[0m  
[2KAttention weights: tensor([[0.8216, 0.1784]], device='cuda:0', grad_fn=<SoftmaxBackward0>)mâ”â”â”â”[0m 181/203 [2m0:13:11 â€¢ 0:02:11[0m [2;4m0.17it/s[0m  
[2KAttention weights: tensor([[0.8742, 0.1258]], device='cuda:0', grad_fn=<SoftmaxBackward0>)mâ”â”â”â”[0m 181/203 [2m0:13:11 â€¢ 0:02:11[0m [2;4m0.17it/s[0m  
[2KAttention weights: tensor([[0.5665, 0.4335]], device='cuda:0')8;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”[0m 181/203 [2m0:13:11 â€¢ 0:02:11[0m [2;4m0.17it/s[0m  
[2KAttention weights: tensor([[0.8606, 0.1394],â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”[0m 181/203 [2m0:13:11 â€¢ 0:02:11[0m [2;4m0.17it/s[0m  
        [0.7908, 0.2092],
        [0.9272, 0.0728],
        [0.9277, 0.0723],
        [0.8272, 0.1728],
        [0.8475, 0.1525],
        [0.8367, 0.1633],
        [0.8547, 0.1453],
        [0.8993, 0.1007],
[2K        [0.8933, 0.1067]], device='cuda:0')â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”[0m 181/203 [2m0:13:11 â€¢ 0:02:11[0m [2;4m0.17it/s[0m  
[2KAttention weights: tensor([[0.5595, 0.4405],â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”[0m 182/203 [2m0:13:15 â€¢ 0:01:53[0m [2;4m0.19it/s[0m  
        [0.5545, 0.4455],
        [0.5569, 0.4431],
        [0.5560, 0.4440],
        [0.5547, 0.4453],
        [0.5540, 0.4460],
        [0.5550, 0.4450],
        [0.5578, 0.4422],
        [0.5584, 0.4416],
[2K        [0.5551, 0.4449]], device='cuda:0', grad_fn=<SoftmaxBackward0>)224mâ•¸[0m[38;5;237mâ”â”â”â”[0m 182/203 [2m0:13:15 â€¢ 0:01:53[0m [2;4m0.19it/s[0m  
[2KClass label: CleanAndJerkâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”[0m 182/203 [2m0:13:15 â€¢ 0:01:53[0m [2;4m0.19it/s[0m  
[2KAttention weights: tensor([[0.6228, 0.3772]], device='cuda:0', grad_fn=<SoftmaxBackward0>)mâ”â”â”â”[0m 182/203 [2m0:13:15 â€¢ 0:01:53[0m [2;4m0.19it/s[0m  
[2KStep 0 - TTA Loss: 0.7695â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”[0m 182/203 [2m0:13:15 â€¢ 0:01:53[0m [2;4m0.19it/s[0m  
[2KAttention weights: tensor([[0.7209, 0.2791]], device='cuda:0', grad_fn=<SoftmaxBackward0>)mâ”â”â”â”[0m 182/203 [2m0:13:15 â€¢ 0:01:53[0m [2;4m0.19it/s[0m  
[2KAttention weights: tensor([[0.8011, 0.1989]], device='cuda:0', grad_fn=<SoftmaxBackward0>)mâ”â”â”â”[0m 182/203 [2m0:13:15 â€¢ 0:01:53[0m [2;4m0.19it/s[0m  
[2KAttention weights: tensor([[0.8558, 0.1442]], device='cuda:0', grad_fn=<SoftmaxBackward0>)mâ”â”â”â”[0m 182/203 [2m0:13:15 â€¢ 0:01:53[0m [2;4m0.19it/s[0m  
[2KAttention weights: tensor([[0.8900, 0.1100]], device='cuda:0', grad_fn=<SoftmaxBackward0>)mâ”â”â”â”[0m 182/203 [2m0:13:15 â€¢ 0:01:53[0m [2;4m0.19it/s[0m  
[2KAttention weights: tensor([[0.9107, 0.0893]], device='cuda:0', grad_fn=<SoftmaxBackward0>)mâ”â”â”â”[0m 182/203 [2m0:13:15 â€¢ 0:01:53[0m [2;4m0.19it/s[0m  
[2KAttention weights: tensor([[0.9235, 0.0765]], device='cuda:0', grad_fn=<SoftmaxBackward0>)mâ”â”â”â”[0m 182/203 [2m0:13:15 â€¢ 0:01:53[0m [2;4m0.19it/s[0m  
[2KAttention weights: tensor([[0.9299, 0.0701]], device='cuda:0', grad_fn=<SoftmaxBackward0>)mâ”â”â”â”[0m 182/203 [2m0:13:15 â€¢ 0:01:53[0m [2;4m0.19it/s[0m  
[2KAttention weights: tensor([[0.9338, 0.0662]], device='cuda:0', grad_fn=<SoftmaxBackward0>)mâ”â”â”â”[0m 182/203 [2m0:13:15 â€¢ 0:01:53[0m [2;4m0.19it/s[0m  
[2KAttention weights: tensor([[0.9355, 0.0645]], device='cuda:0', grad_fn=<SoftmaxBackward0>)mâ”â”â”â”[0m 182/203 [2m0:13:15 â€¢ 0:01:53[0m [2;4m0.19it/s[0m  
[2KAttention weights: tensor([[0.5690, 0.4310]], device='cuda:0')8;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”[0m 182/203 [2m0:13:15 â€¢ 0:01:53[0m [2;4m0.19it/s[0m  
[2KAttention weights: tensor([[0.8849, 0.1151],â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”[0m 182/203 [2m0:13:15 â€¢ 0:01:53[0m [2;4m0.19it/s[0m  
        [0.8173, 0.1827],
        [0.9360, 0.0640],
        [0.9526, 0.0474],
        [0.8497, 0.1503],
        [0.8686, 0.1314],
        [0.8541, 0.1459],
        [0.8780, 0.1220],
        [0.9192, 0.0808],
[2K        [0.9095, 0.0905]], device='cuda:0')â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”[0m 182/203 [2m0:13:15 â€¢ 0:01:53[0m [2;4m0.19it/s[0m  
[2KAttention weights: tensor([[0.5595, 0.4405],â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”[0m 183/203 [2m0:13:16 â€¢ 0:01:28[0m [2;4m0.23it/s[0m   
        [0.5545, 0.4455],
        [0.5569, 0.4431],
        [0.5560, 0.4440],
        [0.5547, 0.4453],
        [0.5540, 0.4460],
        [0.5550, 0.4450],
        [0.5579, 0.4421],
        [0.5584, 0.4416],
[2K        [0.5552, 0.4448]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â•º[0m[38;5;237mâ”â”â”[0m 183/203 [2m0:13:16 â€¢ 0:01:28[0m [2;4m0.23it/s[0m  
[2KClass label: BaseballPitchâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”[0m 183/203 [2m0:13:16 â€¢ 0:01:28[0m [2;4m0.23it/s[0m  
[2KAttention weights: tensor([[0.6461, 0.3539]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 183/203 [2m0:13:16 â€¢ 0:01:28[0m [2;4m0.23it/s[0m  
[2KStep 0 - TTA Loss: 0.6012â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”[0m 183/203 [2m0:13:16 â€¢ 0:01:28[0m [2;4m0.23it/s[0m  
[2KAttention weights: tensor([[0.6461, 0.3539]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 183/203 [2m0:13:16 â€¢ 0:01:28[0m [2;4m0.23it/s[0m  
[2KAttention weights: tensor([[0.6492, 0.3508]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 183/203 [2m0:13:16 â€¢ 0:01:28[0m [2;4m0.23it/s[0m  
[2KAttention weights: tensor([[0.6647, 0.3353]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 183/203 [2m0:13:16 â€¢ 0:01:28[0m [2;4m0.23it/s[0m  
[2KAttention weights: tensor([[0.7039, 0.2961]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 183/203 [2m0:13:16 â€¢ 0:01:28[0m [2;4m0.23it/s[0m  
[2KAttention weights: tensor([[0.7721, 0.2279]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 183/203 [2m0:13:16 â€¢ 0:01:28[0m [2;4m0.23it/s[0m  
[2KAttention weights: tensor([[0.8566, 0.1434]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 183/203 [2m0:13:16 â€¢ 0:01:28[0m [2;4m0.23it/s[0m  
[2KAttention weights: tensor([[0.9279, 0.0721]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 183/203 [2m0:13:16 â€¢ 0:01:28[0m [2;4m0.23it/s[0m  
[2KAttention weights: tensor([[0.9678, 0.0322]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 183/203 [2m0:13:16 â€¢ 0:01:28[0m [2;4m0.23it/s[0m  
[2KAttention weights: tensor([[0.9882, 0.0118]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 183/203 [2m0:13:16 â€¢ 0:01:28[0m [2;4m0.23it/s[0m  
[2KAttention weights: tensor([[0.5832, 0.4168]], device='cuda:0')38;5;237mâ•º[0m[38;5;237mâ”â”â”[0m 183/203 [2m0:13:16 â€¢ 0:01:28[0m [2;4m0.23it/s[0m  
[2KAttention weights: tensor([[0.9976, 0.0024],â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”[0m 183/203 [2m0:13:16 â€¢ 0:01:28[0m [2;4m0.23it/s[0m  
        [0.9001, 0.0999],
        [0.9125, 0.0875],
        [0.9668, 0.0332],
        [0.9573, 0.0427],
        [0.9318, 0.0682],
        [0.9393, 0.0607],
        [0.9716, 0.0284],
        [0.9619, 0.0381],
[2K        [0.9177, 0.0823]], device='cuda:0')â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”[0m 183/203 [2m0:13:16 â€¢ 0:01:28[0m [2;4m0.23it/s[0m  
[2KAttention weights: tensor([[0.5596, 0.4404],â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”[0m 184/203 [2m0:13:19 â€¢ 0:01:17[0m [2;4m0.25it/s[0m  
        [0.5545, 0.4455],
        [0.5569, 0.4431],
        [0.5560, 0.4440],
        [0.5548, 0.4452],
        [0.5541, 0.4459],
        [0.5551, 0.4449],
        [0.5579, 0.4421],
        [0.5584, 0.4416],
[2K        [0.5552, 0.4448]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â•º[0m[38;5;237mâ”â”â”[0m 184/203 [2m0:13:19 â€¢ 0:01:17[0m [2;4m0.25it/s[0m  
[2KClass label: SoccerPenaltyâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”[0m 184/203 [2m0:13:19 â€¢ 0:01:17[0m [2;4m0.25it/s[0m  
[2KAttention weights: tensor([[0.6386, 0.3614]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 184/203 [2m0:13:19 â€¢ 0:01:17[0m [2;4m0.25it/s[0m  
[2KStep 0 - TTA Loss: 0.4999â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”[0m 184/203 [2m0:13:19 â€¢ 0:01:17[0m [2;4m0.25it/s[0m  
[2KAttention weights: tensor([[0.8067, 0.1933]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 184/203 [2m0:13:19 â€¢ 0:01:17[0m [2;4m0.25it/s[0m  
[2KAttention weights: tensor([[0.9058, 0.0942]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 184/203 [2m0:13:19 â€¢ 0:01:17[0m [2;4m0.25it/s[0m  
[2KAttention weights: tensor([[0.9501, 0.0499]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 184/203 [2m0:13:19 â€¢ 0:01:17[0m [2;4m0.25it/s[0m  
[2KAttention weights: tensor([[0.9645, 0.0355]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 184/203 [2m0:13:19 â€¢ 0:01:17[0m [2;4m0.25it/s[0m  
[2KAttention weights: tensor([[0.9671, 0.0329]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 184/203 [2m0:13:19 â€¢ 0:01:17[0m [2;4m0.25it/s[0m  
[2KAttention weights: tensor([[0.9625, 0.0375]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 184/203 [2m0:13:19 â€¢ 0:01:17[0m [2;4m0.25it/s[0m  
[2KAttention weights: tensor([[0.9536, 0.0464]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 184/203 [2m0:13:19 â€¢ 0:01:17[0m [2;4m0.25it/s[0m  
[2KAttention weights: tensor([[0.9449, 0.0551]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 184/203 [2m0:13:19 â€¢ 0:01:17[0m [2;4m0.25it/s[0m  
[2KAttention weights: tensor([[0.9402, 0.0598]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 184/203 [2m0:13:19 â€¢ 0:01:17[0m [2;4m0.25it/s[0m  
[2KAttention weights: tensor([[0.5701, 0.4299]], device='cuda:0')38;5;237mâ•º[0m[38;5;237mâ”â”â”[0m 184/203 [2m0:13:19 â€¢ 0:01:17[0m [2;4m0.25it/s[0m  
[2KAttention weights: tensor([[0.9981, 0.0019],â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”[0m 184/203 [2m0:13:19 â€¢ 0:01:17[0m [2;4m0.25it/s[0m  
        [0.8736, 0.1264],
        [0.8873, 0.1127],
        [0.9561, 0.0439],
        [0.9437, 0.0563],
        [0.9077, 0.0923],
        [0.9242, 0.0758],
        [0.9388, 0.0612],
        [0.9507, 0.0493],
[2K        [0.8983, 0.1017]], device='cuda:0')â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”[0m 184/203 [2m0:13:19 â€¢ 0:01:17[0m [2;4m0.25it/s[0m  
[2KAttention weights: tensor([[0.5596, 0.4404],â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”[0m 185/203 [2m0:13:22 â€¢ 0:01:09[0m [2;4m0.26it/s[0m  
        [0.5545, 0.4455],
        [0.5569, 0.4431],
        [0.5560, 0.4440],
        [0.5548, 0.4452],
        [0.5541, 0.4459],
        [0.5551, 0.4449],
        [0.5579, 0.4421],
        [0.5584, 0.4416],
[2K        [0.5552, 0.4448]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â•º[0m[38;5;237mâ”â”â”[0m 185/203 [2m0:13:22 â€¢ 0:01:09[0m [2;4m0.26it/s[0m  
[2KClass label: Billiardsâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”[0m 185/203 [2m0:13:22 â€¢ 0:01:09[0m [2;4m0.26it/s[0m  
[2KAttention weights: tensor([[0.5950, 0.4050]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 185/203 [2m0:13:22 â€¢ 0:01:09[0m [2;4m0.26it/s[0m  
[2KStep 0 - TTA Loss: 0.6213â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”[0m 185/203 [2m0:13:22 â€¢ 0:01:09[0m [2;4m0.26it/s[0m  
[2KAttention weights: tensor([[0.5950, 0.4050]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 185/203 [2m0:13:22 â€¢ 0:01:09[0m [2;4m0.26it/s[0m  
[2KAttention weights: tensor([[0.5945, 0.4055]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 185/203 [2m0:13:22 â€¢ 0:01:09[0m [2;4m0.26it/s[0m  
[2KAttention weights: tensor([[0.5942, 0.4058]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 185/203 [2m0:13:22 â€¢ 0:01:09[0m [2;4m0.26it/s[0m  
[2KAttention weights: tensor([[0.5971, 0.4029]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 185/203 [2m0:13:22 â€¢ 0:01:09[0m [2;4m0.26it/s[0m  
[2KAttention weights: tensor([[0.6044, 0.3956]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 185/203 [2m0:13:22 â€¢ 0:01:09[0m [2;4m0.26it/s[0m  
[2KAttention weights: tensor([[0.6148, 0.3852]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 185/203 [2m0:13:22 â€¢ 0:01:09[0m [2;4m0.26it/s[0m  
[2KAttention weights: tensor([[0.6244, 0.3756]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 185/203 [2m0:13:22 â€¢ 0:01:09[0m [2;4m0.26it/s[0m  
[2KAttention weights: tensor([[0.6352, 0.3648]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 185/203 [2m0:13:22 â€¢ 0:01:09[0m [2;4m0.26it/s[0m  
[2KAttention weights: tensor([[0.6650, 0.3350]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 185/203 [2m0:13:22 â€¢ 0:01:09[0m [2;4m0.26it/s[0m  
[2KAttention weights: tensor([[0.5569, 0.4431]], device='cuda:0')38;5;237mâ•º[0m[38;5;237mâ”â”â”[0m 185/203 [2m0:13:22 â€¢ 0:01:09[0m [2;4m0.26it/s[0m  
[2KAttention weights: tensor([[0.6844, 0.3156],â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”[0m 185/203 [2m0:13:22 â€¢ 0:01:09[0m [2;4m0.26it/s[0m  
        [0.7295, 0.2705],
        [0.6127, 0.3873],
        [0.5650, 0.4350],
        [0.4305, 0.5695],
        [0.4998, 0.5002],
        [0.5362, 0.4638],
        [0.2674, 0.7326],
        [0.6155, 0.3845],
[2K        [0.5961, 0.4039]], device='cuda:0')â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”[0m 185/203 [2m0:13:22 â€¢ 0:01:09[0m [2;4m0.26it/s[0m  
[2KAttention weights: tensor([[0.5596, 0.4404],â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”[0m 186/203 [2m0:13:22 â€¢ 0:00:57[0m [2;4m0.30it/s[0m  
        [0.5545, 0.4455],
        [0.5569, 0.4431],
        [0.5560, 0.4440],
        [0.5548, 0.4452],
        [0.5541, 0.4459],
        [0.5550, 0.4450],
        [0.5578, 0.4422],
        [0.5584, 0.4416],
[2K        [0.5552, 0.4448]], device='cuda:0', grad_fn=<SoftmaxBackward0>);224mâ•¸[0m[38;5;237mâ”â”â”[0m 186/203 [2m0:13:22 â€¢ 0:00:57[0m [2;4m0.30it/s[0m  
[2KClass label: SoccerPenaltyâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”[0m 186/203 [2m0:13:22 â€¢ 0:00:57[0m [2;4m0.30it/s[0m  
[2KAttention weights: tensor([[0.6354, 0.3646]], device='cuda:0', grad_fn=<SoftmaxBackward0>)7mâ”â”â”[0m 186/203 [2m0:13:22 â€¢ 0:00:57[0m [2;4m0.30it/s[0m  
[2KStep 0 - TTA Loss: 0.7230â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”[0m 186/203 [2m0:13:22 â€¢ 0:00:57[0m [2;4m0.30it/s[0m  
[2KAttention weights: tensor([[0.6318, 0.3682]], device='cuda:0', grad_fn=<SoftmaxBackward0>)7mâ”â”â”[0m 186/203 [2m0:13:22 â€¢ 0:00:57[0m [2;4m0.30it/s[0m  
[2KAttention weights: tensor([[0.6605, 0.3395]], device='cuda:0', grad_fn=<SoftmaxBackward0>)7mâ”â”â”[0m 186/203 [2m0:13:22 â€¢ 0:00:57[0m [2;4m0.30it/s[0m  
[2KAttention weights: tensor([[0.7087, 0.2913]], device='cuda:0', grad_fn=<SoftmaxBackward0>)7mâ”â”â”[0m 186/203 [2m0:13:22 â€¢ 0:00:57[0m [2;4m0.30it/s[0m  
[2KAttention weights: tensor([[0.7590, 0.2410]], device='cuda:0', grad_fn=<SoftmaxBackward0>)7mâ”â”â”[0m 186/203 [2m0:13:22 â€¢ 0:00:57[0m [2;4m0.30it/s[0m  
[2KAttention weights: tensor([[0.7977, 0.2023]], device='cuda:0', grad_fn=<SoftmaxBackward0>)7mâ”â”â”[0m 186/203 [2m0:13:22 â€¢ 0:00:57[0m [2;4m0.30it/s[0m  
[2KAttention weights: tensor([[0.8216, 0.1784]], device='cuda:0', grad_fn=<SoftmaxBackward0>)7mâ”â”â”[0m 186/203 [2m0:13:22 â€¢ 0:00:57[0m [2;4m0.30it/s[0m  
[2KAttention weights: tensor([[0.8317, 0.1683]], device='cuda:0', grad_fn=<SoftmaxBackward0>)7mâ”â”â”[0m 186/203 [2m0:13:22 â€¢ 0:00:57[0m [2;4m0.30it/s[0m  
[2KAttention weights: tensor([[0.8336, 0.1664]], device='cuda:0', grad_fn=<SoftmaxBackward0>)7mâ”â”â”[0m 186/203 [2m0:13:22 â€¢ 0:00:57[0m [2;4m0.30it/s[0m  
[2KAttention weights: tensor([[0.8330, 0.1670]], device='cuda:0', grad_fn=<SoftmaxBackward0>)7mâ”â”â”[0m 186/203 [2m0:13:22 â€¢ 0:00:57[0m [2;4m0.30it/s[0m  
[2KAttention weights: tensor([[0.5629, 0.4371]], device='cuda:0')38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”[0m 186/203 [2m0:13:22 â€¢ 0:00:57[0m [2;4m0.30it/s[0m  
[2KAttention weights: tensor([[0.8610, 0.1390],â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”[0m 186/203 [2m0:13:22 â€¢ 0:00:57[0m [2;4m0.30it/s[0m  
        [0.9044, 0.0956],
        [0.7386, 0.2614],
        [0.7930, 0.2070],
        [0.7338, 0.2662],
        [0.7605, 0.2395],
        [0.7579, 0.2421],
        [0.8327, 0.1673],
        [0.8232, 0.1768],
[2K        [0.7373, 0.2627]], device='cuda:0')â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”[0m 186/203 [2m0:13:22 â€¢ 0:00:57[0m [2;4m0.30it/s[0m  
[2KAttention weights: tensor([[0.5596, 0.4404],â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”[0m 187/203 [2m0:13:25 â€¢ 0:00:52[0m [2;4m0.31it/s[0m  
        [0.5546, 0.4454],
        [0.5569, 0.4431],
        [0.5560, 0.4440],
        [0.5548, 0.4452],
        [0.5541, 0.4459],
        [0.5551, 0.4449],
        [0.5578, 0.4422],
        [0.5584, 0.4416],
[2K        [0.5552, 0.4448]], device='cuda:0', grad_fn=<SoftmaxBackward0>);224mâ•¸[0m[38;5;237mâ”â”â”[0m 187/203 [2m0:13:25 â€¢ 0:00:52[0m [2;4m0.31it/s[0m  
[2KClass label: CleanAndJerkâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”[0m 187/203 [2m0:13:25 â€¢ 0:00:52[0m [2;4m0.31it/s[0m  
[2KAttention weights: tensor([[0.6217, 0.3783]], device='cuda:0', grad_fn=<SoftmaxBackward0>)7mâ”â”â”[0m 187/203 [2m0:13:25 â€¢ 0:00:52[0m [2;4m0.31it/s[0m  
[2KStep 0 - TTA Loss: 0.7900â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”[0m 187/203 [2m0:13:25 â€¢ 0:00:52[0m [2;4m0.31it/s[0m  
[2KAttention weights: tensor([[0.6217, 0.3783]], device='cuda:0', grad_fn=<SoftmaxBackward0>)7mâ”â”â”[0m 187/203 [2m0:13:25 â€¢ 0:00:52[0m [2;4m0.31it/s[0m  
[2KAttention weights: tensor([[0.6219, 0.3781]], device='cuda:0', grad_fn=<SoftmaxBackward0>)7mâ”â”â”[0m 187/203 [2m0:13:25 â€¢ 0:00:52[0m [2;4m0.31it/s[0m  
[2KAttention weights: tensor([[0.6235, 0.3765]], device='cuda:0', grad_fn=<SoftmaxBackward0>)7mâ”â”â”[0m 187/203 [2m0:13:25 â€¢ 0:00:52[0m [2;4m0.31it/s[0m  
[2KAttention weights: tensor([[0.6290, 0.3710]], device='cuda:0', grad_fn=<SoftmaxBackward0>)7mâ”â”â”[0m 187/203 [2m0:13:25 â€¢ 0:00:52[0m [2;4m0.31it/s[0m  
[2KAttention weights: tensor([[0.6408, 0.3592]], device='cuda:0', grad_fn=<SoftmaxBackward0>)7mâ”â”â”[0m 187/203 [2m0:13:25 â€¢ 0:00:52[0m [2;4m0.31it/s[0m  
[2KAttention weights: tensor([[0.6591, 0.3409]], device='cuda:0', grad_fn=<SoftmaxBackward0>)7mâ”â”â”[0m 187/203 [2m0:13:25 â€¢ 0:00:52[0m [2;4m0.31it/s[0m  
[2KAttention weights: tensor([[0.6836, 0.3164]], device='cuda:0', grad_fn=<SoftmaxBackward0>)7mâ”â”â”[0m 187/203 [2m0:13:25 â€¢ 0:00:52[0m [2;4m0.31it/s[0m  
[2KAttention weights: tensor([[0.7127, 0.2873]], device='cuda:0', grad_fn=<SoftmaxBackward0>)7mâ”â”â”[0m 187/203 [2m0:13:25 â€¢ 0:00:52[0m [2;4m0.31it/s[0m  
[2KAttention weights: tensor([[0.7493, 0.2507]], device='cuda:0', grad_fn=<SoftmaxBackward0>)7mâ”â”â”[0m 187/203 [2m0:13:25 â€¢ 0:00:52[0m [2;4m0.31it/s[0m  
[2KAttention weights: tensor([[0.5621, 0.4379]], device='cuda:0')38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”[0m 187/203 [2m0:13:25 â€¢ 0:00:52[0m [2;4m0.31it/s[0m  
[2KAttention weights: tensor([[0.6857, 0.3143],â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”[0m 187/203 [2m0:13:25 â€¢ 0:00:52[0m [2;4m0.31it/s[0m  
        [0.6717, 0.3283],
        [0.7784, 0.2216],
        [0.6532, 0.3468],
        [0.6050, 0.3950],
        [0.6583, 0.3417],
        [0.6636, 0.3364],
        [0.6218, 0.3782],
        [0.7227, 0.2773],
[2K        [0.7203, 0.2797]], device='cuda:0')â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”[0m 187/203 [2m0:13:25 â€¢ 0:00:52[0m [2;4m0.31it/s[0m  
[2KAttention weights: tensor([[0.5596, 0.4404],â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”[0m 188/203 [2m0:13:26 â€¢ 0:00:45[0m [2;4m0.33it/s[0m   
        [0.5546, 0.4454],
        [0.5569, 0.4431],
        [0.5560, 0.4440],
        [0.5548, 0.4452],
        [0.5541, 0.4459],
        [0.5551, 0.4449],
        [0.5578, 0.4422],
        [0.5584, 0.4416],
[2K        [0.5552, 0.4448]], device='cuda:0', grad_fn=<SoftmaxBackward0>)mâ•º[0m[38;5;237mâ”â”[0m 188/203 [2m0:13:26 â€¢ 0:00:45[0m [2;4m0.33it/s[0m  
[2KClass label: TennisSwingâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”[0m 188/203 [2m0:13:26 â€¢ 0:00:45[0m [2;4m0.33it/s[0m  
[2KAttention weights: tensor([[0.6613, 0.3387]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 188/203 [2m0:13:26 â€¢ 0:00:45[0m [2;4m0.33it/s[0m  
[2KStep 0 - TTA Loss: 0.6139â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”[0m 188/203 [2m0:13:26 â€¢ 0:00:45[0m [2;4m0.33it/s[0m  
[2KAttention weights: tensor([[0.7009, 0.2991]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 188/203 [2m0:13:26 â€¢ 0:00:45[0m [2;4m0.33it/s[0m  
[2KAttention weights: tensor([[0.7575, 0.2425]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 188/203 [2m0:13:26 â€¢ 0:00:45[0m [2;4m0.33it/s[0m  
[2KAttention weights: tensor([[0.8178, 0.1822]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 188/203 [2m0:13:26 â€¢ 0:00:45[0m [2;4m0.33it/s[0m  
[2KAttention weights: tensor([[0.8691, 0.1309]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 188/203 [2m0:13:26 â€¢ 0:00:45[0m [2;4m0.33it/s[0m  
[2KAttention weights: tensor([[0.9043, 0.0957]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 188/203 [2m0:13:26 â€¢ 0:00:45[0m [2;4m0.33it/s[0m  
[2KAttention weights: tensor([[0.9238, 0.0762]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 188/203 [2m0:13:26 â€¢ 0:00:45[0m [2;4m0.33it/s[0m  
[2KAttention weights: tensor([[0.9327, 0.0673]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 188/203 [2m0:13:26 â€¢ 0:00:45[0m [2;4m0.33it/s[0m  
[2KAttention weights: tensor([[0.9353, 0.0647]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 188/203 [2m0:13:26 â€¢ 0:00:45[0m [2;4m0.33it/s[0m  
[2KAttention weights: tensor([[0.9358, 0.0642]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 188/203 [2m0:13:26 â€¢ 0:00:45[0m [2;4m0.33it/s[0m  
[2KAttention weights: tensor([[0.5704, 0.4296]], device='cuda:0')[38;5;237mâ•º[0m[38;5;237mâ”â”[0m 188/203 [2m0:13:26 â€¢ 0:00:45[0m [2;4m0.33it/s[0m  
[2KAttention weights: tensor([[0.8282, 0.1718],â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”[0m 188/203 [2m0:13:26 â€¢ 0:00:45[0m [2;4m0.33it/s[0m  
        [0.7876, 0.2124],
        [0.8702, 0.1298],
        [0.8317, 0.1683],
        [0.7716, 0.2284],
        [0.8231, 0.1769],
        [0.7803, 0.2197],
        [0.8046, 0.1954],
        [0.9357, 0.0643],
[2K        [0.8587, 0.1413]], device='cuda:0')â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”[0m 188/203 [2m0:13:26 â€¢ 0:00:45[0m [2;4m0.33it/s[0m  
[2KAttention weights: tensor([[0.5596, 0.4404],â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”[0m 189/203 [2m0:13:29 â€¢ 0:00:42[0m [2;4m0.33it/s[0m  
        [0.5546, 0.4454],
        [0.5569, 0.4431],
        [0.5560, 0.4440],
        [0.5548, 0.4452],
        [0.5541, 0.4459],
        [0.5551, 0.4449],
        [0.5578, 0.4422],
        [0.5584, 0.4416],
[2K        [0.5552, 0.4448]], device='cuda:0', grad_fn=<SoftmaxBackward0>)mâ•º[0m[38;5;237mâ”â”[0m 189/203 [2m0:13:29 â€¢ 0:00:42[0m [2;4m0.33it/s[0m  
[2KClass label: GolfSwingâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”[0m 189/203 [2m0:13:29 â€¢ 0:00:42[0m [2;4m0.33it/s[0m  
[2KAttention weights: tensor([[0.6049, 0.3951]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 189/203 [2m0:13:29 â€¢ 0:00:42[0m [2;4m0.33it/s[0m  
[2KStep 0 - TTA Loss: 0.9269â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”[0m 189/203 [2m0:13:29 â€¢ 0:00:42[0m [2;4m0.33it/s[0m  
[2KAttention weights: tensor([[0.6049, 0.3951]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 189/203 [2m0:13:29 â€¢ 0:00:42[0m [2;4m0.33it/s[0m  
[2KAttention weights: tensor([[0.6048, 0.3952]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 189/203 [2m0:13:29 â€¢ 0:00:42[0m [2;4m0.33it/s[0m  
[2KAttention weights: tensor([[0.6043, 0.3957]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 189/203 [2m0:13:29 â€¢ 0:00:42[0m [2;4m0.33it/s[0m  
[2KAttention weights: tensor([[0.6036, 0.3964]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 189/203 [2m0:13:29 â€¢ 0:00:42[0m [2;4m0.33it/s[0m  
[2KAttention weights: tensor([[0.6030, 0.3970]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 189/203 [2m0:13:29 â€¢ 0:00:42[0m [2;4m0.33it/s[0m  
[2KAttention weights: tensor([[0.6023, 0.3977]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 189/203 [2m0:13:29 â€¢ 0:00:42[0m [2;4m0.33it/s[0m  
[2KAttention weights: tensor([[0.6000, 0.4000]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 189/203 [2m0:13:29 â€¢ 0:00:42[0m [2;4m0.33it/s[0m  
[2KAttention weights: tensor([[0.5946, 0.4054]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 189/203 [2m0:13:29 â€¢ 0:00:42[0m [2;4m0.33it/s[0m  
[2KAttention weights: tensor([[0.5830, 0.4170]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 189/203 [2m0:13:29 â€¢ 0:00:42[0m [2;4m0.33it/s[0m  
[2KAttention weights: tensor([[0.5544, 0.4456]], device='cuda:0')[38;5;237mâ•º[0m[38;5;237mâ”â”[0m 189/203 [2m0:13:29 â€¢ 0:00:42[0m [2;4m0.33it/s[0m  
[2KAttention weights: tensor([[0.6104, 0.3896],â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”[0m 189/203 [2m0:13:29 â€¢ 0:00:42[0m [2;4m0.33it/s[0m  
        [0.5779, 0.4221],
        [0.6138, 0.3862],
        [0.5625, 0.4375],
        [0.5116, 0.4884],
        [0.5695, 0.4305],
        [0.5902, 0.4098],
        [0.5986, 0.4014],
        [0.6033, 0.3967],
[2K        [0.5922, 0.4078]], device='cuda:0')â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”[0m 189/203 [2m0:13:29 â€¢ 0:00:42[0m [2;4m0.33it/s[0m  
[2KAttention weights: tensor([[0.5596, 0.4404],â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”[0m 190/203 [2m0:13:31 â€¢ 0:00:35[0m [2;4m0.38it/s[0m  
        [0.5546, 0.4454],
        [0.5569, 0.4431],
        [0.5560, 0.4440],
        [0.5547, 0.4453],
        [0.5540, 0.4460],
        [0.5550, 0.4450],
        [0.5578, 0.4422],
        [0.5584, 0.4416],
[2K        [0.5552, 0.4448]], device='cuda:0', grad_fn=<SoftmaxBackward0>)mâ•º[0m[38;5;237mâ”â”[0m 190/203 [2m0:13:31 â€¢ 0:00:35[0m [2;4m0.38it/s[0m  
[2KClass label: PoleVaultâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”[0m 190/203 [2m0:13:31 â€¢ 0:00:35[0m [2;4m0.38it/s[0m  
[2KAttention weights: tensor([[0.6145, 0.3855]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 190/203 [2m0:13:31 â€¢ 0:00:35[0m [2;4m0.38it/s[0m  
[2KStep 0 - TTA Loss: 0.7139â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”[0m 190/203 [2m0:13:31 â€¢ 0:00:35[0m [2;4m0.38it/s[0m  
[2KAttention weights: tensor([[0.6319, 0.3681]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 190/203 [2m0:13:31 â€¢ 0:00:35[0m [2;4m0.38it/s[0m  
[2KAttention weights: tensor([[0.6712, 0.3288]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 190/203 [2m0:13:31 â€¢ 0:00:35[0m [2;4m0.38it/s[0m  
[2KAttention weights: tensor([[0.7198, 0.2802]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 190/203 [2m0:13:31 â€¢ 0:00:35[0m [2;4m0.38it/s[0m  
[2KAttention weights: tensor([[0.7675, 0.2325]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 190/203 [2m0:13:31 â€¢ 0:00:35[0m [2;4m0.38it/s[0m  
[2KAttention weights: tensor([[0.8045, 0.1955]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 190/203 [2m0:13:31 â€¢ 0:00:35[0m [2;4m0.38it/s[0m  
[2KAttention weights: tensor([[0.8285, 0.1715]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 190/203 [2m0:13:31 â€¢ 0:00:35[0m [2;4m0.38it/s[0m  
[2KAttention weights: tensor([[0.8421, 0.1579]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 190/203 [2m0:13:31 â€¢ 0:00:35[0m [2;4m0.38it/s[0m  
[2KAttention weights: tensor([[0.8490, 0.1510]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 190/203 [2m0:13:31 â€¢ 0:00:35[0m [2;4m0.38it/s[0m  
[2KAttention weights: tensor([[0.8519, 0.1481]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 190/203 [2m0:13:31 â€¢ 0:00:35[0m [2;4m0.38it/s[0m  
[2KAttention weights: tensor([[0.5634, 0.4366]], device='cuda:0')[38;5;237mâ•º[0m[38;5;237mâ”â”[0m 190/203 [2m0:13:31 â€¢ 0:00:35[0m [2;4m0.38it/s[0m  
[2KAttention weights: tensor([[0.7850, 0.2150],â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”[0m 190/203 [2m0:13:31 â€¢ 0:00:35[0m [2;4m0.38it/s[0m  
        [0.6935, 0.3065],
        [0.7673, 0.2327],
        [0.7024, 0.2976],
        [0.7365, 0.2635],
        [0.8079, 0.1921],
        [0.8527, 0.1473],
        [0.7885, 0.2115],
        [0.7551, 0.2449],
[2K        [0.7693, 0.2307]], device='cuda:0')â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”[0m 190/203 [2m0:13:31 â€¢ 0:00:35[0m [2;4m0.38it/s[0m  
[2KAttention weights: tensor([[0.5596, 0.4404],â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”[0m 191/203 [2m0:13:52 â€¢ 0:01:24[0m [2;4m0.14it/s[0m  
        [0.5546, 0.4454],
        [0.5569, 0.4431],
        [0.5560, 0.4440],
        [0.5547, 0.4453],
        [0.5540, 0.4460],
        [0.5550, 0.4450],
        [0.5578, 0.4422],
        [0.5584, 0.4416],
[2K        [0.5552, 0.4448]], device='cuda:0', grad_fn=<SoftmaxBackward0>)6;224mâ•¸[0m[38;5;237mâ”â”[0m 191/203 [2m0:13:52 â€¢ 0:01:24[0m [2;4m0.14it/s[0m  
[2KClass label: CleanAndJerkâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”[0m 191/203 [2m0:13:52 â€¢ 0:01:24[0m [2;4m0.14it/s[0m  
[2KAttention weights: tensor([[0.6243, 0.3757]], device='cuda:0', grad_fn=<SoftmaxBackward0>)37mâ”â”[0m 191/203 [2m0:13:52 â€¢ 0:01:24[0m [2;4m0.14it/s[0m  
[2KStep 0 - TTA Loss: 0.8839â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”[0m 191/203 [2m0:13:52 â€¢ 0:01:24[0m [2;4m0.14it/s[0m  
[2KAttention weights: tensor([[0.6243, 0.3757]], device='cuda:0', grad_fn=<SoftmaxBackward0>)37mâ”â”[0m 191/203 [2m0:13:52 â€¢ 0:01:24[0m [2;4m0.14it/s[0m  
[2KAttention weights: tensor([[0.6255, 0.3745]], device='cuda:0', grad_fn=<SoftmaxBackward0>)37mâ”â”[0m 191/203 [2m0:13:52 â€¢ 0:01:24[0m [2;4m0.14it/s[0m  
[2KAttention weights: tensor([[0.6314, 0.3686]], device='cuda:0', grad_fn=<SoftmaxBackward0>)37mâ”â”[0m 191/203 [2m0:13:52 â€¢ 0:01:24[0m [2;4m0.14it/s[0m  
[2KAttention weights: tensor([[0.6467, 0.3533]], device='cuda:0', grad_fn=<SoftmaxBackward0>)37mâ”â”[0m 191/203 [2m0:13:52 â€¢ 0:01:24[0m [2;4m0.14it/s[0m  
[2KAttention weights: tensor([[0.6739, 0.3261]], device='cuda:0', grad_fn=<SoftmaxBackward0>)37mâ”â”[0m 191/203 [2m0:13:52 â€¢ 0:01:24[0m [2;4m0.14it/s[0m  
[2KAttention weights: tensor([[0.7133, 0.2867]], device='cuda:0', grad_fn=<SoftmaxBackward0>)37mâ”â”[0m 191/203 [2m0:13:52 â€¢ 0:01:24[0m [2;4m0.14it/s[0m  
[2KAttention weights: tensor([[0.7553, 0.2447]], device='cuda:0', grad_fn=<SoftmaxBackward0>)37mâ”â”[0m 191/203 [2m0:13:52 â€¢ 0:01:24[0m [2;4m0.14it/s[0m  
[2KAttention weights: tensor([[0.7901, 0.2099]], device='cuda:0', grad_fn=<SoftmaxBackward0>)37mâ”â”[0m 191/203 [2m0:13:52 â€¢ 0:01:24[0m [2;4m0.14it/s[0m  
[2KAttention weights: tensor([[0.8029, 0.1971]], device='cuda:0', grad_fn=<SoftmaxBackward0>)37mâ”â”[0m 191/203 [2m0:13:52 â€¢ 0:01:24[0m [2;4m0.14it/s[0m  
[2KAttention weights: tensor([[0.5604, 0.4396]], device='cuda:0')[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”[0m 191/203 [2m0:13:52 â€¢ 0:01:24[0m [2;4m0.14it/s[0m  
[2KAttention weights: tensor([[0.7333, 0.2667],â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”[0m 191/203 [2m0:13:52 â€¢ 0:01:24[0m [2;4m0.14it/s[0m  
        [0.6664, 0.3336],
        [0.8050, 0.1950],
        [0.6959, 0.3041],
        [0.6831, 0.3169],
        [0.7379, 0.2621],
        [0.7567, 0.2433],
        [0.7310, 0.2690],
        [0.7573, 0.2427],
[2K        [0.7626, 0.2374]], device='cuda:0')â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”[0m 191/203 [2m0:13:52 â€¢ 0:01:24[0m [2;4m0.14it/s[0m  
[2KAttention weights: tensor([[0.5596, 0.4404],â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”[0m 192/203 [2m0:13:57 â€¢ 0:01:45[0m [2;4m0.11it/s[0m  
        [0.5546, 0.4454],
        [0.5569, 0.4431],
        [0.5560, 0.4440],
        [0.5547, 0.4453],
        [0.5540, 0.4460],
        [0.5550, 0.4450],
        [0.5578, 0.4422],
        [0.5584, 0.4416],
[2K        [0.5552, 0.4448]], device='cuda:0', grad_fn=<SoftmaxBackward0>)6;224mâ•¸[0m[38;5;237mâ”â”[0m 192/203 [2m0:13:57 â€¢ 0:01:45[0m [2;4m0.11it/s[0m  
[2KClass label: HammerThrowâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”[0m 192/203 [2m0:13:57 â€¢ 0:01:45[0m [2;4m0.11it/s[0m  
[2KAttention weights: tensor([[0.5362, 0.4638]], device='cuda:0', grad_fn=<SoftmaxBackward0>)37mâ”â”[0m 192/203 [2m0:13:57 â€¢ 0:01:45[0m [2;4m0.11it/s[0m  
[2KStep 0 - TTA Loss: 0.8636â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”[0m 192/203 [2m0:13:57 â€¢ 0:01:45[0m [2;4m0.11it/s[0m  
[2KAttention weights: tensor([[0.5561, 0.4439]], device='cuda:0', grad_fn=<SoftmaxBackward0>)37mâ”â”[0m 192/203 [2m0:13:57 â€¢ 0:01:45[0m [2;4m0.11it/s[0m  
[2KAttention weights: tensor([[0.6043, 0.3957]], device='cuda:0', grad_fn=<SoftmaxBackward0>)37mâ”â”[0m 192/203 [2m0:13:57 â€¢ 0:01:45[0m [2;4m0.11it/s[0m  
[2KAttention weights: tensor([[0.6666, 0.3334]], device='cuda:0', grad_fn=<SoftmaxBackward0>)37mâ”â”[0m 192/203 [2m0:13:57 â€¢ 0:01:45[0m [2;4m0.11it/s[0m  
[2KAttention weights: tensor([[0.7254, 0.2746]], device='cuda:0', grad_fn=<SoftmaxBackward0>)37mâ”â”[0m 192/203 [2m0:13:57 â€¢ 0:01:45[0m [2;4m0.11it/s[0m  
[2KAttention weights: tensor([[0.7679, 0.2321]], device='cuda:0', grad_fn=<SoftmaxBackward0>)37mâ”â”[0m 192/203 [2m0:13:57 â€¢ 0:01:45[0m [2;4m0.11it/s[0m  
[2KAttention weights: tensor([[0.7951, 0.2049]], device='cuda:0', grad_fn=<SoftmaxBackward0>)37mâ”â”[0m 192/203 [2m0:13:57 â€¢ 0:01:45[0m [2;4m0.11it/s[0m  
[2KAttention weights: tensor([[0.8117, 0.1883]], device='cuda:0', grad_fn=<SoftmaxBackward0>)37mâ”â”[0m 192/203 [2m0:13:57 â€¢ 0:01:45[0m [2;4m0.11it/s[0m  
[2KAttention weights: tensor([[0.8217, 0.1783]], device='cuda:0', grad_fn=<SoftmaxBackward0>)37mâ”â”[0m 192/203 [2m0:13:57 â€¢ 0:01:45[0m [2;4m0.11it/s[0m  
[2KAttention weights: tensor([[0.8264, 0.1736]], device='cuda:0', grad_fn=<SoftmaxBackward0>)37mâ”â”[0m 192/203 [2m0:13:57 â€¢ 0:01:45[0m [2;4m0.11it/s[0m  
[2KAttention weights: tensor([[0.5636, 0.4364]], device='cuda:0')[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”[0m 192/203 [2m0:13:57 â€¢ 0:01:45[0m [2;4m0.11it/s[0m  
[2KAttention weights: tensor([[0.7928, 0.2072],â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”[0m 192/203 [2m0:13:57 â€¢ 0:01:45[0m [2;4m0.11it/s[0m  
        [0.6925, 0.3075],
        [0.7427, 0.2573],
        [0.7288, 0.2712],
        [0.8277, 0.1723],
        [0.7773, 0.2227],
        [0.7760, 0.2240],
        [0.7975, 0.2025],
        [0.7772, 0.2228],
[2K        [0.7731, 0.2269]], device='cuda:0')â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”[0m 192/203 [2m0:13:57 â€¢ 0:01:45[0m [2;4m0.11it/s[0m  
[2KAttention weights: tensor([[0.5596, 0.4404],â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”[0m 193/203 [2m0:14:02 â€¢ 0:00:51[0m [2;4m0.20it/s[0m   
        [0.5546, 0.4454],
        [0.5569, 0.4431],
        [0.5560, 0.4440],
        [0.5547, 0.4453],
        [0.5540, 0.4460],
        [0.5550, 0.4450],
        [0.5578, 0.4422],
        [0.5583, 0.4417],
[2K        [0.5552, 0.4448]], device='cuda:0', grad_fn=<SoftmaxBackward0>)7mâ•º[0m[38;5;237mâ”[0m 193/203 [2m0:14:02 â€¢ 0:00:51[0m [2;4m0.20it/s[0m  
[2KClass label: BaseballPitchâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”[0m 193/203 [2m0:14:02 â€¢ 0:00:51[0m [2;4m0.20it/s[0m  
[2KAttention weights: tensor([[0.6454, 0.3546]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 193/203 [2m0:14:02 â€¢ 0:00:51[0m [2;4m0.20it/s[0m  
[2KStep 0 - TTA Loss: 1.0907â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”[0m 193/203 [2m0:14:02 â€¢ 0:00:51[0m [2;4m0.20it/s[0m  
[2KAttention weights: tensor([[0.6454, 0.3546]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 193/203 [2m0:14:02 â€¢ 0:00:51[0m [2;4m0.20it/s[0m  
[2KAttention weights: tensor([[0.6468, 0.3532]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 193/203 [2m0:14:02 â€¢ 0:00:51[0m [2;4m0.20it/s[0m  
[2KAttention weights: tensor([[0.6535, 0.3465]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 193/203 [2m0:14:02 â€¢ 0:00:51[0m [2;4m0.20it/s[0m  
[2KAttention weights: tensor([[0.6699, 0.3301]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 193/203 [2m0:14:02 â€¢ 0:00:51[0m [2;4m0.20it/s[0m  
[2KAttention weights: tensor([[0.6995, 0.3005]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 193/203 [2m0:14:02 â€¢ 0:00:51[0m [2;4m0.20it/s[0m  
[2KAttention weights: tensor([[0.7404, 0.2596]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 193/203 [2m0:14:02 â€¢ 0:00:51[0m [2;4m0.20it/s[0m  
[2KAttention weights: tensor([[0.7849, 0.2151]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 193/203 [2m0:14:02 â€¢ 0:00:51[0m [2;4m0.20it/s[0m  
[2KAttention weights: tensor([[0.8237, 0.1763]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 193/203 [2m0:14:02 â€¢ 0:00:51[0m [2;4m0.20it/s[0m  
[2KAttention weights: tensor([[0.8482, 0.1518]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 193/203 [2m0:14:02 â€¢ 0:00:51[0m [2;4m0.20it/s[0m  
[2KAttention weights: tensor([[0.5642, 0.4358]], device='cuda:0')[38;5;237mâ•º[0m[38;5;237mâ”[0m 193/203 [2m0:14:02 â€¢ 0:00:51[0m [2;4m0.20it/s[0m  
[2KAttention weights: tensor([[0.8580, 0.1420],â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”[0m 193/203 [2m0:14:02 â€¢ 0:00:51[0m [2;4m0.20it/s[0m  
        [0.6989, 0.3011],
        [0.7336, 0.2664],
        [0.7508, 0.2492],
        [0.7929, 0.2071],
        [0.7565, 0.2435],
        [0.7602, 0.2398],
        [0.8020, 0.1980],
        [0.7913, 0.2087],
[2K        [0.7525, 0.2475]], device='cuda:0')â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”[0m 193/203 [2m0:14:02 â€¢ 0:00:51[0m [2;4m0.20it/s[0m  
[2KAttention weights: tensor([[0.5596, 0.4404],â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”[0m 194/203 [2m0:14:04 â€¢ 0:00:34[0m [2;4m0.27it/s[0m  
        [0.5546, 0.4454],
        [0.5569, 0.4431],
        [0.5560, 0.4440],
        [0.5547, 0.4453],
        [0.5540, 0.4460],
        [0.5550, 0.4450],
        [0.5578, 0.4422],
        [0.5583, 0.4417],
[2K        [0.5552, 0.4448]], device='cuda:0', grad_fn=<SoftmaxBackward0>)7mâ•º[0m[38;5;237mâ”[0m 194/203 [2m0:14:04 â€¢ 0:00:34[0m [2;4m0.27it/s[0m  
[2KClass label: TennisSwingâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”[0m 194/203 [2m0:14:04 â€¢ 0:00:34[0m [2;4m0.27it/s[0m  
[2KAttention weights: tensor([[0.6617, 0.3383]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 194/203 [2m0:14:04 â€¢ 0:00:34[0m [2;4m0.27it/s[0m  
[2KStep 0 - TTA Loss: 0.7094â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”[0m 194/203 [2m0:14:04 â€¢ 0:00:34[0m [2;4m0.27it/s[0m  
[2KAttention weights: tensor([[0.6764, 0.3236]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 194/203 [2m0:14:04 â€¢ 0:00:34[0m [2;4m0.27it/s[0m  
[2KAttention weights: tensor([[0.6858, 0.3142]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 194/203 [2m0:14:04 â€¢ 0:00:34[0m [2;4m0.27it/s[0m  
[2KAttention weights: tensor([[0.6862, 0.3138]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 194/203 [2m0:14:04 â€¢ 0:00:34[0m [2;4m0.27it/s[0m  
[2KAttention weights: tensor([[0.6880, 0.3120]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 194/203 [2m0:14:04 â€¢ 0:00:34[0m [2;4m0.27it/s[0m  
[2KAttention weights: tensor([[0.7044, 0.2956]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 194/203 [2m0:14:04 â€¢ 0:00:34[0m [2;4m0.27it/s[0m  
[2KAttention weights: tensor([[0.7323, 0.2677]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 194/203 [2m0:14:04 â€¢ 0:00:34[0m [2;4m0.27it/s[0m  
[2KAttention weights: tensor([[0.7598, 0.2402]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 194/203 [2m0:14:04 â€¢ 0:00:34[0m [2;4m0.27it/s[0m  
[2KAttention weights: tensor([[0.7785, 0.2215]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 194/203 [2m0:14:04 â€¢ 0:00:34[0m [2;4m0.27it/s[0m  
[2KAttention weights: tensor([[0.7879, 0.2121]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 194/203 [2m0:14:04 â€¢ 0:00:34[0m [2;4m0.27it/s[0m  
[2KAttention weights: tensor([[0.5615, 0.4385]], device='cuda:0')[38;5;237mâ•º[0m[38;5;237mâ”[0m 194/203 [2m0:14:04 â€¢ 0:00:34[0m [2;4m0.27it/s[0m  
[2KAttention weights: tensor([[0.7477, 0.2523],â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”[0m 194/203 [2m0:14:04 â€¢ 0:00:34[0m [2;4m0.27it/s[0m  
        [0.6686, 0.3314],
        [0.7149, 0.2851],
        [0.7084, 0.2916],
        [0.7077, 0.2923],
        [0.7163, 0.2837],
        [0.7056, 0.2944],
        [0.7432, 0.2568],
        [0.7905, 0.2095],
[2K        [0.7278, 0.2722]], device='cuda:0')â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”[0m 194/203 [2m0:14:04 â€¢ 0:00:34[0m [2;4m0.27it/s[0m  
[2KAttention weights: tensor([[0.5596, 0.4404],â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”[0m 195/203 [2m0:14:15 â€¢ 0:00:46[0m [2;4m0.18it/s[0m  
        [0.5546, 0.4454],
        [0.5569, 0.4431],
        [0.5560, 0.4440],
        [0.5547, 0.4453],
        [0.5540, 0.4460],
        [0.5550, 0.4450],
        [0.5578, 0.4422],
        [0.5584, 0.4416],
[2K        [0.5552, 0.4448]], device='cuda:0', grad_fn=<SoftmaxBackward0>)7mâ•º[0m[38;5;237mâ”[0m 195/203 [2m0:14:15 â€¢ 0:00:46[0m [2;4m0.18it/s[0m  
[2KClass label: GolfSwingâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”[0m 195/203 [2m0:14:15 â€¢ 0:00:46[0m [2;4m0.18it/s[0m  
[2KAttention weights: tensor([[0.6061, 0.3939]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 195/203 [2m0:14:15 â€¢ 0:00:46[0m [2;4m0.18it/s[0m  
[2KStep 0 - TTA Loss: 0.5896â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”[0m 195/203 [2m0:14:15 â€¢ 0:00:46[0m [2;4m0.18it/s[0m  
[2KAttention weights: tensor([[0.6061, 0.3939]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 195/203 [2m0:14:15 â€¢ 0:00:46[0m [2;4m0.18it/s[0m  
[2KAttention weights: tensor([[0.6082, 0.3918]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 195/203 [2m0:14:15 â€¢ 0:00:46[0m [2;4m0.18it/s[0m  
[2KAttention weights: tensor([[0.6166, 0.3834]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 195/203 [2m0:14:15 â€¢ 0:00:46[0m [2;4m0.18it/s[0m  
[2KAttention weights: tensor([[0.6352, 0.3648]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 195/203 [2m0:14:15 â€¢ 0:00:46[0m [2;4m0.18it/s[0m  
[2KAttention weights: tensor([[0.6667, 0.3333]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 195/203 [2m0:14:15 â€¢ 0:00:46[0m [2;4m0.18it/s[0m  
[2KAttention weights: tensor([[0.7077, 0.2923]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 195/203 [2m0:14:15 â€¢ 0:00:46[0m [2;4m0.18it/s[0m  
[2KAttention weights: tensor([[0.7523, 0.2477]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 195/203 [2m0:14:15 â€¢ 0:00:46[0m [2;4m0.18it/s[0m  
[2KAttention weights: tensor([[0.7831, 0.2169]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 195/203 [2m0:14:15 â€¢ 0:00:46[0m [2;4m0.18it/s[0m  
[2KAttention weights: tensor([[0.8000, 0.2000]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 195/203 [2m0:14:15 â€¢ 0:00:46[0m [2;4m0.18it/s[0m  
[2KAttention weights: tensor([[0.5606, 0.4394]], device='cuda:0')[38;5;237mâ•º[0m[38;5;237mâ”[0m 195/203 [2m0:14:15 â€¢ 0:00:46[0m [2;4m0.18it/s[0m  
[2KAttention weights: tensor([[0.7952, 0.2048],â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”[0m 195/203 [2m0:14:15 â€¢ 0:00:46[0m [2;4m0.18it/s[0m  
        [0.7240, 0.2760],
        [0.7622, 0.2378],
        [0.8051, 0.1949],
        [0.7231, 0.2769],
        [0.7709, 0.2291],
        [0.7400, 0.2600],
        [0.7929, 0.2071],
        [0.8900, 0.1100],
[2K        [0.7824, 0.2176]], device='cuda:0')â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”[0m 195/203 [2m0:14:15 â€¢ 0:00:46[0m [2;4m0.18it/s[0m  
[2KAttention weights: tensor([[0.5596, 0.4404],â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”[0m 196/203 [2m0:14:20 â€¢ 0:00:39[0m [2;4m0.18it/s[0m  
        [0.5546, 0.4454],
        [0.5569, 0.4431],
        [0.5560, 0.4440],
        [0.5548, 0.4452],
        [0.5540, 0.4460],
        [0.5550, 0.4450],
        [0.5578, 0.4422],
        [0.5584, 0.4416],
[2K        [0.5552, 0.4448]], device='cuda:0', grad_fn=<SoftmaxBackward0>);6;224mâ•¸[0m[38;5;237mâ”[0m 196/203 [2m0:14:20 â€¢ 0:00:39[0m [2;4m0.18it/s[0m  
[2KClass label: PoleVaultâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”[0m 196/203 [2m0:14:20 â€¢ 0:00:39[0m [2;4m0.18it/s[0m  
[2KAttention weights: tensor([[0.6142, 0.3858]], device='cuda:0', grad_fn=<SoftmaxBackward0>)237mâ”[0m 196/203 [2m0:14:20 â€¢ 0:00:39[0m [2;4m0.18it/s[0m  
[2KStep 0 - TTA Loss: 1.1147â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”[0m 196/203 [2m0:14:20 â€¢ 0:00:39[0m [2;4m0.18it/s[0m  
[2KAttention weights: tensor([[0.6384, 0.3616]], device='cuda:0', grad_fn=<SoftmaxBackward0>)237mâ”[0m 196/203 [2m0:14:20 â€¢ 0:00:39[0m [2;4m0.18it/s[0m  
[2KAttention weights: tensor([[0.6680, 0.3320]], device='cuda:0', grad_fn=<SoftmaxBackward0>)237mâ”[0m 196/203 [2m0:14:20 â€¢ 0:00:39[0m [2;4m0.18it/s[0m  
[2KAttention weights: tensor([[0.7031, 0.2969]], device='cuda:0', grad_fn=<SoftmaxBackward0>)237mâ”[0m 196/203 [2m0:14:20 â€¢ 0:00:39[0m [2;4m0.18it/s[0m  
[2KAttention weights: tensor([[0.7344, 0.2656]], device='cuda:0', grad_fn=<SoftmaxBackward0>)237mâ”[0m 196/203 [2m0:14:20 â€¢ 0:00:39[0m [2;4m0.18it/s[0m  
[2KAttention weights: tensor([[0.7569, 0.2431]], device='cuda:0', grad_fn=<SoftmaxBackward0>)237mâ”[0m 196/203 [2m0:14:20 â€¢ 0:00:39[0m [2;4m0.18it/s[0m  
[2KAttention weights: tensor([[0.7703, 0.2297]], device='cuda:0', grad_fn=<SoftmaxBackward0>)237mâ”[0m 196/203 [2m0:14:20 â€¢ 0:00:39[0m [2;4m0.18it/s[0m  
[2KAttention weights: tensor([[0.7725, 0.2275]], device='cuda:0', grad_fn=<SoftmaxBackward0>)237mâ”[0m 196/203 [2m0:14:20 â€¢ 0:00:39[0m [2;4m0.18it/s[0m  
[2KAttention weights: tensor([[0.7728, 0.2272]], device='cuda:0', grad_fn=<SoftmaxBackward0>)237mâ”[0m 196/203 [2m0:14:20 â€¢ 0:00:39[0m [2;4m0.18it/s[0m  
[2KAttention weights: tensor([[0.7724, 0.2276]], device='cuda:0', grad_fn=<SoftmaxBackward0>)237mâ”[0m 196/203 [2m0:14:20 â€¢ 0:00:39[0m [2;4m0.18it/s[0m  
[2KAttention weights: tensor([[0.5597, 0.4403]], device='cuda:0')[38;2;98;6;224mâ•¸[0m[38;5;237mâ”[0m 196/203 [2m0:14:20 â€¢ 0:00:39[0m [2;4m0.18it/s[0m  
[2KAttention weights: tensor([[0.7668, 0.2332],â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”[0m 196/203 [2m0:14:20 â€¢ 0:00:39[0m [2;4m0.18it/s[0m  
        [0.6901, 0.3099],
        [0.7459, 0.2541],
        [0.7022, 0.2978],
        [0.7020, 0.2980],
        [0.7683, 0.2317],
        [0.7720, 0.2280],
        [0.7677, 0.2323],
        [0.8355, 0.1645],
[2K        [0.7589, 0.2411]], device='cuda:0')â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”[0m 196/203 [2m0:14:20 â€¢ 0:00:39[0m [2;4m0.18it/s[0m  
[2KAttention weights: tensor([[0.5596, 0.4404],â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”[0m 197/203 [2m0:14:25 â€¢ 0:00:33[0m [2;4m0.18it/s[0m  
        [0.5546, 0.4454],
        [0.5569, 0.4431],
        [0.5560, 0.4440],
        [0.5548, 0.4452],
        [0.5541, 0.4459],
        [0.5551, 0.4449],
        [0.5578, 0.4422],
        [0.5584, 0.4416],
[2K        [0.5552, 0.4448]], device='cuda:0', grad_fn=<SoftmaxBackward0>);6;224mâ•¸[0m[38;5;237mâ”[0m 197/203 [2m0:14:25 â€¢ 0:00:33[0m [2;4m0.18it/s[0m  
[2KClass label: PoleVaultâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”[0m 197/203 [2m0:14:25 â€¢ 0:00:33[0m [2;4m0.18it/s[0m  
[2KAttention weights: tensor([[0.6126, 0.3874]], device='cuda:0', grad_fn=<SoftmaxBackward0>)237mâ”[0m 197/203 [2m0:14:25 â€¢ 0:00:33[0m [2;4m0.18it/s[0m  
[2KStep 0 - TTA Loss: 0.8335â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”[0m 197/203 [2m0:14:25 â€¢ 0:00:33[0m [2;4m0.18it/s[0m  
[2KAttention weights: tensor([[0.6126, 0.3874]], device='cuda:0', grad_fn=<SoftmaxBackward0>)237mâ”[0m 197/203 [2m0:14:25 â€¢ 0:00:33[0m [2;4m0.18it/s[0m  
[2KAttention weights: tensor([[0.6123, 0.3877]], device='cuda:0', grad_fn=<SoftmaxBackward0>)237mâ”[0m 197/203 [2m0:14:25 â€¢ 0:00:33[0m [2;4m0.18it/s[0m  
[2KAttention weights: tensor([[0.6120, 0.3880]], device='cuda:0', grad_fn=<SoftmaxBackward0>)237mâ”[0m 197/203 [2m0:14:25 â€¢ 0:00:33[0m [2;4m0.18it/s[0m  
[2KAttention weights: tensor([[0.6137, 0.3863]], device='cuda:0', grad_fn=<SoftmaxBackward0>)237mâ”[0m 197/203 [2m0:14:25 â€¢ 0:00:33[0m [2;4m0.18it/s[0m  
[2KAttention weights: tensor([[0.6198, 0.3802]], device='cuda:0', grad_fn=<SoftmaxBackward0>)237mâ”[0m 197/203 [2m0:14:25 â€¢ 0:00:33[0m [2;4m0.18it/s[0m  
[2KAttention weights: tensor([[0.6344, 0.3656]], device='cuda:0', grad_fn=<SoftmaxBackward0>)237mâ”[0m 197/203 [2m0:14:25 â€¢ 0:00:33[0m [2;4m0.18it/s[0m  
[2KAttention weights: tensor([[0.6540, 0.3460]], device='cuda:0', grad_fn=<SoftmaxBackward0>)237mâ”[0m 197/203 [2m0:14:25 â€¢ 0:00:33[0m [2;4m0.18it/s[0m  
[2KAttention weights: tensor([[0.6823, 0.3177]], device='cuda:0', grad_fn=<SoftmaxBackward0>)237mâ”[0m 197/203 [2m0:14:25 â€¢ 0:00:33[0m [2;4m0.18it/s[0m  
[2KAttention weights: tensor([[0.7148, 0.2852]], device='cuda:0', grad_fn=<SoftmaxBackward0>)237mâ”[0m 197/203 [2m0:14:25 â€¢ 0:00:33[0m [2;4m0.18it/s[0m  
[2KAttention weights: tensor([[0.5587, 0.4413]], device='cuda:0')[38;2;98;6;224mâ•¸[0m[38;5;237mâ”[0m 197/203 [2m0:14:25 â€¢ 0:00:33[0m [2;4m0.18it/s[0m  
[2KAttention weights: tensor([[0.7245, 0.2755],â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”[0m 197/203 [2m0:14:25 â€¢ 0:00:33[0m [2;4m0.18it/s[0m  
        [0.6557, 0.3443],
        [0.7031, 0.2969],
        [0.6786, 0.3214],
        [0.6513, 0.3487],
        [0.7205, 0.2795],
        [0.7438, 0.2562],
        [0.7263, 0.2737],
        [0.7453, 0.2547],
[2K        [0.7071, 0.2929]], device='cuda:0')â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”[0m 197/203 [2m0:14:25 â€¢ 0:00:33[0m [2;4m0.18it/s[0m  
[2KAttention weights: tensor([[0.5596, 0.4404],â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m 198/203 [2m0:14:31 â€¢ 0:00:29[0m [2;4m0.18it/s[0m  4m0.18it/s[0m  
        [0.5546, 0.4454],
        [0.5569, 0.4431],
        [0.5560, 0.4440],
        [0.5547, 0.4453],
        [0.5540, 0.4460],
        [0.5550, 0.4450],
        [0.5578, 0.4422],
        [0.5584, 0.4416],
[2K        [0.5552, 0.4448]], device='cuda:0', grad_fn=<SoftmaxBackward0>)37mâ•º[0m 198/203 [2m0:14:31 â€¢ 0:00:29[0m [2;4m0.18it/s[0m  
[2KClass label: SoccerPenaltyâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m 198/203 [2m0:14:31 â€¢ 0:00:29[0m [2;4m0.18it/s[0m  
[2KAttention weights: tensor([[0.6352, 0.3648]], device='cuda:0', grad_fn=<SoftmaxBackward0>)2m0:14:31 â€¢ 0:00:29[0m [2;4m0.18it/s[0m  
[2KStep 0 - TTA Loss: 0.6271â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m 198/203 [2m0:14:31 â€¢ 0:00:29[0m [2;4m0.18it/s[0m  
[2KAttention weights: tensor([[0.6916, 0.3084]], device='cuda:0', grad_fn=<SoftmaxBackward0>)2m0:14:31 â€¢ 0:00:29[0m [2;4m0.18it/s[0m  
[2KAttention weights: tensor([[0.7723, 0.2277]], device='cuda:0', grad_fn=<SoftmaxBackward0>)2m0:14:31 â€¢ 0:00:29[0m [2;4m0.18it/s[0m  
[2KAttention weights: tensor([[0.8501, 0.1499]], device='cuda:0', grad_fn=<SoftmaxBackward0>)2m0:14:31 â€¢ 0:00:29[0m [2;4m0.18it/s[0m  
[2KAttention weights: tensor([[0.9031, 0.0969]], device='cuda:0', grad_fn=<SoftmaxBackward0>)2m0:14:31 â€¢ 0:00:29[0m [2;4m0.18it/s[0m  
[2KAttention weights: tensor([[0.9328, 0.0672]], device='cuda:0', grad_fn=<SoftmaxBackward0>)2m0:14:31 â€¢ 0:00:29[0m [2;4m0.18it/s[0m  
[2KAttention weights: tensor([[0.9471, 0.0529]], device='cuda:0', grad_fn=<SoftmaxBackward0>)2m0:14:31 â€¢ 0:00:29[0m [2;4m0.18it/s[0m  
[2KAttention weights: tensor([[0.9532, 0.0468]], device='cuda:0', grad_fn=<SoftmaxBackward0>)2m0:14:31 â€¢ 0:00:29[0m [2;4m0.18it/s[0m  
[2KAttention weights: tensor([[0.9561, 0.0439]], device='cuda:0', grad_fn=<SoftmaxBackward0>)2m0:14:31 â€¢ 0:00:29[0m [2;4m0.18it/s[0m  
[2KAttention weights: tensor([[0.9578, 0.0422]], device='cuda:0', grad_fn=<SoftmaxBackward0>)2m0:14:31 â€¢ 0:00:29[0m [2;4m0.18it/s[0m  
[2KAttention weights: tensor([[0.5712, 0.4288]], device='cuda:0')m[38;5;237mâ•º[0m 198/203 [2m0:14:31 â€¢ 0:00:29[0m [2;4m0.18it/s[0m  
[2KAttention weights: tensor([[0.8874, 0.1126],â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m 198/203 [2m0:14:31 â€¢ 0:00:29[0m [2;4m0.18it/s[0m  
        [0.8096, 0.1904],
        [0.7907, 0.2093],
        [0.8449, 0.1551],
        [0.8473, 0.1527],
        [0.8686, 0.1314],
        [0.8709, 0.1291],
        [0.9583, 0.0417],
        [0.8740, 0.1260],
[2K        [0.8045, 0.1955]], device='cuda:0')â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m 198/203 [2m0:14:31 â€¢ 0:00:29[0m [2;4m0.18it/s[0m  
[2KAttention weights: tensor([[0.5596, 0.4404],â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m 199/203 [2m0:14:33 â€¢ 0:00:24[0m [2;4m0.17it/s[0m  
        [0.5546, 0.4454],
        [0.5569, 0.4431],
        [0.5560, 0.4440],
        [0.5548, 0.4452],
        [0.5541, 0.4459],
        [0.5550, 0.4450],
        [0.5578, 0.4422],
        [0.5584, 0.4416],
[2K        [0.5552, 0.4448]], device='cuda:0', grad_fn=<SoftmaxBackward0>)37mâ•º[0m 199/203 [2m0:14:33 â€¢ 0:00:24[0m [2;4m0.17it/s[0m  
[2KClass label: PoleVaultâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m 199/203 [2m0:14:33 â€¢ 0:00:24[0m [2;4m0.17it/s[0m  
[2KAttention weights: tensor([[0.6110, 0.3890]], device='cuda:0', grad_fn=<SoftmaxBackward0>)2m0:14:33 â€¢ 0:00:24[0m [2;4m0.17it/s[0m  
[2KStep 0 - TTA Loss: 0.6473â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m 199/203 [2m0:14:33 â€¢ 0:00:24[0m [2;4m0.17it/s[0m  
[2KAttention weights: tensor([[0.6110, 0.3890]], device='cuda:0', grad_fn=<SoftmaxBackward0>)2m0:14:33 â€¢ 0:00:24[0m [2;4m0.17it/s[0m  
[2KAttention weights: tensor([[0.6126, 0.3874]], device='cuda:0', grad_fn=<SoftmaxBackward0>)2m0:14:33 â€¢ 0:00:24[0m [2;4m0.17it/s[0m  
[2KAttention weights: tensor([[0.6190, 0.3810]], device='cuda:0', grad_fn=<SoftmaxBackward0>)2m0:14:33 â€¢ 0:00:24[0m [2;4m0.17it/s[0m  
[2KAttention weights: tensor([[0.6337, 0.3663]], device='cuda:0', grad_fn=<SoftmaxBackward0>)2m0:14:33 â€¢ 0:00:24[0m [2;4m0.17it/s[0m  
[2KAttention weights: tensor([[0.6599, 0.3401]], device='cuda:0', grad_fn=<SoftmaxBackward0>)2m0:14:33 â€¢ 0:00:24[0m [2;4m0.17it/s[0m  
[2KAttention weights: tensor([[0.6949, 0.3051]], device='cuda:0', grad_fn=<SoftmaxBackward0>)2m0:14:33 â€¢ 0:00:24[0m [2;4m0.17it/s[0m  
[2KAttention weights: tensor([[0.7434, 0.2566]], device='cuda:0', grad_fn=<SoftmaxBackward0>)2m0:14:33 â€¢ 0:00:24[0m [2;4m0.17it/s[0m  
[2KAttention weights: tensor([[0.8023, 0.1977]], device='cuda:0', grad_fn=<SoftmaxBackward0>)2m0:14:33 â€¢ 0:00:24[0m [2;4m0.17it/s[0m  
[2KAttention weights: tensor([[0.8602, 0.1398]], device='cuda:0', grad_fn=<SoftmaxBackward0>)2m0:14:33 â€¢ 0:00:24[0m [2;4m0.17it/s[0m  
[2KAttention weights: tensor([[0.5655, 0.4345]], device='cuda:0')m[38;5;237mâ•º[0m 199/203 [2m0:14:33 â€¢ 0:00:24[0m [2;4m0.17it/s[0m  
[2KAttention weights: tensor([[0.8865, 0.1135],â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m 199/203 [2m0:14:33 â€¢ 0:00:24[0m [2;4m0.17it/s[0m  
        [0.7935, 0.2065],
        [0.8307, 0.1693],
        [0.8430, 0.1570],
        [0.8573, 0.1427],
        [0.8983, 0.1017],
        [0.9209, 0.0791],
        [0.9278, 0.0722],
        [0.8680, 0.1320],
[2K        [0.8463, 0.1537]], device='cuda:0')â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m 199/203 [2m0:14:33 â€¢ 0:00:24[0m [2;4m0.17it/s[0m  
[2KAttention weights: tensor([[0.5596, 0.4404],â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m 200/203 [2m0:14:50 â€¢ 0:00:26[0m [2;4m0.12it/s[0m  
        [0.5546, 0.4454],
        [0.5569, 0.4431],
        [0.5560, 0.4440],
        [0.5548, 0.4452],
        [0.5541, 0.4459],
        [0.5550, 0.4450],
        [0.5578, 0.4422],
        [0.5584, 0.4416],
[2K        [0.5552, 0.4448]], device='cuda:0', grad_fn=<SoftmaxBackward0>)37mâ•º[0m 200/203 [2m0:14:50 â€¢ 0:00:26[0m [2;4m0.12it/s[0m  
[2KClass label: CleanAndJerkâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m 200/203 [2m0:14:50 â€¢ 0:00:26[0m [2;4m0.12it/s[0m  
[2KAttention weights: tensor([[0.6230, 0.3770]], device='cuda:0', grad_fn=<SoftmaxBackward0>)2m0:14:50 â€¢ 0:00:26[0m [2;4m0.12it/s[0m  
[2KStep 0 - TTA Loss: 0.9066â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m 200/203 [2m0:14:50 â€¢ 0:00:26[0m [2;4m0.12it/s[0m  
[2KAttention weights: tensor([[0.6980, 0.3020]], device='cuda:0', grad_fn=<SoftmaxBackward0>)2m0:14:50 â€¢ 0:00:26[0m [2;4m0.12it/s[0m  
[2KAttention weights: tensor([[0.7585, 0.2415]], device='cuda:0', grad_fn=<SoftmaxBackward0>)2m0:14:50 â€¢ 0:00:26[0m [2;4m0.12it/s[0m  
[2KAttention weights: tensor([[0.8013, 0.1987]], device='cuda:0', grad_fn=<SoftmaxBackward0>)2m0:14:50 â€¢ 0:00:26[0m [2;4m0.12it/s[0m  
[2KAttention weights: tensor([[0.8321, 0.1679]], device='cuda:0', grad_fn=<SoftmaxBackward0>)2m0:14:50 â€¢ 0:00:26[0m [2;4m0.12it/s[0m  
[2KAttention weights: tensor([[0.8549, 0.1451]], device='cuda:0', grad_fn=<SoftmaxBackward0>)2m0:14:50 â€¢ 0:00:26[0m [2;4m0.12it/s[0m  
[2KAttention weights: tensor([[0.8702, 0.1298]], device='cuda:0', grad_fn=<SoftmaxBackward0>)2m0:14:50 â€¢ 0:00:26[0m [2;4m0.12it/s[0m  
[2KAttention weights: tensor([[0.8784, 0.1216]], device='cuda:0', grad_fn=<SoftmaxBackward0>)2m0:14:50 â€¢ 0:00:26[0m [2;4m0.12it/s[0m  
[2KAttention weights: tensor([[0.8823, 0.1177]], device='cuda:0', grad_fn=<SoftmaxBackward0>)2m0:14:50 â€¢ 0:00:26[0m [2;4m0.12it/s[0m  
[2KAttention weights: tensor([[0.8832, 0.1168]], device='cuda:0', grad_fn=<SoftmaxBackward0>)2m0:14:50 â€¢ 0:00:26[0m [2;4m0.12it/s[0m  
[2KAttention weights: tensor([[0.5681, 0.4319]], device='cuda:0')m[38;5;237mâ•º[0m 200/203 [2m0:14:50 â€¢ 0:00:26[0m [2;4m0.12it/s[0m  
[2KAttention weights: tensor([[0.9114, 0.0886],â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m 200/203 [2m0:14:50 â€¢ 0:00:26[0m [2;4m0.12it/s[0m  
        [0.8211, 0.1789],
        [0.8834, 0.1166],
        [0.8717, 0.1283],
        [0.8969, 0.1031],
        [0.9329, 0.0671],
        [0.9538, 0.0462],
        [0.9370, 0.0630],
        [0.8940, 0.1060],
[2K        [0.8935, 0.1065]], device='cuda:0')â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m 200/203 [2m0:14:50 â€¢ 0:00:26[0m [2;4m0.12it/s[0m  
[2KAttention weights: tensor([[0.5596, 0.4404],â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m 201/203 [2m0:14:51 â€¢ 0:00:14[0m [2;4m0.15it/s[0m  
        [0.5546, 0.4454],
        [0.5569, 0.4431],
        [0.5560, 0.4440],
        [0.5548, 0.4452],
        [0.5541, 0.4459],
        [0.5551, 0.4449],
        [0.5578, 0.4422],
        [0.5584, 0.4416],
[2K        [0.5552, 0.4448]], device='cuda:0', grad_fn=<SoftmaxBackward0>)8;6;224mâ•¸[0m 201/203 [2m0:14:51 â€¢ 0:00:14[0m [2;4m0.15it/s[0m  
[2KClass label: CleanAndJerkâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m 201/203 [2m0:14:51 â€¢ 0:00:14[0m [2;4m0.15it/s[0m  
[2KAttention weights: tensor([[0.6202, 0.3798]], device='cuda:0', grad_fn=<SoftmaxBackward0>)03 [2m0:14:51 â€¢ 0:00:14[0m [2;4m0.15it/s[0m  
[2KStep 0 - TTA Loss: 0.7688â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m 201/203 [2m0:14:51 â€¢ 0:00:14[0m [2;4m0.15it/s[0m  
[2KAttention weights: tensor([[0.6202, 0.3798]], device='cuda:0', grad_fn=<SoftmaxBackward0>)03 [2m0:14:51 â€¢ 0:00:14[0m [2;4m0.15it/s[0m  
[2KAttention weights: tensor([[0.6204, 0.3796]], device='cuda:0', grad_fn=<SoftmaxBackward0>)03 [2m0:14:51 â€¢ 0:00:14[0m [2;4m0.15it/s[0m  
[2KAttention weights: tensor([[0.6208, 0.3792]], device='cuda:0', grad_fn=<SoftmaxBackward0>)03 [2m0:14:51 â€¢ 0:00:14[0m [2;4m0.15it/s[0m  
[2KAttention weights: tensor([[0.6205, 0.3795]], device='cuda:0', grad_fn=<SoftmaxBackward0>)03 [2m0:14:51 â€¢ 0:00:14[0m [2;4m0.15it/s[0m  
[2KAttention weights: tensor([[0.6190, 0.3810]], device='cuda:0', grad_fn=<SoftmaxBackward0>)03 [2m0:14:51 â€¢ 0:00:14[0m [2;4m0.15it/s[0m  
[2KAttention weights: tensor([[0.6159, 0.3841]], device='cuda:0', grad_fn=<SoftmaxBackward0>)03 [2m0:14:51 â€¢ 0:00:14[0m [2;4m0.15it/s[0m  
[2KAttention weights: tensor([[0.6100, 0.3900]], device='cuda:0', grad_fn=<SoftmaxBackward0>)03 [2m0:14:51 â€¢ 0:00:14[0m [2;4m0.15it/s[0m  
[2KAttention weights: tensor([[0.6002, 0.3998]], device='cuda:0', grad_fn=<SoftmaxBackward0>)03 [2m0:14:51 â€¢ 0:00:14[0m [2;4m0.15it/s[0m  
[2KAttention weights: tensor([[0.5849, 0.4151]], device='cuda:0', grad_fn=<SoftmaxBackward0>)03 [2m0:14:51 â€¢ 0:00:14[0m [2;4m0.15it/s[0m  
[2KAttention weights: tensor([[0.5547, 0.4453]], device='cuda:0')m[38;2;98;6;224mâ•¸[0m 201/203 [2m0:14:51 â€¢ 0:00:14[0m [2;4m0.15it/s[0m  
[2KAttention weights: tensor([[0.6873, 0.3127],â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m 201/203 [2m0:14:51 â€¢ 0:00:14[0m [2;4m0.15it/s[0m  
        [0.6163, 0.3837],
        [0.5662, 0.4338],
        [0.6334, 0.3666],
        [0.5728, 0.4272],
        [0.6488, 0.3512],
        [0.6791, 0.3209],
        [0.6973, 0.3027],
        [0.6754, 0.3246],
[2K        [0.6071, 0.3929]], device='cuda:0')â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m 201/203 [2m0:14:51 â€¢ 0:00:14[0m [2;4m0.15it/s[0m  
[2KAttention weights: tensor([[0.5596, 0.4404],â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m 202/203 [2m0:14:54 â€¢ 0:00:06[0m [2;4m0.17it/s[0m  
        [0.5546, 0.4454],
        [0.5569, 0.4431],
        [0.5560, 0.4440],
        [0.5548, 0.4452],
        [0.5541, 0.4459],
        [0.5551, 0.4449],
        [0.5578, 0.4422],
        [0.5584, 0.4416],
[2K        [0.5552, 0.4448]], device='cuda:0', grad_fn=<SoftmaxBackward0>)8;6;224mâ•¸[0m 202/203 [2m0:14:54 â€¢ 0:00:06[0m [2;4m0.17it/s[0m  
[2KClass label: PoleVaultâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m 202/203 [2m0:14:54 â€¢ 0:00:06[0m [2;4m0.17it/s[0m  
[2KAttention weights: tensor([[0.6146, 0.3854]], device='cuda:0', grad_fn=<SoftmaxBackward0>)03 [2m0:14:54 â€¢ 0:00:06[0m [2;4m0.17it/s[0m  
[2KStep 0 - TTA Loss: 0.4977â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m 202/203 [2m0:14:54 â€¢ 0:00:06[0m [2;4m0.17it/s[0m  
[2KAttention weights: tensor([[0.6377, 0.3623]], device='cuda:0', grad_fn=<SoftmaxBackward0>)03 [2m0:14:54 â€¢ 0:00:06[0m [2;4m0.17it/s[0m  
[2KAttention weights: tensor([[0.6728, 0.3272]], device='cuda:0', grad_fn=<SoftmaxBackward0>)03 [2m0:14:54 â€¢ 0:00:06[0m [2;4m0.17it/s[0m  
[2KAttention weights: tensor([[0.7167, 0.2833]], device='cuda:0', grad_fn=<SoftmaxBackward0>)03 [2m0:14:54 â€¢ 0:00:06[0m [2;4m0.17it/s[0m  
[2KAttention weights: tensor([[0.7628, 0.2372]], device='cuda:0', grad_fn=<SoftmaxBackward0>)03 [2m0:14:54 â€¢ 0:00:06[0m [2;4m0.17it/s[0m  
[2KAttention weights: tensor([[0.8003, 0.1997]], device='cuda:0', grad_fn=<SoftmaxBackward0>)03 [2m0:14:54 â€¢ 0:00:06[0m [2;4m0.17it/s[0m  
[2KAttention weights: tensor([[0.8265, 0.1735]], device='cuda:0', grad_fn=<SoftmaxBackward0>)03 [2m0:14:54 â€¢ 0:00:06[0m [2;4m0.17it/s[0m  
[2KAttention weights: tensor([[0.8415, 0.1585]], device='cuda:0', grad_fn=<SoftmaxBackward0>)03 [2m0:14:54 â€¢ 0:00:06[0m [2;4m0.17it/s[0m  
[2KAttention weights: tensor([[0.8499, 0.1501]], device='cuda:0', grad_fn=<SoftmaxBackward0>)03 [2m0:14:54 â€¢ 0:00:06[0m [2;4m0.17it/s[0m  
[2KAttention weights: tensor([[0.8530, 0.1470]], device='cuda:0', grad_fn=<SoftmaxBackward0>)03 [2m0:14:54 â€¢ 0:00:06[0m [2;4m0.17it/s[0m  
[2KAttention weights: tensor([[0.5643, 0.4357]], device='cuda:0')m[38;2;98;6;224mâ•¸[0m 202/203 [2m0:14:54 â€¢ 0:00:06[0m [2;4m0.17it/s[0m  
[2KAttention weights: tensor([[0.8004, 0.1996],â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m 202/203 [2m0:14:54 â€¢ 0:00:06[0m [2;4m0.17it/s[0m  
        [0.6998, 0.3002],
        [0.6957, 0.3043],
        [0.7416, 0.2584],
        [0.7323, 0.2677],
        [0.8102, 0.1898],
        [0.8538, 0.1462],
        [0.8129, 0.1871],
        [0.7738, 0.2262],
[2K        [0.7445, 0.2555]], device='cuda:0')â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m 202/203 [2m0:14:54 â€¢ 0:00:06[0m [2;4m0.17it/s[0m  
[2K                   video-id  t-start  t-end     labelâ”â”â”â”â”â”â”â”â”â”â”[0m 203/203 [2m0:15:00 â€¢ 0:00:00[0m [2;4m0.17it/s[0m  4m0.17it/s[0m  
0  video_validation_0000365     18.1   24.3  HighJump
1  video_validation_0000365     29.6   33.3  HighJump
2  video_validation_0000365     69.7   77.3  HighJump
3  video_validation_0000365     80.8   84.3  HighJump
[2K4  video_validation_0000365    110.4  116.2  HighJumpâ”â”â”â”â”â”â”[0m 203/203 [2m0:15:00 â€¢ 0:00:00[0m [2;4m0.17it/s[0m  
[2K                   video-id     t-start       t-end       score     label[2m0:15:00 â€¢ 0:00:00[0m [2;4m0.17it/s[0m  
0  video_validation_0000365   18.833333   37.700000   2.1725001  HighJump
1  video_validation_0000365   66.300000   88.866667    2.390969  HighJump
2  video_validation_0000365  111.500000  124.166667   2.0065112  HighJump
3  video_validation_0000365  137.700000  156.000000    1.885701  HighJump
[2K4  video_validation_0000365  156.733333  159.100000  0.76130694  HighJump[2m0:15:00 â€¢ 0:00:00[0m [2;4m0.17it/s[0m  
[2KGround truth labels:  ['HighJump' 'PoleVault' 'TennisSwing' 'GolfSwing' 'HammerThrow'â€¢ 0:00:00[0m [2;4m0.17it/s[0m  
[2K 'Billiards' 'BaseballPitch' 'CleanAndJerk' 'ThrowDiscus' 'SoccerPenalty'][2m0:15:00 â€¢ 0:00:00[0m [2;4m0.17it/s[0m  
[2KPredicted labels:  ['HighJump' 'HammerThrow' 'TennisSwing' 'GolfSwing' 'Billiards'00 â€¢ 0:00:00[0m [2;4m0.17it/s[0m  
[2K 'BaseballPitch' 'CleanAndJerk' 'PoleVault' 'ThrowDiscus' 'SoccerPenalty'][2m0:15:00 â€¢ 0:00:00[0m [2;4m0.17it/s[0m  
[2King [38;2;98;6;224mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 203/203 [2m0:15:00 â€¢ 0:00:00[0m [2;4m0.17it/s[0m  
[2King [38;2;98;6;224mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 203/203 [2m0:15:00 â€¢ 0:00:00[0m [2;4m0.17it/s[0m  
[2KBaseballPitch [13.0, 3.3, 1.3, 0.4, 0.3]â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 203/203 [2m0:15:00 â€¢ 0:00:00[0m [2;4m0.17it/s[0m  
[2King [38;2;98;6;224mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 203/203 [2m0:15:00 â€¢ 0:00:00[0m [2;4m0.17it/s[0m  
[2King [38;2;98;6;224mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 203/203 [2m0:15:00 â€¢ 0:00:00[0m [2;4m0.17it/s[0m  
[2KBilliards [6.5, 4.1, 1.5, 0.7, 0.1]â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 203/203 [2m0:15:00 â€¢ 0:00:00[0m [2;4m0.17it/s[0m  
[2King [38;2;98;6;224mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 203/203 [2m0:15:00 â€¢ 0:00:00[0m [2;4m0.17it/s[0m  
[2King [38;2;98;6;224mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 203/203 [2m0:15:00 â€¢ 0:00:00[0m [2;4m0.17it/s[0m  
[2KCleanAndJerk [37.2, 28.1, 17.2, 9.1, 5.0]â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 203/203 [2m0:15:00 â€¢ 0:00:00[0m [2;4m0.17it/s[0m  
[2King [38;2;98;6;224mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 203/203 [2m0:15:00 â€¢ 0:00:00[0m [2;4m0.17it/s[0m  
[2King [38;2;98;6;224mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 203/203 [2m0:15:00 â€¢ 0:00:00[0m [2;4m0.17it/s[0m  
[2KGolfSwing [19.4, 10.8, 6.3, 1.3, 0.9]â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 203/203 [2m0:15:00 â€¢ 0:00:00[0m [2;4m0.17it/s[0m  
[2King [38;2;98;6;224mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 203/203 [2m0:15:00 â€¢ 0:00:00[0m [2;4m0.17it/s[0m  
[2King [38;2;98;6;224mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 203/203 [2m0:15:00 â€¢ 0:00:00[0m [2;4m0.17it/s[0m  
[2KHammerThrow [21.1, 16.2, 12.1, 8.8, 6.4]â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 203/203 [2m0:15:00 â€¢ 0:00:00[0m [2;4m0.17it/s[0m  
[2King [38;2;98;6;224mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 203/203 [2m0:15:00 â€¢ 0:00:00[0m [2;4m0.17it/s[0m  
[2King [38;2;98;6;224mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 203/203 [2m0:15:00 â€¢ 0:00:00[0m [2;4m0.17it/s[0m  
[2KHighJump [13.0, 6.5, 3.3, 1.4, 0.9]â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 203/203 [2m0:15:00 â€¢ 0:00:00[0m [2;4m0.17it/s[0m  
[2King [38;2;98;6;224mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 203/203 [2m0:15:00 â€¢ 0:00:00[0m [2;4m0.17it/s[0m  
[2King [38;2;98;6;224mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 203/203 [2m0:15:00 â€¢ 0:00:00[0m [2;4m0.17it/s[0m  
[2KPoleVault [26.9, 23.6, 17.0, 12.0, 6.7]â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 203/203 [2m0:15:00 â€¢ 0:00:00[0m [2;4m0.17it/s[0m  
[2King [38;2;98;6;224mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 203/203 [2m0:15:00 â€¢ 0:00:00[0m [2;4m0.17it/s[0m  
[2King [38;2;98;6;224mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 203/203 [2m0:15:00 â€¢ 0:00:00[0m [2;4m0.17it/s[0m  
[2KSoccerPenalty [26.8, 12.5, 7.7, 3.1, 0.9]â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 203/203 [2m0:15:00 â€¢ 0:00:00[0m [2;4m0.17it/s[0m  
[2King [38;2;98;6;224mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 203/203 [2m0:15:00 â€¢ 0:00:00[0m [2;4m0.17it/s[0m  
[2King [38;2;98;6;224mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 203/203 [2m0:15:00 â€¢ 0:00:00[0m [2;4m0.17it/s[0m  
[2KTennisSwing [1.9, 0.7, 0.4, 0.2, 0.1]â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 203/203 [2m0:15:00 â€¢ 0:00:00[0m [2;4m0.17it/s[0m  
[2King [38;2;98;6;224mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 203/203 [2m0:15:00 â€¢ 0:00:00[0m [2;4m0.17it/s[0m  
[2King [38;2;98;6;224mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 203/203 [2m0:15:00 â€¢ 0:00:00[0m [2;4m0.17it/s[0m  
[2KThrowDiscus [3.4, 2.9, 0.8, 0.7, 0.0]â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 203/203 [2m0:15:00 â€¢ 0:00:00[0m [2;4m0.17it/s[0m  
[2King [38;2;98;6;224mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 203/203 [2m0:15:00 â€¢ 0:00:00[0m [2;4m0.17it/s[0m  
[2King [38;2;98;6;224mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 203/203 [2m0:15:00 â€¢ 0:00:00[0m [2;4m0.17it/s[0m  
[2K\begin{tabular}{lrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr}
\hline
 Class         &   AP@0% &   AP@0% &   AP@0% &   AP@0% &    AP@0% \\
\hline
 BaseballPitch &   13    &     3.3 &     1.3 &     0.4 & 0.3      \\
 Billiards     &    6.5  &     4.1 &     1.5 &     0.7 & 0.1      \\
 CleanAndJerk  &   37.2  &    28.1 &    17.2 &     9.1 & 5        \\
 GolfSwing     &   19.4  &    10.8 &     6.3 &     1.3 & 0.9      \\
 HammerThrow   &   21.1  &    16.2 &    12.1 &     8.8 & 6.4      \\
 HighJump      &   13    &     6.5 &     3.3 &     1.4 & 0.9      \\
 PoleVault     &   26.9  &    23.6 &    17   &    12   & 6.7      \\
 SoccerPenalty &   26.8  &    12.5 &     7.7 &     3.1 & 0.9      \\
 TennisSwing   &    1.9  &     0.7 &     0.4 &     0.2 & 0.1      \\
 ThrowDiscus   &    3.4  &     2.9 &     0.8 &     0.7 & 0        \\
 IoU           &    0.39 &     0   &     0   &     0   & 0.128238 \\
\hline
[2K\end{tabular};6;224mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 203/203 [2m0:15:00 â€¢ 0:00:00[0m [2;4m0.17it/s[0m  
[2K[16.92 10.87  6.76  3.77  2.13]â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 203/203 [2m0:15:00 â€¢ 0:00:00[0m [2;4m0.17it/s[0m  
[2KAverage TIOU:  0.009728995255912889â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 203/203 [2m0:15:00 â€¢ 0:00:00[0m [2;4m0.17it/s[0m  
[2Kpreds_tensor: torch.Size([203, 10])â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 203/203 [2m0:15:00 â€¢ 0:00:00[0m [2;4m0.17it/s[0m  
[2KTop-1 accuracy: 0.7536945812807881â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 203/203 [2m0:15:00 â€¢ 0:00:00[0m [2;4m0.17it/s[0m  
[2Kpreds_tensor: torch.Size([203, 10])â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 203/203 [2m0:15:00 â€¢ 0:00:00[0m [2;4m0.17it/s[0m  
[2KTop-3 accuracy: 0.9014778325123153â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 203/203 [2m0:15:00 â€¢ 0:00:00[0m [2;4m0.17it/s[0m  
[2Kpreds_tensor: torch.Size([203, 10])â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 203/203 [2m0:15:00 â€¢ 0:00:00[0m [2;4m0.17it/s[0m  
[2KTop-5 accuracy: 0.9655172413793104â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 203/203 [2m0:15:00 â€¢ 0:00:00[0m [2;4m0.17it/s[0m  
[2Kâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“â”â”â”[0m 203/203 [2m0:15:00 â€¢ 0:00:00[0m [2;4m0.17it/s[0m  
â”ƒ[1m [0m[1m       Test metric       [0m[1m [0mâ”ƒ[1m [0m[1m      DataLoader 0       [0m[1m [0mâ”ƒ
â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©
â”‚[36m [0m[36m          AP_0           [0m[36m [0mâ”‚[35m [0m[35m   16.920000076293945    [0m[35m [0mâ”‚
â”‚[36m [0m[36m         avg_AP          [0m[36m [0mâ”‚[35m [0m[35m    8.09000015258789     [0m[35m [0mâ”‚
â”‚[36m [0m[36m  label top-1 accuracy   [0m[36m [0mâ”‚[35m [0m[35m   0.7536945939064026    [0m[35m [0mâ”‚
â”‚[36m [0m[36m  label top-3 accuracy   [0m[36m [0mâ”‚[35m [0m[35m   0.9014778137207031    [0m[35m [0mâ”‚
â”‚[36m [0m[36m  label top-5 accuracy   [0m[36m [0mâ”‚[35m [0m[35m   0.9655172228813171    [0m[35m [0mâ”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
[2KTesting [38;2;98;6;224mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 203/203 [2m0:15:00 â€¢ 0:00:00[0m [2;4m0.17it/s[0m
[?25h[[36m2025-02-14 10:20:38,684[0m][[34m__main__[0m][[32mINFO[0m] - Best ckpt path: None[0m
[[36m2025-02-14 10:20:38,696[0m][[34msrc.utils.utils[0m][[32mINFO[0m] - Output dir: /home/def/fewshot/logs/train/runs/2025-02-14_10-05-08[0m
[[36m2025-02-14 10:20:38,696[0m][[34msrc.utils.utils[0m][[32mINFO[0m] - Closing wandb![0m
