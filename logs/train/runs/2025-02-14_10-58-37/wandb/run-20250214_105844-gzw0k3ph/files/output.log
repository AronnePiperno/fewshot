[[36m2025-02-14 10:58:45,622[0m][[34m__main__[0m][[32mINFO[0m] - Starting training![0m
You are using a CUDA device ('NVIDIA GeForce RTX 4070 SUPER') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision
No of videos in train is 214
Loading train Video Information ...
No of class 10
No of videos in validation is 203
Loading validation Video Information ...
No of class 10
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”“
â”ƒ[1;35m [0m[1;35m   [0m[1;35m [0mâ”ƒ[1;35m [0m[1;35mName                                                   [0m[1;35m [0mâ”ƒ[1;35m [0m[1;35mType                           [0m[1;35m [0mâ”ƒ[1;35m [0m[1;35mParams[0m[1;35m [0mâ”ƒ[1;35m [0m[1;35mMode [0m[1;35m [0mâ”ƒ
â”¡â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”©
â”‚[2m [0m[2m0  [0m[2m [0mâ”‚ net                                                     â”‚ T3ALNet                         â”‚  639 M â”‚ train â”‚
â”‚[2m [0m[2m1  [0m[2m [0mâ”‚ net.model                                               â”‚ CoCa                            â”‚  638 M â”‚ train â”‚
â”‚[2m [0m[2m2  [0m[2m [0mâ”‚ net.model.text                                          â”‚ TextTransformer                 â”‚  123 M â”‚ train â”‚
â”‚[2m [0m[2m3  [0m[2m [0mâ”‚ net.model.text.token_embedding                          â”‚ Embedding                       â”‚ 37.9 M â”‚ train â”‚
â”‚[2m [0m[2m4  [0m[2m [0mâ”‚ net.model.text.transformer                              â”‚ Transformer                     â”‚ 85.1 M â”‚ train â”‚
â”‚[2m [0m[2m5  [0m[2m [0mâ”‚ net.model.text.transformer.resblocks                    â”‚ ModuleList                      â”‚ 85.1 M â”‚ train â”‚
â”‚[2m [0m[2m6  [0m[2m [0mâ”‚ net.model.text.transformer.resblocks.0                  â”‚ ResidualAttentionBlock          â”‚  7.1 M â”‚ train â”‚
â”‚[2m [0m[2m7  [0m[2m [0mâ”‚ net.model.text.transformer.resblocks.0.ln_1             â”‚ LayerNorm                       â”‚  1.5 K â”‚ train â”‚
â”‚[2m [0m[2m8  [0m[2m [0mâ”‚ net.model.text.transformer.resblocks.0.attn             â”‚ MultiheadAttention              â”‚  2.4 M â”‚ train â”‚
â”‚[2m [0m[2m9  [0m[2m [0mâ”‚ net.model.text.transformer.resblocks.0.attn.out_proj    â”‚ NonDynamicallyQuantizableLinear â”‚  590 K â”‚ train â”‚
â”‚[2m [0m[2m10 [0m[2m [0mâ”‚ net.model.text.transformer.resblocks.0.ls_1             â”‚ Identity                        â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m11 [0m[2m [0mâ”‚ net.model.text.transformer.resblocks.0.ln_2             â”‚ LayerNorm                       â”‚  1.5 K â”‚ train â”‚
â”‚[2m [0m[2m12 [0m[2m [0mâ”‚ net.model.text.transformer.resblocks.0.mlp              â”‚ Sequential                      â”‚  4.7 M â”‚ train â”‚
â”‚[2m [0m[2m13 [0m[2m [0mâ”‚ net.model.text.transformer.resblocks.0.mlp.c_fc         â”‚ Linear                          â”‚  2.4 M â”‚ train â”‚
â”‚[2m [0m[2m14 [0m[2m [0mâ”‚ net.model.text.transformer.resblocks.0.mlp.gelu         â”‚ GELU                            â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m15 [0m[2m [0mâ”‚ net.model.text.transformer.resblocks.0.mlp.c_proj       â”‚ Linear                          â”‚  2.4 M â”‚ train â”‚
â”‚[2m [0m[2m16 [0m[2m [0mâ”‚ net.model.text.transformer.resblocks.0.ls_2             â”‚ Identity                        â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m17 [0m[2m [0mâ”‚ net.model.text.transformer.resblocks.1                  â”‚ ResidualAttentionBlock          â”‚  7.1 M â”‚ train â”‚
â”‚[2m [0m[2m18 [0m[2m [0mâ”‚ net.model.text.transformer.resblocks.1.ln_1             â”‚ LayerNorm                       â”‚  1.5 K â”‚ train â”‚
â”‚[2m [0m[2m19 [0m[2m [0mâ”‚ net.model.text.transformer.resblocks.1.attn             â”‚ MultiheadAttention              â”‚  2.4 M â”‚ train â”‚
â”‚[2m [0m[2m20 [0m[2m [0mâ”‚ net.model.text.transformer.resblocks.1.attn.out_proj    â”‚ NonDynamicallyQuantizableLinear â”‚  590 K â”‚ train â”‚
â”‚[2m [0m[2m21 [0m[2m [0mâ”‚ net.model.text.transformer.resblocks.1.ls_1             â”‚ Identity                        â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m22 [0m[2m [0mâ”‚ net.model.text.transformer.resblocks.1.ln_2             â”‚ LayerNorm                       â”‚  1.5 K â”‚ train â”‚
â”‚[2m [0m[2m23 [0m[2m [0mâ”‚ net.model.text.transformer.resblocks.1.mlp              â”‚ Sequential                      â”‚  4.7 M â”‚ train â”‚
â”‚[2m [0m[2m24 [0m[2m [0mâ”‚ net.model.text.transformer.resblocks.1.mlp.c_fc         â”‚ Linear                          â”‚  2.4 M â”‚ train â”‚
â”‚[2m [0m[2m25 [0m[2m [0mâ”‚ net.model.text.transformer.resblocks.1.mlp.gelu         â”‚ GELU                            â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m26 [0m[2m [0mâ”‚ net.model.text.transformer.resblocks.1.mlp.c_proj       â”‚ Linear                          â”‚  2.4 M â”‚ train â”‚
â”‚[2m [0m[2m27 [0m[2m [0mâ”‚ net.model.text.transformer.resblocks.1.ls_2             â”‚ Identity                        â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m28 [0m[2m [0mâ”‚ net.model.text.transformer.resblocks.2                  â”‚ ResidualAttentionBlock          â”‚  7.1 M â”‚ train â”‚
â”‚[2m [0m[2m29 [0m[2m [0mâ”‚ net.model.text.transformer.resblocks.2.ln_1             â”‚ LayerNorm                       â”‚  1.5 K â”‚ train â”‚
â”‚[2m [0m[2m30 [0m[2m [0mâ”‚ net.model.text.transformer.resblocks.2.attn             â”‚ MultiheadAttention              â”‚  2.4 M â”‚ train â”‚
â”‚[2m [0m[2m31 [0m[2m [0mâ”‚ net.model.text.transformer.resblocks.2.attn.out_proj    â”‚ NonDynamicallyQuantizableLinear â”‚  590 K â”‚ train â”‚
â”‚[2m [0m[2m32 [0m[2m [0mâ”‚ net.model.text.transformer.resblocks.2.ls_1             â”‚ Identity                        â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m33 [0m[2m [0mâ”‚ net.model.text.transformer.resblocks.2.ln_2             â”‚ LayerNorm                       â”‚  1.5 K â”‚ train â”‚
â”‚[2m [0m[2m34 [0m[2m [0mâ”‚ net.model.text.transformer.resblocks.2.mlp              â”‚ Sequential                      â”‚  4.7 M â”‚ train â”‚
â”‚[2m [0m[2m35 [0m[2m [0mâ”‚ net.model.text.transformer.resblocks.2.mlp.c_fc         â”‚ Linear                          â”‚  2.4 M â”‚ train â”‚
â”‚[2m [0m[2m36 [0m[2m [0mâ”‚ net.model.text.transformer.resblocks.2.mlp.gelu         â”‚ GELU                            â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m37 [0m[2m [0mâ”‚ net.model.text.transformer.resblocks.2.mlp.c_proj       â”‚ Linear                          â”‚  2.4 M â”‚ train â”‚
â”‚[2m [0m[2m38 [0m[2m [0mâ”‚ net.model.text.transformer.resblocks.2.ls_2             â”‚ Identity                        â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m39 [0m[2m [0mâ”‚ net.model.text.transformer.resblocks.3                  â”‚ ResidualAttentionBlock          â”‚  7.1 M â”‚ train â”‚
â”‚[2m [0m[2m40 [0m[2m [0mâ”‚ net.model.text.transformer.resblocks.3.ln_1             â”‚ LayerNorm                       â”‚  1.5 K â”‚ train â”‚
â”‚[2m [0m[2m41 [0m[2m [0mâ”‚ net.model.text.transformer.resblocks.3.attn             â”‚ MultiheadAttention              â”‚  2.4 M â”‚ train â”‚
â”‚[2m [0m[2m42 [0m[2m [0mâ”‚ net.model.text.transformer.resblocks.3.attn.out_proj    â”‚ NonDynamicallyQuantizableLinear â”‚  590 K â”‚ train â”‚
â”‚[2m [0m[2m43 [0m[2m [0mâ”‚ net.model.text.transformer.resblocks.3.ls_1             â”‚ Identity                        â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m44 [0m[2m [0mâ”‚ net.model.text.transformer.resblocks.3.ln_2             â”‚ LayerNorm                       â”‚  1.5 K â”‚ train â”‚
â”‚[2m [0m[2m45 [0m[2m [0mâ”‚ net.model.text.transformer.resblocks.3.mlp              â”‚ Sequential                      â”‚  4.7 M â”‚ train â”‚
â”‚[2m [0m[2m46 [0m[2m [0mâ”‚ net.model.text.transformer.resblocks.3.mlp.c_fc         â”‚ Linear                          â”‚  2.4 M â”‚ train â”‚
â”‚[2m [0m[2m47 [0m[2m [0mâ”‚ net.model.text.transformer.resblocks.3.mlp.gelu         â”‚ GELU                            â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m48 [0m[2m [0mâ”‚ net.model.text.transformer.resblocks.3.mlp.c_proj       â”‚ Linear                          â”‚  2.4 M â”‚ train â”‚
â”‚[2m [0m[2m49 [0m[2m [0mâ”‚ net.model.text.transformer.resblocks.3.ls_2             â”‚ Identity                        â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m50 [0m[2m [0mâ”‚ net.model.text.transformer.resblocks.4                  â”‚ ResidualAttentionBlock          â”‚  7.1 M â”‚ train â”‚
â”‚[2m [0m[2m51 [0m[2m [0mâ”‚ net.model.text.transformer.resblocks.4.ln_1             â”‚ LayerNorm                       â”‚  1.5 K â”‚ train â”‚
â”‚[2m [0m[2m52 [0m[2m [0mâ”‚ net.model.text.transformer.resblocks.4.attn             â”‚ MultiheadAttention              â”‚  2.4 M â”‚ train â”‚
â”‚[2m [0m[2m53 [0m[2m [0mâ”‚ net.model.text.transformer.resblocks.4.attn.out_proj    â”‚ NonDynamicallyQuantizableLinear â”‚  590 K â”‚ train â”‚
â”‚[2m [0m[2m54 [0m[2m [0mâ”‚ net.model.text.transformer.resblocks.4.ls_1             â”‚ Identity                        â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m55 [0m[2m [0mâ”‚ net.model.text.transformer.resblocks.4.ln_2             â”‚ LayerNorm                       â”‚  1.5 K â”‚ train â”‚
â”‚[2m [0m[2m56 [0m[2m [0mâ”‚ net.model.text.transformer.resblocks.4.mlp              â”‚ Sequential                      â”‚  4.7 M â”‚ train â”‚
â”‚[2m [0m[2m57 [0m[2m [0mâ”‚ net.model.text.transformer.resblocks.4.mlp.c_fc         â”‚ Linear                          â”‚  2.4 M â”‚ train â”‚
â”‚[2m [0m[2m58 [0m[2m [0mâ”‚ net.model.text.transformer.resblocks.4.mlp.gelu         â”‚ GELU                            â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m59 [0m[2m [0mâ”‚ net.model.text.transformer.resblocks.4.mlp.c_proj       â”‚ Linear                          â”‚  2.4 M â”‚ train â”‚
â”‚[2m [0m[2m60 [0m[2m [0mâ”‚ net.model.text.transformer.resblocks.4.ls_2             â”‚ Identity                        â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m61 [0m[2m [0mâ”‚ net.model.text.transformer.resblocks.5                  â”‚ ResidualAttentionBlock          â”‚  7.1 M â”‚ train â”‚
â”‚[2m [0m[2m62 [0m[2m [0mâ”‚ net.model.text.transformer.resblocks.5.ln_1             â”‚ LayerNorm                       â”‚  1.5 K â”‚ train â”‚
â”‚[2m [0m[2m63 [0m[2m [0mâ”‚ net.model.text.transformer.resblocks.5.attn             â”‚ MultiheadAttention              â”‚  2.4 M â”‚ train â”‚
â”‚[2m [0m[2m64 [0m[2m [0mâ”‚ net.model.text.transformer.resblocks.5.attn.out_proj    â”‚ NonDynamicallyQuantizableLinear â”‚  590 K â”‚ train â”‚
â”‚[2m [0m[2m65 [0m[2m [0mâ”‚ net.model.text.transformer.resblocks.5.ls_1             â”‚ Identity                        â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m66 [0m[2m [0mâ”‚ net.model.text.transformer.resblocks.5.ln_2             â”‚ LayerNorm                       â”‚  1.5 K â”‚ train â”‚
â”‚[2m [0m[2m67 [0m[2m [0mâ”‚ net.model.text.transformer.resblocks.5.mlp              â”‚ Sequential                      â”‚  4.7 M â”‚ train â”‚
â”‚[2m [0m[2m68 [0m[2m [0mâ”‚ net.model.text.transformer.resblocks.5.mlp.c_fc         â”‚ Linear                          â”‚  2.4 M â”‚ train â”‚
â”‚[2m [0m[2m69 [0m[2m [0mâ”‚ net.model.text.transformer.resblocks.5.mlp.gelu         â”‚ GELU                            â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m70 [0m[2m [0mâ”‚ net.model.text.transformer.resblocks.5.mlp.c_proj       â”‚ Linear                          â”‚  2.4 M â”‚ train â”‚
â”‚[2m [0m[2m71 [0m[2m [0mâ”‚ net.model.text.transformer.resblocks.5.ls_2             â”‚ Identity                        â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m72 [0m[2m [0mâ”‚ net.model.text.transformer.resblocks.6                  â”‚ ResidualAttentionBlock          â”‚  7.1 M â”‚ train â”‚
â”‚[2m [0m[2m73 [0m[2m [0mâ”‚ net.model.text.transformer.resblocks.6.ln_1             â”‚ LayerNorm                       â”‚  1.5 K â”‚ train â”‚
â”‚[2m [0m[2m74 [0m[2m [0mâ”‚ net.model.text.transformer.resblocks.6.attn             â”‚ MultiheadAttention              â”‚  2.4 M â”‚ train â”‚
â”‚[2m [0m[2m75 [0m[2m [0mâ”‚ net.model.text.transformer.resblocks.6.attn.out_proj    â”‚ NonDynamicallyQuantizableLinear â”‚  590 K â”‚ train â”‚
â”‚[2m [0m[2m76 [0m[2m [0mâ”‚ net.model.text.transformer.resblocks.6.ls_1             â”‚ Identity                        â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m77 [0m[2m [0mâ”‚ net.model.text.transformer.resblocks.6.ln_2             â”‚ LayerNorm                       â”‚  1.5 K â”‚ train â”‚
â”‚[2m [0m[2m78 [0m[2m [0mâ”‚ net.model.text.transformer.resblocks.6.mlp              â”‚ Sequential                      â”‚  4.7 M â”‚ train â”‚
â”‚[2m [0m[2m79 [0m[2m [0mâ”‚ net.model.text.transformer.resblocks.6.mlp.c_fc         â”‚ Linear                          â”‚  2.4 M â”‚ train â”‚
â”‚[2m [0m[2m80 [0m[2m [0mâ”‚ net.model.text.transformer.resblocks.6.mlp.gelu         â”‚ GELU                            â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m81 [0m[2m [0mâ”‚ net.model.text.transformer.resblocks.6.mlp.c_proj       â”‚ Linear                          â”‚  2.4 M â”‚ train â”‚
â”‚[2m [0m[2m82 [0m[2m [0mâ”‚ net.model.text.transformer.resblocks.6.ls_2             â”‚ Identity                        â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m83 [0m[2m [0mâ”‚ net.model.text.transformer.resblocks.7                  â”‚ ResidualAttentionBlock          â”‚  7.1 M â”‚ train â”‚
â”‚[2m [0m[2m84 [0m[2m [0mâ”‚ net.model.text.transformer.resblocks.7.ln_1             â”‚ LayerNorm                       â”‚  1.5 K â”‚ train â”‚
â”‚[2m [0m[2m85 [0m[2m [0mâ”‚ net.model.text.transformer.resblocks.7.attn             â”‚ MultiheadAttention              â”‚  2.4 M â”‚ train â”‚
â”‚[2m [0m[2m86 [0m[2m [0mâ”‚ net.model.text.transformer.resblocks.7.attn.out_proj    â”‚ NonDynamicallyQuantizableLinear â”‚  590 K â”‚ train â”‚
â”‚[2m [0m[2m87 [0m[2m [0mâ”‚ net.model.text.transformer.resblocks.7.ls_1             â”‚ Identity                        â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m88 [0m[2m [0mâ”‚ net.model.text.transformer.resblocks.7.ln_2             â”‚ LayerNorm                       â”‚  1.5 K â”‚ train â”‚
â”‚[2m [0m[2m89 [0m[2m [0mâ”‚ net.model.text.transformer.resblocks.7.mlp              â”‚ Sequential                      â”‚  4.7 M â”‚ train â”‚
â”‚[2m [0m[2m90 [0m[2m [0mâ”‚ net.model.text.transformer.resblocks.7.mlp.c_fc         â”‚ Linear                          â”‚  2.4 M â”‚ train â”‚
â”‚[2m [0m[2m91 [0m[2m [0mâ”‚ net.model.text.transformer.resblocks.7.mlp.gelu         â”‚ GELU                            â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m92 [0m[2m [0mâ”‚ net.model.text.transformer.resblocks.7.mlp.c_proj       â”‚ Linear                          â”‚  2.4 M â”‚ train â”‚
â”‚[2m [0m[2m93 [0m[2m [0mâ”‚ net.model.text.transformer.resblocks.7.ls_2             â”‚ Identity                        â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m94 [0m[2m [0mâ”‚ net.model.text.transformer.resblocks.8                  â”‚ ResidualAttentionBlock          â”‚  7.1 M â”‚ train â”‚
â”‚[2m [0m[2m95 [0m[2m [0mâ”‚ net.model.text.transformer.resblocks.8.ln_1             â”‚ LayerNorm                       â”‚  1.5 K â”‚ train â”‚
â”‚[2m [0m[2m96 [0m[2m [0mâ”‚ net.model.text.transformer.resblocks.8.attn             â”‚ MultiheadAttention              â”‚  2.4 M â”‚ train â”‚
â”‚[2m [0m[2m97 [0m[2m [0mâ”‚ net.model.text.transformer.resblocks.8.attn.out_proj    â”‚ NonDynamicallyQuantizableLinear â”‚  590 K â”‚ train â”‚
â”‚[2m [0m[2m98 [0m[2m [0mâ”‚ net.model.text.transformer.resblocks.8.ls_1             â”‚ Identity                        â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m99 [0m[2m [0mâ”‚ net.model.text.transformer.resblocks.8.ln_2             â”‚ LayerNorm                       â”‚  1.5 K â”‚ train â”‚
â”‚[2m [0m[2m100[0m[2m [0mâ”‚ net.model.text.transformer.resblocks.8.mlp              â”‚ Sequential                      â”‚  4.7 M â”‚ train â”‚
â”‚[2m [0m[2m101[0m[2m [0mâ”‚ net.model.text.transformer.resblocks.8.mlp.c_fc         â”‚ Linear                          â”‚  2.4 M â”‚ train â”‚
â”‚[2m [0m[2m102[0m[2m [0mâ”‚ net.model.text.transformer.resblocks.8.mlp.gelu         â”‚ GELU                            â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m103[0m[2m [0mâ”‚ net.model.text.transformer.resblocks.8.mlp.c_proj       â”‚ Linear                          â”‚  2.4 M â”‚ train â”‚
â”‚[2m [0m[2m104[0m[2m [0mâ”‚ net.model.text.transformer.resblocks.8.ls_2             â”‚ Identity                        â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m105[0m[2m [0mâ”‚ net.model.text.transformer.resblocks.9                  â”‚ ResidualAttentionBlock          â”‚  7.1 M â”‚ train â”‚
â”‚[2m [0m[2m106[0m[2m [0mâ”‚ net.model.text.transformer.resblocks.9.ln_1             â”‚ LayerNorm                       â”‚  1.5 K â”‚ train â”‚
â”‚[2m [0m[2m107[0m[2m [0mâ”‚ net.model.text.transformer.resblocks.9.attn             â”‚ MultiheadAttention              â”‚  2.4 M â”‚ train â”‚
â”‚[2m [0m[2m108[0m[2m [0mâ”‚ net.model.text.transformer.resblocks.9.attn.out_proj    â”‚ NonDynamicallyQuantizableLinear â”‚  590 K â”‚ train â”‚
â”‚[2m [0m[2m109[0m[2m [0mâ”‚ net.model.text.transformer.resblocks.9.ls_1             â”‚ Identity                        â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m110[0m[2m [0mâ”‚ net.model.text.transformer.resblocks.9.ln_2             â”‚ LayerNorm                       â”‚  1.5 K â”‚ train â”‚
â”‚[2m [0m[2m111[0m[2m [0mâ”‚ net.model.text.transformer.resblocks.9.mlp              â”‚ Sequential                      â”‚  4.7 M â”‚ train â”‚
â”‚[2m [0m[2m112[0m[2m [0mâ”‚ net.model.text.transformer.resblocks.9.mlp.c_fc         â”‚ Linear                          â”‚  2.4 M â”‚ train â”‚
â”‚[2m [0m[2m113[0m[2m [0mâ”‚ net.model.text.transformer.resblocks.9.mlp.gelu         â”‚ GELU                            â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m114[0m[2m [0mâ”‚ net.model.text.transformer.resblocks.9.mlp.c_proj       â”‚ Linear                          â”‚  2.4 M â”‚ train â”‚
â”‚[2m [0m[2m115[0m[2m [0mâ”‚ net.model.text.transformer.resblocks.9.ls_2             â”‚ Identity                        â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m116[0m[2m [0mâ”‚ net.model.text.transformer.resblocks.10                 â”‚ ResidualAttentionBlock          â”‚  7.1 M â”‚ train â”‚
â”‚[2m [0m[2m117[0m[2m [0mâ”‚ net.model.text.transformer.resblocks.10.ln_1            â”‚ LayerNorm                       â”‚  1.5 K â”‚ train â”‚
â”‚[2m [0m[2m118[0m[2m [0mâ”‚ net.model.text.transformer.resblocks.10.attn            â”‚ MultiheadAttention              â”‚  2.4 M â”‚ train â”‚
â”‚[2m [0m[2m119[0m[2m [0mâ”‚ net.model.text.transformer.resblocks.10.attn.out_proj   â”‚ NonDynamicallyQuantizableLinear â”‚  590 K â”‚ train â”‚
â”‚[2m [0m[2m120[0m[2m [0mâ”‚ net.model.text.transformer.resblocks.10.ls_1            â”‚ Identity                        â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m121[0m[2m [0mâ”‚ net.model.text.transformer.resblocks.10.ln_2            â”‚ LayerNorm                       â”‚  1.5 K â”‚ train â”‚
â”‚[2m [0m[2m122[0m[2m [0mâ”‚ net.model.text.transformer.resblocks.10.mlp             â”‚ Sequential                      â”‚  4.7 M â”‚ train â”‚
â”‚[2m [0m[2m123[0m[2m [0mâ”‚ net.model.text.transformer.resblocks.10.mlp.c_fc        â”‚ Linear                          â”‚  2.4 M â”‚ train â”‚
â”‚[2m [0m[2m124[0m[2m [0mâ”‚ net.model.text.transformer.resblocks.10.mlp.gelu        â”‚ GELU                            â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m125[0m[2m [0mâ”‚ net.model.text.transformer.resblocks.10.mlp.c_proj      â”‚ Linear                          â”‚  2.4 M â”‚ train â”‚
â”‚[2m [0m[2m126[0m[2m [0mâ”‚ net.model.text.transformer.resblocks.10.ls_2            â”‚ Identity                        â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m127[0m[2m [0mâ”‚ net.model.text.transformer.resblocks.11                 â”‚ ResidualAttentionBlock          â”‚  7.1 M â”‚ train â”‚
â”‚[2m [0m[2m128[0m[2m [0mâ”‚ net.model.text.transformer.resblocks.11.ln_1            â”‚ LayerNorm                       â”‚  1.5 K â”‚ train â”‚
â”‚[2m [0m[2m129[0m[2m [0mâ”‚ net.model.text.transformer.resblocks.11.attn            â”‚ MultiheadAttention              â”‚  2.4 M â”‚ train â”‚
â”‚[2m [0m[2m130[0m[2m [0mâ”‚ net.model.text.transformer.resblocks.11.attn.out_proj   â”‚ NonDynamicallyQuantizableLinear â”‚  590 K â”‚ train â”‚
â”‚[2m [0m[2m131[0m[2m [0mâ”‚ net.model.text.transformer.resblocks.11.ls_1            â”‚ Identity                        â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m132[0m[2m [0mâ”‚ net.model.text.transformer.resblocks.11.ln_2            â”‚ LayerNorm                       â”‚  1.5 K â”‚ train â”‚
â”‚[2m [0m[2m133[0m[2m [0mâ”‚ net.model.text.transformer.resblocks.11.mlp             â”‚ Sequential                      â”‚  4.7 M â”‚ train â”‚
â”‚[2m [0m[2m134[0m[2m [0mâ”‚ net.model.text.transformer.resblocks.11.mlp.c_fc        â”‚ Linear                          â”‚  2.4 M â”‚ train â”‚
â”‚[2m [0m[2m135[0m[2m [0mâ”‚ net.model.text.transformer.resblocks.11.mlp.gelu        â”‚ GELU                            â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m136[0m[2m [0mâ”‚ net.model.text.transformer.resblocks.11.mlp.c_proj      â”‚ Linear                          â”‚  2.4 M â”‚ train â”‚
â”‚[2m [0m[2m137[0m[2m [0mâ”‚ net.model.text.transformer.resblocks.11.ls_2            â”‚ Identity                        â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m138[0m[2m [0mâ”‚ net.model.text.ln_final                                 â”‚ LayerNorm                       â”‚  1.5 K â”‚ train â”‚
â”‚[2m [0m[2m139[0m[2m [0mâ”‚ net.model.visual                                        â”‚ VisionTransformer               â”‚  306 M â”‚ train â”‚
â”‚[2m [0m[2m140[0m[2m [0mâ”‚ net.model.visual.conv1                                  â”‚ Conv2d                          â”‚  602 K â”‚ train â”‚
â”‚[2m [0m[2m141[0m[2m [0mâ”‚ net.model.visual.patch_dropout                          â”‚ Identity                        â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m142[0m[2m [0mâ”‚ net.model.visual.ln_pre                                 â”‚ LayerNorm                       â”‚  2.0 K â”‚ train â”‚
â”‚[2m [0m[2m143[0m[2m [0mâ”‚ net.model.visual.transformer                            â”‚ Transformer                     â”‚  302 M â”‚ train â”‚
â”‚[2m [0m[2m144[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks                  â”‚ ModuleList                      â”‚  302 M â”‚ train â”‚
â”‚[2m [0m[2m145[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.0                â”‚ ResidualAttentionBlock          â”‚ 12.6 M â”‚ train â”‚
â”‚[2m [0m[2m146[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.0.ln_1           â”‚ LayerNorm                       â”‚  2.0 K â”‚ train â”‚
â”‚[2m [0m[2m147[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.0.attn           â”‚ MultiheadAttention              â”‚  4.2 M â”‚ train â”‚
â”‚[2m [0m[2m148[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.0.attn.out_proj  â”‚ NonDynamicallyQuantizableLinear â”‚  1.0 M â”‚ train â”‚
â”‚[2m [0m[2m149[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.0.ls_1           â”‚ Identity                        â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m150[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.0.ln_2           â”‚ LayerNorm                       â”‚  2.0 K â”‚ train â”‚
â”‚[2m [0m[2m151[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.0.mlp            â”‚ Sequential                      â”‚  8.4 M â”‚ train â”‚
â”‚[2m [0m[2m152[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.0.mlp.c_fc       â”‚ Linear                          â”‚  4.2 M â”‚ train â”‚
â”‚[2m [0m[2m153[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.0.mlp.gelu       â”‚ GELU                            â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m154[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.0.mlp.c_proj     â”‚ Linear                          â”‚  4.2 M â”‚ train â”‚
â”‚[2m [0m[2m155[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.0.ls_2           â”‚ Identity                        â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m156[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.1                â”‚ ResidualAttentionBlock          â”‚ 12.6 M â”‚ train â”‚
â”‚[2m [0m[2m157[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.1.ln_1           â”‚ LayerNorm                       â”‚  2.0 K â”‚ train â”‚
â”‚[2m [0m[2m158[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.1.attn           â”‚ MultiheadAttention              â”‚  4.2 M â”‚ train â”‚
â”‚[2m [0m[2m159[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.1.attn.out_proj  â”‚ NonDynamicallyQuantizableLinear â”‚  1.0 M â”‚ train â”‚
â”‚[2m [0m[2m160[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.1.ls_1           â”‚ Identity                        â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m161[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.1.ln_2           â”‚ LayerNorm                       â”‚  2.0 K â”‚ train â”‚
â”‚[2m [0m[2m162[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.1.mlp            â”‚ Sequential                      â”‚  8.4 M â”‚ train â”‚
â”‚[2m [0m[2m163[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.1.mlp.c_fc       â”‚ Linear                          â”‚  4.2 M â”‚ train â”‚
â”‚[2m [0m[2m164[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.1.mlp.gelu       â”‚ GELU                            â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m165[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.1.mlp.c_proj     â”‚ Linear                          â”‚  4.2 M â”‚ train â”‚
â”‚[2m [0m[2m166[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.1.ls_2           â”‚ Identity                        â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m167[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.2                â”‚ ResidualAttentionBlock          â”‚ 12.6 M â”‚ train â”‚
â”‚[2m [0m[2m168[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.2.ln_1           â”‚ LayerNorm                       â”‚  2.0 K â”‚ train â”‚
â”‚[2m [0m[2m169[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.2.attn           â”‚ MultiheadAttention              â”‚  4.2 M â”‚ train â”‚
â”‚[2m [0m[2m170[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.2.attn.out_proj  â”‚ NonDynamicallyQuantizableLinear â”‚  1.0 M â”‚ train â”‚
â”‚[2m [0m[2m171[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.2.ls_1           â”‚ Identity                        â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m172[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.2.ln_2           â”‚ LayerNorm                       â”‚  2.0 K â”‚ train â”‚
â”‚[2m [0m[2m173[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.2.mlp            â”‚ Sequential                      â”‚  8.4 M â”‚ train â”‚
â”‚[2m [0m[2m174[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.2.mlp.c_fc       â”‚ Linear                          â”‚  4.2 M â”‚ train â”‚
â”‚[2m [0m[2m175[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.2.mlp.gelu       â”‚ GELU                            â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m176[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.2.mlp.c_proj     â”‚ Linear                          â”‚  4.2 M â”‚ train â”‚
â”‚[2m [0m[2m177[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.2.ls_2           â”‚ Identity                        â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m178[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.3                â”‚ ResidualAttentionBlock          â”‚ 12.6 M â”‚ train â”‚
â”‚[2m [0m[2m179[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.3.ln_1           â”‚ LayerNorm                       â”‚  2.0 K â”‚ train â”‚
â”‚[2m [0m[2m180[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.3.attn           â”‚ MultiheadAttention              â”‚  4.2 M â”‚ train â”‚
â”‚[2m [0m[2m181[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.3.attn.out_proj  â”‚ NonDynamicallyQuantizableLinear â”‚  1.0 M â”‚ train â”‚
â”‚[2m [0m[2m182[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.3.ls_1           â”‚ Identity                        â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m183[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.3.ln_2           â”‚ LayerNorm                       â”‚  2.0 K â”‚ train â”‚
â”‚[2m [0m[2m184[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.3.mlp            â”‚ Sequential                      â”‚  8.4 M â”‚ train â”‚
â”‚[2m [0m[2m185[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.3.mlp.c_fc       â”‚ Linear                          â”‚  4.2 M â”‚ train â”‚
â”‚[2m [0m[2m186[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.3.mlp.gelu       â”‚ GELU                            â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m187[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.3.mlp.c_proj     â”‚ Linear                          â”‚  4.2 M â”‚ train â”‚
â”‚[2m [0m[2m188[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.3.ls_2           â”‚ Identity                        â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m189[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.4                â”‚ ResidualAttentionBlock          â”‚ 12.6 M â”‚ train â”‚
â”‚[2m [0m[2m190[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.4.ln_1           â”‚ LayerNorm                       â”‚  2.0 K â”‚ train â”‚
â”‚[2m [0m[2m191[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.4.attn           â”‚ MultiheadAttention              â”‚  4.2 M â”‚ train â”‚
â”‚[2m [0m[2m192[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.4.attn.out_proj  â”‚ NonDynamicallyQuantizableLinear â”‚  1.0 M â”‚ train â”‚
â”‚[2m [0m[2m193[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.4.ls_1           â”‚ Identity                        â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m194[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.4.ln_2           â”‚ LayerNorm                       â”‚  2.0 K â”‚ train â”‚
â”‚[2m [0m[2m195[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.4.mlp            â”‚ Sequential                      â”‚  8.4 M â”‚ train â”‚
â”‚[2m [0m[2m196[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.4.mlp.c_fc       â”‚ Linear                          â”‚  4.2 M â”‚ train â”‚
â”‚[2m [0m[2m197[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.4.mlp.gelu       â”‚ GELU                            â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m198[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.4.mlp.c_proj     â”‚ Linear                          â”‚  4.2 M â”‚ train â”‚
â”‚[2m [0m[2m199[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.4.ls_2           â”‚ Identity                        â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m200[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.5                â”‚ ResidualAttentionBlock          â”‚ 12.6 M â”‚ train â”‚
â”‚[2m [0m[2m201[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.5.ln_1           â”‚ LayerNorm                       â”‚  2.0 K â”‚ train â”‚
â”‚[2m [0m[2m202[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.5.attn           â”‚ MultiheadAttention              â”‚  4.2 M â”‚ train â”‚
â”‚[2m [0m[2m203[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.5.attn.out_proj  â”‚ NonDynamicallyQuantizableLinear â”‚  1.0 M â”‚ train â”‚
â”‚[2m [0m[2m204[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.5.ls_1           â”‚ Identity                        â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m205[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.5.ln_2           â”‚ LayerNorm                       â”‚  2.0 K â”‚ train â”‚
â”‚[2m [0m[2m206[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.5.mlp            â”‚ Sequential                      â”‚  8.4 M â”‚ train â”‚
â”‚[2m [0m[2m207[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.5.mlp.c_fc       â”‚ Linear                          â”‚  4.2 M â”‚ train â”‚
â”‚[2m [0m[2m208[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.5.mlp.gelu       â”‚ GELU                            â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m209[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.5.mlp.c_proj     â”‚ Linear                          â”‚  4.2 M â”‚ train â”‚
â”‚[2m [0m[2m210[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.5.ls_2           â”‚ Identity                        â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m211[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.6                â”‚ ResidualAttentionBlock          â”‚ 12.6 M â”‚ train â”‚
â”‚[2m [0m[2m212[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.6.ln_1           â”‚ LayerNorm                       â”‚  2.0 K â”‚ train â”‚
â”‚[2m [0m[2m213[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.6.attn           â”‚ MultiheadAttention              â”‚  4.2 M â”‚ train â”‚
â”‚[2m [0m[2m214[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.6.attn.out_proj  â”‚ NonDynamicallyQuantizableLinear â”‚  1.0 M â”‚ train â”‚
â”‚[2m [0m[2m215[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.6.ls_1           â”‚ Identity                        â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m216[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.6.ln_2           â”‚ LayerNorm                       â”‚  2.0 K â”‚ train â”‚
â”‚[2m [0m[2m217[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.6.mlp            â”‚ Sequential                      â”‚  8.4 M â”‚ train â”‚
â”‚[2m [0m[2m218[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.6.mlp.c_fc       â”‚ Linear                          â”‚  4.2 M â”‚ train â”‚
â”‚[2m [0m[2m219[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.6.mlp.gelu       â”‚ GELU                            â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m220[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.6.mlp.c_proj     â”‚ Linear                          â”‚  4.2 M â”‚ train â”‚
â”‚[2m [0m[2m221[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.6.ls_2           â”‚ Identity                        â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m222[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.7                â”‚ ResidualAttentionBlock          â”‚ 12.6 M â”‚ train â”‚
â”‚[2m [0m[2m223[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.7.ln_1           â”‚ LayerNorm                       â”‚  2.0 K â”‚ train â”‚
â”‚[2m [0m[2m224[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.7.attn           â”‚ MultiheadAttention              â”‚  4.2 M â”‚ train â”‚
â”‚[2m [0m[2m225[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.7.attn.out_proj  â”‚ NonDynamicallyQuantizableLinear â”‚  1.0 M â”‚ train â”‚
â”‚[2m [0m[2m226[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.7.ls_1           â”‚ Identity                        â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m227[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.7.ln_2           â”‚ LayerNorm                       â”‚  2.0 K â”‚ train â”‚
â”‚[2m [0m[2m228[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.7.mlp            â”‚ Sequential                      â”‚  8.4 M â”‚ train â”‚
â”‚[2m [0m[2m229[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.7.mlp.c_fc       â”‚ Linear                          â”‚  4.2 M â”‚ train â”‚
â”‚[2m [0m[2m230[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.7.mlp.gelu       â”‚ GELU                            â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m231[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.7.mlp.c_proj     â”‚ Linear                          â”‚  4.2 M â”‚ train â”‚
â”‚[2m [0m[2m232[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.7.ls_2           â”‚ Identity                        â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m233[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.8                â”‚ ResidualAttentionBlock          â”‚ 12.6 M â”‚ train â”‚
â”‚[2m [0m[2m234[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.8.ln_1           â”‚ LayerNorm                       â”‚  2.0 K â”‚ train â”‚
â”‚[2m [0m[2m235[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.8.attn           â”‚ MultiheadAttention              â”‚  4.2 M â”‚ train â”‚
â”‚[2m [0m[2m236[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.8.attn.out_proj  â”‚ NonDynamicallyQuantizableLinear â”‚  1.0 M â”‚ train â”‚
â”‚[2m [0m[2m237[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.8.ls_1           â”‚ Identity                        â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m238[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.8.ln_2           â”‚ LayerNorm                       â”‚  2.0 K â”‚ train â”‚
â”‚[2m [0m[2m239[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.8.mlp            â”‚ Sequential                      â”‚  8.4 M â”‚ train â”‚
â”‚[2m [0m[2m240[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.8.mlp.c_fc       â”‚ Linear                          â”‚  4.2 M â”‚ train â”‚
â”‚[2m [0m[2m241[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.8.mlp.gelu       â”‚ GELU                            â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m242[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.8.mlp.c_proj     â”‚ Linear                          â”‚  4.2 M â”‚ train â”‚
â”‚[2m [0m[2m243[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.8.ls_2           â”‚ Identity                        â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m244[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.9                â”‚ ResidualAttentionBlock          â”‚ 12.6 M â”‚ train â”‚
â”‚[2m [0m[2m245[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.9.ln_1           â”‚ LayerNorm                       â”‚  2.0 K â”‚ train â”‚
â”‚[2m [0m[2m246[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.9.attn           â”‚ MultiheadAttention              â”‚  4.2 M â”‚ train â”‚
â”‚[2m [0m[2m247[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.9.attn.out_proj  â”‚ NonDynamicallyQuantizableLinear â”‚  1.0 M â”‚ train â”‚
â”‚[2m [0m[2m248[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.9.ls_1           â”‚ Identity                        â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m249[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.9.ln_2           â”‚ LayerNorm                       â”‚  2.0 K â”‚ train â”‚
â”‚[2m [0m[2m250[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.9.mlp            â”‚ Sequential                      â”‚  8.4 M â”‚ train â”‚
â”‚[2m [0m[2m251[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.9.mlp.c_fc       â”‚ Linear                          â”‚  4.2 M â”‚ train â”‚
â”‚[2m [0m[2m252[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.9.mlp.gelu       â”‚ GELU                            â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m253[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.9.mlp.c_proj     â”‚ Linear                          â”‚  4.2 M â”‚ train â”‚
â”‚[2m [0m[2m254[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.9.ls_2           â”‚ Identity                        â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m255[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.10               â”‚ ResidualAttentionBlock          â”‚ 12.6 M â”‚ train â”‚
â”‚[2m [0m[2m256[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.10.ln_1          â”‚ LayerNorm                       â”‚  2.0 K â”‚ train â”‚
â”‚[2m [0m[2m257[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.10.attn          â”‚ MultiheadAttention              â”‚  4.2 M â”‚ train â”‚
â”‚[2m [0m[2m258[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.10.attn.out_proj â”‚ NonDynamicallyQuantizableLinear â”‚  1.0 M â”‚ train â”‚
â”‚[2m [0m[2m259[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.10.ls_1          â”‚ Identity                        â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m260[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.10.ln_2          â”‚ LayerNorm                       â”‚  2.0 K â”‚ train â”‚
â”‚[2m [0m[2m261[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.10.mlp           â”‚ Sequential                      â”‚  8.4 M â”‚ train â”‚
â”‚[2m [0m[2m262[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.10.mlp.c_fc      â”‚ Linear                          â”‚  4.2 M â”‚ train â”‚
â”‚[2m [0m[2m263[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.10.mlp.gelu      â”‚ GELU                            â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m264[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.10.mlp.c_proj    â”‚ Linear                          â”‚  4.2 M â”‚ train â”‚
â”‚[2m [0m[2m265[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.10.ls_2          â”‚ Identity                        â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m266[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.11               â”‚ ResidualAttentionBlock          â”‚ 12.6 M â”‚ train â”‚
â”‚[2m [0m[2m267[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.11.ln_1          â”‚ LayerNorm                       â”‚  2.0 K â”‚ train â”‚
â”‚[2m [0m[2m268[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.11.attn          â”‚ MultiheadAttention              â”‚  4.2 M â”‚ train â”‚
â”‚[2m [0m[2m269[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.11.attn.out_proj â”‚ NonDynamicallyQuantizableLinear â”‚  1.0 M â”‚ train â”‚
â”‚[2m [0m[2m270[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.11.ls_1          â”‚ Identity                        â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m271[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.11.ln_2          â”‚ LayerNorm                       â”‚  2.0 K â”‚ train â”‚
â”‚[2m [0m[2m272[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.11.mlp           â”‚ Sequential                      â”‚  8.4 M â”‚ train â”‚
â”‚[2m [0m[2m273[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.11.mlp.c_fc      â”‚ Linear                          â”‚  4.2 M â”‚ train â”‚
â”‚[2m [0m[2m274[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.11.mlp.gelu      â”‚ GELU                            â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m275[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.11.mlp.c_proj    â”‚ Linear                          â”‚  4.2 M â”‚ train â”‚
â”‚[2m [0m[2m276[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.11.ls_2          â”‚ Identity                        â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m277[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.12               â”‚ ResidualAttentionBlock          â”‚ 12.6 M â”‚ train â”‚
â”‚[2m [0m[2m278[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.12.ln_1          â”‚ LayerNorm                       â”‚  2.0 K â”‚ train â”‚
â”‚[2m [0m[2m279[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.12.attn          â”‚ MultiheadAttention              â”‚  4.2 M â”‚ train â”‚
â”‚[2m [0m[2m280[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.12.attn.out_proj â”‚ NonDynamicallyQuantizableLinear â”‚  1.0 M â”‚ train â”‚
â”‚[2m [0m[2m281[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.12.ls_1          â”‚ Identity                        â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m282[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.12.ln_2          â”‚ LayerNorm                       â”‚  2.0 K â”‚ train â”‚
â”‚[2m [0m[2m283[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.12.mlp           â”‚ Sequential                      â”‚  8.4 M â”‚ train â”‚
â”‚[2m [0m[2m284[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.12.mlp.c_fc      â”‚ Linear                          â”‚  4.2 M â”‚ train â”‚
â”‚[2m [0m[2m285[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.12.mlp.gelu      â”‚ GELU                            â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m286[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.12.mlp.c_proj    â”‚ Linear                          â”‚  4.2 M â”‚ train â”‚
â”‚[2m [0m[2m287[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.12.ls_2          â”‚ Identity                        â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m288[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.13               â”‚ ResidualAttentionBlock          â”‚ 12.6 M â”‚ train â”‚
â”‚[2m [0m[2m289[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.13.ln_1          â”‚ LayerNorm                       â”‚  2.0 K â”‚ train â”‚
â”‚[2m [0m[2m290[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.13.attn          â”‚ MultiheadAttention              â”‚  4.2 M â”‚ train â”‚
â”‚[2m [0m[2m291[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.13.attn.out_proj â”‚ NonDynamicallyQuantizableLinear â”‚  1.0 M â”‚ train â”‚
â”‚[2m [0m[2m292[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.13.ls_1          â”‚ Identity                        â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m293[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.13.ln_2          â”‚ LayerNorm                       â”‚  2.0 K â”‚ train â”‚
â”‚[2m [0m[2m294[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.13.mlp           â”‚ Sequential                      â”‚  8.4 M â”‚ train â”‚
â”‚[2m [0m[2m295[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.13.mlp.c_fc      â”‚ Linear                          â”‚  4.2 M â”‚ train â”‚
â”‚[2m [0m[2m296[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.13.mlp.gelu      â”‚ GELU                            â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m297[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.13.mlp.c_proj    â”‚ Linear                          â”‚  4.2 M â”‚ train â”‚
â”‚[2m [0m[2m298[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.13.ls_2          â”‚ Identity                        â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m299[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.14               â”‚ ResidualAttentionBlock          â”‚ 12.6 M â”‚ train â”‚
â”‚[2m [0m[2m300[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.14.ln_1          â”‚ LayerNorm                       â”‚  2.0 K â”‚ train â”‚
â”‚[2m [0m[2m301[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.14.attn          â”‚ MultiheadAttention              â”‚  4.2 M â”‚ train â”‚
â”‚[2m [0m[2m302[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.14.attn.out_proj â”‚ NonDynamicallyQuantizableLinear â”‚  1.0 M â”‚ train â”‚
â”‚[2m [0m[2m303[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.14.ls_1          â”‚ Identity                        â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m304[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.14.ln_2          â”‚ LayerNorm                       â”‚  2.0 K â”‚ train â”‚
â”‚[2m [0m[2m305[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.14.mlp           â”‚ Sequential                      â”‚  8.4 M â”‚ train â”‚
â”‚[2m [0m[2m306[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.14.mlp.c_fc      â”‚ Linear                          â”‚  4.2 M â”‚ train â”‚
â”‚[2m [0m[2m307[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.14.mlp.gelu      â”‚ GELU                            â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m308[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.14.mlp.c_proj    â”‚ Linear                          â”‚  4.2 M â”‚ train â”‚
â”‚[2m [0m[2m309[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.14.ls_2          â”‚ Identity                        â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m310[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.15               â”‚ ResidualAttentionBlock          â”‚ 12.6 M â”‚ train â”‚
â”‚[2m [0m[2m311[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.15.ln_1          â”‚ LayerNorm                       â”‚  2.0 K â”‚ train â”‚
â”‚[2m [0m[2m312[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.15.attn          â”‚ MultiheadAttention              â”‚  4.2 M â”‚ train â”‚
â”‚[2m [0m[2m313[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.15.attn.out_proj â”‚ NonDynamicallyQuantizableLinear â”‚  1.0 M â”‚ train â”‚
â”‚[2m [0m[2m314[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.15.ls_1          â”‚ Identity                        â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m315[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.15.ln_2          â”‚ LayerNorm                       â”‚  2.0 K â”‚ train â”‚
â”‚[2m [0m[2m316[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.15.mlp           â”‚ Sequential                      â”‚  8.4 M â”‚ train â”‚
â”‚[2m [0m[2m317[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.15.mlp.c_fc      â”‚ Linear                          â”‚  4.2 M â”‚ train â”‚
â”‚[2m [0m[2m318[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.15.mlp.gelu      â”‚ GELU                            â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m319[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.15.mlp.c_proj    â”‚ Linear                          â”‚  4.2 M â”‚ train â”‚
â”‚[2m [0m[2m320[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.15.ls_2          â”‚ Identity                        â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m321[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.16               â”‚ ResidualAttentionBlock          â”‚ 12.6 M â”‚ train â”‚
â”‚[2m [0m[2m322[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.16.ln_1          â”‚ LayerNorm                       â”‚  2.0 K â”‚ train â”‚
â”‚[2m [0m[2m323[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.16.attn          â”‚ MultiheadAttention              â”‚  4.2 M â”‚ train â”‚
â”‚[2m [0m[2m324[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.16.attn.out_proj â”‚ NonDynamicallyQuantizableLinear â”‚  1.0 M â”‚ train â”‚
â”‚[2m [0m[2m325[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.16.ls_1          â”‚ Identity                        â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m326[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.16.ln_2          â”‚ LayerNorm                       â”‚  2.0 K â”‚ train â”‚
â”‚[2m [0m[2m327[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.16.mlp           â”‚ Sequential                      â”‚  8.4 M â”‚ train â”‚
â”‚[2m [0m[2m328[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.16.mlp.c_fc      â”‚ Linear                          â”‚  4.2 M â”‚ train â”‚
â”‚[2m [0m[2m329[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.16.mlp.gelu      â”‚ GELU                            â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m330[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.16.mlp.c_proj    â”‚ Linear                          â”‚  4.2 M â”‚ train â”‚
â”‚[2m [0m[2m331[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.16.ls_2          â”‚ Identity                        â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m332[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.17               â”‚ ResidualAttentionBlock          â”‚ 12.6 M â”‚ train â”‚
â”‚[2m [0m[2m333[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.17.ln_1          â”‚ LayerNorm                       â”‚  2.0 K â”‚ train â”‚
â”‚[2m [0m[2m334[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.17.attn          â”‚ MultiheadAttention              â”‚  4.2 M â”‚ train â”‚
â”‚[2m [0m[2m335[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.17.attn.out_proj â”‚ NonDynamicallyQuantizableLinear â”‚  1.0 M â”‚ train â”‚
â”‚[2m [0m[2m336[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.17.ls_1          â”‚ Identity                        â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m337[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.17.ln_2          â”‚ LayerNorm                       â”‚  2.0 K â”‚ train â”‚
â”‚[2m [0m[2m338[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.17.mlp           â”‚ Sequential                      â”‚  8.4 M â”‚ train â”‚
â”‚[2m [0m[2m339[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.17.mlp.c_fc      â”‚ Linear                          â”‚  4.2 M â”‚ train â”‚
â”‚[2m [0m[2m340[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.17.mlp.gelu      â”‚ GELU                            â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m341[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.17.mlp.c_proj    â”‚ Linear                          â”‚  4.2 M â”‚ train â”‚
â”‚[2m [0m[2m342[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.17.ls_2          â”‚ Identity                        â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m343[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.18               â”‚ ResidualAttentionBlock          â”‚ 12.6 M â”‚ train â”‚
â”‚[2m [0m[2m344[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.18.ln_1          â”‚ LayerNorm                       â”‚  2.0 K â”‚ train â”‚
â”‚[2m [0m[2m345[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.18.attn          â”‚ MultiheadAttention              â”‚  4.2 M â”‚ train â”‚
â”‚[2m [0m[2m346[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.18.attn.out_proj â”‚ NonDynamicallyQuantizableLinear â”‚  1.0 M â”‚ train â”‚
â”‚[2m [0m[2m347[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.18.ls_1          â”‚ Identity                        â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m348[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.18.ln_2          â”‚ LayerNorm                       â”‚  2.0 K â”‚ train â”‚
â”‚[2m [0m[2m349[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.18.mlp           â”‚ Sequential                      â”‚  8.4 M â”‚ train â”‚
â”‚[2m [0m[2m350[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.18.mlp.c_fc      â”‚ Linear                          â”‚  4.2 M â”‚ train â”‚
â”‚[2m [0m[2m351[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.18.mlp.gelu      â”‚ GELU                            â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m352[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.18.mlp.c_proj    â”‚ Linear                          â”‚  4.2 M â”‚ train â”‚
â”‚[2m [0m[2m353[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.18.ls_2          â”‚ Identity                        â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m354[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.19               â”‚ ResidualAttentionBlock          â”‚ 12.6 M â”‚ train â”‚
â”‚[2m [0m[2m355[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.19.ln_1          â”‚ LayerNorm                       â”‚  2.0 K â”‚ train â”‚
â”‚[2m [0m[2m356[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.19.attn          â”‚ MultiheadAttention              â”‚  4.2 M â”‚ train â”‚
â”‚[2m [0m[2m357[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.19.attn.out_proj â”‚ NonDynamicallyQuantizableLinear â”‚  1.0 M â”‚ train â”‚
â”‚[2m [0m[2m358[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.19.ls_1          â”‚ Identity                        â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m359[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.19.ln_2          â”‚ LayerNorm                       â”‚  2.0 K â”‚ train â”‚
â”‚[2m [0m[2m360[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.19.mlp           â”‚ Sequential                      â”‚  8.4 M â”‚ train â”‚
â”‚[2m [0m[2m361[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.19.mlp.c_fc      â”‚ Linear                          â”‚  4.2 M â”‚ train â”‚
â”‚[2m [0m[2m362[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.19.mlp.gelu      â”‚ GELU                            â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m363[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.19.mlp.c_proj    â”‚ Linear                          â”‚  4.2 M â”‚ train â”‚
â”‚[2m [0m[2m364[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.19.ls_2          â”‚ Identity                        â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m365[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.20               â”‚ ResidualAttentionBlock          â”‚ 12.6 M â”‚ train â”‚
â”‚[2m [0m[2m366[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.20.ln_1          â”‚ LayerNorm                       â”‚  2.0 K â”‚ train â”‚
â”‚[2m [0m[2m367[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.20.attn          â”‚ MultiheadAttention              â”‚  4.2 M â”‚ train â”‚
â”‚[2m [0m[2m368[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.20.attn.out_proj â”‚ NonDynamicallyQuantizableLinear â”‚  1.0 M â”‚ train â”‚
â”‚[2m [0m[2m369[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.20.ls_1          â”‚ Identity                        â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m370[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.20.ln_2          â”‚ LayerNorm                       â”‚  2.0 K â”‚ train â”‚
â”‚[2m [0m[2m371[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.20.mlp           â”‚ Sequential                      â”‚  8.4 M â”‚ train â”‚
â”‚[2m [0m[2m372[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.20.mlp.c_fc      â”‚ Linear                          â”‚  4.2 M â”‚ train â”‚
â”‚[2m [0m[2m373[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.20.mlp.gelu      â”‚ GELU                            â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m374[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.20.mlp.c_proj    â”‚ Linear                          â”‚  4.2 M â”‚ train â”‚
â”‚[2m [0m[2m375[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.20.ls_2          â”‚ Identity                        â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m376[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.21               â”‚ ResidualAttentionBlock          â”‚ 12.6 M â”‚ train â”‚
â”‚[2m [0m[2m377[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.21.ln_1          â”‚ LayerNorm                       â”‚  2.0 K â”‚ train â”‚
â”‚[2m [0m[2m378[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.21.attn          â”‚ MultiheadAttention              â”‚  4.2 M â”‚ train â”‚
â”‚[2m [0m[2m379[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.21.attn.out_proj â”‚ NonDynamicallyQuantizableLinear â”‚  1.0 M â”‚ train â”‚
â”‚[2m [0m[2m380[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.21.ls_1          â”‚ Identity                        â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m381[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.21.ln_2          â”‚ LayerNorm                       â”‚  2.0 K â”‚ train â”‚
â”‚[2m [0m[2m382[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.21.mlp           â”‚ Sequential                      â”‚  8.4 M â”‚ train â”‚
â”‚[2m [0m[2m383[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.21.mlp.c_fc      â”‚ Linear                          â”‚  4.2 M â”‚ train â”‚
â”‚[2m [0m[2m384[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.21.mlp.gelu      â”‚ GELU                            â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m385[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.21.mlp.c_proj    â”‚ Linear                          â”‚  4.2 M â”‚ train â”‚
â”‚[2m [0m[2m386[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.21.ls_2          â”‚ Identity                        â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m387[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.22               â”‚ ResidualAttentionBlock          â”‚ 12.6 M â”‚ train â”‚
â”‚[2m [0m[2m388[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.22.ln_1          â”‚ LayerNorm                       â”‚  2.0 K â”‚ train â”‚
â”‚[2m [0m[2m389[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.22.attn          â”‚ MultiheadAttention              â”‚  4.2 M â”‚ train â”‚
â”‚[2m [0m[2m390[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.22.attn.out_proj â”‚ NonDynamicallyQuantizableLinear â”‚  1.0 M â”‚ train â”‚
â”‚[2m [0m[2m391[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.22.ls_1          â”‚ Identity                        â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m392[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.22.ln_2          â”‚ LayerNorm                       â”‚  2.0 K â”‚ train â”‚
â”‚[2m [0m[2m393[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.22.mlp           â”‚ Sequential                      â”‚  8.4 M â”‚ train â”‚
â”‚[2m [0m[2m394[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.22.mlp.c_fc      â”‚ Linear                          â”‚  4.2 M â”‚ train â”‚
â”‚[2m [0m[2m395[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.22.mlp.gelu      â”‚ GELU                            â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m396[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.22.mlp.c_proj    â”‚ Linear                          â”‚  4.2 M â”‚ train â”‚
â”‚[2m [0m[2m397[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.22.ls_2          â”‚ Identity                        â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m398[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.23               â”‚ ResidualAttentionBlock          â”‚ 12.6 M â”‚ train â”‚
â”‚[2m [0m[2m399[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.23.ln_1          â”‚ LayerNorm                       â”‚  2.0 K â”‚ train â”‚
â”‚[2m [0m[2m400[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.23.attn          â”‚ MultiheadAttention              â”‚  4.2 M â”‚ train â”‚
â”‚[2m [0m[2m401[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.23.attn.out_proj â”‚ NonDynamicallyQuantizableLinear â”‚  1.0 M â”‚ train â”‚
â”‚[2m [0m[2m402[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.23.ls_1          â”‚ Identity                        â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m403[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.23.ln_2          â”‚ LayerNorm                       â”‚  2.0 K â”‚ train â”‚
â”‚[2m [0m[2m404[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.23.mlp           â”‚ Sequential                      â”‚  8.4 M â”‚ train â”‚
â”‚[2m [0m[2m405[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.23.mlp.c_fc      â”‚ Linear                          â”‚  4.2 M â”‚ train â”‚
â”‚[2m [0m[2m406[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.23.mlp.gelu      â”‚ GELU                            â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m407[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.23.mlp.c_proj    â”‚ Linear                          â”‚  4.2 M â”‚ train â”‚
â”‚[2m [0m[2m408[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.23.ls_2          â”‚ Identity                        â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m409[0m[2m [0mâ”‚ net.model.visual.attn_pool                              â”‚ AttentionalPooler               â”‚  3.0 M â”‚ train â”‚
â”‚[2m [0m[2m410[0m[2m [0mâ”‚ net.model.visual.attn_pool.attn                         â”‚ MultiheadAttention              â”‚  2.8 M â”‚ train â”‚
â”‚[2m [0m[2m411[0m[2m [0mâ”‚ net.model.visual.attn_pool.attn.out_proj                â”‚ NonDynamicallyQuantizableLinear â”‚  590 K â”‚ train â”‚
â”‚[2m [0m[2m412[0m[2m [0mâ”‚ net.model.visual.attn_pool.ln_q                         â”‚ LayerNorm                       â”‚  1.5 K â”‚ train â”‚
â”‚[2m [0m[2m413[0m[2m [0mâ”‚ net.model.visual.attn_pool.ln_k                         â”‚ LayerNorm                       â”‚  2.0 K â”‚ train â”‚
â”‚[2m [0m[2m414[0m[2m [0mâ”‚ net.model.visual.ln_post                                â”‚ LayerNorm                       â”‚  1.5 K â”‚ train â”‚
â”‚[2m [0m[2m415[0m[2m [0mâ”‚ net.model.text_decoder                                  â”‚ MultimodalTransformer           â”‚  208 M â”‚ train â”‚
â”‚[2m [0m[2m416[0m[2m [0mâ”‚ net.model.text_decoder.resblocks                        â”‚ ModuleList                      â”‚ 85.1 M â”‚ train â”‚
â”‚[2m [0m[2m417[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.0                      â”‚ ResidualAttentionBlock          â”‚  7.1 M â”‚ train â”‚
â”‚[2m [0m[2m418[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.0.ln_1                 â”‚ LayerNorm                       â”‚  1.5 K â”‚ train â”‚
â”‚[2m [0m[2m419[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.0.attn                 â”‚ MultiheadAttention              â”‚  2.4 M â”‚ train â”‚
â”‚[2m [0m[2m420[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.0.attn.out_proj        â”‚ NonDynamicallyQuantizableLinear â”‚  590 K â”‚ train â”‚
â”‚[2m [0m[2m421[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.0.ls_1                 â”‚ Identity                        â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m422[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.0.ln_2                 â”‚ LayerNorm                       â”‚  1.5 K â”‚ train â”‚
â”‚[2m [0m[2m423[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.0.mlp                  â”‚ Sequential                      â”‚  4.7 M â”‚ train â”‚
â”‚[2m [0m[2m424[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.0.mlp.c_fc             â”‚ Linear                          â”‚  2.4 M â”‚ train â”‚
â”‚[2m [0m[2m425[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.0.mlp.gelu             â”‚ GELU                            â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m426[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.0.mlp.c_proj           â”‚ Linear                          â”‚  2.4 M â”‚ train â”‚
â”‚[2m [0m[2m427[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.0.ls_2                 â”‚ Identity                        â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m428[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.1                      â”‚ ResidualAttentionBlock          â”‚  7.1 M â”‚ train â”‚
â”‚[2m [0m[2m429[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.1.ln_1                 â”‚ LayerNorm                       â”‚  1.5 K â”‚ train â”‚
â”‚[2m [0m[2m430[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.1.attn                 â”‚ MultiheadAttention              â”‚  2.4 M â”‚ train â”‚
â”‚[2m [0m[2m431[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.1.attn.out_proj        â”‚ NonDynamicallyQuantizableLinear â”‚  590 K â”‚ train â”‚
â”‚[2m [0m[2m432[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.1.ls_1                 â”‚ Identity                        â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m433[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.1.ln_2                 â”‚ LayerNorm                       â”‚  1.5 K â”‚ train â”‚
â”‚[2m [0m[2m434[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.1.mlp                  â”‚ Sequential                      â”‚  4.7 M â”‚ train â”‚
â”‚[2m [0m[2m435[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.1.mlp.c_fc             â”‚ Linear                          â”‚  2.4 M â”‚ train â”‚
â”‚[2m [0m[2m436[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.1.mlp.gelu             â”‚ GELU                            â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m437[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.1.mlp.c_proj           â”‚ Linear                          â”‚  2.4 M â”‚ train â”‚
â”‚[2m [0m[2m438[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.1.ls_2                 â”‚ Identity                        â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m439[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.2                      â”‚ ResidualAttentionBlock          â”‚  7.1 M â”‚ train â”‚
â”‚[2m [0m[2m440[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.2.ln_1                 â”‚ LayerNorm                       â”‚  1.5 K â”‚ train â”‚
â”‚[2m [0m[2m441[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.2.attn                 â”‚ MultiheadAttention              â”‚  2.4 M â”‚ train â”‚
â”‚[2m [0m[2m442[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.2.attn.out_proj        â”‚ NonDynamicallyQuantizableLinear â”‚  590 K â”‚ train â”‚
â”‚[2m [0m[2m443[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.2.ls_1                 â”‚ Identity                        â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m444[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.2.ln_2                 â”‚ LayerNorm                       â”‚  1.5 K â”‚ train â”‚
â”‚[2m [0m[2m445[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.2.mlp                  â”‚ Sequential                      â”‚  4.7 M â”‚ train â”‚
â”‚[2m [0m[2m446[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.2.mlp.c_fc             â”‚ Linear                          â”‚  2.4 M â”‚ train â”‚
â”‚[2m [0m[2m447[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.2.mlp.gelu             â”‚ GELU                            â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m448[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.2.mlp.c_proj           â”‚ Linear                          â”‚  2.4 M â”‚ train â”‚
â”‚[2m [0m[2m449[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.2.ls_2                 â”‚ Identity                        â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m450[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.3                      â”‚ ResidualAttentionBlock          â”‚  7.1 M â”‚ train â”‚
â”‚[2m [0m[2m451[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.3.ln_1                 â”‚ LayerNorm                       â”‚  1.5 K â”‚ train â”‚
â”‚[2m [0m[2m452[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.3.attn                 â”‚ MultiheadAttention              â”‚  2.4 M â”‚ train â”‚
â”‚[2m [0m[2m453[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.3.attn.out_proj        â”‚ NonDynamicallyQuantizableLinear â”‚  590 K â”‚ train â”‚
â”‚[2m [0m[2m454[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.3.ls_1                 â”‚ Identity                        â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m455[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.3.ln_2                 â”‚ LayerNorm                       â”‚  1.5 K â”‚ train â”‚
â”‚[2m [0m[2m456[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.3.mlp                  â”‚ Sequential                      â”‚  4.7 M â”‚ train â”‚
â”‚[2m [0m[2m457[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.3.mlp.c_fc             â”‚ Linear                          â”‚  2.4 M â”‚ train â”‚
â”‚[2m [0m[2m458[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.3.mlp.gelu             â”‚ GELU                            â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m459[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.3.mlp.c_proj           â”‚ Linear                          â”‚  2.4 M â”‚ train â”‚
â”‚[2m [0m[2m460[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.3.ls_2                 â”‚ Identity                        â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m461[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.4                      â”‚ ResidualAttentionBlock          â”‚  7.1 M â”‚ train â”‚
â”‚[2m [0m[2m462[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.4.ln_1                 â”‚ LayerNorm                       â”‚  1.5 K â”‚ train â”‚
â”‚[2m [0m[2m463[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.4.attn                 â”‚ MultiheadAttention              â”‚  2.4 M â”‚ train â”‚
â”‚[2m [0m[2m464[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.4.attn.out_proj        â”‚ NonDynamicallyQuantizableLinear â”‚  590 K â”‚ train â”‚
â”‚[2m [0m[2m465[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.4.ls_1                 â”‚ Identity                        â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m466[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.4.ln_2                 â”‚ LayerNorm                       â”‚  1.5 K â”‚ train â”‚
â”‚[2m [0m[2m467[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.4.mlp                  â”‚ Sequential                      â”‚  4.7 M â”‚ train â”‚
â”‚[2m [0m[2m468[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.4.mlp.c_fc             â”‚ Linear                          â”‚  2.4 M â”‚ train â”‚
â”‚[2m [0m[2m469[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.4.mlp.gelu             â”‚ GELU                            â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m470[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.4.mlp.c_proj           â”‚ Linear                          â”‚  2.4 M â”‚ train â”‚
â”‚[2m [0m[2m471[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.4.ls_2                 â”‚ Identity                        â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m472[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.5                      â”‚ ResidualAttentionBlock          â”‚  7.1 M â”‚ train â”‚
â”‚[2m [0m[2m473[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.5.ln_1                 â”‚ LayerNorm                       â”‚  1.5 K â”‚ train â”‚
â”‚[2m [0m[2m474[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.5.attn                 â”‚ MultiheadAttention              â”‚  2.4 M â”‚ train â”‚
â”‚[2m [0m[2m475[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.5.attn.out_proj        â”‚ NonDynamicallyQuantizableLinear â”‚  590 K â”‚ train â”‚
â”‚[2m [0m[2m476[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.5.ls_1                 â”‚ Identity                        â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m477[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.5.ln_2                 â”‚ LayerNorm                       â”‚  1.5 K â”‚ train â”‚
â”‚[2m [0m[2m478[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.5.mlp                  â”‚ Sequential                      â”‚  4.7 M â”‚ train â”‚
â”‚[2m [0m[2m479[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.5.mlp.c_fc             â”‚ Linear                          â”‚  2.4 M â”‚ train â”‚
â”‚[2m [0m[2m480[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.5.mlp.gelu             â”‚ GELU                            â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m481[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.5.mlp.c_proj           â”‚ Linear                          â”‚  2.4 M â”‚ train â”‚
â”‚[2m [0m[2m482[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.5.ls_2                 â”‚ Identity                        â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m483[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.6                      â”‚ ResidualAttentionBlock          â”‚  7.1 M â”‚ train â”‚
â”‚[2m [0m[2m484[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.6.ln_1                 â”‚ LayerNorm                       â”‚  1.5 K â”‚ train â”‚
â”‚[2m [0m[2m485[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.6.attn                 â”‚ MultiheadAttention              â”‚  2.4 M â”‚ train â”‚
â”‚[2m [0m[2m486[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.6.attn.out_proj        â”‚ NonDynamicallyQuantizableLinear â”‚  590 K â”‚ train â”‚
â”‚[2m [0m[2m487[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.6.ls_1                 â”‚ Identity                        â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m488[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.6.ln_2                 â”‚ LayerNorm                       â”‚  1.5 K â”‚ train â”‚
â”‚[2m [0m[2m489[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.6.mlp                  â”‚ Sequential                      â”‚  4.7 M â”‚ train â”‚
â”‚[2m [0m[2m490[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.6.mlp.c_fc             â”‚ Linear                          â”‚  2.4 M â”‚ train â”‚
â”‚[2m [0m[2m491[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.6.mlp.gelu             â”‚ GELU                            â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m492[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.6.mlp.c_proj           â”‚ Linear                          â”‚  2.4 M â”‚ train â”‚
â”‚[2m [0m[2m493[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.6.ls_2                 â”‚ Identity                        â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m494[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.7                      â”‚ ResidualAttentionBlock          â”‚  7.1 M â”‚ train â”‚
â”‚[2m [0m[2m495[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.7.ln_1                 â”‚ LayerNorm                       â”‚  1.5 K â”‚ train â”‚
â”‚[2m [0m[2m496[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.7.attn                 â”‚ MultiheadAttention              â”‚  2.4 M â”‚ train â”‚
â”‚[2m [0m[2m497[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.7.attn.out_proj        â”‚ NonDynamicallyQuantizableLinear â”‚  590 K â”‚ train â”‚
â”‚[2m [0m[2m498[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.7.ls_1                 â”‚ Identity                        â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m499[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.7.ln_2                 â”‚ LayerNorm                       â”‚  1.5 K â”‚ train â”‚
â”‚[2m [0m[2m500[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.7.mlp                  â”‚ Sequential                      â”‚  4.7 M â”‚ train â”‚
â”‚[2m [0m[2m501[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.7.mlp.c_fc             â”‚ Linear                          â”‚  2.4 M â”‚ train â”‚
â”‚[2m [0m[2m502[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.7.mlp.gelu             â”‚ GELU                            â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m503[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.7.mlp.c_proj           â”‚ Linear                          â”‚  2.4 M â”‚ train â”‚
â”‚[2m [0m[2m504[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.7.ls_2                 â”‚ Identity                        â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m505[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.8                      â”‚ ResidualAttentionBlock          â”‚  7.1 M â”‚ train â”‚
â”‚[2m [0m[2m506[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.8.ln_1                 â”‚ LayerNorm                       â”‚  1.5 K â”‚ train â”‚
â”‚[2m [0m[2m507[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.8.attn                 â”‚ MultiheadAttention              â”‚  2.4 M â”‚ train â”‚
â”‚[2m [0m[2m508[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.8.attn.out_proj        â”‚ NonDynamicallyQuantizableLinear â”‚  590 K â”‚ train â”‚
â”‚[2m [0m[2m509[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.8.ls_1                 â”‚ Identity                        â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m510[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.8.ln_2                 â”‚ LayerNorm                       â”‚  1.5 K â”‚ train â”‚
â”‚[2m [0m[2m511[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.8.mlp                  â”‚ Sequential                      â”‚  4.7 M â”‚ train â”‚
â”‚[2m [0m[2m512[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.8.mlp.c_fc             â”‚ Linear                          â”‚  2.4 M â”‚ train â”‚
â”‚[2m [0m[2m513[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.8.mlp.gelu             â”‚ GELU                            â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m514[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.8.mlp.c_proj           â”‚ Linear                          â”‚  2.4 M â”‚ train â”‚
â”‚[2m [0m[2m515[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.8.ls_2                 â”‚ Identity                        â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m516[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.9                      â”‚ ResidualAttentionBlock          â”‚  7.1 M â”‚ train â”‚
â”‚[2m [0m[2m517[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.9.ln_1                 â”‚ LayerNorm                       â”‚  1.5 K â”‚ train â”‚
â”‚[2m [0m[2m518[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.9.attn                 â”‚ MultiheadAttention              â”‚  2.4 M â”‚ train â”‚
â”‚[2m [0m[2m519[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.9.attn.out_proj        â”‚ NonDynamicallyQuantizableLinear â”‚  590 K â”‚ train â”‚
â”‚[2m [0m[2m520[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.9.ls_1                 â”‚ Identity                        â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m521[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.9.ln_2                 â”‚ LayerNorm                       â”‚  1.5 K â”‚ train â”‚
â”‚[2m [0m[2m522[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.9.mlp                  â”‚ Sequential                      â”‚  4.7 M â”‚ train â”‚
â”‚[2m [0m[2m523[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.9.mlp.c_fc             â”‚ Linear                          â”‚  2.4 M â”‚ train â”‚
â”‚[2m [0m[2m524[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.9.mlp.gelu             â”‚ GELU                            â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m525[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.9.mlp.c_proj           â”‚ Linear                          â”‚  2.4 M â”‚ train â”‚
â”‚[2m [0m[2m526[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.9.ls_2                 â”‚ Identity                        â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m527[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.10                     â”‚ ResidualAttentionBlock          â”‚  7.1 M â”‚ train â”‚
â”‚[2m [0m[2m528[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.10.ln_1                â”‚ LayerNorm                       â”‚  1.5 K â”‚ train â”‚
â”‚[2m [0m[2m529[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.10.attn                â”‚ MultiheadAttention              â”‚  2.4 M â”‚ train â”‚
â”‚[2m [0m[2m530[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.10.attn.out_proj       â”‚ NonDynamicallyQuantizableLinear â”‚  590 K â”‚ train â”‚
â”‚[2m [0m[2m531[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.10.ls_1                â”‚ Identity                        â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m532[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.10.ln_2                â”‚ LayerNorm                       â”‚  1.5 K â”‚ train â”‚
â”‚[2m [0m[2m533[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.10.mlp                 â”‚ Sequential                      â”‚  4.7 M â”‚ train â”‚
â”‚[2m [0m[2m534[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.10.mlp.c_fc            â”‚ Linear                          â”‚  2.4 M â”‚ train â”‚
â”‚[2m [0m[2m535[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.10.mlp.gelu            â”‚ GELU                            â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m536[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.10.mlp.c_proj          â”‚ Linear                          â”‚  2.4 M â”‚ train â”‚
â”‚[2m [0m[2m537[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.10.ls_2                â”‚ Identity                        â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m538[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.11                     â”‚ ResidualAttentionBlock          â”‚  7.1 M â”‚ train â”‚
â”‚[2m [0m[2m539[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.11.ln_1                â”‚ LayerNorm                       â”‚  1.5 K â”‚ train â”‚
â”‚[2m [0m[2m540[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.11.attn                â”‚ MultiheadAttention              â”‚  2.4 M â”‚ train â”‚
â”‚[2m [0m[2m541[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.11.attn.out_proj       â”‚ NonDynamicallyQuantizableLinear â”‚  590 K â”‚ train â”‚
â”‚[2m [0m[2m542[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.11.ls_1                â”‚ Identity                        â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m543[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.11.ln_2                â”‚ LayerNorm                       â”‚  1.5 K â”‚ train â”‚
â”‚[2m [0m[2m544[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.11.mlp                 â”‚ Sequential                      â”‚  4.7 M â”‚ train â”‚
â”‚[2m [0m[2m545[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.11.mlp.c_fc            â”‚ Linear                          â”‚  2.4 M â”‚ train â”‚
â”‚[2m [0m[2m546[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.11.mlp.gelu            â”‚ GELU                            â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m547[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.11.mlp.c_proj          â”‚ Linear                          â”‚  2.4 M â”‚ train â”‚
â”‚[2m [0m[2m548[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.11.ls_2                â”‚ Identity                        â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m549[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn                       â”‚ ModuleList                      â”‚ 85.1 M â”‚ train â”‚
â”‚[2m [0m[2m550[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.0                     â”‚ ResidualAttentionBlock          â”‚  7.1 M â”‚ train â”‚
â”‚[2m [0m[2m551[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.0.ln_1                â”‚ LayerNorm                       â”‚  1.5 K â”‚ train â”‚
â”‚[2m [0m[2m552[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.0.attn                â”‚ MultiheadAttention              â”‚  2.4 M â”‚ train â”‚
â”‚[2m [0m[2m553[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.0.attn.out_proj       â”‚ NonDynamicallyQuantizableLinear â”‚  590 K â”‚ train â”‚
â”‚[2m [0m[2m554[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.0.ls_1                â”‚ Identity                        â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m555[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.0.ln_1_kv             â”‚ LayerNorm                       â”‚  1.5 K â”‚ train â”‚
â”‚[2m [0m[2m556[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.0.ln_2                â”‚ LayerNorm                       â”‚  1.5 K â”‚ train â”‚
â”‚[2m [0m[2m557[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.0.mlp                 â”‚ Sequential                      â”‚  4.7 M â”‚ train â”‚
â”‚[2m [0m[2m558[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.0.mlp.c_fc            â”‚ Linear                          â”‚  2.4 M â”‚ train â”‚
â”‚[2m [0m[2m559[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.0.mlp.gelu            â”‚ GELU                            â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m560[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.0.mlp.c_proj          â”‚ Linear                          â”‚  2.4 M â”‚ train â”‚
â”‚[2m [0m[2m561[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.0.ls_2                â”‚ Identity                        â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m562[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.1                     â”‚ ResidualAttentionBlock          â”‚  7.1 M â”‚ train â”‚
â”‚[2m [0m[2m563[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.1.ln_1                â”‚ LayerNorm                       â”‚  1.5 K â”‚ train â”‚
â”‚[2m [0m[2m564[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.1.attn                â”‚ MultiheadAttention              â”‚  2.4 M â”‚ train â”‚
â”‚[2m [0m[2m565[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.1.attn.out_proj       â”‚ NonDynamicallyQuantizableLinear â”‚  590 K â”‚ train â”‚
â”‚[2m [0m[2m566[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.1.ls_1                â”‚ Identity                        â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m567[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.1.ln_1_kv             â”‚ LayerNorm                       â”‚  1.5 K â”‚ train â”‚
â”‚[2m [0m[2m568[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.1.ln_2                â”‚ LayerNorm                       â”‚  1.5 K â”‚ train â”‚
â”‚[2m [0m[2m569[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.1.mlp                 â”‚ Sequential                      â”‚  4.7 M â”‚ train â”‚
â”‚[2m [0m[2m570[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.1.mlp.c_fc            â”‚ Linear                          â”‚  2.4 M â”‚ train â”‚
â”‚[2m [0m[2m571[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.1.mlp.gelu            â”‚ GELU                            â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m572[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.1.mlp.c_proj          â”‚ Linear                          â”‚  2.4 M â”‚ train â”‚
â”‚[2m [0m[2m573[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.1.ls_2                â”‚ Identity                        â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m574[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.2                     â”‚ ResidualAttentionBlock          â”‚  7.1 M â”‚ train â”‚
â”‚[2m [0m[2m575[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.2.ln_1                â”‚ LayerNorm                       â”‚  1.5 K â”‚ train â”‚
â”‚[2m [0m[2m576[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.2.attn                â”‚ MultiheadAttention              â”‚  2.4 M â”‚ train â”‚
â”‚[2m [0m[2m577[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.2.attn.out_proj       â”‚ NonDynamicallyQuantizableLinear â”‚  590 K â”‚ train â”‚
â”‚[2m [0m[2m578[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.2.ls_1                â”‚ Identity                        â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m579[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.2.ln_1_kv             â”‚ LayerNorm                       â”‚  1.5 K â”‚ train â”‚
â”‚[2m [0m[2m580[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.2.ln_2                â”‚ LayerNorm                       â”‚  1.5 K â”‚ train â”‚
â”‚[2m [0m[2m581[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.2.mlp                 â”‚ Sequential                      â”‚  4.7 M â”‚ train â”‚
â”‚[2m [0m[2m582[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.2.mlp.c_fc            â”‚ Linear                          â”‚  2.4 M â”‚ train â”‚
â”‚[2m [0m[2m583[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.2.mlp.gelu            â”‚ GELU                            â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m584[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.2.mlp.c_proj          â”‚ Linear                          â”‚  2.4 M â”‚ train â”‚
â”‚[2m [0m[2m585[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.2.ls_2                â”‚ Identity                        â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m586[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.3                     â”‚ ResidualAttentionBlock          â”‚  7.1 M â”‚ train â”‚
â”‚[2m [0m[2m587[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.3.ln_1                â”‚ LayerNorm                       â”‚  1.5 K â”‚ train â”‚
â”‚[2m [0m[2m588[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.3.attn                â”‚ MultiheadAttention              â”‚  2.4 M â”‚ train â”‚
â”‚[2m [0m[2m589[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.3.attn.out_proj       â”‚ NonDynamicallyQuantizableLinear â”‚  590 K â”‚ train â”‚
â”‚[2m [0m[2m590[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.3.ls_1                â”‚ Identity                        â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m591[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.3.ln_1_kv             â”‚ LayerNorm                       â”‚  1.5 K â”‚ train â”‚
â”‚[2m [0m[2m592[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.3.ln_2                â”‚ LayerNorm                       â”‚  1.5 K â”‚ train â”‚
â”‚[2m [0m[2m593[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.3.mlp                 â”‚ Sequential                      â”‚  4.7 M â”‚ train â”‚
â”‚[2m [0m[2m594[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.3.mlp.c_fc            â”‚ Linear                          â”‚  2.4 M â”‚ train â”‚
â”‚[2m [0m[2m595[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.3.mlp.gelu            â”‚ GELU                            â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m596[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.3.mlp.c_proj          â”‚ Linear                          â”‚  2.4 M â”‚ train â”‚
â”‚[2m [0m[2m597[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.3.ls_2                â”‚ Identity                        â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m598[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.4                     â”‚ ResidualAttentionBlock          â”‚  7.1 M â”‚ train â”‚
â”‚[2m [0m[2m599[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.4.ln_1                â”‚ LayerNorm                       â”‚  1.5 K â”‚ train â”‚
â”‚[2m [0m[2m600[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.4.attn                â”‚ MultiheadAttention              â”‚  2.4 M â”‚ train â”‚
â”‚[2m [0m[2m601[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.4.attn.out_proj       â”‚ NonDynamicallyQuantizableLinear â”‚  590 K â”‚ train â”‚
â”‚[2m [0m[2m602[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.4.ls_1                â”‚ Identity                        â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m603[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.4.ln_1_kv             â”‚ LayerNorm                       â”‚  1.5 K â”‚ train â”‚
â”‚[2m [0m[2m604[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.4.ln_2                â”‚ LayerNorm                       â”‚  1.5 K â”‚ train â”‚
â”‚[2m [0m[2m605[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.4.mlp                 â”‚ Sequential                      â”‚  4.7 M â”‚ train â”‚
â”‚[2m [0m[2m606[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.4.mlp.c_fc            â”‚ Linear                          â”‚  2.4 M â”‚ train â”‚
â”‚[2m [0m[2m607[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.4.mlp.gelu            â”‚ GELU                            â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m608[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.4.mlp.c_proj          â”‚ Linear                          â”‚  2.4 M â”‚ train â”‚
â”‚[2m [0m[2m609[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.4.ls_2                â”‚ Identity                        â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m610[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.5                     â”‚ ResidualAttentionBlock          â”‚  7.1 M â”‚ train â”‚
â”‚[2m [0m[2m611[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.5.ln_1                â”‚ LayerNorm                       â”‚  1.5 K â”‚ train â”‚
â”‚[2m [0m[2m612[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.5.attn                â”‚ MultiheadAttention              â”‚  2.4 M â”‚ train â”‚
â”‚[2m [0m[2m613[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.5.attn.out_proj       â”‚ NonDynamicallyQuantizableLinear â”‚  590 K â”‚ train â”‚
â”‚[2m [0m[2m614[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.5.ls_1                â”‚ Identity                        â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m615[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.5.ln_1_kv             â”‚ LayerNorm                       â”‚  1.5 K â”‚ train â”‚
â”‚[2m [0m[2m616[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.5.ln_2                â”‚ LayerNorm                       â”‚  1.5 K â”‚ train â”‚
â”‚[2m [0m[2m617[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.5.mlp                 â”‚ Sequential                      â”‚  4.7 M â”‚ train â”‚
â”‚[2m [0m[2m618[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.5.mlp.c_fc            â”‚ Linear                          â”‚  2.4 M â”‚ train â”‚
â”‚[2m [0m[2m619[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.5.mlp.gelu            â”‚ GELU                            â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m620[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.5.mlp.c_proj          â”‚ Linear                          â”‚  2.4 M â”‚ train â”‚
â”‚[2m [0m[2m621[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.5.ls_2                â”‚ Identity                        â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m622[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.6                     â”‚ ResidualAttentionBlock          â”‚  7.1 M â”‚ train â”‚
â”‚[2m [0m[2m623[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.6.ln_1                â”‚ LayerNorm                       â”‚  1.5 K â”‚ train â”‚
â”‚[2m [0m[2m624[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.6.attn                â”‚ MultiheadAttention              â”‚  2.4 M â”‚ train â”‚
â”‚[2m [0m[2m625[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.6.attn.out_proj       â”‚ NonDynamicallyQuantizableLinear â”‚  590 K â”‚ train â”‚
â”‚[2m [0m[2m626[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.6.ls_1                â”‚ Identity                        â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m627[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.6.ln_1_kv             â”‚ LayerNorm                       â”‚  1.5 K â”‚ train â”‚
â”‚[2m [0m[2m628[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.6.ln_2                â”‚ LayerNorm                       â”‚  1.5 K â”‚ train â”‚
â”‚[2m [0m[2m629[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.6.mlp                 â”‚ Sequential                      â”‚  4.7 M â”‚ train â”‚
â”‚[2m [0m[2m630[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.6.mlp.c_fc            â”‚ Linear                          â”‚  2.4 M â”‚ train â”‚
â”‚[2m [0m[2m631[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.6.mlp.gelu            â”‚ GELU                            â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m632[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.6.mlp.c_proj          â”‚ Linear                          â”‚  2.4 M â”‚ train â”‚
â”‚[2m [0m[2m633[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.6.ls_2                â”‚ Identity                        â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m634[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.7                     â”‚ ResidualAttentionBlock          â”‚  7.1 M â”‚ train â”‚
â”‚[2m [0m[2m635[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.7.ln_1                â”‚ LayerNorm                       â”‚  1.5 K â”‚ train â”‚
â”‚[2m [0m[2m636[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.7.attn                â”‚ MultiheadAttention              â”‚  2.4 M â”‚ train â”‚
â”‚[2m [0m[2m637[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.7.attn.out_proj       â”‚ NonDynamicallyQuantizableLinear â”‚  590 K â”‚ train â”‚
â”‚[2m [0m[2m638[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.7.ls_1                â”‚ Identity                        â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m639[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.7.ln_1_kv             â”‚ LayerNorm                       â”‚  1.5 K â”‚ train â”‚
â”‚[2m [0m[2m640[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.7.ln_2                â”‚ LayerNorm                       â”‚  1.5 K â”‚ train â”‚
â”‚[2m [0m[2m641[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.7.mlp                 â”‚ Sequential                      â”‚  4.7 M â”‚ train â”‚
â”‚[2m [0m[2m642[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.7.mlp.c_fc            â”‚ Linear                          â”‚  2.4 M â”‚ train â”‚
â”‚[2m [0m[2m643[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.7.mlp.gelu            â”‚ GELU                            â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m644[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.7.mlp.c_proj          â”‚ Linear                          â”‚  2.4 M â”‚ train â”‚
â”‚[2m [0m[2m645[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.7.ls_2                â”‚ Identity                        â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m646[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.8                     â”‚ ResidualAttentionBlock          â”‚  7.1 M â”‚ train â”‚
â”‚[2m [0m[2m647[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.8.ln_1                â”‚ LayerNorm                       â”‚  1.5 K â”‚ train â”‚
â”‚[2m [0m[2m648[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.8.attn                â”‚ MultiheadAttention              â”‚  2.4 M â”‚ train â”‚
â”‚[2m [0m[2m649[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.8.attn.out_proj       â”‚ NonDynamicallyQuantizableLinear â”‚  590 K â”‚ train â”‚
â”‚[2m [0m[2m650[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.8.ls_1                â”‚ Identity                        â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m651[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.8.ln_1_kv             â”‚ LayerNorm                       â”‚  1.5 K â”‚ train â”‚
â”‚[2m [0m[2m652[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.8.ln_2                â”‚ LayerNorm                       â”‚  1.5 K â”‚ train â”‚
â”‚[2m [0m[2m653[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.8.mlp                 â”‚ Sequential                      â”‚  4.7 M â”‚ train â”‚
â”‚[2m [0m[2m654[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.8.mlp.c_fc            â”‚ Linear                          â”‚  2.4 M â”‚ train â”‚
â”‚[2m [0m[2m655[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.8.mlp.gelu            â”‚ GELU                            â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m656[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.8.mlp.c_proj          â”‚ Linear                          â”‚  2.4 M â”‚ train â”‚
â”‚[2m [0m[2m657[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.8.ls_2                â”‚ Identity                        â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m658[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.9                     â”‚ ResidualAttentionBlock          â”‚  7.1 M â”‚ train â”‚
â”‚[2m [0m[2m659[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.9.ln_1                â”‚ LayerNorm                       â”‚  1.5 K â”‚ train â”‚
â”‚[2m [0m[2m660[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.9.attn                â”‚ MultiheadAttention              â”‚  2.4 M â”‚ train â”‚
â”‚[2m [0m[2m661[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.9.attn.out_proj       â”‚ NonDynamicallyQuantizableLinear â”‚  590 K â”‚ train â”‚
â”‚[2m [0m[2m662[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.9.ls_1                â”‚ Identity                        â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m663[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.9.ln_1_kv             â”‚ LayerNorm                       â”‚  1.5 K â”‚ train â”‚
â”‚[2m [0m[2m664[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.9.ln_2                â”‚ LayerNorm                       â”‚  1.5 K â”‚ train â”‚
â”‚[2m [0m[2m665[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.9.mlp                 â”‚ Sequential                      â”‚  4.7 M â”‚ train â”‚
â”‚[2m [0m[2m666[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.9.mlp.c_fc            â”‚ Linear                          â”‚  2.4 M â”‚ train â”‚
â”‚[2m [0m[2m667[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.9.mlp.gelu            â”‚ GELU                            â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m668[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.9.mlp.c_proj          â”‚ Linear                          â”‚  2.4 M â”‚ train â”‚
â”‚[2m [0m[2m669[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.9.ls_2                â”‚ Identity                        â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m670[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.10                    â”‚ ResidualAttentionBlock          â”‚  7.1 M â”‚ train â”‚
â”‚[2m [0m[2m671[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.10.ln_1               â”‚ LayerNorm                       â”‚  1.5 K â”‚ train â”‚
â”‚[2m [0m[2m672[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.10.attn               â”‚ MultiheadAttention              â”‚  2.4 M â”‚ train â”‚
â”‚[2m [0m[2m673[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.10.attn.out_proj      â”‚ NonDynamicallyQuantizableLinear â”‚  590 K â”‚ train â”‚
â”‚[2m [0m[2m674[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.10.ls_1               â”‚ Identity                        â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m675[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.10.ln_1_kv            â”‚ LayerNorm                       â”‚  1.5 K â”‚ train â”‚
â”‚[2m [0m[2m676[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.10.ln_2               â”‚ LayerNorm                       â”‚  1.5 K â”‚ train â”‚
â”‚[2m [0m[2m677[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.10.mlp                â”‚ Sequential                      â”‚  4.7 M â”‚ train â”‚
â”‚[2m [0m[2m678[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.10.mlp.c_fc           â”‚ Linear                          â”‚  2.4 M â”‚ train â”‚
â”‚[2m [0m[2m679[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.10.mlp.gelu           â”‚ GELU                            â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m680[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.10.mlp.c_proj         â”‚ Linear                          â”‚  2.4 M â”‚ train â”‚
â”‚[2m [0m[2m681[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.10.ls_2               â”‚ Identity                        â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m682[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.11                    â”‚ ResidualAttentionBlock          â”‚  7.1 M â”‚ train â”‚
â”‚[2m [0m[2m683[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.11.ln_1               â”‚ LayerNorm                       â”‚  1.5 K â”‚ train â”‚
â”‚[2m [0m[2m684[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.11.attn               â”‚ MultiheadAttention              â”‚  2.4 M â”‚ train â”‚
â”‚[2m [0m[2m685[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.11.attn.out_proj      â”‚ NonDynamicallyQuantizableLinear â”‚  590 K â”‚ train â”‚
â”‚[2m [0m[2m686[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.11.ls_1               â”‚ Identity                        â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m687[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.11.ln_1_kv            â”‚ LayerNorm                       â”‚  1.5 K â”‚ train â”‚
â”‚[2m [0m[2m688[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.11.ln_2               â”‚ LayerNorm                       â”‚  1.5 K â”‚ train â”‚
â”‚[2m [0m[2m689[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.11.mlp                â”‚ Sequential                      â”‚  4.7 M â”‚ train â”‚
â”‚[2m [0m[2m690[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.11.mlp.c_fc           â”‚ Linear                          â”‚  2.4 M â”‚ train â”‚
â”‚[2m [0m[2m691[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.11.mlp.gelu           â”‚ GELU                            â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m692[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.11.mlp.c_proj         â”‚ Linear                          â”‚  2.4 M â”‚ train â”‚
â”‚[2m [0m[2m693[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.11.ls_2               â”‚ Identity                        â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m694[0m[2m [0mâ”‚ net.model.text_decoder.ln_final                         â”‚ LayerNorm                       â”‚  1.5 K â”‚ train â”‚
â”‚[2m [0m[2m695[0m[2m [0mâ”‚ net.tta_loss                                            â”‚ ByolLoss                        â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m696[0m[2m [0mâ”‚ net.video_proj                                          â”‚ VideoProjector                  â”‚  591 K â”‚ train â”‚
â”‚[2m [0m[2m697[0m[2m [0mâ”‚ net.video_proj.transform                                â”‚ Sequential                      â”‚  1.5 K â”‚ train â”‚
â”‚[2m [0m[2m698[0m[2m [0mâ”‚ net.video_proj.transform.0                              â”‚ LayerNorm                       â”‚  1.5 K â”‚ train â”‚
â”‚[2m [0m[2m699[0m[2m [0mâ”‚ net.video_proj.transform.1                              â”‚ Dropout                         â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m700[0m[2m [0mâ”‚ net.visual_proj                                         â”‚ VideoProjector                  â”‚  591 K â”‚ train â”‚
â”‚[2m [0m[2m701[0m[2m [0mâ”‚ net.visual_proj.transform                               â”‚ Sequential                      â”‚  1.5 K â”‚ train â”‚
â”‚[2m [0m[2m702[0m[2m [0mâ”‚ net.visual_proj.transform.0                             â”‚ LayerNorm                       â”‚  1.5 K â”‚ train â”‚
â”‚[2m [0m[2m703[0m[2m [0mâ”‚ net.visual_proj.transform.1                             â”‚ Dropout                         â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m704[0m[2m [0mâ”‚ net.fusion                                              â”‚ Fusion                          â”‚  6.2 K â”‚ train â”‚
â”‚[2m [0m[2m705[0m[2m [0mâ”‚ net.fusion.attn                                         â”‚ Sequential                      â”‚  6.2 K â”‚ train â”‚
â”‚[2m [0m[2m706[0m[2m [0mâ”‚ net.fusion.attn.0                                       â”‚ Linear                          â”‚  6.1 K â”‚ train â”‚
â”‚[2m [0m[2m707[0m[2m [0mâ”‚ net.fusion.attn.1                                       â”‚ Linear                          â”‚     10 â”‚ train â”‚
â”‚[2m [0m[2m708[0m[2m [0mâ”‚ net.fusion.attn.2                                       â”‚ Softmax                         â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m709[0m[2m [0mâ”‚ binary_acc                                              â”‚ BinaryAccuracy                  â”‚      0 â”‚ train â”‚
â””â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”˜
[1mTrainable params[0m: 1.2 M
[1mNon-trainable params[0m: 638 M
[1mTotal params[0m: 639 M
[1mTotal estimated model params size (MB)[0m: 2.6 K
[1mModules in train mode[0m: 710
[1mModules in eval mode[0m: 0
/home/def/miniforge3/envs/fewshot/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:425: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.
`Trainer.fit` stopped: `max_epochs=0` reached.
[[36m2025-02-14 10:58:47,231[0m][[34m__main__[0m][[32mINFO[0m] - Starting testing![0m
[[36m2025-02-14 10:58:47,232[0m][[34m__main__[0m][[33mWARNING[0m] - Best ckpt not found! Using current weights for testing...[0m
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
/home/def/miniforge3/envs/fewshot/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:425: The 'test_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.
[2KStart testing...
[2KAttention weights: tensor([[0.5204, 0.4796],â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 0/203 [2m0:00:00 â€¢ -:--:--[0m [2;4m0.00it/s[0m  
        [0.5123, 0.4877],
        [0.5140, 0.4860],
        [0.5197, 0.4803],
        [0.5214, 0.4786],
        [0.5241, 0.4759],
        [0.5214, 0.4786],
        [0.5185, 0.4815],
        [0.5154, 0.4846],
[2K        [0.5216, 0.4784]], device='cuda:0', grad_fn=<SoftmaxBackward0>):00:00 â€¢ -:--:--[0m [2;4m0.00it/s[0m  
[2K/home/def/fewshot/src/models/components/tt_method.py:319: UserWarning: The use of `x.T` on tensors of dimension other than 2 to reverse their shape is deprecated and it will throw an error in a future release. Consider `x.mT` to transpose batches of matrices or
`x.permute(*torch.arange(x.ndim - 1, -1, -1))` to reverse the dimensions of a tensor. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3683.)
  dot_product = (x @ y.T)
[2KClass label: HighJumpâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 0/203 [2m0:00:00 â€¢ -:--:--[0m [2;4m0.00it/s[0m  
[2KAttention weights: tensor([[0.6850, 0.3150]], device='cuda:0', grad_fn=<SoftmaxBackward0>)m [2;4m0.00it/s[0m  
[2KStep 0 - TTA Loss: 1.2758â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 0/203 [2m0:00:00 â€¢ -:--:--[0m [2;4m0.00it/s[0m  
[2KAttention weights: tensor([[0.7505, 0.2495]], device='cuda:0', grad_fn=<SoftmaxBackward0>)m [2;4m0.00it/s[0m  
[2KAttention weights: tensor([[0.7371, 0.2629]], device='cuda:0', grad_fn=<SoftmaxBackward0>)m [2;4m0.00it/s[0m  
[2KAttention weights: tensor([[0.7367, 0.2633]], device='cuda:0', grad_fn=<SoftmaxBackward0>)m [2;4m0.00it/s[0m  
[2KAttention weights: tensor([[0.7245, 0.2755]], device='cuda:0', grad_fn=<SoftmaxBackward0>)m [2;4m0.00it/s[0m  
[2KAttention weights: tensor([[0.7219, 0.2781]], device='cuda:0', grad_fn=<SoftmaxBackward0>)m [2;4m0.00it/s[0m  
[2KAttention weights: tensor([[0.7213, 0.2787]], device='cuda:0', grad_fn=<SoftmaxBackward0>)m [2;4m0.00it/s[0m  
[2KAttention weights: tensor([[0.7210, 0.2790]], device='cuda:0', grad_fn=<SoftmaxBackward0>)m [2;4m0.00it/s[0m  
[2KAttention weights: tensor([[0.7206, 0.2794]], device='cuda:0', grad_fn=<SoftmaxBackward0>)m [2;4m0.00it/s[0m  
[2KAttention weights: tensor([[0.7204, 0.2796]], device='cuda:0', grad_fn=<SoftmaxBackward0>)m [2;4m0.00it/s[0m  
[2KAttention weights: tensor([[0.5236, 0.4764]], device='cuda:0')203 [2m0:00:00 â€¢ -:--:--[0m [2;4m0.00it/s[0m  
[2KAttention weights: tensor([[0.6113, 0.3887],â”â”â”â”â”â”â”â”â”â”â”[0m 0/203 [2m0:00:00 â€¢ -:--:--[0m [2;4m0.00it/s[0m  
        [0.4476, 0.5524],
        [0.5013, 0.4987],
        [0.6151, 0.3849],
        [0.6023, 0.3977],
        [0.7211, 0.2789],
        [0.6703, 0.3297],
        [0.6185, 0.3815],
        [0.5317, 0.4683],
[2K        [0.6104, 0.3896]], device='cuda:0')â”â”â”â”â”â”â”â”â”â”â”â”[0m 0/203 [2m0:00:00 â€¢ -:--:--[0m [2;4m0.00it/s[0m  
[2KAttention weights: tensor([[0.5203, 0.4797],â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 1/203 [2m0:00:00 â€¢ -:--:--[0m [2;4m0.00it/s[0m  
        [0.5122, 0.4878],
        [0.5139, 0.4861],
        [0.5196, 0.4804],
        [0.5213, 0.4787],
        [0.5240, 0.4760],
        [0.5213, 0.4787],
        [0.5184, 0.4816],
        [0.5153, 0.4847],
[2K        [0.5215, 0.4785]], device='cuda:0', grad_fn=<SoftmaxBackward0>):00:00 â€¢ -:--:--[0m [2;4m0.00it/s[0m  
[2KClass label: HighJumpâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 1/203 [2m0:00:00 â€¢ -:--:--[0m [2;4m0.00it/s[0m  
[2KAttention weights: tensor([[0.6825, 0.3175]], device='cuda:0', grad_fn=<SoftmaxBackward0>)m [2;4m0.00it/s[0m  
[2KStep 0 - TTA Loss: 1.7808â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 1/203 [2m0:00:00 â€¢ -:--:--[0m [2;4m0.00it/s[0m  
[2KAttention weights: tensor([[0.6825, 0.3175]], device='cuda:0', grad_fn=<SoftmaxBackward0>)m [2;4m0.00it/s[0m  
[2KAttention weights: tensor([[0.6826, 0.3174]], device='cuda:0', grad_fn=<SoftmaxBackward0>)m [2;4m0.00it/s[0m  
[2KAttention weights: tensor([[0.6831, 0.3169]], device='cuda:0', grad_fn=<SoftmaxBackward0>)m [2;4m0.00it/s[0m  
[2KAttention weights: tensor([[0.6872, 0.3128]], device='cuda:0', grad_fn=<SoftmaxBackward0>)m [2;4m0.00it/s[0m  
[2KAttention weights: tensor([[0.6984, 0.3016]], device='cuda:0', grad_fn=<SoftmaxBackward0>)m [2;4m0.00it/s[0m  
[2KAttention weights: tensor([[0.7167, 0.2833]], device='cuda:0', grad_fn=<SoftmaxBackward0>)m [2;4m0.00it/s[0m  
[2KAttention weights: tensor([[0.7514, 0.2486]], device='cuda:0', grad_fn=<SoftmaxBackward0>)m [2;4m0.00it/s[0m  
[2KAttention weights: tensor([[0.7939, 0.2061]], device='cuda:0', grad_fn=<SoftmaxBackward0>)m [2;4m0.00it/s[0m  
[2KAttention weights: tensor([[0.8348, 0.1652]], device='cuda:0', grad_fn=<SoftmaxBackward0>)m [2;4m0.00it/s[0m  
[2KAttention weights: tensor([[0.5309, 0.4691]], device='cuda:0')203 [2m0:00:00 â€¢ -:--:--[0m [2;4m0.00it/s[0m  
[2KAttention weights: tensor([[0.6935, 0.3065],â”â”â”â”â”â”â”â”â”â”â”[0m 1/203 [2m0:00:00 â€¢ -:--:--[0m [2;4m0.00it/s[0m  
        [0.4602, 0.5398],
        [0.5393, 0.4607],
        [0.6813, 0.3187],
        [0.7369, 0.2631],
        [0.8683, 0.1317],
        [0.7945, 0.2055],
        [0.6958, 0.3042],
        [0.6189, 0.3811],
[2K        [0.7503, 0.2497]], device='cuda:0')â”â”â”â”â”â”â”â”â”â”â”â”[0m 1/203 [2m0:00:00 â€¢ -:--:--[0m [2;4m0.00it/s[0m  
[2KAttention weights: tensor([[0.5203, 0.4797],â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 2/203 [2m0:00:01 â€¢ 0:01:16[0m [2;4m2.68it/s[0m  
        [0.5122, 0.4878],
        [0.5140, 0.4860],
        [0.5196, 0.4804],
        [0.5213, 0.4787],
        [0.5240, 0.4760],
        [0.5214, 0.4786],
        [0.5184, 0.4816],
        [0.5153, 0.4847],
[2K        [0.5215, 0.4785]], device='cuda:0', grad_fn=<SoftmaxBackward0>):00:01 â€¢ 0:01:16[0m [2;4m2.68it/s[0m  
[2KClass label: TennisSwingâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 2/203 [2m0:00:01 â€¢ 0:01:16[0m [2;4m2.68it/s[0m  
[2KAttention weights: tensor([[0.5189, 0.4811]], device='cuda:0', grad_fn=<SoftmaxBackward0>)m [2;4m2.68it/s[0m  
[2KStep 0 - TTA Loss: 1.5833â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 2/203 [2m0:00:01 â€¢ 0:01:16[0m [2;4m2.68it/s[0m  
[2KAttention weights: tensor([[0.5301, 0.4699]], device='cuda:0', grad_fn=<SoftmaxBackward0>)m [2;4m2.68it/s[0m  
[2KAttention weights: tensor([[0.5390, 0.4610]], device='cuda:0', grad_fn=<SoftmaxBackward0>)m [2;4m2.68it/s[0m  
[2KAttention weights: tensor([[0.5466, 0.4534]], device='cuda:0', grad_fn=<SoftmaxBackward0>)m [2;4m2.68it/s[0m  
[2KAttention weights: tensor([[0.5547, 0.4453]], device='cuda:0', grad_fn=<SoftmaxBackward0>)m [2;4m2.68it/s[0m  
[2KAttention weights: tensor([[0.5612, 0.4388]], device='cuda:0', grad_fn=<SoftmaxBackward0>)m [2;4m2.68it/s[0m  
[2KAttention weights: tensor([[0.5689, 0.4311]], device='cuda:0', grad_fn=<SoftmaxBackward0>)m [2;4m2.68it/s[0m  
[2KAttention weights: tensor([[0.5775, 0.4225]], device='cuda:0', grad_fn=<SoftmaxBackward0>)m [2;4m2.68it/s[0m  
[2KAttention weights: tensor([[0.5816, 0.4184]], device='cuda:0', grad_fn=<SoftmaxBackward0>)m [2;4m2.68it/s[0m  
[2KAttention weights: tensor([[0.5833, 0.4167]], device='cuda:0', grad_fn=<SoftmaxBackward0>)m [2;4m2.68it/s[0m  
[2KAttention weights: tensor([[0.5173, 0.4827]], device='cuda:0')203 [2m0:00:01 â€¢ 0:01:16[0m [2;4m2.68it/s[0m  
[2KAttention weights: tensor([[0.6802, 0.3198],â”â”â”â”â”â”â”â”â”â”â”[0m 2/203 [2m0:00:01 â€¢ 0:01:16[0m [2;4m2.68it/s[0m  
        [0.4528, 0.5472],
        [0.5314, 0.4686],
        [0.6700, 0.3300],
        [0.7171, 0.2829],
        [0.8537, 0.1463],
        [0.7819, 0.2181],
        [0.6845, 0.3155],
        [0.5838, 0.4162],
[2K        [0.7284, 0.2716]], device='cuda:0')â”â”â”â”â”â”â”â”â”â”â”â”[0m 2/203 [2m0:00:01 â€¢ 0:01:16[0m [2;4m2.68it/s[0m  
[2KAttention weights: tensor([[0.5204, 0.4796],â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 3/203 [2m0:00:01 â€¢ 0:01:10[0m [2;4m2.86it/s[0m  
        [0.5123, 0.4877],
        [0.5140, 0.4860],
        [0.5197, 0.4803],
        [0.5214, 0.4786],
        [0.5241, 0.4759],
        [0.5215, 0.4785],
        [0.5185, 0.4815],
        [0.5154, 0.4846],
[2K        [0.5216, 0.4784]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”[0m 3/203 [2m0:00:01 â€¢ 0:01:10[0m [2;4m2.86it/s[0m  
[2KClass label: HighJump[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 3/203 [2m0:00:01 â€¢ 0:01:10[0m [2;4m2.86it/s[0m  
[2KAttention weights: tensor([[0.6886, 0.3114]], device='cuda:0', grad_fn=<SoftmaxBackward0>)0:00:01 â€¢ 0:01:10[0m [2;4m2.86it/s[0m  
[2KStep 0 - TTA Loss: 1.2512[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 3/203 [2m0:00:01 â€¢ 0:01:10[0m [2;4m2.86it/s[0m  
[2KAttention weights: tensor([[0.6886, 0.3114]], device='cuda:0', grad_fn=<SoftmaxBackward0>)0:00:01 â€¢ 0:01:10[0m [2;4m2.86it/s[0m  
[2KAttention weights: tensor([[0.6890, 0.3110]], device='cuda:0', grad_fn=<SoftmaxBackward0>)0:00:01 â€¢ 0:01:10[0m [2;4m2.86it/s[0m  
[2KAttention weights: tensor([[0.6904, 0.3096]], device='cuda:0', grad_fn=<SoftmaxBackward0>)0:00:01 â€¢ 0:01:10[0m [2;4m2.86it/s[0m  
[2KAttention weights: tensor([[0.6926, 0.3074]], device='cuda:0', grad_fn=<SoftmaxBackward0>)0:00:01 â€¢ 0:01:10[0m [2;4m2.86it/s[0m  
[2KAttention weights: tensor([[0.6962, 0.3038]], device='cuda:0', grad_fn=<SoftmaxBackward0>)0:00:01 â€¢ 0:01:10[0m [2;4m2.86it/s[0m  
[2KAttention weights: tensor([[0.7009, 0.2991]], device='cuda:0', grad_fn=<SoftmaxBackward0>)0:00:01 â€¢ 0:01:10[0m [2;4m2.86it/s[0m  
[2KAttention weights: tensor([[0.7068, 0.2932]], device='cuda:0', grad_fn=<SoftmaxBackward0>)0:00:01 â€¢ 0:01:10[0m [2;4m2.86it/s[0m  
[2KAttention weights: tensor([[0.7206, 0.2794]], device='cuda:0', grad_fn=<SoftmaxBackward0>)0:00:01 â€¢ 0:01:10[0m [2;4m2.86it/s[0m  
[2KAttention weights: tensor([[0.7391, 0.2609]], device='cuda:0', grad_fn=<SoftmaxBackward0>)0:00:01 â€¢ 0:01:10[0m [2;4m2.86it/s[0m  
[2KAttention weights: tensor([[0.5277, 0.4723]], device='cuda:0')â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 3/203 [2m0:00:01 â€¢ 0:01:10[0m [2;4m2.86it/s[0m  
[2KAttention weights: tensor([[0.6332, 0.3668],â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 3/203 [2m0:00:01 â€¢ 0:01:10[0m [2;4m2.86it/s[0m  
        [0.4508, 0.5492],
        [0.5085, 0.4915],
        [0.6301, 0.3699],
        [0.6349, 0.3651],
        [0.7602, 0.2398],
        [0.6965, 0.3035],
        [0.6354, 0.3646],
        [0.5639, 0.4361],
[2K        [0.6450, 0.3550]], device='cuda:0')â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 3/203 [2m0:00:01 â€¢ 0:01:10[0m [2;4m2.86it/s[0m  
[2KAttention weights: tensor([[0.5204, 0.4796],â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 4/203 [2m0:00:02 â€¢ 0:01:18[0m [2;4m2.56it/s[0m  
        [0.5123, 0.4877],
        [0.5140, 0.4860],
        [0.5197, 0.4803],
        [0.5214, 0.4786],
        [0.5241, 0.4759],
        [0.5215, 0.4785],
        [0.5185, 0.4815],
        [0.5154, 0.4846],
[2K        [0.5216, 0.4784]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”[0m 4/203 [2m0:00:02 â€¢ 0:01:18[0m [2;4m2.56it/s[0m  
[2KClass label: GolfSwing[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 4/203 [2m0:00:02 â€¢ 0:01:18[0m [2;4m2.56it/s[0m  
[2KAttention weights: tensor([[0.5972, 0.4028]], device='cuda:0', grad_fn=<SoftmaxBackward0>)0:00:02 â€¢ 0:01:18[0m [2;4m2.56it/s[0m  
[2KStep 0 - TTA Loss: 1.1763[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 4/203 [2m0:00:02 â€¢ 0:01:18[0m [2;4m2.56it/s[0m  
[2KAttention weights: tensor([[0.6039, 0.3961]], device='cuda:0', grad_fn=<SoftmaxBackward0>)0:00:02 â€¢ 0:01:18[0m [2;4m2.56it/s[0m  
[2KAttention weights: tensor([[0.6116, 0.3884]], device='cuda:0', grad_fn=<SoftmaxBackward0>)0:00:02 â€¢ 0:01:18[0m [2;4m2.56it/s[0m  
[2KAttention weights: tensor([[0.6234, 0.3766]], device='cuda:0', grad_fn=<SoftmaxBackward0>)0:00:02 â€¢ 0:01:18[0m [2;4m2.56it/s[0m  
[2KAttention weights: tensor([[0.6300, 0.3700]], device='cuda:0', grad_fn=<SoftmaxBackward0>)0:00:02 â€¢ 0:01:18[0m [2;4m2.56it/s[0m  
[2KAttention weights: tensor([[0.6359, 0.3641]], device='cuda:0', grad_fn=<SoftmaxBackward0>)0:00:02 â€¢ 0:01:18[0m [2;4m2.56it/s[0m  
[2KAttention weights: tensor([[0.6404, 0.3596]], device='cuda:0', grad_fn=<SoftmaxBackward0>)0:00:02 â€¢ 0:01:18[0m [2;4m2.56it/s[0m  
[2KAttention weights: tensor([[0.6435, 0.3565]], device='cuda:0', grad_fn=<SoftmaxBackward0>)0:00:02 â€¢ 0:01:18[0m [2;4m2.56it/s[0m  
[2KAttention weights: tensor([[0.6451, 0.3549]], device='cuda:0', grad_fn=<SoftmaxBackward0>)0:00:02 â€¢ 0:01:18[0m [2;4m2.56it/s[0m  
[2KAttention weights: tensor([[0.6457, 0.3543]], device='cuda:0', grad_fn=<SoftmaxBackward0>)0:00:02 â€¢ 0:01:18[0m [2;4m2.56it/s[0m  
[2KAttention weights: tensor([[0.5220, 0.4780]], device='cuda:0')â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 4/203 [2m0:00:02 â€¢ 0:01:18[0m [2;4m2.56it/s[0m  
[2KAttention weights: tensor([[0.6411, 0.3589],â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 4/203 [2m0:00:02 â€¢ 0:01:18[0m [2;4m2.56it/s[0m  
        [0.4562, 0.5438],
        [0.5094, 0.4906],
        [0.6462, 0.3538],
        [0.6420, 0.3580],
        [0.7716, 0.2284],
        [0.7086, 0.2914],
        [0.6421, 0.3579],
        [0.5604, 0.4396],
[2K        [0.6556, 0.3444]], device='cuda:0')â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 4/203 [2m0:00:02 â€¢ 0:01:18[0m [2;4m2.56it/s[0m  
[2KAttention weights: tensor([[0.5204, 0.4796],â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 5/203 [2m0:00:02 â€¢ 0:01:16[0m [2;4m2.62it/s[0m  
        [0.5123, 0.4877],
        [0.5140, 0.4860],
        [0.5197, 0.4803],
        [0.5214, 0.4786],
        [0.5241, 0.4759],
        [0.5215, 0.4785],
        [0.5185, 0.4815],
        [0.5154, 0.4846],
[2K        [0.5216, 0.4784]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”[0m 5/203 [2m0:00:02 â€¢ 0:01:16[0m [2;4m2.62it/s[0m  
[2KClass label: HammerThrowm[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 5/203 [2m0:00:02 â€¢ 0:01:16[0m [2;4m2.62it/s[0m  
[2KAttention weights: tensor([[0.5782, 0.4218]], device='cuda:0', grad_fn=<SoftmaxBackward0>)0:00:02 â€¢ 0:01:16[0m [2;4m2.62it/s[0m  
[2KStep 0 - TTA Loss: 1.3421[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 5/203 [2m0:00:02 â€¢ 0:01:16[0m [2;4m2.62it/s[0m  
[2KAttention weights: tensor([[0.5782, 0.4218]], device='cuda:0', grad_fn=<SoftmaxBackward0>)0:00:02 â€¢ 0:01:16[0m [2;4m2.62it/s[0m  
[2KAttention weights: tensor([[0.5787, 0.4213]], device='cuda:0', grad_fn=<SoftmaxBackward0>)0:00:02 â€¢ 0:01:16[0m [2;4m2.62it/s[0m  
[2KAttention weights: tensor([[0.5816, 0.4184]], device='cuda:0', grad_fn=<SoftmaxBackward0>)0:00:02 â€¢ 0:01:16[0m [2;4m2.62it/s[0m  
[2KAttention weights: tensor([[0.5873, 0.4127]], device='cuda:0', grad_fn=<SoftmaxBackward0>)0:00:02 â€¢ 0:01:16[0m [2;4m2.62it/s[0m  
[2KAttention weights: tensor([[0.5975, 0.4025]], device='cuda:0', grad_fn=<SoftmaxBackward0>)0:00:02 â€¢ 0:01:16[0m [2;4m2.62it/s[0m  
[2KAttention weights: tensor([[0.6147, 0.3853]], device='cuda:0', grad_fn=<SoftmaxBackward0>)0:00:02 â€¢ 0:01:16[0m [2;4m2.62it/s[0m  
[2KAttention weights: tensor([[0.6343, 0.3657]], device='cuda:0', grad_fn=<SoftmaxBackward0>)0:00:02 â€¢ 0:01:16[0m [2;4m2.62it/s[0m  
[2KAttention weights: tensor([[0.6580, 0.3420]], device='cuda:0', grad_fn=<SoftmaxBackward0>)0:00:02 â€¢ 0:01:16[0m [2;4m2.62it/s[0m  
[2KAttention weights: tensor([[0.6841, 0.3159]], device='cuda:0', grad_fn=<SoftmaxBackward0>)0:00:02 â€¢ 0:01:16[0m [2;4m2.62it/s[0m  
[2KAttention weights: tensor([[0.5252, 0.4748]], device='cuda:0')â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 5/203 [2m0:00:02 â€¢ 0:01:16[0m [2;4m2.62it/s[0m  
[2KAttention weights: tensor([[0.6738, 0.3262],â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 5/203 [2m0:00:02 â€¢ 0:01:16[0m [2;4m2.62it/s[0m  
        [0.4619, 0.5381],
        [0.5258, 0.4742],
        [0.6671, 0.3329],
        [0.7138, 0.2862],
        [0.7534, 0.2466],
        [0.7067, 0.2933],
        [0.6406, 0.3594],
        [0.5556, 0.4444],
[2K        [0.6935, 0.3065]], device='cuda:0')â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 5/203 [2m0:00:02 â€¢ 0:01:16[0m [2;4m2.62it/s[0m  
[2KAttention weights: tensor([[0.5204, 0.4796],m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 6/203 [2m0:00:02 â€¢ 0:01:15[0m [2;4m2.63it/s[0m  
        [0.5123, 0.4877],
        [0.5140, 0.4860],
        [0.5197, 0.4803],
        [0.5214, 0.4786],
        [0.5241, 0.4759],
        [0.5215, 0.4785],
        [0.5185, 0.4815],
        [0.5154, 0.4846],
[2K        [0.5216, 0.4784]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 6/203 [2m0:00:02 â€¢ 0:01:15[0m [2;4m2.63it/s[0m  
[2KClass label: HammerThrowm[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 6/203 [2m0:00:02 â€¢ 0:01:15[0m [2;4m2.63it/s[0m  
[2KAttention weights: tensor([[0.5722, 0.4278]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 6/203 [2m0:00:02 â€¢ 0:01:15[0m [2;4m2.63it/s[0m  
[2KStep 0 - TTA Loss: 0.9956[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 6/203 [2m0:00:02 â€¢ 0:01:15[0m [2;4m2.63it/s[0m  
[2KAttention weights: tensor([[0.5952, 0.4048]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 6/203 [2m0:00:02 â€¢ 0:01:15[0m [2;4m2.63it/s[0m  
[2KAttention weights: tensor([[0.6133, 0.3867]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 6/203 [2m0:00:02 â€¢ 0:01:15[0m [2;4m2.63it/s[0m  
[2KAttention weights: tensor([[0.6300, 0.3700]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 6/203 [2m0:00:02 â€¢ 0:01:15[0m [2;4m2.63it/s[0m  
[2KAttention weights: tensor([[0.6488, 0.3512]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 6/203 [2m0:00:02 â€¢ 0:01:15[0m [2;4m2.63it/s[0m  
[2KAttention weights: tensor([[0.6657, 0.3343]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 6/203 [2m0:00:02 â€¢ 0:01:15[0m [2;4m2.63it/s[0m  
[2KAttention weights: tensor([[0.6790, 0.3210]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 6/203 [2m0:00:02 â€¢ 0:01:15[0m [2;4m2.63it/s[0m  
[2KAttention weights: tensor([[0.6880, 0.3120]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 6/203 [2m0:00:02 â€¢ 0:01:15[0m [2;4m2.63it/s[0m  
[2KAttention weights: tensor([[0.6921, 0.3079]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 6/203 [2m0:00:02 â€¢ 0:01:15[0m [2;4m2.63it/s[0m  
[2KAttention weights: tensor([[0.6938, 0.3062]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 6/203 [2m0:00:02 â€¢ 0:01:15[0m [2;4m2.63it/s[0m  
[2KAttention weights: tensor([[0.5247, 0.4753]], device='cuda:0')â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 6/203 [2m0:00:02 â€¢ 0:01:15[0m [2;4m2.63it/s[0m  
[2KAttention weights: tensor([[0.6645, 0.3355],8;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 6/203 [2m0:00:02 â€¢ 0:01:15[0m [2;4m2.63it/s[0m  
        [0.4595, 0.5405],
        [0.5258, 0.4742],
        [0.6527, 0.3473],
        [0.6942, 0.3058],
        [0.7413, 0.2587],
        [0.6952, 0.3048],
        [0.6343, 0.3657],
        [0.5491, 0.4509],
[2K        [0.6787, 0.3213]], device='cuda:0')38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 6/203 [2m0:00:02 â€¢ 0:01:15[0m [2;4m2.63it/s[0m  
[2KAttention weights: tensor([[0.5204, 0.4796],m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 7/203 [2m0:00:03 â€¢ 0:01:16[0m [2;4m2.60it/s[0m  
        [0.5123, 0.4877],
        [0.5141, 0.4859],
        [0.5197, 0.4803],
        [0.5214, 0.4786],
        [0.5241, 0.4759],
        [0.5215, 0.4785],
        [0.5185, 0.4815],
        [0.5154, 0.4846],
[2K        [0.5216, 0.4784]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 7/203 [2m0:00:03 â€¢ 0:01:16[0m [2;4m2.60it/s[0m  
[2KClass label: Billiards[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 7/203 [2m0:00:03 â€¢ 0:01:16[0m [2;4m2.60it/s[0m  
[2KAttention weights: tensor([[0.4434, 0.5566]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 7/203 [2m0:00:03 â€¢ 0:01:16[0m [2;4m2.60it/s[0m  
[2KStep 0 - TTA Loss: 0.7608[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 7/203 [2m0:00:03 â€¢ 0:01:16[0m [2;4m2.60it/s[0m  
[2KAttention weights: tensor([[0.4434, 0.5566]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 7/203 [2m0:00:03 â€¢ 0:01:16[0m [2;4m2.60it/s[0m  
[2KAttention weights: tensor([[0.4433, 0.5567]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 7/203 [2m0:00:03 â€¢ 0:01:16[0m [2;4m2.60it/s[0m  
[2KAttention weights: tensor([[0.4431, 0.5569]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 7/203 [2m0:00:03 â€¢ 0:01:16[0m [2;4m2.60it/s[0m  
[2KAttention weights: tensor([[0.4423, 0.5577]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 7/203 [2m0:00:03 â€¢ 0:01:16[0m [2;4m2.60it/s[0m  
[2KAttention weights: tensor([[0.4400, 0.5600]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 7/203 [2m0:00:03 â€¢ 0:01:16[0m [2;4m2.60it/s[0m  
[2KAttention weights: tensor([[0.4356, 0.5644]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 7/203 [2m0:00:03 â€¢ 0:01:16[0m [2;4m2.60it/s[0m  
[2KAttention weights: tensor([[0.4318, 0.5682]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 7/203 [2m0:00:03 â€¢ 0:01:16[0m [2;4m2.60it/s[0m  
[2KAttention weights: tensor([[0.4237, 0.5763]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 7/203 [2m0:00:03 â€¢ 0:01:16[0m [2;4m2.60it/s[0m  
[2KAttention weights: tensor([[0.4126, 0.5874]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 7/203 [2m0:00:03 â€¢ 0:01:16[0m [2;4m2.60it/s[0m  
[2KAttention weights: tensor([[0.5112, 0.4888]], device='cuda:0')â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 7/203 [2m0:00:03 â€¢ 0:01:16[0m [2;4m2.60it/s[0m  
[2KAttention weights: tensor([[0.6014, 0.3986],8;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 7/203 [2m0:00:03 â€¢ 0:01:16[0m [2;4m2.60it/s[0m  
        [0.3995, 0.6005],
        [0.4945, 0.5055],
        [0.5965, 0.4035],
        [0.5804, 0.4196],
        [0.6891, 0.3109],
        [0.6448, 0.3552],
        [0.5989, 0.4011],
        [0.5139, 0.4861],
[2K        [0.5869, 0.4131]], device='cuda:0')38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 7/203 [2m0:00:03 â€¢ 0:01:16[0m [2;4m2.60it/s[0m  
[2KAttention weights: tensor([[0.5204, 0.4796],mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 8/203 [2m0:00:03 â€¢ 0:01:14[0m [2;4m2.64it/s[0m  
        [0.5123, 0.4877],
        [0.5140, 0.4860],
        [0.5197, 0.4803],
        [0.5214, 0.4786],
        [0.5241, 0.4759],
        [0.5215, 0.4785],
        [0.5185, 0.4815],
        [0.5154, 0.4846],
[2K        [0.5216, 0.4784]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 8/203 [2m0:00:03 â€¢ 0:01:14[0m [2;4m2.64it/s[0m  
[2KClass label: BaseballPitch[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 8/203 [2m0:00:03 â€¢ 0:01:14[0m [2;4m2.64it/s[0m  
[2KAttention weights: tensor([[0.6037, 0.3963]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 8/203 [2m0:00:03 â€¢ 0:01:14[0m [2;4m2.64it/s[0m  
[2KStep 0 - TTA Loss: 1.6968[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 8/203 [2m0:00:03 â€¢ 0:01:14[0m [2;4m2.64it/s[0m  
[2KAttention weights: tensor([[0.5969, 0.4031]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 8/203 [2m0:00:03 â€¢ 0:01:14[0m [2;4m2.64it/s[0m  
[2KAttention weights: tensor([[0.5799, 0.4201]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 8/203 [2m0:00:03 â€¢ 0:01:14[0m [2;4m2.64it/s[0m  
[2KAttention weights: tensor([[0.5598, 0.4402]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 8/203 [2m0:00:03 â€¢ 0:01:14[0m [2;4m2.64it/s[0m  
[2KAttention weights: tensor([[0.5388, 0.4612]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 8/203 [2m0:00:03 â€¢ 0:01:14[0m [2;4m2.64it/s[0m  
[2KAttention weights: tensor([[0.5180, 0.4820]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 8/203 [2m0:00:03 â€¢ 0:01:14[0m [2;4m2.64it/s[0m  
[2KAttention weights: tensor([[0.5072, 0.4928]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 8/203 [2m0:00:03 â€¢ 0:01:14[0m [2;4m2.64it/s[0m  
[2KAttention weights: tensor([[0.5002, 0.4998]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 8/203 [2m0:00:03 â€¢ 0:01:14[0m [2;4m2.64it/s[0m  
[2KAttention weights: tensor([[0.4963, 0.5037]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 8/203 [2m0:00:03 â€¢ 0:01:14[0m [2;4m2.64it/s[0m  
[2KAttention weights: tensor([[0.4950, 0.5050]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 8/203 [2m0:00:03 â€¢ 0:01:14[0m [2;4m2.64it/s[0m  
[2KAttention weights: tensor([[0.5174, 0.4826]], device='cuda:0')â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 8/203 [2m0:00:03 â€¢ 0:01:14[0m [2;4m2.64it/s[0m  
[2KAttention weights: tensor([[0.4947, 0.5053],0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 8/203 [2m0:00:03 â€¢ 0:01:14[0m [2;4m2.64it/s[0m  
        [0.3857, 0.6143],
        [0.4723, 0.5277],
        [0.5626, 0.4374],
        [0.5314, 0.4686],
        [0.6633, 0.3367],
        [0.6194, 0.3806],
        [0.6003, 0.3997],
        [0.4847, 0.5153],
[2K        [0.5335, 0.4665]], device='cuda:0')[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 8/203 [2m0:00:03 â€¢ 0:01:14[0m [2;4m2.64it/s[0m  
[2KAttention weights: tensor([[0.5204, 0.4796],mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 9/203 [2m0:00:03 â€¢ 0:01:14[0m [2;4m2.63it/s[0m  
        [0.5122, 0.4878],
        [0.5140, 0.4860],
        [0.5197, 0.4803],
        [0.5214, 0.4786],
        [0.5241, 0.4759],
        [0.5215, 0.4785],
        [0.5185, 0.4815],
        [0.5154, 0.4846],
[2K        [0.5216, 0.4784]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 9/203 [2m0:00:03 â€¢ 0:01:14[0m [2;4m2.63it/s[0m  
[2KClass label: BaseballPitch[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 9/203 [2m0:00:03 â€¢ 0:01:14[0m [2;4m2.63it/s[0m  
[2KAttention weights: tensor([[0.5943, 0.4057]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 9/203 [2m0:00:03 â€¢ 0:01:14[0m [2;4m2.63it/s[0m  
[2KStep 0 - TTA Loss: 2.7567[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 9/203 [2m0:00:03 â€¢ 0:01:14[0m [2;4m2.63it/s[0m  
[2KAttention weights: tensor([[0.5943, 0.4057]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 9/203 [2m0:00:03 â€¢ 0:01:14[0m [2;4m2.63it/s[0m  
[2KAttention weights: tensor([[0.5933, 0.4067]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 9/203 [2m0:00:03 â€¢ 0:01:14[0m [2;4m2.63it/s[0m  
[2KAttention weights: tensor([[0.5890, 0.4110]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 9/203 [2m0:00:03 â€¢ 0:01:14[0m [2;4m2.63it/s[0m  
[2KAttention weights: tensor([[0.5787, 0.4213]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 9/203 [2m0:00:03 â€¢ 0:01:14[0m [2;4m2.63it/s[0m  
[2KAttention weights: tensor([[0.5580, 0.4420]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 9/203 [2m0:00:03 â€¢ 0:01:14[0m [2;4m2.63it/s[0m  
[2KAttention weights: tensor([[0.5343, 0.4657]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 9/203 [2m0:00:03 â€¢ 0:01:14[0m [2;4m2.63it/s[0m  
[2KAttention weights: tensor([[0.4962, 0.5038]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 9/203 [2m0:00:03 â€¢ 0:01:14[0m [2;4m2.63it/s[0m  
[2KAttention weights: tensor([[0.4554, 0.5446]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 9/203 [2m0:00:03 â€¢ 0:01:14[0m [2;4m2.63it/s[0m  
[2KAttention weights: tensor([[0.4214, 0.5786]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 9/203 [2m0:00:03 â€¢ 0:01:14[0m [2;4m2.63it/s[0m  
[2KAttention weights: tensor([[0.5157, 0.4843]], device='cuda:0')â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 9/203 [2m0:00:03 â€¢ 0:01:14[0m [2;4m2.63it/s[0m  
[2KAttention weights: tensor([[0.3941, 0.6059],0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 9/203 [2m0:00:03 â€¢ 0:01:14[0m [2;4m2.63it/s[0m  
        [0.4167, 0.5833],
        [0.4564, 0.5436],
        [0.5312, 0.4688],
        [0.4850, 0.5150],
        [0.6366, 0.3634],
        [0.5907, 0.4093],
        [0.6019, 0.3981],
        [0.4625, 0.5375],
[2K        [0.4877, 0.5123]], device='cuda:0')[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 9/203 [2m0:00:03 â€¢ 0:01:14[0m [2;4m2.63it/s[0m  
[2KAttention weights: tensor([[0.5204, 0.4796],mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 10/203 [2m0:00:04 â€¢ 0:01:13[0m [2;4m2.67it/s[0m  
        [0.5123, 0.4877],
        [0.5140, 0.4860],
        [0.5197, 0.4803],
        [0.5214, 0.4786],
        [0.5241, 0.4759],
        [0.5215, 0.4785],
        [0.5185, 0.4815],
        [0.5154, 0.4846],
[2K        [0.5216, 0.4784]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 10/203 [2m0:00:04 â€¢ 0:01:13[0m [2;4m2.67it/s[0m  
[2KClass label: TennisSwingm[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 10/203 [2m0:00:04 â€¢ 0:01:13[0m [2;4m2.67it/s[0m  
[2KAttention weights: tensor([[0.5146, 0.4854]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 10/203 [2m0:00:04 â€¢ 0:01:13[0m [2;4m2.67it/s[0m  
[2KStep 0 - TTA Loss: 1.2985[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 10/203 [2m0:00:04 â€¢ 0:01:13[0m [2;4m2.67it/s[0m  
[2KAttention weights: tensor([[0.5117, 0.4883]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 10/203 [2m0:00:04 â€¢ 0:01:13[0m [2;4m2.67it/s[0m  
[2KAttention weights: tensor([[0.5018, 0.4982]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 10/203 [2m0:00:04 â€¢ 0:01:13[0m [2;4m2.67it/s[0m  
[2KAttention weights: tensor([[0.4980, 0.5020]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 10/203 [2m0:00:04 â€¢ 0:01:13[0m [2;4m2.67it/s[0m  
[2KAttention weights: tensor([[0.4972, 0.5028]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 10/203 [2m0:00:04 â€¢ 0:01:13[0m [2;4m2.67it/s[0m  
[2KAttention weights: tensor([[0.4971, 0.5029]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 10/203 [2m0:00:04 â€¢ 0:01:13[0m [2;4m2.67it/s[0m  
[2KAttention weights: tensor([[0.4982, 0.5018]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 10/203 [2m0:00:04 â€¢ 0:01:13[0m [2;4m2.67it/s[0m  
[2KAttention weights: tensor([[0.5011, 0.4989]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 10/203 [2m0:00:04 â€¢ 0:01:13[0m [2;4m2.67it/s[0m  
[2KAttention weights: tensor([[0.5019, 0.4981]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 10/203 [2m0:00:04 â€¢ 0:01:13[0m [2;4m2.67it/s[0m  
[2KAttention weights: tensor([[0.5021, 0.4979]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 10/203 [2m0:00:04 â€¢ 0:01:13[0m [2;4m2.67it/s[0m  
[2KAttention weights: tensor([[0.5150, 0.4850]], device='cuda:0')â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 10/203 [2m0:00:04 â€¢ 0:01:13[0m [2;4m2.67it/s[0m  
[2KAttention weights: tensor([[0.4943, 0.5057],0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 10/203 [2m0:00:04 â€¢ 0:01:13[0m [2;4m2.67it/s[0m  
        [0.4347, 0.5653],
        [0.4798, 0.5202],
        [0.5699, 0.4301],
        [0.5335, 0.4665],
        [0.6674, 0.3326],
        [0.6196, 0.3804],
        [0.6060, 0.3940],
        [0.5020, 0.4980],
[2K        [0.5409, 0.4591]], device='cuda:0')[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 10/203 [2m0:00:04 â€¢ 0:01:13[0m [2;4m2.67it/s[0m  
[2KAttention weights: tensor([[0.5205, 0.4795],0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 11/203 [2m0:00:04 â€¢ 0:01:12[0m [2;4m2.67it/s[0m   
        [0.5123, 0.4877],
        [0.5140, 0.4860],
        [0.5197, 0.4803],
        [0.5214, 0.4786],
        [0.5241, 0.4759],
        [0.5215, 0.4785],
        [0.5185, 0.4815],
        [0.5154, 0.4846],
[2K        [0.5216, 0.4784]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 11/203 [2m0:00:04 â€¢ 0:01:12[0m [2;4m2.67it/s[0m  
[2KClass label: HammerThrow0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 11/203 [2m0:00:04 â€¢ 0:01:12[0m [2;4m2.67it/s[0m  
[2KAttention weights: tensor([[0.5752, 0.4248]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 11/203 [2m0:00:04 â€¢ 0:01:12[0m [2;4m2.67it/s[0m  
[2KStep 0 - TTA Loss: 1.8248m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 11/203 [2m0:00:04 â€¢ 0:01:12[0m [2;4m2.67it/s[0m  
[2KAttention weights: tensor([[0.5752, 0.4248]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 11/203 [2m0:00:04 â€¢ 0:01:12[0m [2;4m2.67it/s[0m  
[2KAttention weights: tensor([[0.5750, 0.4250]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 11/203 [2m0:00:04 â€¢ 0:01:12[0m [2;4m2.67it/s[0m  
[2KAttention weights: tensor([[0.5730, 0.4270]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 11/203 [2m0:00:04 â€¢ 0:01:12[0m [2;4m2.67it/s[0m  
[2KAttention weights: tensor([[0.5686, 0.4314]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 11/203 [2m0:00:04 â€¢ 0:01:12[0m [2;4m2.67it/s[0m  
[2KAttention weights: tensor([[0.5635, 0.4365]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 11/203 [2m0:00:04 â€¢ 0:01:12[0m [2;4m2.67it/s[0m  
[2KAttention weights: tensor([[0.5496, 0.4504]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 11/203 [2m0:00:04 â€¢ 0:01:12[0m [2;4m2.67it/s[0m  
[2KAttention weights: tensor([[0.5312, 0.4688]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 11/203 [2m0:00:04 â€¢ 0:01:12[0m [2;4m2.67it/s[0m  
[2KAttention weights: tensor([[0.5090, 0.4910]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 11/203 [2m0:00:04 â€¢ 0:01:12[0m [2;4m2.67it/s[0m  
[2KAttention weights: tensor([[0.4888, 0.5112]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 11/203 [2m0:00:04 â€¢ 0:01:12[0m [2;4m2.67it/s[0m  
[2KAttention weights: tensor([[0.5185, 0.4815]], device='cuda:0')â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 11/203 [2m0:00:04 â€¢ 0:01:12[0m [2;4m2.67it/s[0m  
[2KAttention weights: tensor([[0.5428, 0.4572],38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 11/203 [2m0:00:04 â€¢ 0:01:12[0m [2;4m2.67it/s[0m  
        [0.4273, 0.5727],
        [0.4692, 0.5308],
        [0.5559, 0.4441],
        [0.4719, 0.5281],
        [0.6378, 0.3622],
        [0.5933, 0.4067],
        [0.5747, 0.4253],
        [0.4852, 0.5148],
[2K        [0.5002, 0.4998]], device='cuda:0')[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 11/203 [2m0:00:04 â€¢ 0:01:12[0m [2;4m2.67it/s[0m  
[2KAttention weights: tensor([[0.5205, 0.4795],0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 12/203 [2m0:00:04 â€¢ 0:01:11[0m [2;4m2.70it/s[0m  
        [0.5123, 0.4877],
        [0.5140, 0.4860],
        [0.5198, 0.4802],
        [0.5214, 0.4786],
        [0.5242, 0.4758],
        [0.5215, 0.4785],
        [0.5185, 0.4815],
        [0.5155, 0.4845],
[2K        [0.5216, 0.4784]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 12/203 [2m0:00:04 â€¢ 0:01:11[0m [2;4m2.70it/s[0m  
[2KClass label: CleanAndJerkm[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 12/203 [2m0:00:04 â€¢ 0:01:11[0m [2;4m2.70it/s[0m  
[2KAttention weights: tensor([[0.4931, 0.5069]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 12/203 [2m0:00:04 â€¢ 0:01:11[0m [2;4m2.70it/s[0m  
[2KStep 0 - TTA Loss: 1.9259m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 12/203 [2m0:00:04 â€¢ 0:01:11[0m [2;4m2.70it/s[0m  
[2KAttention weights: tensor([[0.4741, 0.5259]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 12/203 [2m0:00:04 â€¢ 0:01:11[0m [2;4m2.70it/s[0m  
[2KAttention weights: tensor([[0.4482, 0.5518]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 12/203 [2m0:00:04 â€¢ 0:01:11[0m [2;4m2.70it/s[0m  
[2KAttention weights: tensor([[0.4161, 0.5839]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 12/203 [2m0:00:04 â€¢ 0:01:11[0m [2;4m2.70it/s[0m  
[2KAttention weights: tensor([[0.3902, 0.6098]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 12/203 [2m0:00:04 â€¢ 0:01:11[0m [2;4m2.70it/s[0m  
[2KAttention weights: tensor([[0.3673, 0.6327]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 12/203 [2m0:00:04 â€¢ 0:01:11[0m [2;4m2.70it/s[0m  
[2KAttention weights: tensor([[0.3497, 0.6503]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 12/203 [2m0:00:04 â€¢ 0:01:11[0m [2;4m2.70it/s[0m  
[2KAttention weights: tensor([[0.3393, 0.6607]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 12/203 [2m0:00:04 â€¢ 0:01:11[0m [2;4m2.70it/s[0m  
[2KAttention weights: tensor([[0.3337, 0.6663]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 12/203 [2m0:00:04 â€¢ 0:01:11[0m [2;4m2.70it/s[0m  
[2KAttention weights: tensor([[0.3316, 0.6684]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 12/203 [2m0:00:04 â€¢ 0:01:11[0m [2;4m2.70it/s[0m  
[2KAttention weights: tensor([[0.5095, 0.4905]], device='cuda:0')â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 12/203 [2m0:00:04 â€¢ 0:01:11[0m [2;4m2.70it/s[0m  
[2KAttention weights: tensor([[0.5430, 0.4570],38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 12/203 [2m0:00:04 â€¢ 0:01:11[0m [2;4m2.70it/s[0m  
        [0.4363, 0.5637],
        [0.3308, 0.6692],
        [0.5512, 0.4488],
        [0.4872, 0.5128],
        [0.6402, 0.3598],
        [0.5895, 0.4105],
        [0.5860, 0.4140],
        [0.4792, 0.5208],
[2K        [0.5027, 0.4973]], device='cuda:0')[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 12/203 [2m0:00:04 â€¢ 0:01:11[0m [2;4m2.70it/s[0m  
[2KAttention weights: tensor([[0.5205, 0.4795],4mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 13/203 [2m0:00:05 â€¢ 0:01:10[0m [2;4m2.72it/s[0m  
        [0.5123, 0.4877],
        [0.5141, 0.4859],
        [0.5198, 0.4802],
        [0.5215, 0.4785],
        [0.5242, 0.4758],
        [0.5215, 0.4785],
        [0.5186, 0.4814],
        [0.5155, 0.4845],
[2K        [0.5217, 0.4783]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 13/203 [2m0:00:05 â€¢ 0:01:10[0m [2;4m2.72it/s[0m  
[2KClass label: BaseballPitch[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 13/203 [2m0:00:05 â€¢ 0:01:10[0m [2;4m2.72it/s[0m  
[2KAttention weights: tensor([[0.5992, 0.4008]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 13/203 [2m0:00:05 â€¢ 0:01:10[0m [2;4m2.72it/s[0m  
[2KStep 0 - TTA Loss: 2.0440m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 13/203 [2m0:00:05 â€¢ 0:01:10[0m [2;4m2.72it/s[0m  
[2KAttention weights: tensor([[0.5992, 0.4008]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 13/203 [2m0:00:05 â€¢ 0:01:10[0m [2;4m2.72it/s[0m  
[2KAttention weights: tensor([[0.5993, 0.4007]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 13/203 [2m0:00:05 â€¢ 0:01:10[0m [2;4m2.72it/s[0m  
[2KAttention weights: tensor([[0.6005, 0.3995]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 13/203 [2m0:00:05 â€¢ 0:01:10[0m [2;4m2.72it/s[0m  
[2KAttention weights: tensor([[0.6041, 0.3959]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 13/203 [2m0:00:05 â€¢ 0:01:10[0m [2;4m2.72it/s[0m  
[2KAttention weights: tensor([[0.6119, 0.3881]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 13/203 [2m0:00:05 â€¢ 0:01:10[0m [2;4m2.72it/s[0m  
[2KAttention weights: tensor([[0.6248, 0.3752]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 13/203 [2m0:00:05 â€¢ 0:01:10[0m [2;4m2.72it/s[0m  
[2KAttention weights: tensor([[0.6385, 0.3615]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 13/203 [2m0:00:05 â€¢ 0:01:10[0m [2;4m2.72it/s[0m  
[2KAttention weights: tensor([[0.6520, 0.3480]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 13/203 [2m0:00:05 â€¢ 0:01:10[0m [2;4m2.72it/s[0m  
[2KAttention weights: tensor([[0.6633, 0.3367]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 13/203 [2m0:00:05 â€¢ 0:01:10[0m [2;4m2.72it/s[0m  
[2KAttention weights: tensor([[0.5218, 0.4782]], device='cuda:0')â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 13/203 [2m0:00:05 â€¢ 0:01:10[0m [2;4m2.72it/s[0m  
[2KAttention weights: tensor([[0.6725, 0.3275],[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 13/203 [2m0:00:05 â€¢ 0:01:10[0m [2;4m2.72it/s[0m  
        [0.4482, 0.5518],
        [0.4718, 0.5282],
        [0.6208, 0.3792],
        [0.5989, 0.4011],
        [0.7042, 0.2958],
        [0.6562, 0.3438],
        [0.6063, 0.3937],
        [0.5384, 0.4616],
[2K        [0.6117, 0.3883]], device='cuda:0')[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 13/203 [2m0:00:05 â€¢ 0:01:10[0m [2;4m2.72it/s[0m  
[2KAttention weights: tensor([[0.5205, 0.4795],4mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 14/203 [2m0:00:05 â€¢ 0:01:09[0m [2;4m2.74it/s[0m  
        [0.5123, 0.4877],
        [0.5141, 0.4859],
        [0.5198, 0.4802],
        [0.5215, 0.4785],
        [0.5242, 0.4758],
        [0.5216, 0.4784],
        [0.5186, 0.4814],
        [0.5155, 0.4845],
[2K        [0.5217, 0.4783]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 14/203 [2m0:00:05 â€¢ 0:01:09[0m [2;4m2.74it/s[0m  
[2KClass label: GolfSwing[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 14/203 [2m0:00:05 â€¢ 0:01:09[0m [2;4m2.74it/s[0m  
[2KAttention weights: tensor([[0.5975, 0.4025]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 14/203 [2m0:00:05 â€¢ 0:01:09[0m [2;4m2.74it/s[0m  
[2KStep 0 - TTA Loss: 1.4273m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 14/203 [2m0:00:05 â€¢ 0:01:09[0m [2;4m2.74it/s[0m  
[2KAttention weights: tensor([[0.5992, 0.4008]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 14/203 [2m0:00:05 â€¢ 0:01:09[0m [2;4m2.74it/s[0m  
[2KAttention weights: tensor([[0.6041, 0.3959]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 14/203 [2m0:00:05 â€¢ 0:01:09[0m [2;4m2.74it/s[0m  
[2KAttention weights: tensor([[0.6090, 0.3910]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 14/203 [2m0:00:05 â€¢ 0:01:09[0m [2;4m2.74it/s[0m  
[2KAttention weights: tensor([[0.6124, 0.3876]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 14/203 [2m0:00:05 â€¢ 0:01:09[0m [2;4m2.74it/s[0m  
[2KAttention weights: tensor([[0.6128, 0.3872]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 14/203 [2m0:00:05 â€¢ 0:01:09[0m [2;4m2.74it/s[0m  
[2KAttention weights: tensor([[0.6119, 0.3881]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 14/203 [2m0:00:05 â€¢ 0:01:09[0m [2;4m2.74it/s[0m  
[2KAttention weights: tensor([[0.6121, 0.3879]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 14/203 [2m0:00:05 â€¢ 0:01:09[0m [2;4m2.74it/s[0m  
[2KAttention weights: tensor([[0.6129, 0.3871]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 14/203 [2m0:00:05 â€¢ 0:01:09[0m [2;4m2.74it/s[0m  
[2KAttention weights: tensor([[0.6134, 0.3866]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 14/203 [2m0:00:05 â€¢ 0:01:09[0m [2;4m2.74it/s[0m  
[2KAttention weights: tensor([[0.5209, 0.4791]], device='cuda:0')â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 14/203 [2m0:00:05 â€¢ 0:01:09[0m [2;4m2.74it/s[0m  
[2KAttention weights: tensor([[0.6358, 0.3642],[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 14/203 [2m0:00:05 â€¢ 0:01:09[0m [2;4m2.74it/s[0m  
        [0.4486, 0.5514],
        [0.4789, 0.5211],
        [0.6137, 0.3863],
        [0.5880, 0.4120],
        [0.6938, 0.3062],
        [0.6494, 0.3506],
        [0.6067, 0.3933],
        [0.5202, 0.4798],
[2K        [0.5963, 0.4037]], device='cuda:0')[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 14/203 [2m0:00:05 â€¢ 0:01:09[0m [2;4m2.74it/s[0m  
[2KAttention weights: tensor([[0.5206, 0.4794],4mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 15/203 [2m0:00:05 â€¢ 0:01:09[0m [2;4m2.76it/s[0m  
        [0.5123, 0.4877],
        [0.5141, 0.4859],
        [0.5198, 0.4802],
        [0.5215, 0.4785],
        [0.5242, 0.4758],
        [0.5216, 0.4784],
        [0.5186, 0.4814],
        [0.5155, 0.4845],
[2K        [0.5217, 0.4783]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 15/203 [2m0:00:05 â€¢ 0:01:09[0m [2;4m2.76it/s[0m  
[2KClass label: HighJumpâ”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 15/203 [2m0:00:05 â€¢ 0:01:09[0m [2;4m2.76it/s[0m  
[2KAttention weights: tensor([[0.6870, 0.3130]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 15/203 [2m0:00:05 â€¢ 0:01:09[0m [2;4m2.76it/s[0m  
[2KStep 0 - TTA Loss: 2.9027m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 15/203 [2m0:00:05 â€¢ 0:01:09[0m [2;4m2.76it/s[0m  
[2KAttention weights: tensor([[0.6870, 0.3130]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 15/203 [2m0:00:05 â€¢ 0:01:09[0m [2;4m2.76it/s[0m  
[2KAttention weights: tensor([[0.6875, 0.3125]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 15/203 [2m0:00:05 â€¢ 0:01:09[0m [2;4m2.76it/s[0m  
[2KAttention weights: tensor([[0.6922, 0.3078]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 15/203 [2m0:00:05 â€¢ 0:01:09[0m [2;4m2.76it/s[0m  
[2KAttention weights: tensor([[0.7052, 0.2948]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 15/203 [2m0:00:05 â€¢ 0:01:09[0m [2;4m2.76it/s[0m  
[2KAttention weights: tensor([[0.7293, 0.2707]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 15/203 [2m0:00:05 â€¢ 0:01:09[0m [2;4m2.76it/s[0m  
[2KAttention weights: tensor([[0.7587, 0.2413]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 15/203 [2m0:00:05 â€¢ 0:01:09[0m [2;4m2.76it/s[0m  
[2KAttention weights: tensor([[0.7872, 0.2128]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 15/203 [2m0:00:05 â€¢ 0:01:09[0m [2;4m2.76it/s[0m  
[2KAttention weights: tensor([[0.8143, 0.1857]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 15/203 [2m0:00:05 â€¢ 0:01:09[0m [2;4m2.76it/s[0m  
[2KAttention weights: tensor([[0.8407, 0.1593]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 15/203 [2m0:00:05 â€¢ 0:01:09[0m [2;4m2.76it/s[0m  
[2KAttention weights: tensor([[0.5276, 0.4724]], device='cuda:0')â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 15/203 [2m0:00:05 â€¢ 0:01:09[0m [2;4m2.76it/s[0m  
[2KAttention weights: tensor([[0.6751, 0.3249],[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 15/203 [2m0:00:05 â€¢ 0:01:09[0m [2;4m2.76it/s[0m  
        [0.4561, 0.5439],
        [0.5318, 0.4682],
        [0.6604, 0.3396],
        [0.7103, 0.2897],
        [0.8629, 0.1371],
        [0.7884, 0.2116],
        [0.6900, 0.3100],
        [0.6055, 0.3945],
[2K        [0.7275, 0.2725]], device='cuda:0')[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 15/203 [2m0:00:05 â€¢ 0:01:09[0m [2;4m2.76it/s[0m  
[2KAttention weights: tensor([[0.5206, 0.4794],[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 16/203 [2m0:00:06 â€¢ 0:01:08[0m [2;4m2.79it/s[0m   
        [0.5124, 0.4876],
        [0.5142, 0.4858],
        [0.5199, 0.4801],
        [0.5216, 0.4784],
        [0.5243, 0.4757],
        [0.5217, 0.4783],
        [0.5187, 0.4813],
        [0.5156, 0.4844],
[2K        [0.5218, 0.4782]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 16/203 [2m0:00:06 â€¢ 0:01:08[0m [2;4m2.79it/s[0m  
[2KClass label: HighJumpâ”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 16/203 [2m0:00:06 â€¢ 0:01:08[0m [2;4m2.79it/s[0m  
[2KAttention weights: tensor([[0.6837, 0.3163]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 16/203 [2m0:00:06 â€¢ 0:01:08[0m [2;4m2.79it/s[0m  
[2KStep 0 - TTA Loss: 1.25550m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 16/203 [2m0:00:06 â€¢ 0:01:08[0m [2;4m2.79it/s[0m  
[2KAttention weights: tensor([[0.7164, 0.2836]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 16/203 [2m0:00:06 â€¢ 0:01:08[0m [2;4m2.79it/s[0m  
[2KAttention weights: tensor([[0.7454, 0.2546]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 16/203 [2m0:00:06 â€¢ 0:01:08[0m [2;4m2.79it/s[0m  
[2KAttention weights: tensor([[0.7670, 0.2330]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 16/203 [2m0:00:06 â€¢ 0:01:08[0m [2;4m2.79it/s[0m  
[2KAttention weights: tensor([[0.7829, 0.2171]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 16/203 [2m0:00:06 â€¢ 0:01:08[0m [2;4m2.79it/s[0m  
[2KAttention weights: tensor([[0.7968, 0.2032]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 16/203 [2m0:00:06 â€¢ 0:01:08[0m [2;4m2.79it/s[0m  
[2KAttention weights: tensor([[0.8060, 0.1940]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 16/203 [2m0:00:06 â€¢ 0:01:08[0m [2;4m2.79it/s[0m  
[2KAttention weights: tensor([[0.8120, 0.1880]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 16/203 [2m0:00:06 â€¢ 0:01:08[0m [2;4m2.79it/s[0m  
[2KAttention weights: tensor([[0.8150, 0.1850]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 16/203 [2m0:00:06 â€¢ 0:01:08[0m [2;4m2.79it/s[0m  
[2KAttention weights: tensor([[0.8163, 0.1837]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 16/203 [2m0:00:06 â€¢ 0:01:08[0m [2;4m2.79it/s[0m  
[2KAttention weights: tensor([[0.5275, 0.4725]], device='cuda:0')â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 16/203 [2m0:00:06 â€¢ 0:01:08[0m [2;4m2.79it/s[0m  
[2KAttention weights: tensor([[0.6513, 0.3487],[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 16/203 [2m0:00:06 â€¢ 0:01:08[0m [2;4m2.79it/s[0m  
        [0.4515, 0.5485],
        [0.5213, 0.4787],
        [0.6446, 0.3554],
        [0.6699, 0.3301],
        [0.8173, 0.1827],
        [0.7478, 0.2522],
        [0.6620, 0.3380],
        [0.5792, 0.4208],
[2K        [0.6862, 0.3138]], device='cuda:0')[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 16/203 [2m0:00:06 â€¢ 0:01:08[0m [2;4m2.79it/s[0m  
[2KAttention weights: tensor([[0.5207, 0.4793],[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 17/203 [2m0:00:06 â€¢ 0:01:07[0m [2;4m2.80it/s[0m  
        [0.5124, 0.4876],
        [0.5142, 0.4858],
        [0.5199, 0.4801],
        [0.5216, 0.4784],
        [0.5244, 0.4756],
        [0.5217, 0.4783],
        [0.5187, 0.4813],
        [0.5156, 0.4844],
[2K        [0.5218, 0.4782]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 17/203 [2m0:00:06 â€¢ 0:01:07[0m [2;4m2.80it/s[0m  
[2KClass label: GolfSwingâ”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 17/203 [2m0:00:06 â€¢ 0:01:07[0m [2;4m2.80it/s[0m  
[2KAttention weights: tensor([[0.6005, 0.3995]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 17/203 [2m0:00:06 â€¢ 0:01:07[0m [2;4m2.80it/s[0m  
[2KStep 0 - TTA Loss: 1.68390m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 17/203 [2m0:00:06 â€¢ 0:01:07[0m [2;4m2.80it/s[0m  
[2KAttention weights: tensor([[0.6005, 0.3995]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 17/203 [2m0:00:06 â€¢ 0:01:07[0m [2;4m2.80it/s[0m  
[2KAttention weights: tensor([[0.6006, 0.3994]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 17/203 [2m0:00:06 â€¢ 0:01:07[0m [2;4m2.80it/s[0m  
[2KAttention weights: tensor([[0.6010, 0.3990]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 17/203 [2m0:00:06 â€¢ 0:01:07[0m [2;4m2.80it/s[0m  
[2KAttention weights: tensor([[0.6017, 0.3983]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 17/203 [2m0:00:06 â€¢ 0:01:07[0m [2;4m2.80it/s[0m  
[2KAttention weights: tensor([[0.6024, 0.3976]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 17/203 [2m0:00:06 â€¢ 0:01:07[0m [2;4m2.80it/s[0m  
[2KAttention weights: tensor([[0.6037, 0.3963]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 17/203 [2m0:00:06 â€¢ 0:01:07[0m [2;4m2.80it/s[0m  
[2KAttention weights: tensor([[0.6056, 0.3944]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 17/203 [2m0:00:06 â€¢ 0:01:07[0m [2;4m2.80it/s[0m  
[2KAttention weights: tensor([[0.6080, 0.3920]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 17/203 [2m0:00:06 â€¢ 0:01:07[0m [2;4m2.80it/s[0m  
[2KAttention weights: tensor([[0.6110, 0.3890]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 17/203 [2m0:00:06 â€¢ 0:01:07[0m [2;4m2.80it/s[0m  
[2KAttention weights: tensor([[0.5201, 0.4799]], device='cuda:0')â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 17/203 [2m0:00:06 â€¢ 0:01:07[0m [2;4m2.80it/s[0m  
[2KAttention weights: tensor([[0.6146, 0.3854],[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 17/203 [2m0:00:06 â€¢ 0:01:07[0m [2;4m2.80it/s[0m  
        [0.4499, 0.5501],
        [0.4968, 0.5032],
        [0.6144, 0.3856],
        [0.5960, 0.4040],
        [0.7152, 0.2848],
        [0.6616, 0.3384],
        [0.6207, 0.3793],
        [0.5333, 0.4667],
[2K        [0.6042, 0.3958]], device='cuda:0')[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 17/203 [2m0:00:06 â€¢ 0:01:07[0m [2;4m2.80it/s[0m  
[2KAttention weights: tensor([[0.5207, 0.4793],24mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 18/203 [2m0:00:06 â€¢ 0:01:06[0m [2;4m2.81it/s[0m  
        [0.5124, 0.4876],
        [0.5142, 0.4858],
        [0.5199, 0.4801],
        [0.5217, 0.4783],
        [0.5244, 0.4756],
        [0.5217, 0.4783],
        [0.5187, 0.4813],
        [0.5156, 0.4844],
[2K        [0.5218, 0.4782]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 18/203 [2m0:00:06 â€¢ 0:01:06[0m [2;4m2.81it/s[0m  
[2KClass label: ThrowDiscus[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 18/203 [2m0:00:06 â€¢ 0:01:06[0m [2;4m2.81it/s[0m  
[2KAttention weights: tensor([[0.5834, 0.4166]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 18/203 [2m0:00:06 â€¢ 0:01:06[0m [2;4m2.81it/s[0m  
[2KStep 0 - TTA Loss: 2.20680m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 18/203 [2m0:00:06 â€¢ 0:01:06[0m [2;4m2.81it/s[0m  
[2KAttention weights: tensor([[0.5831, 0.4169]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 18/203 [2m0:00:06 â€¢ 0:01:06[0m [2;4m2.81it/s[0m  
[2KAttention weights: tensor([[0.5775, 0.4225]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 18/203 [2m0:00:06 â€¢ 0:01:06[0m [2;4m2.81it/s[0m  
[2KAttention weights: tensor([[0.5706, 0.4294]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 18/203 [2m0:00:06 â€¢ 0:01:06[0m [2;4m2.81it/s[0m  
[2KAttention weights: tensor([[0.5650, 0.4350]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 18/203 [2m0:00:06 â€¢ 0:01:06[0m [2;4m2.81it/s[0m  
[2KAttention weights: tensor([[0.5635, 0.4365]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 18/203 [2m0:00:06 â€¢ 0:01:06[0m [2;4m2.81it/s[0m  
[2KAttention weights: tensor([[0.5603, 0.4397]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 18/203 [2m0:00:06 â€¢ 0:01:06[0m [2;4m2.81it/s[0m  
[2KAttention weights: tensor([[0.5599, 0.4401]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 18/203 [2m0:00:06 â€¢ 0:01:06[0m [2;4m2.81it/s[0m  
[2KAttention weights: tensor([[0.5601, 0.4399]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 18/203 [2m0:00:06 â€¢ 0:01:06[0m [2;4m2.81it/s[0m  
[2KAttention weights: tensor([[0.5602, 0.4398]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 18/203 [2m0:00:06 â€¢ 0:01:06[0m [2;4m2.81it/s[0m  
[2KAttention weights: tensor([[0.5213, 0.4787]], device='cuda:0')â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 18/203 [2m0:00:06 â€¢ 0:01:06[0m [2;4m2.81it/s[0m  
[2KAttention weights: tensor([[0.5910, 0.4090],[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 18/203 [2m0:00:06 â€¢ 0:01:06[0m [2;4m2.81it/s[0m  
        [0.4475, 0.5525],
        [0.4890, 0.5110],
        [0.5980, 0.4020],
        [0.5610, 0.4390],
        [0.6868, 0.3132],
        [0.6374, 0.3626],
        [0.6071, 0.3929],
        [0.5138, 0.4862],
[2K        [0.5605, 0.4395]], device='cuda:0')â•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 18/203 [2m0:00:06 â€¢ 0:01:06[0m [2;4m2.81it/s[0m  
[2KAttention weights: tensor([[0.5207, 0.4793],24mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 19/203 [2m0:00:07 â€¢ 0:01:06[0m [2;4m2.81it/s[0m  
        [0.5124, 0.4876],
        [0.5143, 0.4857],
        [0.5199, 0.4801],
        [0.5217, 0.4783],
        [0.5244, 0.4756],
        [0.5218, 0.4782],
        [0.5187, 0.4813],
        [0.5156, 0.4844],
[2K        [0.5219, 0.4781]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 19/203 [2m0:00:07 â€¢ 0:01:06[0m [2;4m2.81it/s[0m  
[2KClass label: SoccerPenaltym[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 19/203 [2m0:00:07 â€¢ 0:01:06[0m [2;4m2.81it/s[0m  
[2KAttention weights: tensor([[0.6078, 0.3922]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 19/203 [2m0:00:07 â€¢ 0:01:06[0m [2;4m2.81it/s[0m  
[2KStep 0 - TTA Loss: 2.13240m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 19/203 [2m0:00:07 â€¢ 0:01:06[0m [2;4m2.81it/s[0m  
[2KAttention weights: tensor([[0.6078, 0.3922]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 19/203 [2m0:00:07 â€¢ 0:01:06[0m [2;4m2.81it/s[0m  
[2KAttention weights: tensor([[0.6082, 0.3918]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 19/203 [2m0:00:07 â€¢ 0:01:06[0m [2;4m2.81it/s[0m  
[2KAttention weights: tensor([[0.6119, 0.3881]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 19/203 [2m0:00:07 â€¢ 0:01:06[0m [2;4m2.81it/s[0m  
[2KAttention weights: tensor([[0.6225, 0.3775]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 19/203 [2m0:00:07 â€¢ 0:01:06[0m [2;4m2.81it/s[0m  
[2KAttention weights: tensor([[0.6373, 0.3627]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 19/203 [2m0:00:07 â€¢ 0:01:06[0m [2;4m2.81it/s[0m  
[2KAttention weights: tensor([[0.6594, 0.3406]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 19/203 [2m0:00:07 â€¢ 0:01:06[0m [2;4m2.81it/s[0m  
[2KAttention weights: tensor([[0.6824, 0.3176]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 19/203 [2m0:00:07 â€¢ 0:01:06[0m [2;4m2.81it/s[0m  
[2KAttention weights: tensor([[0.7091, 0.2909]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 19/203 [2m0:00:07 â€¢ 0:01:06[0m [2;4m2.81it/s[0m  
[2KAttention weights: tensor([[0.7340, 0.2660]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 19/203 [2m0:00:07 â€¢ 0:01:06[0m [2;4m2.81it/s[0m  
[2KAttention weights: tensor([[0.5207, 0.4793]], device='cuda:0')â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 19/203 [2m0:00:07 â€¢ 0:01:06[0m [2;4m2.81it/s[0m  
[2KAttention weights: tensor([[0.6068, 0.3932],[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 19/203 [2m0:00:07 â€¢ 0:01:06[0m [2;4m2.81it/s[0m  
        [0.4732, 0.5268],
        [0.5021, 0.4979],
        [0.6226, 0.3774],
        [0.6207, 0.3793],
        [0.7301, 0.2699],
        [0.6761, 0.3239],
        [0.7536, 0.2464],
        [0.5518, 0.4482],
[2K        [0.6148, 0.3852]], device='cuda:0')â•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 19/203 [2m0:00:07 â€¢ 0:01:06[0m [2;4m2.81it/s[0m  
[2KAttention weights: tensor([[0.5207, 0.4793],24mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 20/203 [2m0:00:07 â€¢ 0:01:06[0m [2;4m2.81it/s[0m  
        [0.5125, 0.4875],
        [0.5143, 0.4857],
        [0.5200, 0.4800],
        [0.5217, 0.4783],
        [0.5245, 0.4755],
        [0.5218, 0.4782],
        [0.5188, 0.4812],
        [0.5157, 0.4843],
[2K        [0.5219, 0.4781]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 20/203 [2m0:00:07 â€¢ 0:01:06[0m [2;4m2.81it/s[0m  
[2KClass label: HighJumpâ”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 20/203 [2m0:00:07 â€¢ 0:01:06[0m [2;4m2.81it/s[0m  
[2KAttention weights: tensor([[0.6888, 0.3112]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 20/203 [2m0:00:07 â€¢ 0:01:06[0m [2;4m2.81it/s[0m  
[2KStep 0 - TTA Loss: 1.00090m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 20/203 [2m0:00:07 â€¢ 0:01:06[0m [2;4m2.81it/s[0m  
[2KAttention weights: tensor([[0.6928, 0.3072]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 20/203 [2m0:00:07 â€¢ 0:01:06[0m [2;4m2.81it/s[0m  
[2KAttention weights: tensor([[0.6934, 0.3066]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 20/203 [2m0:00:07 â€¢ 0:01:06[0m [2;4m2.81it/s[0m  
[2KAttention weights: tensor([[0.6922, 0.3078]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 20/203 [2m0:00:07 â€¢ 0:01:06[0m [2;4m2.81it/s[0m  
[2KAttention weights: tensor([[0.6896, 0.3104]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 20/203 [2m0:00:07 â€¢ 0:01:06[0m [2;4m2.81it/s[0m  
[2KAttention weights: tensor([[0.6867, 0.3133]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 20/203 [2m0:00:07 â€¢ 0:01:06[0m [2;4m2.81it/s[0m  
[2KAttention weights: tensor([[0.6866, 0.3134]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 20/203 [2m0:00:07 â€¢ 0:01:06[0m [2;4m2.81it/s[0m  
[2KAttention weights: tensor([[0.6851, 0.3149]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 20/203 [2m0:00:07 â€¢ 0:01:06[0m [2;4m2.81it/s[0m  
[2KAttention weights: tensor([[0.6844, 0.3156]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 20/203 [2m0:00:07 â€¢ 0:01:06[0m [2;4m2.81it/s[0m  
[2KAttention weights: tensor([[0.6834, 0.3166]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 20/203 [2m0:00:07 â€¢ 0:01:06[0m [2;4m2.81it/s[0m  
[2KAttention weights: tensor([[0.5252, 0.4748]], device='cuda:0')â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 20/203 [2m0:00:07 â€¢ 0:01:06[0m [2;4m2.81it/s[0m  
[2KAttention weights: tensor([[0.5923, 0.4077],[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 20/203 [2m0:00:07 â€¢ 0:01:06[0m [2;4m2.81it/s[0m  
        [0.4600, 0.5400],
        [0.4900, 0.5100],
        [0.6080, 0.3920],
        [0.5812, 0.4188],
        [0.6837, 0.3163],
        [0.6404, 0.3596],
        [0.6837, 0.3163],
        [0.5247, 0.4753],
[2K        [0.5815, 0.4185]], device='cuda:0')â•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 20/203 [2m0:00:07 â€¢ 0:01:06[0m [2;4m2.81it/s[0m  
[2KAttention weights: tensor([[0.5208, 0.4792],[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 21/203 [2m0:00:08 â€¢ 0:01:06[0m [2;4m2.77it/s[0m   
        [0.5125, 0.4875],
        [0.5143, 0.4857],
        [0.5200, 0.4800],
        [0.5217, 0.4783],
        [0.5245, 0.4755],
        [0.5218, 0.4782],
        [0.5188, 0.4812],
        [0.5157, 0.4843],
[2K        [0.5219, 0.4781]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 21/203 [2m0:00:08 â€¢ 0:01:06[0m [2;4m2.77it/s[0m  
[2KClass label: BaseballPitch0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 21/203 [2m0:00:08 â€¢ 0:01:06[0m [2;4m2.77it/s[0m  
[2KAttention weights: tensor([[0.6001, 0.3999]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 21/203 [2m0:00:08 â€¢ 0:01:06[0m [2;4m2.77it/s[0m  
[2KStep 0 - TTA Loss: 2.2284[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 21/203 [2m0:00:08 â€¢ 0:01:06[0m [2;4m2.77it/s[0m  
[2KAttention weights: tensor([[0.6001, 0.3999]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 21/203 [2m0:00:08 â€¢ 0:01:06[0m [2;4m2.77it/s[0m  
[2KAttention weights: tensor([[0.6002, 0.3998]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 21/203 [2m0:00:08 â€¢ 0:01:06[0m [2;4m2.77it/s[0m  
[2KAttention weights: tensor([[0.6010, 0.3990]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 21/203 [2m0:00:08 â€¢ 0:01:06[0m [2;4m2.77it/s[0m  
[2KAttention weights: tensor([[0.6037, 0.3963]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 21/203 [2m0:00:08 â€¢ 0:01:06[0m [2;4m2.77it/s[0m  
[2KAttention weights: tensor([[0.6097, 0.3903]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 21/203 [2m0:00:08 â€¢ 0:01:06[0m [2;4m2.77it/s[0m  
[2KAttention weights: tensor([[0.6115, 0.3885]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 21/203 [2m0:00:08 â€¢ 0:01:06[0m [2;4m2.77it/s[0m  
[2KAttention weights: tensor([[0.6120, 0.3880]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 21/203 [2m0:00:08 â€¢ 0:01:06[0m [2;4m2.77it/s[0m  
[2KAttention weights: tensor([[0.6146, 0.3854]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 21/203 [2m0:00:08 â€¢ 0:01:06[0m [2;4m2.77it/s[0m  
[2KAttention weights: tensor([[0.6194, 0.3806]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 21/203 [2m0:00:08 â€¢ 0:01:06[0m [2;4m2.77it/s[0m  
[2KAttention weights: tensor([[0.5203, 0.4797]], device='cuda:0')â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 21/203 [2m0:00:08 â€¢ 0:01:06[0m [2;4m2.77it/s[0m  
[2KAttention weights: tensor([[0.6271, 0.3729],[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 21/203 [2m0:00:08 â€¢ 0:01:06[0m [2;4m2.77it/s[0m  
        [0.4471, 0.5529],
        [0.4959, 0.5041],
        [0.6120, 0.3880],
        [0.5835, 0.4165],
        [0.6788, 0.3212],
        [0.6364, 0.3636],
        [0.6126, 0.3874],
        [0.5236, 0.4764],
[2K        [0.5894, 0.4106]], device='cuda:0')m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 21/203 [2m0:00:08 â€¢ 0:01:06[0m [2;4m2.77it/s[0m  
[2KAttention weights: tensor([[0.5208, 0.4792],[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 22/203 [2m0:00:08 â€¢ 0:01:06[0m [2;4m2.78it/s[0m  
        [0.5125, 0.4875],
        [0.5143, 0.4857],
        [0.5200, 0.4800],
        [0.5218, 0.4782],
        [0.5245, 0.4755],
        [0.5218, 0.4782],
        [0.5188, 0.4812],
        [0.5157, 0.4843],
[2K        [0.5220, 0.4780]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 22/203 [2m0:00:08 â€¢ 0:01:06[0m [2;4m2.78it/s[0m  
[2KClass label: CleanAndJerk[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 22/203 [2m0:00:08 â€¢ 0:01:06[0m [2;4m2.78it/s[0m  
[2KAttention weights: tensor([[0.4932, 0.5068]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 22/203 [2m0:00:08 â€¢ 0:01:06[0m [2;4m2.78it/s[0m  
[2KStep 0 - TTA Loss: 0.9359[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 22/203 [2m0:00:08 â€¢ 0:01:06[0m [2;4m2.78it/s[0m  
[2KAttention weights: tensor([[0.4924, 0.5076]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 22/203 [2m0:00:08 â€¢ 0:01:06[0m [2;4m2.78it/s[0m  
[2KAttention weights: tensor([[0.4892, 0.5108]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 22/203 [2m0:00:08 â€¢ 0:01:06[0m [2;4m2.78it/s[0m  
[2KAttention weights: tensor([[0.4876, 0.5124]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 22/203 [2m0:00:08 â€¢ 0:01:06[0m [2;4m2.78it/s[0m  
[2KAttention weights: tensor([[0.4871, 0.5129]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 22/203 [2m0:00:08 â€¢ 0:01:06[0m [2;4m2.78it/s[0m  
[2KAttention weights: tensor([[0.4872, 0.5128]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 22/203 [2m0:00:08 â€¢ 0:01:06[0m [2;4m2.78it/s[0m  
[2KAttention weights: tensor([[0.4887, 0.5113]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 22/203 [2m0:00:08 â€¢ 0:01:06[0m [2;4m2.78it/s[0m  
[2KAttention weights: tensor([[0.4900, 0.5100]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 22/203 [2m0:00:08 â€¢ 0:01:06[0m [2;4m2.78it/s[0m  
[2KAttention weights: tensor([[0.4908, 0.5092]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 22/203 [2m0:00:08 â€¢ 0:01:06[0m [2;4m2.78it/s[0m  
[2KAttention weights: tensor([[0.4912, 0.5088]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 22/203 [2m0:00:08 â€¢ 0:01:06[0m [2;4m2.78it/s[0m  
[2KAttention weights: tensor([[0.5141, 0.4859]], device='cuda:0')â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 22/203 [2m0:00:08 â€¢ 0:01:06[0m [2;4m2.78it/s[0m  
[2KAttention weights: tensor([[0.6288, 0.3712],[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 22/203 [2m0:00:08 â€¢ 0:01:06[0m [2;4m2.78it/s[0m  
        [0.4483, 0.5517],
        [0.4912, 0.5088],
        [0.6120, 0.3880],
        [0.5844, 0.4156],
        [0.6801, 0.3199],
        [0.6377, 0.3623],
        [0.6126, 0.3874],
        [0.5175, 0.4825],
[2K        [0.5885, 0.4115]], device='cuda:0')m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 22/203 [2m0:00:08 â€¢ 0:01:06[0m [2;4m2.78it/s[0m  
[2KAttention weights: tensor([[0.5208, 0.4792],224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 23/203 [2m0:00:08 â€¢ 0:01:05[0m [2;4m2.80it/s[0m  
        [0.5125, 0.4875],
        [0.5143, 0.4857],
        [0.5200, 0.4800],
        [0.5218, 0.4782],
        [0.5245, 0.4755],
        [0.5218, 0.4782],
        [0.5189, 0.4811],
        [0.5157, 0.4843],
[2K        [0.5220, 0.4780]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 23/203 [2m0:00:08 â€¢ 0:01:05[0m [2;4m2.80it/s[0m  
[2KClass label: TennisSwing[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 23/203 [2m0:00:08 â€¢ 0:01:05[0m [2;4m2.80it/s[0m  
[2KAttention weights: tensor([[0.5157, 0.4843]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 23/203 [2m0:00:08 â€¢ 0:01:05[0m [2;4m2.80it/s[0m  
[2KStep 0 - TTA Loss: 2.1850[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 23/203 [2m0:00:08 â€¢ 0:01:05[0m [2;4m2.80it/s[0m  
[2KAttention weights: tensor([[0.5157, 0.4843]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 23/203 [2m0:00:08 â€¢ 0:01:05[0m [2;4m2.80it/s[0m  
[2KAttention weights: tensor([[0.5165, 0.4835]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 23/203 [2m0:00:08 â€¢ 0:01:05[0m [2;4m2.80it/s[0m  
[2KAttention weights: tensor([[0.5216, 0.4784]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 23/203 [2m0:00:08 â€¢ 0:01:05[0m [2;4m2.80it/s[0m  
[2KAttention weights: tensor([[0.5332, 0.4668]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 23/203 [2m0:00:08 â€¢ 0:01:05[0m [2;4m2.80it/s[0m  
[2KAttention weights: tensor([[0.5532, 0.4468]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 23/203 [2m0:00:08 â€¢ 0:01:05[0m [2;4m2.80it/s[0m  
[2KAttention weights: tensor([[0.5836, 0.4164]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 23/203 [2m0:00:08 â€¢ 0:01:05[0m [2;4m2.80it/s[0m  
[2KAttention weights: tensor([[0.6182, 0.3818]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 23/203 [2m0:00:08 â€¢ 0:01:05[0m [2;4m2.80it/s[0m  
[2KAttention weights: tensor([[0.6557, 0.3443]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 23/203 [2m0:00:08 â€¢ 0:01:05[0m [2;4m2.80it/s[0m  
[2KAttention weights: tensor([[0.6903, 0.3097]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 23/203 [2m0:00:08 â€¢ 0:01:05[0m [2;4m2.80it/s[0m  
[2KAttention weights: tensor([[0.5203, 0.4797]], device='cuda:0')â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 23/203 [2m0:00:08 â€¢ 0:01:05[0m [2;4m2.80it/s[0m  
[2KAttention weights: tensor([[0.6496, 0.3504],â•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 23/203 [2m0:00:08 â€¢ 0:01:05[0m [2;4m2.80it/s[0m  
        [0.4558, 0.5442],
        [0.5243, 0.4757],
        [0.6362, 0.3638],
        [0.6204, 0.3796],
        [0.7377, 0.2623],
        [0.6619, 0.3381],
        [0.6438, 0.3562],
        [0.7173, 0.2827],
[2K        [0.6459, 0.3541]], device='cuda:0')mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 23/203 [2m0:00:08 â€¢ 0:01:05[0m [2;4m2.80it/s[0m  
[2KAttention weights: tensor([[0.5208, 0.4792],224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 24/203 [2m0:00:09 â€¢ 0:01:04[0m [2;4m2.81it/s[0m  
        [0.5125, 0.4875],
        [0.5143, 0.4857],
        [0.5200, 0.4800],
        [0.5218, 0.4782],
        [0.5245, 0.4755],
        [0.5218, 0.4782],
        [0.5189, 0.4811],
        [0.5157, 0.4843],
[2K        [0.5220, 0.4780]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 24/203 [2m0:00:09 â€¢ 0:01:04[0m [2;4m2.81it/s[0m  
[2KClass label: Billiardsâ”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 24/203 [2m0:00:09 â€¢ 0:01:04[0m [2;4m2.81it/s[0m  
[2KAttention weights: tensor([[0.4449, 0.5551]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 24/203 [2m0:00:09 â€¢ 0:01:04[0m [2;4m2.81it/s[0m  
[2KStep 0 - TTA Loss: 0.8729[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 24/203 [2m0:00:09 â€¢ 0:01:04[0m [2;4m2.81it/s[0m  
[2KAttention weights: tensor([[0.4477, 0.5523]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 24/203 [2m0:00:09 â€¢ 0:01:04[0m [2;4m2.81it/s[0m  
[2KAttention weights: tensor([[0.4513, 0.5487]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 24/203 [2m0:00:09 â€¢ 0:01:04[0m [2;4m2.81it/s[0m  
[2KAttention weights: tensor([[0.4550, 0.5450]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 24/203 [2m0:00:09 â€¢ 0:01:04[0m [2;4m2.81it/s[0m  
[2KAttention weights: tensor([[0.4586, 0.5414]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 24/203 [2m0:00:09 â€¢ 0:01:04[0m [2;4m2.81it/s[0m  
[2KAttention weights: tensor([[0.4616, 0.5384]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 24/203 [2m0:00:09 â€¢ 0:01:04[0m [2;4m2.81it/s[0m  
[2KAttention weights: tensor([[0.4640, 0.5360]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 24/203 [2m0:00:09 â€¢ 0:01:04[0m [2;4m2.81it/s[0m  
[2KAttention weights: tensor([[0.4659, 0.5341]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 24/203 [2m0:00:09 â€¢ 0:01:04[0m [2;4m2.81it/s[0m  
[2KAttention weights: tensor([[0.4669, 0.5331]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 24/203 [2m0:00:09 â€¢ 0:01:04[0m [2;4m2.81it/s[0m  
[2KAttention weights: tensor([[0.4674, 0.5326]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 24/203 [2m0:00:09 â€¢ 0:01:04[0m [2;4m2.81it/s[0m  
[2KAttention weights: tensor([[0.5132, 0.4868]], device='cuda:0')â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 24/203 [2m0:00:09 â€¢ 0:01:04[0m [2;4m2.81it/s[0m  
[2KAttention weights: tensor([[0.6330, 0.3670],â•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 24/203 [2m0:00:09 â€¢ 0:01:04[0m [2;4m2.81it/s[0m  
        [0.4675, 0.5325],
        [0.5116, 0.4884],
        [0.6285, 0.3715],
        [0.6077, 0.3923],
        [0.7168, 0.2832],
        [0.6560, 0.3440],
        [0.6238, 0.3762],
        [0.6348, 0.3652],
[2K        [0.6247, 0.3753]], device='cuda:0')mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 24/203 [2m0:00:09 â€¢ 0:01:04[0m [2;4m2.81it/s[0m  
[2KAttention weights: tensor([[0.5208, 0.4792],224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 25/203 [2m0:00:09 â€¢ 0:01:04[0m [2;4m2.81it/s[0m  
        [0.5125, 0.4875],
        [0.5143, 0.4857],
        [0.5200, 0.4800],
        [0.5218, 0.4782],
        [0.5245, 0.4755],
        [0.5218, 0.4782],
        [0.5188, 0.4812],
        [0.5157, 0.4843],
[2K        [0.5219, 0.4781]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 25/203 [2m0:00:09 â€¢ 0:01:04[0m [2;4m2.81it/s[0m  
[2KClass label: GolfSwingâ”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 25/203 [2m0:00:09 â€¢ 0:01:04[0m [2;4m2.81it/s[0m  
[2KAttention weights: tensor([[0.6043, 0.3957]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 25/203 [2m0:00:09 â€¢ 0:01:04[0m [2;4m2.81it/s[0m  
[2KStep 0 - TTA Loss: 1.2272[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 25/203 [2m0:00:09 â€¢ 0:01:04[0m [2;4m2.81it/s[0m  
[2KAttention weights: tensor([[0.6043, 0.3957]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 25/203 [2m0:00:09 â€¢ 0:01:04[0m [2;4m2.81it/s[0m  
[2KAttention weights: tensor([[0.6044, 0.3956]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 25/203 [2m0:00:09 â€¢ 0:01:04[0m [2;4m2.81it/s[0m  
[2KAttention weights: tensor([[0.6047, 0.3953]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 25/203 [2m0:00:09 â€¢ 0:01:04[0m [2;4m2.81it/s[0m  
[2KAttention weights: tensor([[0.6053, 0.3947]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 25/203 [2m0:00:09 â€¢ 0:01:04[0m [2;4m2.81it/s[0m  
[2KAttention weights: tensor([[0.6059, 0.3941]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 25/203 [2m0:00:09 â€¢ 0:01:04[0m [2;4m2.81it/s[0m  
[2KAttention weights: tensor([[0.6080, 0.3920]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 25/203 [2m0:00:09 â€¢ 0:01:04[0m [2;4m2.81it/s[0m  
[2KAttention weights: tensor([[0.6108, 0.3892]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 25/203 [2m0:00:09 â€¢ 0:01:04[0m [2;4m2.81it/s[0m  
[2KAttention weights: tensor([[0.6151, 0.3849]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 25/203 [2m0:00:09 â€¢ 0:01:04[0m [2;4m2.81it/s[0m  
[2KAttention weights: tensor([[0.6237, 0.3763]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 25/203 [2m0:00:09 â€¢ 0:01:04[0m [2;4m2.81it/s[0m  
[2KAttention weights: tensor([[0.5219, 0.4781]], device='cuda:0')â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 25/203 [2m0:00:09 â€¢ 0:01:04[0m [2;4m2.81it/s[0m  
[2KAttention weights: tensor([[0.6160, 0.3840],â•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 25/203 [2m0:00:09 â€¢ 0:01:04[0m [2;4m2.81it/s[0m  
        [0.4608, 0.5392],
        [0.5022, 0.4978],
        [0.6338, 0.3662],
        [0.5925, 0.4075],
        [0.7018, 0.2982],
        [0.6504, 0.3496],
        [0.6107, 0.3893],
        [0.5470, 0.4530],
[2K        [0.6025, 0.3975]], device='cuda:0')mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 25/203 [2m0:00:09 â€¢ 0:01:04[0m [2;4m2.81it/s[0m  
[2KAttention weights: tensor([[0.5208, 0.4792],â•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 26/203 [2m0:00:09 â€¢ 0:01:03[0m [2;4m2.82it/s[0m   
        [0.5125, 0.4875],
        [0.5143, 0.4857],
        [0.5200, 0.4800],
        [0.5218, 0.4782],
        [0.5245, 0.4755],
        [0.5218, 0.4782],
        [0.5188, 0.4812],
        [0.5157, 0.4843],
[2K        [0.5219, 0.4781]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 26/203 [2m0:00:09 â€¢ 0:01:03[0m [2;4m2.82it/s[0m  
[2KClass label: HighJumpâ”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 26/203 [2m0:00:09 â€¢ 0:01:03[0m [2;4m2.82it/s[0m  
[2KAttention weights: tensor([[0.6886, 0.3114]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 26/203 [2m0:00:09 â€¢ 0:01:03[0m [2;4m2.82it/s[0m  
[2KStep 0 - TTA Loss: 1.7745[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 26/203 [2m0:00:09 â€¢ 0:01:03[0m [2;4m2.82it/s[0m  
[2KAttention weights: tensor([[0.7049, 0.2951]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 26/203 [2m0:00:09 â€¢ 0:01:03[0m [2;4m2.82it/s[0m  
[2KAttention weights: tensor([[0.7296, 0.2704]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 26/203 [2m0:00:09 â€¢ 0:01:03[0m [2;4m2.82it/s[0m  
[2KAttention weights: tensor([[0.7440, 0.2560]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 26/203 [2m0:00:09 â€¢ 0:01:03[0m [2;4m2.82it/s[0m  
[2KAttention weights: tensor([[0.7571, 0.2429]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 26/203 [2m0:00:09 â€¢ 0:01:03[0m [2;4m2.82it/s[0m  
[2KAttention weights: tensor([[0.7791, 0.2209]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 26/203 [2m0:00:09 â€¢ 0:01:03[0m [2;4m2.82it/s[0m  
[2KAttention weights: tensor([[0.7956, 0.2044]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 26/203 [2m0:00:09 â€¢ 0:01:03[0m [2;4m2.82it/s[0m  
[2KAttention weights: tensor([[0.8145, 0.1855]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 26/203 [2m0:00:09 â€¢ 0:01:03[0m [2;4m2.82it/s[0m  
[2KAttention weights: tensor([[0.8248, 0.1752]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 26/203 [2m0:00:09 â€¢ 0:01:03[0m [2;4m2.82it/s[0m  
[2KAttention weights: tensor([[0.8289, 0.1711]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 26/203 [2m0:00:09 â€¢ 0:01:03[0m [2;4m2.82it/s[0m  
[2KAttention weights: tensor([[0.5312, 0.4688]], device='cuda:0')â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 26/203 [2m0:00:09 â€¢ 0:01:03[0m [2;4m2.82it/s[0m  
[2KAttention weights: tensor([[0.6637, 0.3363],m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 26/203 [2m0:00:09 â€¢ 0:01:03[0m [2;4m2.82it/s[0m  
        [0.4614, 0.5386],
        [0.5354, 0.4646],
        [0.6848, 0.3152],
        [0.6913, 0.3087],
        [0.8310, 0.1690],
        [0.7608, 0.2392],
        [0.6761, 0.3239],
        [0.6079, 0.3921],
[2K        [0.7084, 0.2916]], device='cuda:0')0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 26/203 [2m0:00:09 â€¢ 0:01:03[0m [2;4m2.82it/s[0m  
[2KAttention weights: tensor([[0.5208, 0.4792],â•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 27/203 [2m0:00:10 â€¢ 0:01:03[0m [2;4m2.80it/s[0m  
        [0.5125, 0.4875],
        [0.5143, 0.4857],
        [0.5200, 0.4800],
        [0.5217, 0.4783],
        [0.5245, 0.4755],
        [0.5218, 0.4782],
        [0.5188, 0.4812],
        [0.5157, 0.4843],
[2K        [0.5219, 0.4781]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 27/203 [2m0:00:10 â€¢ 0:01:03[0m [2;4m2.80it/s[0m  
[2KClass label: GolfSwingâ”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 27/203 [2m0:00:10 â€¢ 0:01:03[0m [2;4m2.80it/s[0m  
[2KAttention weights: tensor([[0.6030, 0.3970]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 27/203 [2m0:00:10 â€¢ 0:01:03[0m [2;4m2.80it/s[0m  
[2KStep 0 - TTA Loss: 1.0916[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 27/203 [2m0:00:10 â€¢ 0:01:03[0m [2;4m2.80it/s[0m  
[2KAttention weights: tensor([[0.6030, 0.3970]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 27/203 [2m0:00:10 â€¢ 0:01:03[0m [2;4m2.80it/s[0m  
[2KAttention weights: tensor([[0.6036, 0.3964]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 27/203 [2m0:00:10 â€¢ 0:01:03[0m [2;4m2.80it/s[0m  
[2KAttention weights: tensor([[0.6057, 0.3943]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 27/203 [2m0:00:10 â€¢ 0:01:03[0m [2;4m2.80it/s[0m  
[2KAttention weights: tensor([[0.6102, 0.3898]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 27/203 [2m0:00:10 â€¢ 0:01:03[0m [2;4m2.80it/s[0m  
[2KAttention weights: tensor([[0.6164, 0.3836]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 27/203 [2m0:00:10 â€¢ 0:01:03[0m [2;4m2.80it/s[0m  
[2KAttention weights: tensor([[0.6242, 0.3758]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 27/203 [2m0:00:10 â€¢ 0:01:03[0m [2;4m2.80it/s[0m  
[2KAttention weights: tensor([[0.6345, 0.3655]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 27/203 [2m0:00:10 â€¢ 0:01:03[0m [2;4m2.80it/s[0m  
[2KAttention weights: tensor([[0.6499, 0.3501]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 27/203 [2m0:00:10 â€¢ 0:01:03[0m [2;4m2.80it/s[0m  
[2KAttention weights: tensor([[0.6677, 0.3323]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 27/203 [2m0:00:10 â€¢ 0:01:03[0m [2;4m2.80it/s[0m  
[2KAttention weights: tensor([[0.5240, 0.4760]], device='cuda:0')â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 27/203 [2m0:00:10 â€¢ 0:01:03[0m [2;4m2.80it/s[0m  
[2KAttention weights: tensor([[0.6668, 0.3332],m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 27/203 [2m0:00:10 â€¢ 0:01:03[0m [2;4m2.80it/s[0m  
        [0.4654, 0.5346],
        [0.5310, 0.4690],
        [0.6906, 0.3094],
        [0.6929, 0.3071],
        [0.8297, 0.1703],
        [0.7618, 0.2382],
        [0.6762, 0.3238],
        [0.5928, 0.4072],
[2K        [0.7086, 0.2914]], device='cuda:0')0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 27/203 [2m0:00:10 â€¢ 0:01:03[0m [2;4m2.80it/s[0m  
[2KAttention weights: tensor([[0.5208, 0.4792],;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 28/203 [2m0:00:10 â€¢ 0:01:03[0m [2;4m2.79it/s[0m  
        [0.5125, 0.4875],
        [0.5143, 0.4857],
        [0.5200, 0.4800],
        [0.5218, 0.4782],
        [0.5245, 0.4755],
        [0.5218, 0.4782],
        [0.5188, 0.4812],
        [0.5157, 0.4843],
[2K        [0.5219, 0.4781]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 28/203 [2m0:00:10 â€¢ 0:01:03[0m [2;4m2.79it/s[0m  
[2KClass label: CleanAndJerk[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 28/203 [2m0:00:10 â€¢ 0:01:03[0m [2;4m2.79it/s[0m  
[2KAttention weights: tensor([[0.4988, 0.5012]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 28/203 [2m0:00:10 â€¢ 0:01:03[0m [2;4m2.79it/s[0m  
[2KStep 0 - TTA Loss: 2.6638[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 28/203 [2m0:00:10 â€¢ 0:01:03[0m [2;4m2.79it/s[0m  
[2KAttention weights: tensor([[0.5036, 0.4964]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 28/203 [2m0:00:10 â€¢ 0:01:03[0m [2;4m2.79it/s[0m  
[2KAttention weights: tensor([[0.5117, 0.4883]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 28/203 [2m0:00:10 â€¢ 0:01:03[0m [2;4m2.79it/s[0m  
[2KAttention weights: tensor([[0.5175, 0.4825]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 28/203 [2m0:00:10 â€¢ 0:01:03[0m [2;4m2.79it/s[0m  
[2KAttention weights: tensor([[0.5259, 0.4741]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 28/203 [2m0:00:10 â€¢ 0:01:03[0m [2;4m2.79it/s[0m  
[2KAttention weights: tensor([[0.5347, 0.4653]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 28/203 [2m0:00:10 â€¢ 0:01:03[0m [2;4m2.79it/s[0m  
[2KAttention weights: tensor([[0.5417, 0.4583]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 28/203 [2m0:00:10 â€¢ 0:01:03[0m [2;4m2.79it/s[0m  
[2KAttention weights: tensor([[0.5471, 0.4529]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 28/203 [2m0:00:10 â€¢ 0:01:03[0m [2;4m2.79it/s[0m  
[2KAttention weights: tensor([[0.5508, 0.4492]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 28/203 [2m0:00:10 â€¢ 0:01:03[0m [2;4m2.79it/s[0m  
[2KAttention weights: tensor([[0.5523, 0.4477]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 28/203 [2m0:00:10 â€¢ 0:01:03[0m [2;4m2.79it/s[0m  
[2KAttention weights: tensor([[0.5159, 0.4841]], device='cuda:0')â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 28/203 [2m0:00:10 â€¢ 0:01:03[0m [2;4m2.79it/s[0m  
[2KAttention weights: tensor([[0.6522, 0.3478],mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 28/203 [2m0:00:10 â€¢ 0:01:03[0m [2;4m2.79it/s[0m  
        [0.4640, 0.5360],
        [0.5526, 0.4474],
        [0.6929, 0.3071],
        [0.6666, 0.3334],
        [0.7916, 0.2084],
        [0.7287, 0.2713],
        [0.6566, 0.3434],
        [0.5730, 0.4270],
[2K        [0.6791, 0.3209]], device='cuda:0')4mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 28/203 [2m0:00:10 â€¢ 0:01:03[0m [2;4m2.79it/s[0m  
[2KAttention weights: tensor([[0.5208, 0.4792],;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 29/203 [2m0:00:10 â€¢ 0:01:03[0m [2;4m2.79it/s[0m  
        [0.5125, 0.4875],
        [0.5143, 0.4857],
        [0.5200, 0.4800],
        [0.5218, 0.4782],
        [0.5245, 0.4755],
        [0.5218, 0.4782],
        [0.5189, 0.4811],
        [0.5157, 0.4843],
[2K        [0.5220, 0.4780]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 29/203 [2m0:00:10 â€¢ 0:01:03[0m [2;4m2.79it/s[0m  
[2KClass label: Billiardsâ”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 29/203 [2m0:00:10 â€¢ 0:01:03[0m [2;4m2.79it/s[0m  
[2KAttention weights: tensor([[0.4436, 0.5564]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 29/203 [2m0:00:10 â€¢ 0:01:03[0m [2;4m2.79it/s[0m  
[2KStep 0 - TTA Loss: 1.6101[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 29/203 [2m0:00:10 â€¢ 0:01:03[0m [2;4m2.79it/s[0m  
[2KAttention weights: tensor([[0.4436, 0.5564]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 29/203 [2m0:00:10 â€¢ 0:01:03[0m [2;4m2.79it/s[0m  
[2KAttention weights: tensor([[0.4428, 0.5572]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 29/203 [2m0:00:10 â€¢ 0:01:03[0m [2;4m2.79it/s[0m  
[2KAttention weights: tensor([[0.4390, 0.5610]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 29/203 [2m0:00:10 â€¢ 0:01:03[0m [2;4m2.79it/s[0m  
[2KAttention weights: tensor([[0.4266, 0.5734]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 29/203 [2m0:00:10 â€¢ 0:01:03[0m [2;4m2.79it/s[0m  
[2KAttention weights: tensor([[0.4073, 0.5927]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 29/203 [2m0:00:10 â€¢ 0:01:03[0m [2;4m2.79it/s[0m  
[2KAttention weights: tensor([[0.3800, 0.6200]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 29/203 [2m0:00:10 â€¢ 0:01:03[0m [2;4m2.79it/s[0m  
[2KAttention weights: tensor([[0.3466, 0.6534]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 29/203 [2m0:00:10 â€¢ 0:01:03[0m [2;4m2.79it/s[0m  
[2KAttention weights: tensor([[0.3074, 0.6926]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 29/203 [2m0:00:10 â€¢ 0:01:03[0m [2;4m2.79it/s[0m  
[2KAttention weights: tensor([[0.2706, 0.7294]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 29/203 [2m0:00:10 â€¢ 0:01:03[0m [2;4m2.79it/s[0m  
[2KAttention weights: tensor([[0.5094, 0.4906]], device='cuda:0')â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 29/203 [2m0:00:10 â€¢ 0:01:03[0m [2;4m2.79it/s[0m  
[2KAttention weights: tensor([[0.5935, 0.4065],mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 29/203 [2m0:00:10 â€¢ 0:01:03[0m [2;4m2.79it/s[0m  
        [0.2368, 0.7632],
        [0.5117, 0.4883],
        [0.5784, 0.4216],
        [0.5766, 0.4234],
        [0.7082, 0.2918],
        [0.6660, 0.3340],
        [0.5838, 0.4162],
        [0.5128, 0.4872],
[2K        [0.5950, 0.4050]], device='cuda:0')4mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 29/203 [2m0:00:10 â€¢ 0:01:03[0m [2;4m2.79it/s[0m  
[2KAttention weights: tensor([[0.5208, 0.4792],;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 30/203 [2m0:00:11 â€¢ 0:01:03[0m [2;4m2.78it/s[0m  
        [0.5125, 0.4875],
        [0.5144, 0.4856],
        [0.5200, 0.4800],
        [0.5218, 0.4782],
        [0.5245, 0.4755],
        [0.5218, 0.4782],
        [0.5189, 0.4811],
        [0.5157, 0.4843],
[2K        [0.5220, 0.4780]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 30/203 [2m0:00:11 â€¢ 0:01:03[0m [2;4m2.78it/s[0m  
[2KClass label: CleanAndJerk[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 30/203 [2m0:00:11 â€¢ 0:01:03[0m [2;4m2.78it/s[0m  
[2KAttention weights: tensor([[0.4923, 0.5077]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 30/203 [2m0:00:11 â€¢ 0:01:03[0m [2;4m2.78it/s[0m  
[2KStep 0 - TTA Loss: 1.5719[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 30/203 [2m0:00:11 â€¢ 0:01:03[0m [2;4m2.78it/s[0m  
[2KAttention weights: tensor([[0.5005, 0.4995]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 30/203 [2m0:00:11 â€¢ 0:01:03[0m [2;4m2.78it/s[0m  
[2KAttention weights: tensor([[0.5190, 0.4810]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 30/203 [2m0:00:11 â€¢ 0:01:03[0m [2;4m2.78it/s[0m  
[2KAttention weights: tensor([[0.5337, 0.4663]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 30/203 [2m0:00:11 â€¢ 0:01:03[0m [2;4m2.78it/s[0m  
[2KAttention weights: tensor([[0.5537, 0.4463]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 30/203 [2m0:00:11 â€¢ 0:01:03[0m [2;4m2.78it/s[0m  
[2KAttention weights: tensor([[0.5666, 0.4334]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 30/203 [2m0:00:11 â€¢ 0:01:03[0m [2;4m2.78it/s[0m  
[2KAttention weights: tensor([[0.5770, 0.4230]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 30/203 [2m0:00:11 â€¢ 0:01:03[0m [2;4m2.78it/s[0m  
[2KAttention weights: tensor([[0.5849, 0.4151]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 30/203 [2m0:00:11 â€¢ 0:01:03[0m [2;4m2.78it/s[0m  
[2KAttention weights: tensor([[0.5894, 0.4106]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 30/203 [2m0:00:11 â€¢ 0:01:03[0m [2;4m2.78it/s[0m  
[2KAttention weights: tensor([[0.5919, 0.4081]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 30/203 [2m0:00:11 â€¢ 0:01:03[0m [2;4m2.78it/s[0m  
[2KAttention weights: tensor([[0.5173, 0.4827]], device='cuda:0')â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 30/203 [2m0:00:11 â€¢ 0:01:03[0m [2;4m2.78it/s[0m  
[2KAttention weights: tensor([[0.6062, 0.3938],mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 30/203 [2m0:00:11 â€¢ 0:01:03[0m [2;4m2.78it/s[0m  
        [0.2842, 0.7158],
        [0.5926, 0.4074],
        [0.6015, 0.3985],
        [0.5932, 0.4068],
        [0.7104, 0.2896],
        [0.6694, 0.3306],
        [0.5952, 0.4048],
        [0.5231, 0.4769],
[2K        [0.6110, 0.3890]], device='cuda:0')4mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 30/203 [2m0:00:11 â€¢ 0:01:03[0m [2;4m2.78it/s[0m  
[2KAttention weights: tensor([[0.5208, 0.4792],mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 31/203 [2m0:00:11 â€¢ 0:01:03[0m [2;4m2.77it/s[0m   
        [0.5125, 0.4875],
        [0.5144, 0.4856],
        [0.5200, 0.4800],
        [0.5218, 0.4782],
        [0.5245, 0.4755],
        [0.5218, 0.4782],
        [0.5189, 0.4811],
        [0.5157, 0.4843],
[2K        [0.5220, 0.4780]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 31/203 [2m0:00:11 â€¢ 0:01:03[0m [2;4m2.77it/s[0m  
[2KClass label: CleanAndJerkâ”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 31/203 [2m0:00:11 â€¢ 0:01:03[0m [2;4m2.77it/s[0m  
[2KAttention weights: tensor([[0.4943, 0.5057]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 31/203 [2m0:00:11 â€¢ 0:01:03[0m [2;4m2.77it/s[0m  
[2KStep 0 - TTA Loss: 0.7247â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 31/203 [2m0:00:11 â€¢ 0:01:03[0m [2;4m2.77it/s[0m  
[2KAttention weights: tensor([[0.4943, 0.5057]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 31/203 [2m0:00:11 â€¢ 0:01:03[0m [2;4m2.77it/s[0m  
[2KAttention weights: tensor([[0.4948, 0.5052]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 31/203 [2m0:00:11 â€¢ 0:01:03[0m [2;4m2.77it/s[0m  
[2KAttention weights: tensor([[0.4970, 0.5030]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 31/203 [2m0:00:11 â€¢ 0:01:03[0m [2;4m2.77it/s[0m  
[2KAttention weights: tensor([[0.5014, 0.4986]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 31/203 [2m0:00:11 â€¢ 0:01:03[0m [2;4m2.77it/s[0m  
[2KAttention weights: tensor([[0.5101, 0.4899]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 31/203 [2m0:00:11 â€¢ 0:01:03[0m [2;4m2.77it/s[0m  
[2KAttention weights: tensor([[0.5250, 0.4750]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 31/203 [2m0:00:11 â€¢ 0:01:03[0m [2;4m2.77it/s[0m  
[2KAttention weights: tensor([[0.5440, 0.4560]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 31/203 [2m0:00:11 â€¢ 0:01:03[0m [2;4m2.77it/s[0m  
[2KAttention weights: tensor([[0.5698, 0.4302]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 31/203 [2m0:00:11 â€¢ 0:01:03[0m [2;4m2.77it/s[0m  
[2KAttention weights: tensor([[0.5942, 0.4058]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 31/203 [2m0:00:11 â€¢ 0:01:03[0m [2;4m2.77it/s[0m  
[2KAttention weights: tensor([[0.5184, 0.4816]], device='cuda:0')â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 31/203 [2m0:00:11 â€¢ 0:01:03[0m [2;4m2.77it/s[0m  
[2KAttention weights: tensor([[0.6169, 0.3831],0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 31/203 [2m0:00:11 â€¢ 0:01:03[0m [2;4m2.77it/s[0m  
        [0.4191, 0.5809],
        [0.6207, 0.3793],
        [0.6191, 0.3809],
        [0.6007, 0.3993],
        [0.7029, 0.2971],
        [0.6642, 0.3358],
        [0.6089, 0.3911],
        [0.5291, 0.4709],
[2K        [0.6121, 0.3879]], device='cuda:0')[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 31/203 [2m0:00:11 â€¢ 0:01:03[0m [2;4m2.77it/s[0m  
[2KAttention weights: tensor([[0.5208, 0.4792],mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 32/203 [2m0:00:12 â€¢ 0:01:02[0m [2;4m2.77it/s[0m  
        [0.5125, 0.4875],
        [0.5143, 0.4857],
        [0.5200, 0.4800],
        [0.5218, 0.4782],
        [0.5245, 0.4755],
        [0.5218, 0.4782],
        [0.5189, 0.4811],
        [0.5157, 0.4843],
[2K        [0.5220, 0.4780]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 32/203 [2m0:00:12 â€¢ 0:01:02[0m [2;4m2.77it/s[0m  
[2KClass label: TennisSwingâ”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 32/203 [2m0:00:12 â€¢ 0:01:02[0m [2;4m2.77it/s[0m  
[2KAttention weights: tensor([[0.5191, 0.4809]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 32/203 [2m0:00:12 â€¢ 0:01:02[0m [2;4m2.77it/s[0m  
[2KStep 0 - TTA Loss: 1.4464â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 32/203 [2m0:00:12 â€¢ 0:01:02[0m [2;4m2.77it/s[0m  
[2KAttention weights: tensor([[0.5253, 0.4747]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 32/203 [2m0:00:12 â€¢ 0:01:02[0m [2;4m2.77it/s[0m  
[2KAttention weights: tensor([[0.5441, 0.4559]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 32/203 [2m0:00:12 â€¢ 0:01:02[0m [2;4m2.77it/s[0m  
[2KAttention weights: tensor([[0.5704, 0.4296]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 32/203 [2m0:00:12 â€¢ 0:01:02[0m [2;4m2.77it/s[0m  
[2KAttention weights: tensor([[0.5956, 0.4044]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 32/203 [2m0:00:12 â€¢ 0:01:02[0m [2;4m2.77it/s[0m  
[2KAttention weights: tensor([[0.6169, 0.3831]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 32/203 [2m0:00:12 â€¢ 0:01:02[0m [2;4m2.77it/s[0m  
[2KAttention weights: tensor([[0.6329, 0.3671]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 32/203 [2m0:00:12 â€¢ 0:01:02[0m [2;4m2.77it/s[0m  
[2KAttention weights: tensor([[0.6424, 0.3576]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 32/203 [2m0:00:12 â€¢ 0:01:02[0m [2;4m2.77it/s[0m  
[2KAttention weights: tensor([[0.6476, 0.3524]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 32/203 [2m0:00:12 â€¢ 0:01:02[0m [2;4m2.77it/s[0m  
[2KAttention weights: tensor([[0.6496, 0.3504]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 32/203 [2m0:00:12 â€¢ 0:01:02[0m [2;4m2.77it/s[0m  
[2KAttention weights: tensor([[0.5198, 0.4802]], device='cuda:0')â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 32/203 [2m0:00:12 â€¢ 0:01:02[0m [2;4m2.77it/s[0m  
[2KAttention weights: tensor([[0.6424, 0.3576],0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 32/203 [2m0:00:12 â€¢ 0:01:02[0m [2;4m2.77it/s[0m  
        [0.4347, 0.5653],
        [0.6191, 0.3809],
        [0.6445, 0.3555],
        [0.6259, 0.3741],
        [0.7326, 0.2674],
        [0.6732, 0.3268],
        [0.6320, 0.3680],
        [0.6503, 0.3497],
[2K        [0.6475, 0.3525]], device='cuda:0')[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 32/203 [2m0:00:12 â€¢ 0:01:02[0m [2;4m2.77it/s[0m  
[2KAttention weights: tensor([[0.5208, 0.4792],6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 33/203 [2m0:00:12 â€¢ 0:01:02[0m [2;4m2.75it/s[0m  
        [0.5125, 0.4875],
        [0.5143, 0.4857],
        [0.5200, 0.4800],
        [0.5218, 0.4782],
        [0.5245, 0.4755],
        [0.5218, 0.4782],
        [0.5189, 0.4811],
        [0.5157, 0.4843],
[2K        [0.5220, 0.4780]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 33/203 [2m0:00:12 â€¢ 0:01:02[0m [2;4m2.75it/s[0m  
[2KClass label: CleanAndJerkâ”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 33/203 [2m0:00:12 â€¢ 0:01:02[0m [2;4m2.75it/s[0m  
[2KAttention weights: tensor([[0.4930, 0.5070]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 33/203 [2m0:00:12 â€¢ 0:01:02[0m [2;4m2.75it/s[0m  
[2KStep 0 - TTA Loss: 1.4945â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 33/203 [2m0:00:12 â€¢ 0:01:02[0m [2;4m2.75it/s[0m  
[2KAttention weights: tensor([[0.4930, 0.5070]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 33/203 [2m0:00:12 â€¢ 0:01:02[0m [2;4m2.75it/s[0m  
[2KAttention weights: tensor([[0.4928, 0.5072]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 33/203 [2m0:00:12 â€¢ 0:01:02[0m [2;4m2.75it/s[0m  
[2KAttention weights: tensor([[0.4938, 0.5062]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 33/203 [2m0:00:12 â€¢ 0:01:02[0m [2;4m2.75it/s[0m  
[2KAttention weights: tensor([[0.4943, 0.5057]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 33/203 [2m0:00:12 â€¢ 0:01:02[0m [2;4m2.75it/s[0m  
[2KAttention weights: tensor([[0.5023, 0.4977]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 33/203 [2m0:00:12 â€¢ 0:01:02[0m [2;4m2.75it/s[0m  
[2KAttention weights: tensor([[0.5105, 0.4895]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 33/203 [2m0:00:12 â€¢ 0:01:02[0m [2;4m2.75it/s[0m  
[2KAttention weights: tensor([[0.5218, 0.4782]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 33/203 [2m0:00:12 â€¢ 0:01:02[0m [2;4m2.75it/s[0m  
[2KAttention weights: tensor([[0.5412, 0.4588]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 33/203 [2m0:00:12 â€¢ 0:01:02[0m [2;4m2.75it/s[0m  
[2KAttention weights: tensor([[0.5584, 0.4416]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 33/203 [2m0:00:12 â€¢ 0:01:02[0m [2;4m2.75it/s[0m  
[2KAttention weights: tensor([[0.5167, 0.4833]], device='cuda:0')â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 33/203 [2m0:00:12 â€¢ 0:01:02[0m [2;4m2.75it/s[0m  
[2KAttention weights: tensor([[0.6200, 0.3800],4mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 33/203 [2m0:00:12 â€¢ 0:01:02[0m [2;4m2.75it/s[0m  
        [0.4514, 0.5486],
        [0.5754, 0.4246],
        [0.6192, 0.3808],
        [0.6004, 0.3996],
        [0.7078, 0.2922],
        [0.6551, 0.3449],
        [0.6189, 0.3811],
        [0.5700, 0.4300],
[2K        [0.6137, 0.3863]], device='cuda:0')24mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 33/203 [2m0:00:12 â€¢ 0:01:02[0m [2;4m2.75it/s[0m  
[2KAttention weights: tensor([[0.5208, 0.4792],6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 34/203 [2m0:00:12 â€¢ 0:01:02[0m [2;4m2.75it/s[0m  
        [0.5125, 0.4875],
        [0.5143, 0.4857],
        [0.5200, 0.4800],
        [0.5218, 0.4782],
        [0.5245, 0.4755],
        [0.5218, 0.4782],
        [0.5189, 0.4811],
        [0.5157, 0.4843],
[2K        [0.5220, 0.4780]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 34/203 [2m0:00:12 â€¢ 0:01:02[0m [2;4m2.75it/s[0m  
[2KClass label: HammerThrowâ”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 34/203 [2m0:00:12 â€¢ 0:01:02[0m [2;4m2.75it/s[0m  
[2KAttention weights: tensor([[0.5817, 0.4183]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 34/203 [2m0:00:12 â€¢ 0:01:02[0m [2;4m2.75it/s[0m  
[2KStep 0 - TTA Loss: 2.1642â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 34/203 [2m0:00:12 â€¢ 0:01:02[0m [2;4m2.75it/s[0m  
[2KAttention weights: tensor([[0.5889, 0.4111]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 34/203 [2m0:00:12 â€¢ 0:01:02[0m [2;4m2.75it/s[0m  
[2KAttention weights: tensor([[0.5901, 0.4099]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 34/203 [2m0:00:12 â€¢ 0:01:02[0m [2;4m2.75it/s[0m  
[2KAttention weights: tensor([[0.5881, 0.4119]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 34/203 [2m0:00:12 â€¢ 0:01:02[0m [2;4m2.75it/s[0m  
[2KAttention weights: tensor([[0.5892, 0.4108]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 34/203 [2m0:00:12 â€¢ 0:01:02[0m [2;4m2.75it/s[0m  
[2KAttention weights: tensor([[0.5940, 0.4060]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 34/203 [2m0:00:12 â€¢ 0:01:02[0m [2;4m2.75it/s[0m  
[2KAttention weights: tensor([[0.6089, 0.3911]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 34/203 [2m0:00:12 â€¢ 0:01:02[0m [2;4m2.75it/s[0m  
[2KAttention weights: tensor([[0.6181, 0.3819]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 34/203 [2m0:00:12 â€¢ 0:01:02[0m [2;4m2.75it/s[0m  
[2KAttention weights: tensor([[0.6240, 0.3760]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 34/203 [2m0:00:12 â€¢ 0:01:02[0m [2;4m2.75it/s[0m  
[2KAttention weights: tensor([[0.6263, 0.3737]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 34/203 [2m0:00:12 â€¢ 0:01:02[0m [2;4m2.75it/s[0m  
[2KAttention weights: tensor([[0.5234, 0.4766]], device='cuda:0')â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 34/203 [2m0:00:12 â€¢ 0:01:02[0m [2;4m2.75it/s[0m  
[2KAttention weights: tensor([[0.6268, 0.3732],4mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 34/203 [2m0:00:12 â€¢ 0:01:02[0m [2;4m2.75it/s[0m  
        [0.4483, 0.5517],
        [0.5690, 0.4310],
        [0.6327, 0.3673],
        [0.6278, 0.3722],
        [0.7151, 0.2849],
        [0.6683, 0.3317],
        [0.6195, 0.3805],
        [0.5617, 0.4383],
[2K        [0.6318, 0.3682]], device='cuda:0')24mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 34/203 [2m0:00:12 â€¢ 0:01:02[0m [2;4m2.75it/s[0m  
[2KAttention weights: tensor([[0.5208, 0.4792],6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 35/203 [2m0:00:13 â€¢ 0:01:02[0m [2;4m2.74it/s[0m  
        [0.5125, 0.4875],
        [0.5144, 0.4856],
        [0.5200, 0.4800],
        [0.5218, 0.4782],
        [0.5245, 0.4755],
        [0.5219, 0.4781],
        [0.5189, 0.4811],
        [0.5158, 0.4842],
[2K        [0.5220, 0.4780]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 35/203 [2m0:00:13 â€¢ 0:01:02[0m [2;4m2.74it/s[0m  
[2KClass label: GolfSwingâ”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 35/203 [2m0:00:13 â€¢ 0:01:02[0m [2;4m2.74it/s[0m  
[2KAttention weights: tensor([[0.6005, 0.3995]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 35/203 [2m0:00:13 â€¢ 0:01:02[0m [2;4m2.74it/s[0m  
[2KStep 0 - TTA Loss: 2.3864â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 35/203 [2m0:00:13 â€¢ 0:01:02[0m [2;4m2.74it/s[0m  
[2KAttention weights: tensor([[0.6005, 0.3995]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 35/203 [2m0:00:13 â€¢ 0:01:02[0m [2;4m2.74it/s[0m  
[2KAttention weights: tensor([[0.6009, 0.3991]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 35/203 [2m0:00:13 â€¢ 0:01:02[0m [2;4m2.74it/s[0m  
[2KAttention weights: tensor([[0.6025, 0.3975]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 35/203 [2m0:00:13 â€¢ 0:01:02[0m [2;4m2.74it/s[0m  
[2KAttention weights: tensor([[0.6063, 0.3937]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 35/203 [2m0:00:13 â€¢ 0:01:02[0m [2;4m2.74it/s[0m  
[2KAttention weights: tensor([[0.6134, 0.3866]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 35/203 [2m0:00:13 â€¢ 0:01:02[0m [2;4m2.74it/s[0m  
[2KAttention weights: tensor([[0.6247, 0.3753]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 35/203 [2m0:00:13 â€¢ 0:01:02[0m [2;4m2.74it/s[0m  
[2KAttention weights: tensor([[0.6380, 0.3620]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 35/203 [2m0:00:13 â€¢ 0:01:02[0m [2;4m2.74it/s[0m  
[2KAttention weights: tensor([[0.6525, 0.3475]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 35/203 [2m0:00:13 â€¢ 0:01:02[0m [2;4m2.74it/s[0m  
[2KAttention weights: tensor([[0.6656, 0.3344]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 35/203 [2m0:00:13 â€¢ 0:01:02[0m [2;4m2.74it/s[0m  
[2KAttention weights: tensor([[0.5206, 0.4794]], device='cuda:0')â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 35/203 [2m0:00:13 â€¢ 0:01:02[0m [2;4m2.74it/s[0m  
[2KAttention weights: tensor([[0.6548, 0.3452],4mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 35/203 [2m0:00:13 â€¢ 0:01:02[0m [2;4m2.74it/s[0m  
        [0.4622, 0.5378],
        [0.5349, 0.4651],
        [0.6766, 0.3234],
        [0.6865, 0.3135],
        [0.7424, 0.2576],
        [0.6966, 0.3034],
        [0.6398, 0.3602],
        [0.5520, 0.4480],
[2K        [0.6746, 0.3254]], device='cuda:0')24mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 35/203 [2m0:00:13 â€¢ 0:01:02[0m [2;4m2.74it/s[0m  
[2KAttention weights: tensor([[0.5208, 0.4792],7mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 36/203 [2m0:00:13 â€¢ 0:01:01[0m [2;4m2.75it/s[0m   
        [0.5125, 0.4875],
        [0.5144, 0.4856],
        [0.5200, 0.4800],
        [0.5218, 0.4782],
        [0.5245, 0.4755],
        [0.5219, 0.4781],
        [0.5189, 0.4811],
        [0.5158, 0.4842],
[2K        [0.5220, 0.4780]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 36/203 [2m0:00:13 â€¢ 0:01:01[0m [2;4m2.75it/s[0m  
[2KClass label: TennisSwingâ”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 36/203 [2m0:00:13 â€¢ 0:01:01[0m [2;4m2.75it/s[0m  
[2KAttention weights: tensor([[0.5183, 0.4817]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 36/203 [2m0:00:13 â€¢ 0:01:01[0m [2;4m2.75it/s[0m  
[2KStep 0 - TTA Loss: 2.2956â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 36/203 [2m0:00:13 â€¢ 0:01:01[0m [2;4m2.75it/s[0m  
[2KAttention weights: tensor([[0.5536, 0.4464]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 36/203 [2m0:00:13 â€¢ 0:01:01[0m [2;4m2.75it/s[0m  
[2KAttention weights: tensor([[0.5781, 0.4219]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 36/203 [2m0:00:13 â€¢ 0:01:01[0m [2;4m2.75it/s[0m  
[2KAttention weights: tensor([[0.6016, 0.3984]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 36/203 [2m0:00:13 â€¢ 0:01:01[0m [2;4m2.75it/s[0m  
[2KAttention weights: tensor([[0.6278, 0.3722]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 36/203 [2m0:00:13 â€¢ 0:01:01[0m [2;4m2.75it/s[0m  
[2KAttention weights: tensor([[0.6410, 0.3590]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 36/203 [2m0:00:13 â€¢ 0:01:01[0m [2;4m2.75it/s[0m  
[2KAttention weights: tensor([[0.6512, 0.3488]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 36/203 [2m0:00:13 â€¢ 0:01:01[0m [2;4m2.75it/s[0m  
[2KAttention weights: tensor([[0.6527, 0.3473]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 36/203 [2m0:00:13 â€¢ 0:01:01[0m [2;4m2.75it/s[0m  
[2KAttention weights: tensor([[0.6545, 0.3455]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 36/203 [2m0:00:13 â€¢ 0:01:01[0m [2;4m2.75it/s[0m  
[2KAttention weights: tensor([[0.6557, 0.3443]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 36/203 [2m0:00:13 â€¢ 0:01:01[0m [2;4m2.75it/s[0m  
[2KAttention weights: tensor([[0.5194, 0.4806]], device='cuda:0')â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 36/203 [2m0:00:13 â€¢ 0:01:01[0m [2;4m2.75it/s[0m  
[2KAttention weights: tensor([[0.6639, 0.3361],[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 36/203 [2m0:00:13 â€¢ 0:01:01[0m [2;4m2.75it/s[0m  
        [0.4602, 0.5398],
        [0.5332, 0.4668],
        [0.6663, 0.3337],
        [0.6749, 0.3251],
        [0.7535, 0.2465],
        [0.6912, 0.3088],
        [0.6478, 0.3522],
        [0.6562, 0.3438],
[2K        [0.6793, 0.3207]], device='cuda:0')[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 36/203 [2m0:00:13 â€¢ 0:01:01[0m [2;4m2.75it/s[0m  
[2KAttention weights: tensor([[0.5209, 0.4791],7mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 37/203 [2m0:00:13 â€¢ 0:01:01[0m [2;4m2.75it/s[0m  
        [0.5125, 0.4875],
        [0.5144, 0.4856],
        [0.5200, 0.4800],
        [0.5219, 0.4781],
        [0.5245, 0.4755],
        [0.5219, 0.4781],
        [0.5189, 0.4811],
        [0.5158, 0.4842],
[2K        [0.5220, 0.4780]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 37/203 [2m0:00:13 â€¢ 0:01:01[0m [2;4m2.75it/s[0m  
[2KClass label: SoccerPenaltyâ”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 37/203 [2m0:00:13 â€¢ 0:01:01[0m [2;4m2.75it/s[0m  
[2KAttention weights: tensor([[0.6084, 0.3916]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 37/203 [2m0:00:13 â€¢ 0:01:01[0m [2;4m2.75it/s[0m  
[2KStep 0 - TTA Loss: 1.6971â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 37/203 [2m0:00:13 â€¢ 0:01:01[0m [2;4m2.75it/s[0m  
[2KAttention weights: tensor([[0.6084, 0.3916]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 37/203 [2m0:00:13 â€¢ 0:01:01[0m [2;4m2.75it/s[0m  
[2KAttention weights: tensor([[0.6083, 0.3917]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 37/203 [2m0:00:13 â€¢ 0:01:01[0m [2;4m2.75it/s[0m  
[2KAttention weights: tensor([[0.6076, 0.3924]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 37/203 [2m0:00:13 â€¢ 0:01:01[0m [2;4m2.75it/s[0m  
[2KAttention weights: tensor([[0.6074, 0.3926]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 37/203 [2m0:00:13 â€¢ 0:01:01[0m [2;4m2.75it/s[0m  
[2KAttention weights: tensor([[0.6073, 0.3927]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 37/203 [2m0:00:13 â€¢ 0:01:01[0m [2;4m2.75it/s[0m  
[2KAttention weights: tensor([[0.6083, 0.3917]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 37/203 [2m0:00:13 â€¢ 0:01:01[0m [2;4m2.75it/s[0m  
[2KAttention weights: tensor([[0.6126, 0.3874]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 37/203 [2m0:00:13 â€¢ 0:01:01[0m [2;4m2.75it/s[0m  
[2KAttention weights: tensor([[0.6174, 0.3826]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 37/203 [2m0:00:13 â€¢ 0:01:01[0m [2;4m2.75it/s[0m  
[2KAttention weights: tensor([[0.6168, 0.3832]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 37/203 [2m0:00:13 â€¢ 0:01:01[0m [2;4m2.75it/s[0m  
[2KAttention weights: tensor([[0.5193, 0.4807]], device='cuda:0')â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 37/203 [2m0:00:13 â€¢ 0:01:01[0m [2;4m2.75it/s[0m  
[2KAttention weights: tensor([[0.6100, 0.3900],[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 37/203 [2m0:00:13 â€¢ 0:01:01[0m [2;4m2.75it/s[0m  
        [0.4515, 0.5485],
        [0.5011, 0.4989],
        [0.6136, 0.3864],
        [0.5972, 0.4028],
        [0.7024, 0.2976],
        [0.6519, 0.3481],
        [0.6158, 0.3842],
        [0.5463, 0.4537],
[2K        [0.6034, 0.3966]], device='cuda:0')[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 37/203 [2m0:00:13 â€¢ 0:01:01[0m [2;4m2.75it/s[0m  
[2KAttention weights: tensor([[0.5209, 0.4791],7mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 38/203 [2m0:00:14 â€¢ 0:01:01[0m [2;4m2.73it/s[0m  
        [0.5125, 0.4875],
        [0.5144, 0.4856],
        [0.5200, 0.4800],
        [0.5219, 0.4781],
        [0.5246, 0.4754],
        [0.5219, 0.4781],
        [0.5189, 0.4811],
        [0.5158, 0.4842],
[2K        [0.5221, 0.4779]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 38/203 [2m0:00:14 â€¢ 0:01:01[0m [2;4m2.73it/s[0m  
[2KClass label: HammerThrowâ”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 38/203 [2m0:00:14 â€¢ 0:01:01[0m [2;4m2.73it/s[0m  
[2KAttention weights: tensor([[0.5758, 0.4242]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 38/203 [2m0:00:14 â€¢ 0:01:01[0m [2;4m2.73it/s[0m  
[2KStep 0 - TTA Loss: 2.1204â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 38/203 [2m0:00:14 â€¢ 0:01:01[0m [2;4m2.73it/s[0m  
[2KAttention weights: tensor([[0.5732, 0.4268]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 38/203 [2m0:00:14 â€¢ 0:01:01[0m [2;4m2.73it/s[0m  
[2KAttention weights: tensor([[0.5439, 0.4561]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 38/203 [2m0:00:14 â€¢ 0:01:01[0m [2;4m2.73it/s[0m  
[2KAttention weights: tensor([[0.5169, 0.4831]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 38/203 [2m0:00:14 â€¢ 0:01:01[0m [2;4m2.73it/s[0m  
[2KAttention weights: tensor([[0.4850, 0.5150]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 38/203 [2m0:00:14 â€¢ 0:01:01[0m [2;4m2.73it/s[0m  
[2KAttention weights: tensor([[0.4672, 0.5328]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 38/203 [2m0:00:14 â€¢ 0:01:01[0m [2;4m2.73it/s[0m  
[2KAttention weights: tensor([[0.4497, 0.5503]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 38/203 [2m0:00:14 â€¢ 0:01:01[0m [2;4m2.73it/s[0m  
[2KAttention weights: tensor([[0.4345, 0.5655]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 38/203 [2m0:00:14 â€¢ 0:01:01[0m [2;4m2.73it/s[0m  
[2KAttention weights: tensor([[0.4261, 0.5739]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 38/203 [2m0:00:14 â€¢ 0:01:01[0m [2;4m2.73it/s[0m  
[2KAttention weights: tensor([[0.4224, 0.5776]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 38/203 [2m0:00:14 â€¢ 0:01:01[0m [2;4m2.73it/s[0m  
[2KAttention weights: tensor([[0.5179, 0.4821]], device='cuda:0')â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 38/203 [2m0:00:14 â€¢ 0:01:01[0m [2;4m2.73it/s[0m  
[2KAttention weights: tensor([[0.5327, 0.4673],[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 38/203 [2m0:00:14 â€¢ 0:01:01[0m [2;4m2.73it/s[0m  
        [0.4249, 0.5751],
        [0.4702, 0.5298],
        [0.5422, 0.4578],
        [0.4212, 0.5788],
        [0.6106, 0.3894],
        [0.5695, 0.4305],
        [0.5584, 0.4416],
        [0.4911, 0.5089],
[2K        [0.4683, 0.5317]], device='cuda:0')[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 38/203 [2m0:00:14 â€¢ 0:01:01[0m [2;4m2.73it/s[0m  
[2KAttention weights: tensor([[0.5209, 0.4791],;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 39/203 [2m0:00:15 â€¢ 0:01:02[0m [2;4m2.68it/s[0m  
        [0.5125, 0.4875],
        [0.5144, 0.4856],
        [0.5201, 0.4799],
        [0.5219, 0.4781],
        [0.5246, 0.4754],
        [0.5219, 0.4781],
        [0.5189, 0.4811],
        [0.5158, 0.4842],
[2K        [0.5221, 0.4779]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 39/203 [2m0:00:15 â€¢ 0:01:02[0m [2;4m2.68it/s[0m  
[2KClass label: GolfSwingâ”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 39/203 [2m0:00:15 â€¢ 0:01:02[0m [2;4m2.68it/s[0m  
[2KAttention weights: tensor([[0.6032, 0.3968]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 39/203 [2m0:00:15 â€¢ 0:01:02[0m [2;4m2.68it/s[0m  
[2KStep 0 - TTA Loss: 1.8402â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 39/203 [2m0:00:15 â€¢ 0:01:02[0m [2;4m2.68it/s[0m  
[2KAttention weights: tensor([[0.6032, 0.3968]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 39/203 [2m0:00:15 â€¢ 0:01:02[0m [2;4m2.68it/s[0m  
[2KAttention weights: tensor([[0.6030, 0.3970]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 39/203 [2m0:00:15 â€¢ 0:01:02[0m [2;4m2.68it/s[0m  
[2KAttention weights: tensor([[0.6026, 0.3974]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 39/203 [2m0:00:15 â€¢ 0:01:02[0m [2;4m2.68it/s[0m  
[2KAttention weights: tensor([[0.6019, 0.3981]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 39/203 [2m0:00:15 â€¢ 0:01:02[0m [2;4m2.68it/s[0m  
[2KAttention weights: tensor([[0.6024, 0.3976]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 39/203 [2m0:00:15 â€¢ 0:01:02[0m [2;4m2.68it/s[0m  
[2KAttention weights: tensor([[0.6042, 0.3958]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 39/203 [2m0:00:15 â€¢ 0:01:02[0m [2;4m2.68it/s[0m  
[2KAttention weights: tensor([[0.6068, 0.3932]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 39/203 [2m0:00:15 â€¢ 0:01:02[0m [2;4m2.68it/s[0m  
[2KAttention weights: tensor([[0.6124, 0.3876]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 39/203 [2m0:00:15 â€¢ 0:01:02[0m [2;4m2.68it/s[0m  
[2KAttention weights: tensor([[0.6180, 0.3820]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 39/203 [2m0:00:15 â€¢ 0:01:02[0m [2;4m2.68it/s[0m  
[2KAttention weights: tensor([[0.5207, 0.4793]], device='cuda:0')mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 39/203 [2m0:00:15 â€¢ 0:01:02[0m [2;4m2.68it/s[0m  
[2KAttention weights: tensor([[0.5803, 0.4197],24mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 39/203 [2m0:00:15 â€¢ 0:01:02[0m [2;4m2.68it/s[0m  
        [0.4486, 0.5514],
        [0.4881, 0.5119],
        [0.6234, 0.3766],
        [0.5127, 0.4873],
        [0.6560, 0.3440],
        [0.6168, 0.3832],
        [0.5886, 0.4114],
        [0.5096, 0.4904],
[2K        [0.5409, 0.4591]], device='cuda:0')224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 39/203 [2m0:00:15 â€¢ 0:01:02[0m [2;4m2.68it/s[0m  
[2KAttention weights: tensor([[0.5209, 0.4791],;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 40/203 [2m0:00:15 â€¢ 0:01:01[0m [2;4m2.68it/s[0m  
        [0.5126, 0.4874],
        [0.5145, 0.4855],
        [0.5201, 0.4799],
        [0.5219, 0.4781],
        [0.5246, 0.4754],
        [0.5219, 0.4781],
        [0.5189, 0.4811],
        [0.5158, 0.4842],
[2K        [0.5221, 0.4779]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 40/203 [2m0:00:15 â€¢ 0:01:01[0m [2;4m2.68it/s[0m  
[2KClass label: HighJumpâ”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 40/203 [2m0:00:15 â€¢ 0:01:01[0m [2;4m2.68it/s[0m  
[2KAttention weights: tensor([[0.6882, 0.3118]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 40/203 [2m0:00:15 â€¢ 0:01:01[0m [2;4m2.68it/s[0m  
[2KStep 0 - TTA Loss: 1.2538â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 40/203 [2m0:00:15 â€¢ 0:01:01[0m [2;4m2.68it/s[0m  
[2KAttention weights: tensor([[0.6831, 0.3169]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 40/203 [2m0:00:15 â€¢ 0:01:01[0m [2;4m2.68it/s[0m  
[2KAttention weights: tensor([[0.6675, 0.3325]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 40/203 [2m0:00:15 â€¢ 0:01:01[0m [2;4m2.68it/s[0m  
[2KAttention weights: tensor([[0.6604, 0.3396]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 40/203 [2m0:00:15 â€¢ 0:01:01[0m [2;4m2.68it/s[0m  
[2KAttention weights: tensor([[0.6570, 0.3430]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 40/203 [2m0:00:15 â€¢ 0:01:01[0m [2;4m2.68it/s[0m  
[2KAttention weights: tensor([[0.6512, 0.3488]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 40/203 [2m0:00:15 â€¢ 0:01:01[0m [2;4m2.68it/s[0m  
[2KAttention weights: tensor([[0.6467, 0.3533]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 40/203 [2m0:00:15 â€¢ 0:01:01[0m [2;4m2.68it/s[0m  
[2KAttention weights: tensor([[0.6448, 0.3552]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 40/203 [2m0:00:15 â€¢ 0:01:01[0m [2;4m2.68it/s[0m  
[2KAttention weights: tensor([[0.6426, 0.3574]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 40/203 [2m0:00:15 â€¢ 0:01:01[0m [2;4m2.68it/s[0m  
[2KAttention weights: tensor([[0.6411, 0.3589]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 40/203 [2m0:00:15 â€¢ 0:01:01[0m [2;4m2.68it/s[0m  
[2KAttention weights: tensor([[0.5243, 0.4757]], device='cuda:0')mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 40/203 [2m0:00:15 â€¢ 0:01:01[0m [2;4m2.68it/s[0m  
[2KAttention weights: tensor([[0.5784, 0.4216],24mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 40/203 [2m0:00:15 â€¢ 0:01:01[0m [2;4m2.68it/s[0m  
        [0.4471, 0.5529],
        [0.4799, 0.5201],
        [0.6126, 0.3874],
        [0.5156, 0.4844],
        [0.6410, 0.3590],
        [0.6074, 0.3926],
        [0.5853, 0.4147],
        [0.4997, 0.5003],
[2K        [0.5379, 0.4621]], device='cuda:0')224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 40/203 [2m0:00:15 â€¢ 0:01:01[0m [2;4m2.68it/s[0m  
[2KAttention weights: tensor([[0.5209, 0.4791],37mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 41/203 [2m0:00:15 â€¢ 0:01:01[0m [2;4m2.67it/s[0m   
        [0.5126, 0.4874],
        [0.5145, 0.4855],
        [0.5201, 0.4799],
        [0.5219, 0.4781],
        [0.5246, 0.4754],
        [0.5219, 0.4781],
        [0.5190, 0.4810],
        [0.5159, 0.4841],
[2K        [0.5221, 0.4779]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 41/203 [2m0:00:15 â€¢ 0:01:01[0m [2;4m2.67it/s[0m  
[2KClass label: HammerThrowâ”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 41/203 [2m0:00:15 â€¢ 0:01:01[0m [2;4m2.67it/s[0m  
[2KAttention weights: tensor([[0.5792, 0.4208]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 41/203 [2m0:00:15 â€¢ 0:01:01[0m [2;4m2.67it/s[0m  
[2KStep 0 - TTA Loss: 1.5106â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 41/203 [2m0:00:15 â€¢ 0:01:01[0m [2;4m2.67it/s[0m  
[2KAttention weights: tensor([[0.5792, 0.4208]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 41/203 [2m0:00:15 â€¢ 0:01:01[0m [2;4m2.67it/s[0m  
[2KAttention weights: tensor([[0.5787, 0.4213]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 41/203 [2m0:00:15 â€¢ 0:01:01[0m [2;4m2.67it/s[0m  
[2KAttention weights: tensor([[0.5766, 0.4234]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 41/203 [2m0:00:15 â€¢ 0:01:01[0m [2;4m2.67it/s[0m  
[2KAttention weights: tensor([[0.5727, 0.4273]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 41/203 [2m0:00:15 â€¢ 0:01:01[0m [2;4m2.67it/s[0m  
[2KAttention weights: tensor([[0.5661, 0.4339]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 41/203 [2m0:00:15 â€¢ 0:01:01[0m [2;4m2.67it/s[0m  
[2KAttention weights: tensor([[0.5593, 0.4407]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 41/203 [2m0:00:15 â€¢ 0:01:01[0m [2;4m2.67it/s[0m  
[2KAttention weights: tensor([[0.5455, 0.4545]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 41/203 [2m0:00:15 â€¢ 0:01:01[0m [2;4m2.67it/s[0m  
[2KAttention weights: tensor([[0.5277, 0.4723]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 41/203 [2m0:00:15 â€¢ 0:01:01[0m [2;4m2.67it/s[0m  
[2KAttention weights: tensor([[0.5050, 0.4950]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 41/203 [2m0:00:15 â€¢ 0:01:01[0m [2;4m2.67it/s[0m  
[2KAttention weights: tensor([[0.5193, 0.4807]], device='cuda:0')â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 41/203 [2m0:00:15 â€¢ 0:01:01[0m [2;4m2.67it/s[0m  
[2KAttention weights: tensor([[0.5568, 0.4432],[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 41/203 [2m0:00:15 â€¢ 0:01:01[0m [2;4m2.67it/s[0m  
        [0.4426, 0.5574],
        [0.4741, 0.5259],
        [0.5773, 0.4227],
        [0.4869, 0.5131],
        [0.6132, 0.3868],
        [0.5809, 0.4191],
        [0.5762, 0.4238],
        [0.4813, 0.5187],
[2K        [0.5072, 0.4928]], device='cuda:0')â•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 41/203 [2m0:00:15 â€¢ 0:01:01[0m [2;4m2.67it/s[0m  
[2KAttention weights: tensor([[0.5209, 0.4791],37mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 42/203 [2m0:00:16 â€¢ 0:01:01[0m [2;4m2.68it/s[0m  
        [0.5126, 0.4874],
        [0.5145, 0.4855],
        [0.5201, 0.4799],
        [0.5219, 0.4781],
        [0.5246, 0.4754],
        [0.5219, 0.4781],
        [0.5190, 0.4810],
        [0.5159, 0.4841],
[2K        [0.5221, 0.4779]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 42/203 [2m0:00:16 â€¢ 0:01:01[0m [2;4m2.68it/s[0m  
[2KClass label: HammerThrowâ”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 42/203 [2m0:00:16 â€¢ 0:01:01[0m [2;4m2.68it/s[0m  
[2KAttention weights: tensor([[0.5759, 0.4241]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 42/203 [2m0:00:16 â€¢ 0:01:01[0m [2;4m2.68it/s[0m  
[2KStep 0 - TTA Loss: 1.3912â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 42/203 [2m0:00:16 â€¢ 0:01:01[0m [2;4m2.68it/s[0m  
[2KAttention weights: tensor([[0.5589, 0.4411]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 42/203 [2m0:00:16 â€¢ 0:01:01[0m [2;4m2.68it/s[0m  
[2KAttention weights: tensor([[0.5477, 0.4523]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 42/203 [2m0:00:16 â€¢ 0:01:01[0m [2;4m2.68it/s[0m  
[2KAttention weights: tensor([[0.5401, 0.4599]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 42/203 [2m0:00:16 â€¢ 0:01:01[0m [2;4m2.68it/s[0m  
[2KAttention weights: tensor([[0.5344, 0.4656]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 42/203 [2m0:00:16 â€¢ 0:01:01[0m [2;4m2.68it/s[0m  
[2KAttention weights: tensor([[0.5280, 0.4720]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 42/203 [2m0:00:16 â€¢ 0:01:01[0m [2;4m2.68it/s[0m  
[2KAttention weights: tensor([[0.5220, 0.4780]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 42/203 [2m0:00:16 â€¢ 0:01:01[0m [2;4m2.68it/s[0m  
[2KAttention weights: tensor([[0.5186, 0.4814]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 42/203 [2m0:00:16 â€¢ 0:01:01[0m [2;4m2.68it/s[0m  
[2KAttention weights: tensor([[0.5168, 0.4832]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 42/203 [2m0:00:16 â€¢ 0:01:01[0m [2;4m2.68it/s[0m  
[2KAttention weights: tensor([[0.5162, 0.4838]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 42/203 [2m0:00:16 â€¢ 0:01:01[0m [2;4m2.68it/s[0m  
[2KAttention weights: tensor([[0.5202, 0.4798]], device='cuda:0')â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 42/203 [2m0:00:16 â€¢ 0:01:01[0m [2;4m2.68it/s[0m  
[2KAttention weights: tensor([[0.5782, 0.4218],[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 42/203 [2m0:00:16 â€¢ 0:01:01[0m [2;4m2.68it/s[0m  
        [0.4394, 0.5606],
        [0.4764, 0.5236],
        [0.5843, 0.4157],
        [0.5160, 0.4840],
        [0.6396, 0.3604],
        [0.6024, 0.3976],
        [0.5826, 0.4174],
        [0.4960, 0.5040],
[2K        [0.5336, 0.4664]], device='cuda:0')â•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 42/203 [2m0:00:16 â€¢ 0:01:01[0m [2;4m2.68it/s[0m  
[2KAttention weights: tensor([[0.5209, 0.4791],37mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 43/203 [2m0:00:16 â€¢ 0:01:00[0m [2;4m2.68it/s[0m  
        [0.5126, 0.4874],
        [0.5145, 0.4855],
        [0.5201, 0.4799],
        [0.5219, 0.4781],
        [0.5246, 0.4754],
        [0.5219, 0.4781],
        [0.5190, 0.4810],
        [0.5159, 0.4841],
[2K        [0.5221, 0.4779]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 43/203 [2m0:00:16 â€¢ 0:01:00[0m [2;4m2.68it/s[0m  
[2KClass label: HammerThrowâ”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 43/203 [2m0:00:16 â€¢ 0:01:00[0m [2;4m2.68it/s[0m  
[2KAttention weights: tensor([[0.5767, 0.4233]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 43/203 [2m0:00:16 â€¢ 0:01:00[0m [2;4m2.68it/s[0m  
[2KStep 0 - TTA Loss: 1.7225â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 43/203 [2m0:00:16 â€¢ 0:01:00[0m [2;4m2.68it/s[0m  
[2KAttention weights: tensor([[0.5767, 0.4233]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 43/203 [2m0:00:16 â€¢ 0:01:00[0m [2;4m2.68it/s[0m  
[2KAttention weights: tensor([[0.5766, 0.4234]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 43/203 [2m0:00:16 â€¢ 0:01:00[0m [2;4m2.68it/s[0m  
[2KAttention weights: tensor([[0.5764, 0.4236]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 43/203 [2m0:00:16 â€¢ 0:01:00[0m [2;4m2.68it/s[0m  
[2KAttention weights: tensor([[0.5756, 0.4244]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 43/203 [2m0:00:16 â€¢ 0:01:00[0m [2;4m2.68it/s[0m  
[2KAttention weights: tensor([[0.5717, 0.4283]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 43/203 [2m0:00:16 â€¢ 0:01:00[0m [2;4m2.68it/s[0m  
[2KAttention weights: tensor([[0.5649, 0.4351]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 43/203 [2m0:00:16 â€¢ 0:01:00[0m [2;4m2.68it/s[0m  
[2KAttention weights: tensor([[0.5593, 0.4407]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 43/203 [2m0:00:16 â€¢ 0:01:00[0m [2;4m2.68it/s[0m  
[2KAttention weights: tensor([[0.5482, 0.4518]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 43/203 [2m0:00:16 â€¢ 0:01:00[0m [2;4m2.68it/s[0m  
[2KAttention weights: tensor([[0.5373, 0.4627]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 43/203 [2m0:00:16 â€¢ 0:01:00[0m [2;4m2.68it/s[0m  
[2KAttention weights: tensor([[0.5207, 0.4793]], device='cuda:0')â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 43/203 [2m0:00:16 â€¢ 0:01:00[0m [2;4m2.68it/s[0m  
[2KAttention weights: tensor([[0.5832, 0.4168],[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 43/203 [2m0:00:16 â€¢ 0:01:00[0m [2;4m2.68it/s[0m  
        [0.4432, 0.5568],
        [0.4849, 0.5151],
        [0.5877, 0.4123],
        [0.5348, 0.4652],
        [0.6691, 0.3309],
        [0.6234, 0.3766],
        [0.5966, 0.4034],
        [0.5082, 0.4918],
[2K        [0.5535, 0.4465]], device='cuda:0')â•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 43/203 [2m0:00:16 â€¢ 0:01:00[0m [2;4m2.68it/s[0m  
[2KAttention weights: tensor([[0.5209, 0.4791],8;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 44/203 [2m0:00:16 â€¢ 0:01:00[0m [2;4m2.68it/s[0m  
        [0.5126, 0.4874],
        [0.5145, 0.4855],
        [0.5201, 0.4799],
        [0.5219, 0.4781],
        [0.5246, 0.4754],
        [0.5219, 0.4781],
        [0.5189, 0.4811],
        [0.5158, 0.4842],
[2K        [0.5221, 0.4779]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 44/203 [2m0:00:16 â€¢ 0:01:00[0m [2;4m2.68it/s[0m  
[2KClass label: HighJumpâ”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 44/203 [2m0:00:16 â€¢ 0:01:00[0m [2;4m2.68it/s[0m  
[2KAttention weights: tensor([[0.6889, 0.3111]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 44/203 [2m0:00:16 â€¢ 0:01:00[0m [2;4m2.68it/s[0m  
[2KStep 0 - TTA Loss: 0.9723â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 44/203 [2m0:00:16 â€¢ 0:01:00[0m [2;4m2.68it/s[0m  
[2KAttention weights: tensor([[0.6821, 0.3179]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 44/203 [2m0:00:16 â€¢ 0:01:00[0m [2;4m2.68it/s[0m  
[2KAttention weights: tensor([[0.6736, 0.3264]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 44/203 [2m0:00:16 â€¢ 0:01:00[0m [2;4m2.68it/s[0m  
[2KAttention weights: tensor([[0.6568, 0.3432]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 44/203 [2m0:00:16 â€¢ 0:01:00[0m [2;4m2.68it/s[0m  
[2KAttention weights: tensor([[0.6380, 0.3620]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 44/203 [2m0:00:16 â€¢ 0:01:00[0m [2;4m2.68it/s[0m  
[2KAttention weights: tensor([[0.6271, 0.3729]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 44/203 [2m0:00:16 â€¢ 0:01:00[0m [2;4m2.68it/s[0m  
[2KAttention weights: tensor([[0.6269, 0.3731]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 44/203 [2m0:00:16 â€¢ 0:01:00[0m [2;4m2.68it/s[0m  
[2KAttention weights: tensor([[0.6296, 0.3704]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 44/203 [2m0:00:16 â€¢ 0:01:00[0m [2;4m2.68it/s[0m  
[2KAttention weights: tensor([[0.6322, 0.3678]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 44/203 [2m0:00:16 â€¢ 0:01:00[0m [2;4m2.68it/s[0m  
[2KAttention weights: tensor([[0.6339, 0.3661]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 44/203 [2m0:00:16 â€¢ 0:01:00[0m [2;4m2.68it/s[0m  
[2KAttention weights: tensor([[0.5237, 0.4763]], device='cuda:0')7mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 44/203 [2m0:00:16 â€¢ 0:01:00[0m [2;4m2.68it/s[0m  
[2KAttention weights: tensor([[0.5817, 0.4183],224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 44/203 [2m0:00:16 â€¢ 0:01:00[0m [2;4m2.68it/s[0m  
        [0.4421, 0.5579],
        [0.4858, 0.5142],
        [0.5897, 0.4103],
        [0.5396, 0.4604],
        [0.6348, 0.3652],
        [0.6042, 0.3958],
        [0.5837, 0.4163],
        [0.4938, 0.5062],
[2K        [0.5475, 0.4525]], device='cuda:0');224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 44/203 [2m0:00:16 â€¢ 0:01:00[0m [2;4m2.68it/s[0m  
[2KAttention weights: tensor([[0.5209, 0.4791],8;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 45/203 [2m0:00:17 â€¢ 0:01:00[0m [2;4m2.66it/s[0m  
        [0.5126, 0.4874],
        [0.5144, 0.4856],
        [0.5201, 0.4799],
        [0.5219, 0.4781],
        [0.5245, 0.4755],
        [0.5219, 0.4781],
        [0.5189, 0.4811],
        [0.5158, 0.4842],
[2K        [0.5221, 0.4779]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 45/203 [2m0:00:17 â€¢ 0:01:00[0m [2;4m2.66it/s[0m  
[2KClass label: GolfSwingâ”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 45/203 [2m0:00:17 â€¢ 0:01:00[0m [2;4m2.66it/s[0m  
[2KAttention weights: tensor([[0.6032, 0.3968]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 45/203 [2m0:00:17 â€¢ 0:01:00[0m [2;4m2.66it/s[0m  
[2KStep 0 - TTA Loss: 1.0875â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 45/203 [2m0:00:17 â€¢ 0:01:00[0m [2;4m2.66it/s[0m  
[2KAttention weights: tensor([[0.6032, 0.3968]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 45/203 [2m0:00:17 â€¢ 0:01:00[0m [2;4m2.66it/s[0m  
[2KAttention weights: tensor([[0.6031, 0.3969]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 45/203 [2m0:00:17 â€¢ 0:01:00[0m [2;4m2.66it/s[0m  
[2KAttention weights: tensor([[0.6029, 0.3971]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 45/203 [2m0:00:17 â€¢ 0:01:00[0m [2;4m2.66it/s[0m  
[2KAttention weights: tensor([[0.6023, 0.3977]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 45/203 [2m0:00:17 â€¢ 0:01:00[0m [2;4m2.66it/s[0m  
[2KAttention weights: tensor([[0.6004, 0.3996]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 45/203 [2m0:00:17 â€¢ 0:01:00[0m [2;4m2.66it/s[0m  
[2KAttention weights: tensor([[0.5976, 0.4024]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 45/203 [2m0:00:17 â€¢ 0:01:00[0m [2;4m2.66it/s[0m  
[2KAttention weights: tensor([[0.5931, 0.4069]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 45/203 [2m0:00:17 â€¢ 0:01:00[0m [2;4m2.66it/s[0m  
[2KAttention weights: tensor([[0.5896, 0.4104]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 45/203 [2m0:00:17 â€¢ 0:01:00[0m [2;4m2.66it/s[0m  
[2KAttention weights: tensor([[0.5843, 0.4157]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 45/203 [2m0:00:17 â€¢ 0:01:00[0m [2;4m2.66it/s[0m  
[2KAttention weights: tensor([[0.5198, 0.4802]], device='cuda:0')7mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 45/203 [2m0:00:17 â€¢ 0:01:00[0m [2;4m2.66it/s[0m  
[2KAttention weights: tensor([[0.6025, 0.3975],224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 45/203 [2m0:00:17 â€¢ 0:01:00[0m [2;4m2.66it/s[0m  
        [0.4393, 0.5607],
        [0.4913, 0.5087],
        [0.5808, 0.4192],
        [0.5897, 0.4103],
        [0.7196, 0.2804],
        [0.6663, 0.3337],
        [0.6169, 0.3831],
        [0.5212, 0.4788],
[2K        [0.5965, 0.4035]], device='cuda:0');224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 45/203 [2m0:00:17 â€¢ 0:01:00[0m [2;4m2.66it/s[0m  
[2KAttention weights: tensor([[0.5209, 0.4791],237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 46/203 [2m0:00:17 â€¢ 0:01:00[0m [2;4m2.65it/s[0m   
        [0.5126, 0.4874],
        [0.5144, 0.4856],
        [0.5201, 0.4799],
        [0.5219, 0.4781],
        [0.5245, 0.4755],
        [0.5219, 0.4781],
        [0.5189, 0.4811],
        [0.5158, 0.4842],
[2K        [0.5221, 0.4779]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 46/203 [2m0:00:17 â€¢ 0:01:00[0m [2;4m2.65it/s[0m  
[2KClass label: GolfSwingâ”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 46/203 [2m0:00:17 â€¢ 0:01:00[0m [2;4m2.65it/s[0m  
[2KAttention weights: tensor([[0.6007, 0.3993]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 46/203 [2m0:00:17 â€¢ 0:01:00[0m [2;4m2.65it/s[0m  
[2KStep 0 - TTA Loss: 2.9622â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 46/203 [2m0:00:17 â€¢ 0:01:00[0m [2;4m2.65it/s[0m  
[2KAttention weights: tensor([[0.6010, 0.3990]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 46/203 [2m0:00:17 â€¢ 0:01:00[0m [2;4m2.65it/s[0m  
[2KAttention weights: tensor([[0.6239, 0.3761]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 46/203 [2m0:00:17 â€¢ 0:01:00[0m [2;4m2.65it/s[0m  
[2KAttention weights: tensor([[0.6473, 0.3527]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 46/203 [2m0:00:17 â€¢ 0:01:00[0m [2;4m2.65it/s[0m  
[2KAttention weights: tensor([[0.6657, 0.3343]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 46/203 [2m0:00:17 â€¢ 0:01:00[0m [2;4m2.65it/s[0m  
[2KAttention weights: tensor([[0.6773, 0.3227]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 46/203 [2m0:00:17 â€¢ 0:01:00[0m [2;4m2.65it/s[0m  
[2KAttention weights: tensor([[0.6835, 0.3165]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 46/203 [2m0:00:17 â€¢ 0:01:00[0m [2;4m2.65it/s[0m  
[2KAttention weights: tensor([[0.6862, 0.3138]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 46/203 [2m0:00:17 â€¢ 0:01:00[0m [2;4m2.65it/s[0m  
[2KAttention weights: tensor([[0.6863, 0.3137]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 46/203 [2m0:00:17 â€¢ 0:01:00[0m [2;4m2.65it/s[0m  
[2KAttention weights: tensor([[0.6856, 0.3144]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 46/203 [2m0:00:17 â€¢ 0:01:00[0m [2;4m2.65it/s[0m  
[2KAttention weights: tensor([[0.5220, 0.4780]], device='cuda:0')â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 46/203 [2m0:00:17 â€¢ 0:01:00[0m [2;4m2.65it/s[0m  
[2KAttention weights: tensor([[0.6340, 0.3660],â•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 46/203 [2m0:00:17 â€¢ 0:01:00[0m [2;4m2.65it/s[0m  
        [0.4646, 0.5354],
        [0.5110, 0.4890],
        [0.6858, 0.3142],
        [0.6220, 0.3780],
        [0.7268, 0.2732],
        [0.6792, 0.3208],
        [0.6286, 0.3714],
        [0.5457, 0.4543],
[2K        [0.6322, 0.3678]], device='cuda:0')mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 46/203 [2m0:00:17 â€¢ 0:01:00[0m [2;4m2.65it/s[0m  
[2KAttention weights: tensor([[0.5210, 0.4790],237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 47/203 [2m0:00:18 â€¢ 0:00:59[0m [2;4m2.65it/s[0m  
        [0.5126, 0.4874],
        [0.5145, 0.4855],
        [0.5202, 0.4798],
        [0.5219, 0.4781],
        [0.5246, 0.4754],
        [0.5219, 0.4781],
        [0.5190, 0.4810],
        [0.5159, 0.4841],
[2K        [0.5221, 0.4779]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 47/203 [2m0:00:18 â€¢ 0:00:59[0m [2;4m2.65it/s[0m  
[2KClass label: HammerThrowâ”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 47/203 [2m0:00:18 â€¢ 0:00:59[0m [2;4m2.65it/s[0m  
[2KAttention weights: tensor([[0.5777, 0.4223]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 47/203 [2m0:00:18 â€¢ 0:00:59[0m [2;4m2.65it/s[0m  
[2KStep 0 - TTA Loss: 1.2227â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 47/203 [2m0:00:18 â€¢ 0:00:59[0m [2;4m2.65it/s[0m  
[2KAttention weights: tensor([[0.5777, 0.4223]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 47/203 [2m0:00:18 â€¢ 0:00:59[0m [2;4m2.65it/s[0m  
[2KAttention weights: tensor([[0.5773, 0.4227]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 47/203 [2m0:00:18 â€¢ 0:00:59[0m [2;4m2.65it/s[0m  
[2KAttention weights: tensor([[0.5755, 0.4245]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 47/203 [2m0:00:18 â€¢ 0:00:59[0m [2;4m2.65it/s[0m  
[2KAttention weights: tensor([[0.5709, 0.4291]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 47/203 [2m0:00:18 â€¢ 0:00:59[0m [2;4m2.65it/s[0m  
[2KAttention weights: tensor([[0.5611, 0.4389]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 47/203 [2m0:00:18 â€¢ 0:00:59[0m [2;4m2.65it/s[0m  
[2KAttention weights: tensor([[0.5482, 0.4518]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 47/203 [2m0:00:18 â€¢ 0:00:59[0m [2;4m2.65it/s[0m  
[2KAttention weights: tensor([[0.5295, 0.4705]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 47/203 [2m0:00:18 â€¢ 0:00:59[0m [2;4m2.65it/s[0m  
[2KAttention weights: tensor([[0.5049, 0.4951]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 47/203 [2m0:00:18 â€¢ 0:00:59[0m [2;4m2.65it/s[0m  
[2KAttention weights: tensor([[0.4761, 0.5239]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 47/203 [2m0:00:18 â€¢ 0:00:59[0m [2;4m2.65it/s[0m  
[2KAttention weights: tensor([[0.5188, 0.4812]], device='cuda:0')â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 47/203 [2m0:00:18 â€¢ 0:00:59[0m [2;4m2.65it/s[0m  
[2KAttention weights: tensor([[0.5392, 0.4608],â•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 47/203 [2m0:00:18 â€¢ 0:00:59[0m [2;4m2.65it/s[0m  
        [0.4247, 0.5753],
        [0.4649, 0.5351],
        [0.5201, 0.4799],
        [0.4452, 0.5548],
        [0.6288, 0.3712],
        [0.5854, 0.4146],
        [0.5685, 0.4315],
        [0.4848, 0.5152],
[2K        [0.4842, 0.5158]], device='cuda:0')mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 47/203 [2m0:00:18 â€¢ 0:00:59[0m [2;4m2.65it/s[0m  
[2KAttention weights: tensor([[0.5210, 0.4790],237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 48/203 [2m0:00:18 â€¢ 0:00:59[0m [2;4m2.63it/s[0m  
        [0.5126, 0.4874],
        [0.5145, 0.4855],
        [0.5202, 0.4798],
        [0.5220, 0.4780],
        [0.5246, 0.4754],
        [0.5220, 0.4780],
        [0.5190, 0.4810],
        [0.5159, 0.4841],
[2K        [0.5221, 0.4779]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 48/203 [2m0:00:18 â€¢ 0:00:59[0m [2;4m2.63it/s[0m  
[2KClass label: TennisSwingâ”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 48/203 [2m0:00:18 â€¢ 0:00:59[0m [2;4m2.63it/s[0m  
[2KAttention weights: tensor([[0.5108, 0.4892]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 48/203 [2m0:00:18 â€¢ 0:00:59[0m [2;4m2.63it/s[0m  
[2KStep 0 - TTA Loss: 0.8587â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 48/203 [2m0:00:18 â€¢ 0:00:59[0m [2;4m2.63it/s[0m  
[2KAttention weights: tensor([[0.5035, 0.4965]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 48/203 [2m0:00:18 â€¢ 0:00:59[0m [2;4m2.63it/s[0m  
[2KAttention weights: tensor([[0.4972, 0.5028]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 48/203 [2m0:00:18 â€¢ 0:00:59[0m [2;4m2.63it/s[0m  
[2KAttention weights: tensor([[0.4928, 0.5072]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 48/203 [2m0:00:18 â€¢ 0:00:59[0m [2;4m2.63it/s[0m  
[2KAttention weights: tensor([[0.4895, 0.5105]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 48/203 [2m0:00:18 â€¢ 0:00:59[0m [2;4m2.63it/s[0m  
[2KAttention weights: tensor([[0.4865, 0.5135]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 48/203 [2m0:00:18 â€¢ 0:00:59[0m [2;4m2.63it/s[0m  
[2KAttention weights: tensor([[0.4840, 0.5160]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 48/203 [2m0:00:18 â€¢ 0:00:59[0m [2;4m2.63it/s[0m  
[2KAttention weights: tensor([[0.4825, 0.5175]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 48/203 [2m0:00:18 â€¢ 0:00:59[0m [2;4m2.63it/s[0m  
[2KAttention weights: tensor([[0.4814, 0.5186]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 48/203 [2m0:00:18 â€¢ 0:00:59[0m [2;4m2.63it/s[0m  
[2KAttention weights: tensor([[0.4809, 0.5191]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 48/203 [2m0:00:18 â€¢ 0:00:59[0m [2;4m2.63it/s[0m  
[2KAttention weights: tensor([[0.5147, 0.4853]], device='cuda:0')â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 48/203 [2m0:00:18 â€¢ 0:00:59[0m [2;4m2.63it/s[0m  
[2KAttention weights: tensor([[0.5421, 0.4579],â•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 48/203 [2m0:00:18 â€¢ 0:00:59[0m [2;4m2.63it/s[0m  
        [0.4254, 0.5746],
        [0.4623, 0.5377],
        [0.5265, 0.4735],
        [0.4518, 0.5482],
        [0.6279, 0.3721],
        [0.5846, 0.4154],
        [0.5742, 0.4258],
        [0.4808, 0.5192],
[2K        [0.4866, 0.5134]], device='cuda:0')mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 48/203 [2m0:00:18 â€¢ 0:00:59[0m [2;4m2.63it/s[0m  
[2KAttention weights: tensor([[0.5210, 0.4790],98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 49/203 [2m0:00:19 â€¢ 0:00:59[0m [2;4m2.64it/s[0m  
        [0.5126, 0.4874],
        [0.5145, 0.4855],
        [0.5202, 0.4798],
        [0.5220, 0.4780],
        [0.5246, 0.4754],
        [0.5220, 0.4780],
        [0.5190, 0.4810],
        [0.5159, 0.4841],
[2K        [0.5222, 0.4778]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 49/203 [2m0:00:19 â€¢ 0:00:59[0m [2;4m2.64it/s[0m  
[2KClass label: CleanAndJerkâ”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 49/203 [2m0:00:19 â€¢ 0:00:59[0m [2;4m2.64it/s[0m  
[2KAttention weights: tensor([[0.4962, 0.5038]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 49/203 [2m0:00:19 â€¢ 0:00:59[0m [2;4m2.64it/s[0m  
[2KStep 0 - TTA Loss: 0.8362â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 49/203 [2m0:00:19 â€¢ 0:00:59[0m [2;4m2.64it/s[0m  
[2KAttention weights: tensor([[0.4962, 0.5038]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 49/203 [2m0:00:19 â€¢ 0:00:59[0m [2;4m2.64it/s[0m  
[2KAttention weights: tensor([[0.4961, 0.5039]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 49/203 [2m0:00:19 â€¢ 0:00:59[0m [2;4m2.64it/s[0m  
[2KAttention weights: tensor([[0.4954, 0.5046]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 49/203 [2m0:00:19 â€¢ 0:00:59[0m [2;4m2.64it/s[0m  
[2KAttention weights: tensor([[0.4934, 0.5066]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 49/203 [2m0:00:19 â€¢ 0:00:59[0m [2;4m2.64it/s[0m  
[2KAttention weights: tensor([[0.4900, 0.5100]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 49/203 [2m0:00:19 â€¢ 0:00:59[0m [2;4m2.64it/s[0m  
[2KAttention weights: tensor([[0.4858, 0.5142]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 49/203 [2m0:00:19 â€¢ 0:00:59[0m [2;4m2.64it/s[0m  
[2KAttention weights: tensor([[0.4821, 0.5179]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 49/203 [2m0:00:19 â€¢ 0:00:59[0m [2;4m2.64it/s[0m  
[2KAttention weights: tensor([[0.4768, 0.5232]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 49/203 [2m0:00:19 â€¢ 0:00:59[0m [2;4m2.64it/s[0m  
[2KAttention weights: tensor([[0.4718, 0.5282]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 49/203 [2m0:00:19 â€¢ 0:00:59[0m [2;4m2.64it/s[0m  
[2KAttention weights: tensor([[0.5135, 0.4865]], device='cuda:0')37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 49/203 [2m0:00:19 â€¢ 0:00:59[0m [2;4m2.64it/s[0m  
[2KAttention weights: tensor([[0.5899, 0.4101],;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 49/203 [2m0:00:19 â€¢ 0:00:59[0m [2;4m2.64it/s[0m  
        [0.4416, 0.5584],
        [0.4652, 0.5348],
        [0.5862, 0.4138],
        [0.5522, 0.4478],
        [0.6756, 0.3244],
        [0.6289, 0.3711],
        [0.5992, 0.4008],
        [0.5052, 0.4948],
[2K        [0.5627, 0.4373]], device='cuda:0')6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 49/203 [2m0:00:19 â€¢ 0:00:59[0m [2;4m2.64it/s[0m  
[2KAttention weights: tensor([[0.5210, 0.4790],98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 50/203 [2m0:00:19 â€¢ 0:00:59[0m [2;4m2.63it/s[0m  
        [0.5126, 0.4874],
        [0.5145, 0.4855],
        [0.5202, 0.4798],
        [0.5220, 0.4780],
        [0.5246, 0.4754],
        [0.5220, 0.4780],
        [0.5190, 0.4810],
        [0.5159, 0.4841],
[2K        [0.5222, 0.4778]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 50/203 [2m0:00:19 â€¢ 0:00:59[0m [2;4m2.63it/s[0m  
[2KClass label: HammerThrowâ”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 50/203 [2m0:00:19 â€¢ 0:00:59[0m [2;4m2.63it/s[0m  
[2KAttention weights: tensor([[0.5751, 0.4249]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 50/203 [2m0:00:19 â€¢ 0:00:59[0m [2;4m2.63it/s[0m  
[2KStep 0 - TTA Loss: 1.7650â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 50/203 [2m0:00:19 â€¢ 0:00:59[0m [2;4m2.63it/s[0m  
[2KAttention weights: tensor([[0.5642, 0.4358]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 50/203 [2m0:00:19 â€¢ 0:00:59[0m [2;4m2.63it/s[0m  
[2KAttention weights: tensor([[0.5545, 0.4455]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 50/203 [2m0:00:19 â€¢ 0:00:59[0m [2;4m2.63it/s[0m  
[2KAttention weights: tensor([[0.5391, 0.4609]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 50/203 [2m0:00:19 â€¢ 0:00:59[0m [2;4m2.63it/s[0m  
[2KAttention weights: tensor([[0.5243, 0.4757]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 50/203 [2m0:00:19 â€¢ 0:00:59[0m [2;4m2.63it/s[0m  
[2KAttention weights: tensor([[0.5125, 0.4875]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 50/203 [2m0:00:19 â€¢ 0:00:59[0m [2;4m2.63it/s[0m  
[2KAttention weights: tensor([[0.4968, 0.5032]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 50/203 [2m0:00:19 â€¢ 0:00:59[0m [2;4m2.63it/s[0m  
[2KAttention weights: tensor([[0.4897, 0.5103]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 50/203 [2m0:00:19 â€¢ 0:00:59[0m [2;4m2.63it/s[0m  
[2KAttention weights: tensor([[0.4873, 0.5127]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 50/203 [2m0:00:19 â€¢ 0:00:59[0m [2;4m2.63it/s[0m  
[2KAttention weights: tensor([[0.4868, 0.5132]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 50/203 [2m0:00:19 â€¢ 0:00:59[0m [2;4m2.63it/s[0m  
[2KAttention weights: tensor([[0.5195, 0.4805]], device='cuda:0')37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 50/203 [2m0:00:19 â€¢ 0:00:59[0m [2;4m2.63it/s[0m  
[2KAttention weights: tensor([[0.5589, 0.4411],;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 50/203 [2m0:00:19 â€¢ 0:00:59[0m [2;4m2.63it/s[0m  
        [0.4330, 0.5670],
        [0.4548, 0.5452],
        [0.5607, 0.4393],
        [0.4866, 0.5134],
        [0.6428, 0.3572],
        [0.5963, 0.4037],
        [0.5833, 0.4167],
        [0.4950, 0.5050],
[2K        [0.5137, 0.4863]], device='cuda:0')6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 50/203 [2m0:00:19 â€¢ 0:00:59[0m [2;4m2.63it/s[0m  
[2KAttention weights: tensor([[0.5210, 0.4790],;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 51/203 [2m0:00:19 â€¢ 0:00:58[0m [2;4m2.62it/s[0m   
        [0.5127, 0.4873],
        [0.5146, 0.4854],
        [0.5203, 0.4797],
        [0.5221, 0.4779],
        [0.5246, 0.4754],
        [0.5220, 0.4780],
        [0.5190, 0.4810],
        [0.5160, 0.4840],
[2K        [0.5222, 0.4778]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 51/203 [2m0:00:19 â€¢ 0:00:58[0m [2;4m2.62it/s[0m  
[2KClass label: BaseballPitchâ”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 51/203 [2m0:00:19 â€¢ 0:00:58[0m [2;4m2.62it/s[0m  
[2KAttention weights: tensor([[0.6034, 0.3966]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 51/203 [2m0:00:19 â€¢ 0:00:58[0m [2;4m2.62it/s[0m  
[2KStep 0 - TTA Loss: 1.4224â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 51/203 [2m0:00:19 â€¢ 0:00:58[0m [2;4m2.62it/s[0m  
[2KAttention weights: tensor([[0.6034, 0.3966]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 51/203 [2m0:00:19 â€¢ 0:00:58[0m [2;4m2.62it/s[0m  
[2KAttention weights: tensor([[0.6033, 0.3967]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 51/203 [2m0:00:19 â€¢ 0:00:58[0m [2;4m2.62it/s[0m  
[2KAttention weights: tensor([[0.6032, 0.3968]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 51/203 [2m0:00:19 â€¢ 0:00:58[0m [2;4m2.62it/s[0m  
[2KAttention weights: tensor([[0.6031, 0.3969]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 51/203 [2m0:00:19 â€¢ 0:00:58[0m [2;4m2.62it/s[0m  
[2KAttention weights: tensor([[0.6041, 0.3959]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 51/203 [2m0:00:19 â€¢ 0:00:58[0m [2;4m2.62it/s[0m  
[2KAttention weights: tensor([[0.6039, 0.3961]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 51/203 [2m0:00:19 â€¢ 0:00:58[0m [2;4m2.62it/s[0m  
[2KAttention weights: tensor([[0.6026, 0.3974]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 51/203 [2m0:00:19 â€¢ 0:00:58[0m [2;4m2.62it/s[0m  
[2KAttention weights: tensor([[0.6024, 0.3976]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 51/203 [2m0:00:19 â€¢ 0:00:58[0m [2;4m2.62it/s[0m  
[2KAttention weights: tensor([[0.6063, 0.3937]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 51/203 [2m0:00:19 â€¢ 0:00:58[0m [2;4m2.62it/s[0m  
[2KAttention weights: tensor([[0.5219, 0.4781]], device='cuda:0')â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 51/203 [2m0:00:19 â€¢ 0:00:58[0m [2;4m2.62it/s[0m  
[2KAttention weights: tensor([[0.6129, 0.3871],mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 51/203 [2m0:00:19 â€¢ 0:00:58[0m [2;4m2.62it/s[0m  
        [0.4423, 0.5577],
        [0.4906, 0.5094],
        [0.6056, 0.3944],
        [0.5764, 0.4236],
        [0.6889, 0.3111],
        [0.6433, 0.3567],
        [0.6065, 0.3935],
        [0.5221, 0.4779],
[2K        [0.5879, 0.4121]], device='cuda:0')7mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 51/203 [2m0:00:19 â€¢ 0:00:58[0m [2;4m2.62it/s[0m  
[2KAttention weights: tensor([[0.5210, 0.4790],;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 52/203 [2m0:00:20 â€¢ 0:00:58[0m [2;4m2.63it/s[0m  
        [0.5127, 0.4873],
        [0.5146, 0.4854],
        [0.5203, 0.4797],
        [0.5221, 0.4779],
        [0.5247, 0.4753],
        [0.5220, 0.4780],
        [0.5190, 0.4810],
        [0.5160, 0.4840],
[2K        [0.5222, 0.4778]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 52/203 [2m0:00:20 â€¢ 0:00:58[0m [2;4m2.63it/s[0m  
[2KClass label: CleanAndJerkâ”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 52/203 [2m0:00:20 â€¢ 0:00:58[0m [2;4m2.63it/s[0m  
[2KAttention weights: tensor([[0.4931, 0.5069]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 52/203 [2m0:00:20 â€¢ 0:00:58[0m [2;4m2.63it/s[0m  
[2KStep 0 - TTA Loss: 1.5834â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 52/203 [2m0:00:20 â€¢ 0:00:58[0m [2;4m2.63it/s[0m  
[2KAttention weights: tensor([[0.4886, 0.5114]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 52/203 [2m0:00:20 â€¢ 0:00:58[0m [2;4m2.63it/s[0m  
[2KAttention weights: tensor([[0.4812, 0.5188]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 52/203 [2m0:00:20 â€¢ 0:00:58[0m [2;4m2.63it/s[0m  
[2KAttention weights: tensor([[0.4593, 0.5407]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 52/203 [2m0:00:20 â€¢ 0:00:58[0m [2;4m2.63it/s[0m  
[2KAttention weights: tensor([[0.4448, 0.5552]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 52/203 [2m0:00:20 â€¢ 0:00:58[0m [2;4m2.63it/s[0m  
[2KAttention weights: tensor([[0.4286, 0.5714]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 52/203 [2m0:00:20 â€¢ 0:00:58[0m [2;4m2.63it/s[0m  
[2KAttention weights: tensor([[0.4192, 0.5808]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 52/203 [2m0:00:20 â€¢ 0:00:58[0m [2;4m2.63it/s[0m  
[2KAttention weights: tensor([[0.4186, 0.5814]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 52/203 [2m0:00:20 â€¢ 0:00:58[0m [2;4m2.63it/s[0m  
[2KAttention weights: tensor([[0.4190, 0.5810]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 52/203 [2m0:00:20 â€¢ 0:00:58[0m [2;4m2.63it/s[0m  
[2KAttention weights: tensor([[0.4192, 0.5808]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 52/203 [2m0:00:20 â€¢ 0:00:58[0m [2;4m2.63it/s[0m  
[2KAttention weights: tensor([[0.5125, 0.4875]], device='cuda:0')â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 52/203 [2m0:00:20 â€¢ 0:00:58[0m [2;4m2.63it/s[0m  
[2KAttention weights: tensor([[0.6148, 0.3852],mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 52/203 [2m0:00:20 â€¢ 0:00:58[0m [2;4m2.63it/s[0m  
        [0.4410, 0.5590],
        [0.4191, 0.5809],
        [0.5936, 0.4064],
        [0.5711, 0.4289],
        [0.6862, 0.3138],
        [0.6403, 0.3597],
        [0.6074, 0.3926],
        [0.5156, 0.4844],
[2K        [0.5813, 0.4187]], device='cuda:0')7mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 52/203 [2m0:00:20 â€¢ 0:00:58[0m [2;4m2.63it/s[0m  
[2KAttention weights: tensor([[0.5210, 0.4790],;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 53/203 [2m0:00:20 â€¢ 0:00:58[0m [2;4m2.62it/s[0m  
        [0.5127, 0.4873],
        [0.5146, 0.4854],
        [0.5203, 0.4797],
        [0.5221, 0.4779],
        [0.5247, 0.4753],
        [0.5220, 0.4780],
        [0.5190, 0.4810],
        [0.5160, 0.4840],
[2K        [0.5222, 0.4778]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 53/203 [2m0:00:20 â€¢ 0:00:58[0m [2;4m2.62it/s[0m  
[2KClass label: Billiardsâ”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 53/203 [2m0:00:20 â€¢ 0:00:58[0m [2;4m2.62it/s[0m  
[2KAttention weights: tensor([[0.4485, 0.5515]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 53/203 [2m0:00:20 â€¢ 0:00:58[0m [2;4m2.62it/s[0m  
[2KStep 0 - TTA Loss: 0.8822â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 53/203 [2m0:00:20 â€¢ 0:00:58[0m [2;4m2.62it/s[0m  
[2KAttention weights: tensor([[0.4485, 0.5515]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 53/203 [2m0:00:20 â€¢ 0:00:58[0m [2;4m2.62it/s[0m  
[2KAttention weights: tensor([[0.4485, 0.5515]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 53/203 [2m0:00:20 â€¢ 0:00:58[0m [2;4m2.62it/s[0m  
[2KAttention weights: tensor([[0.4487, 0.5513]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 53/203 [2m0:00:20 â€¢ 0:00:58[0m [2;4m2.62it/s[0m  
[2KAttention weights: tensor([[0.4488, 0.5512]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 53/203 [2m0:00:20 â€¢ 0:00:58[0m [2;4m2.62it/s[0m  
[2KAttention weights: tensor([[0.4484, 0.5516]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 53/203 [2m0:00:20 â€¢ 0:00:58[0m [2;4m2.62it/s[0m  
[2KAttention weights: tensor([[0.4500, 0.5500]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 53/203 [2m0:00:20 â€¢ 0:00:58[0m [2;4m2.62it/s[0m  
[2KAttention weights: tensor([[0.4569, 0.5431]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 53/203 [2m0:00:20 â€¢ 0:00:58[0m [2;4m2.62it/s[0m  
[2KAttention weights: tensor([[0.4634, 0.5366]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 53/203 [2m0:00:20 â€¢ 0:00:58[0m [2;4m2.62it/s[0m  
[2KAttention weights: tensor([[0.4731, 0.5269]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 53/203 [2m0:00:20 â€¢ 0:00:58[0m [2;4m2.62it/s[0m  
[2KAttention weights: tensor([[0.5138, 0.4862]], device='cuda:0')â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 53/203 [2m0:00:20 â€¢ 0:00:58[0m [2;4m2.62it/s[0m  
[2KAttention weights: tensor([[0.6045, 0.3955],mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 53/203 [2m0:00:20 â€¢ 0:00:58[0m [2;4m2.62it/s[0m  
        [0.4786, 0.5214],
        [0.4969, 0.5031],
        [0.6102, 0.3898],
        [0.5759, 0.4241],
        [0.6839, 0.3161],
        [0.6405, 0.3595],
        [0.6098, 0.3902],
        [0.5177, 0.4823],
[2K        [0.5825, 0.4175]], device='cuda:0')7mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 53/203 [2m0:00:20 â€¢ 0:00:58[0m [2;4m2.62it/s[0m  
[2KAttention weights: tensor([[0.5210, 0.4790],;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 54/203 [2m0:00:21 â€¢ 0:00:58[0m [2;4m2.61it/s[0m  
        [0.5127, 0.4873],
        [0.5146, 0.4854],
        [0.5203, 0.4797],
        [0.5221, 0.4779],
        [0.5247, 0.4753],
        [0.5220, 0.4780],
        [0.5190, 0.4810],
        [0.5160, 0.4840],
[2K        [0.5222, 0.4778]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 54/203 [2m0:00:21 â€¢ 0:00:58[0m [2;4m2.61it/s[0m  
[2KClass label: SoccerPenaltyâ”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 54/203 [2m0:00:21 â€¢ 0:00:58[0m [2;4m2.61it/s[0m  
[2KAttention weights: tensor([[0.6093, 0.3907]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 54/203 [2m0:00:21 â€¢ 0:00:58[0m [2;4m2.61it/s[0m  
[2KStep 0 - TTA Loss: 1.0259â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 54/203 [2m0:00:21 â€¢ 0:00:58[0m [2;4m2.61it/s[0m  
[2KAttention weights: tensor([[0.5987, 0.4013]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 54/203 [2m0:00:21 â€¢ 0:00:58[0m [2;4m2.61it/s[0m  
[2KAttention weights: tensor([[0.5770, 0.4230]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 54/203 [2m0:00:21 â€¢ 0:00:58[0m [2;4m2.61it/s[0m  
[2KAttention weights: tensor([[0.5496, 0.4504]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 54/203 [2m0:00:21 â€¢ 0:00:58[0m [2;4m2.61it/s[0m  
[2KAttention weights: tensor([[0.5150, 0.4850]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 54/203 [2m0:00:21 â€¢ 0:00:58[0m [2;4m2.61it/s[0m  
[2KAttention weights: tensor([[0.4851, 0.5149]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 54/203 [2m0:00:21 â€¢ 0:00:58[0m [2;4m2.61it/s[0m  
[2KAttention weights: tensor([[0.4601, 0.5399]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 54/203 [2m0:00:21 â€¢ 0:00:58[0m [2;4m2.61it/s[0m  
[2KAttention weights: tensor([[0.4432, 0.5568]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 54/203 [2m0:00:21 â€¢ 0:00:58[0m [2;4m2.61it/s[0m  
[2KAttention weights: tensor([[0.4329, 0.5671]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 54/203 [2m0:00:21 â€¢ 0:00:58[0m [2;4m2.61it/s[0m  
[2KAttention weights: tensor([[0.4272, 0.5728]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 54/203 [2m0:00:21 â€¢ 0:00:58[0m [2;4m2.61it/s[0m  
[2KAttention weights: tensor([[0.5132, 0.4868]], device='cuda:0')237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 54/203 [2m0:00:21 â€¢ 0:00:58[0m [2;4m2.61it/s[0m  
[2KAttention weights: tensor([[0.6056, 0.3944],6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 54/203 [2m0:00:21 â€¢ 0:00:58[0m [2;4m2.61it/s[0m  
        [0.4450, 0.5550],
        [0.4863, 0.5137],
        [0.5888, 0.4112],
        [0.5414, 0.4586],
        [0.6435, 0.3565],
        [0.6087, 0.3913],
        [0.4257, 0.5743],
        [0.4811, 0.5189],
[2K        [0.5638, 0.4362]], device='cuda:0');6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 54/203 [2m0:00:21 â€¢ 0:00:58[0m [2;4m2.61it/s[0m  
[2KAttention weights: tensor([[0.5210, 0.4790],;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 55/203 [2m0:00:21 â€¢ 0:00:57[0m [2;4m2.61it/s[0m  
        [0.5127, 0.4873],
        [0.5146, 0.4854],
        [0.5203, 0.4797],
        [0.5221, 0.4779],
        [0.5247, 0.4753],
        [0.5220, 0.4780],
        [0.5190, 0.4810],
        [0.5160, 0.4840],
[2K        [0.5222, 0.4778]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 55/203 [2m0:00:21 â€¢ 0:00:57[0m [2;4m2.61it/s[0m  
[2KClass label: HammerThrowâ”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 55/203 [2m0:00:21 â€¢ 0:00:57[0m [2;4m2.61it/s[0m  
[2KAttention weights: tensor([[0.5768, 0.4232]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 55/203 [2m0:00:21 â€¢ 0:00:57[0m [2;4m2.61it/s[0m  
[2KStep 0 - TTA Loss: 2.2905â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 55/203 [2m0:00:21 â€¢ 0:00:57[0m [2;4m2.61it/s[0m  
[2KAttention weights: tensor([[0.5768, 0.4232]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 55/203 [2m0:00:21 â€¢ 0:00:57[0m [2;4m2.61it/s[0m  
[2KAttention weights: tensor([[0.5767, 0.4233]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 55/203 [2m0:00:21 â€¢ 0:00:57[0m [2;4m2.61it/s[0m  
[2KAttention weights: tensor([[0.5760, 0.4240]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 55/203 [2m0:00:21 â€¢ 0:00:57[0m [2;4m2.61it/s[0m  
[2KAttention weights: tensor([[0.5766, 0.4234]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 55/203 [2m0:00:21 â€¢ 0:00:57[0m [2;4m2.61it/s[0m  
[2KAttention weights: tensor([[0.5771, 0.4229]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 55/203 [2m0:00:21 â€¢ 0:00:57[0m [2;4m2.61it/s[0m  
[2KAttention weights: tensor([[0.5785, 0.4215]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 55/203 [2m0:00:21 â€¢ 0:00:57[0m [2;4m2.61it/s[0m  
[2KAttention weights: tensor([[0.5803, 0.4197]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 55/203 [2m0:00:21 â€¢ 0:00:57[0m [2;4m2.61it/s[0m  
[2KAttention weights: tensor([[0.5835, 0.4165]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 55/203 [2m0:00:21 â€¢ 0:00:57[0m [2;4m2.61it/s[0m  
[2KAttention weights: tensor([[0.5866, 0.4134]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 55/203 [2m0:00:21 â€¢ 0:00:57[0m [2;4m2.61it/s[0m  
[2KAttention weights: tensor([[0.5225, 0.4775]], device='cuda:0')237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 55/203 [2m0:00:21 â€¢ 0:00:57[0m [2;4m2.61it/s[0m  
[2KAttention weights: tensor([[0.6173, 0.3827],6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 55/203 [2m0:00:21 â€¢ 0:00:57[0m [2;4m2.61it/s[0m  
        [0.4371, 0.5629],
        [0.4974, 0.5026],
        [0.6040, 0.3960],
        [0.5875, 0.4125],
        [0.6745, 0.3255],
        [0.6347, 0.3653],
        [0.4856, 0.5144],
        [0.5025, 0.4975],
[2K        [0.5955, 0.4045]], device='cuda:0');6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 55/203 [2m0:00:21 â€¢ 0:00:57[0m [2;4m2.61it/s[0m  
[2KAttention weights: tensor([[0.5210, 0.4790],5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 56/203 [2m0:00:21 â€¢ 0:00:57[0m [2;4m2.60it/s[0m   
        [0.5127, 0.4873],
        [0.5146, 0.4854],
        [0.5203, 0.4797],
        [0.5221, 0.4779],
        [0.5247, 0.4753],
        [0.5220, 0.4780],
        [0.5190, 0.4810],
        [0.5160, 0.4840],
[2K        [0.5222, 0.4778]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 56/203 [2m0:00:21 â€¢ 0:00:57[0m [2;4m2.60it/s[0m  
[2KClass label: HighJumpâ”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 56/203 [2m0:00:21 â€¢ 0:00:57[0m [2;4m2.60it/s[0m  
[2KAttention weights: tensor([[0.6855, 0.3145]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 56/203 [2m0:00:21 â€¢ 0:00:57[0m [2;4m2.60it/s[0m  
[2KStep 0 - TTA Loss: 1.8198â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 56/203 [2m0:00:21 â€¢ 0:00:57[0m [2;4m2.60it/s[0m  
[2KAttention weights: tensor([[0.6968, 0.3032]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 56/203 [2m0:00:21 â€¢ 0:00:57[0m [2;4m2.60it/s[0m  
[2KAttention weights: tensor([[0.7199, 0.2801]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 56/203 [2m0:00:21 â€¢ 0:00:57[0m [2;4m2.60it/s[0m  
[2KAttention weights: tensor([[0.7302, 0.2698]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 56/203 [2m0:00:21 â€¢ 0:00:57[0m [2;4m2.60it/s[0m  
[2KAttention weights: tensor([[0.7310, 0.2690]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 56/203 [2m0:00:21 â€¢ 0:00:57[0m [2;4m2.60it/s[0m  
[2KAttention weights: tensor([[0.7320, 0.2680]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 56/203 [2m0:00:21 â€¢ 0:00:57[0m [2;4m2.60it/s[0m  
[2KAttention weights: tensor([[0.7314, 0.2686]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 56/203 [2m0:00:21 â€¢ 0:00:57[0m [2;4m2.60it/s[0m  
[2KAttention weights: tensor([[0.7327, 0.2673]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 56/203 [2m0:00:21 â€¢ 0:00:57[0m [2;4m2.60it/s[0m  
[2KAttention weights: tensor([[0.7355, 0.2645]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 56/203 [2m0:00:21 â€¢ 0:00:57[0m [2;4m2.60it/s[0m  
[2KAttention weights: tensor([[0.7366, 0.2634]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 56/203 [2m0:00:21 â€¢ 0:00:57[0m [2;4m2.60it/s[0m  
[2KAttention weights: tensor([[0.5273, 0.4727]], device='cuda:0')â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 56/203 [2m0:00:21 â€¢ 0:00:57[0m [2;4m2.60it/s[0m  
[2KAttention weights: tensor([[0.6284, 0.3716],7mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 56/203 [2m0:00:21 â€¢ 0:00:57[0m [2;4m2.60it/s[0m  
        [0.4398, 0.5602],
        [0.5068, 0.4932],
        [0.6125, 0.3875],
        [0.6155, 0.3845],
        [0.7375, 0.2625],
        [0.6787, 0.3213],
        [0.5537, 0.4463],
        [0.5310, 0.4690],
[2K        [0.6290, 0.3710]], device='cuda:0')37mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 56/203 [2m0:00:21 â€¢ 0:00:57[0m [2;4m2.60it/s[0m  
[2KAttention weights: tensor([[0.5211, 0.4789],5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 57/203 [2m0:00:22 â€¢ 0:00:57[0m [2;4m2.60it/s[0m  
        [0.5127, 0.4873],
        [0.5146, 0.4854],
        [0.5203, 0.4797],
        [0.5222, 0.4778],
        [0.5247, 0.4753],
        [0.5221, 0.4779],
        [0.5191, 0.4809],
        [0.5160, 0.4840],
[2K        [0.5223, 0.4777]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 57/203 [2m0:00:22 â€¢ 0:00:57[0m [2;4m2.60it/s[0m  
[2KClass label: HighJumpâ”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 57/203 [2m0:00:22 â€¢ 0:00:57[0m [2;4m2.60it/s[0m  
[2KAttention weights: tensor([[0.6884, 0.3116]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 57/203 [2m0:00:22 â€¢ 0:00:57[0m [2;4m2.60it/s[0m  
[2KStep 0 - TTA Loss: 1.3973â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 57/203 [2m0:00:22 â€¢ 0:00:57[0m [2;4m2.60it/s[0m  
[2KAttention weights: tensor([[0.6884, 0.3116]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 57/203 [2m0:00:22 â€¢ 0:00:57[0m [2;4m2.60it/s[0m  
[2KAttention weights: tensor([[0.6890, 0.3110]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 57/203 [2m0:00:22 â€¢ 0:00:57[0m [2;4m2.60it/s[0m  
[2KAttention weights: tensor([[0.6914, 0.3086]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 57/203 [2m0:00:22 â€¢ 0:00:57[0m [2;4m2.60it/s[0m  
[2KAttention weights: tensor([[0.6960, 0.3040]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 57/203 [2m0:00:22 â€¢ 0:00:57[0m [2;4m2.60it/s[0m  
[2KAttention weights: tensor([[0.7054, 0.2946]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 57/203 [2m0:00:22 â€¢ 0:00:57[0m [2;4m2.60it/s[0m  
[2KAttention weights: tensor([[0.7216, 0.2784]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 57/203 [2m0:00:22 â€¢ 0:00:57[0m [2;4m2.60it/s[0m  
[2KAttention weights: tensor([[0.7399, 0.2601]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 57/203 [2m0:00:22 â€¢ 0:00:57[0m [2;4m2.60it/s[0m  
[2KAttention weights: tensor([[0.7664, 0.2336]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 57/203 [2m0:00:22 â€¢ 0:00:57[0m [2;4m2.60it/s[0m  
[2KAttention weights: tensor([[0.7975, 0.2025]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 57/203 [2m0:00:22 â€¢ 0:00:57[0m [2;4m2.60it/s[0m  
[2KAttention weights: tensor([[0.5296, 0.4704]], device='cuda:0')â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 57/203 [2m0:00:22 â€¢ 0:00:57[0m [2;4m2.60it/s[0m  
[2KAttention weights: tensor([[0.6603, 0.3397],7mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 57/203 [2m0:00:22 â€¢ 0:00:57[0m [2;4m2.60it/s[0m  
        [0.4490, 0.5510],
        [0.5266, 0.4734],
        [0.6497, 0.3503],
        [0.6800, 0.3200],
        [0.8279, 0.1721],
        [0.7579, 0.2421],
        [0.6585, 0.3415],
        [0.5879, 0.4121],
[2K        [0.6975, 0.3025]], device='cuda:0')37mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 57/203 [2m0:00:22 â€¢ 0:00:57[0m [2;4m2.60it/s[0m  
[2KAttention weights: tensor([[0.5211, 0.4789],5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 58/203 [2m0:00:22 â€¢ 0:00:56[0m [2;4m2.61it/s[0m  
        [0.5127, 0.4873],
        [0.5147, 0.4853],
        [0.5203, 0.4797],
        [0.5222, 0.4778],
        [0.5247, 0.4753],
        [0.5221, 0.4779],
        [0.5191, 0.4809],
        [0.5160, 0.4840],
[2K        [0.5223, 0.4777]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 58/203 [2m0:00:22 â€¢ 0:00:56[0m [2;4m2.61it/s[0m  
[2KClass label: HammerThrowâ”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 58/203 [2m0:00:22 â€¢ 0:00:56[0m [2;4m2.61it/s[0m  
[2KAttention weights: tensor([[0.5780, 0.4220]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 58/203 [2m0:00:22 â€¢ 0:00:56[0m [2;4m2.61it/s[0m  
[2KStep 0 - TTA Loss: 2.1123â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 58/203 [2m0:00:22 â€¢ 0:00:56[0m [2;4m2.61it/s[0m  
[2KAttention weights: tensor([[0.5685, 0.4315]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 58/203 [2m0:00:22 â€¢ 0:00:56[0m [2;4m2.61it/s[0m  
[2KAttention weights: tensor([[0.5475, 0.4525]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 58/203 [2m0:00:22 â€¢ 0:00:56[0m [2;4m2.61it/s[0m  
[2KAttention weights: tensor([[0.5306, 0.4694]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 58/203 [2m0:00:22 â€¢ 0:00:56[0m [2;4m2.61it/s[0m  
[2KAttention weights: tensor([[0.5177, 0.4823]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 58/203 [2m0:00:22 â€¢ 0:00:56[0m [2;4m2.61it/s[0m  
[2KAttention weights: tensor([[0.5178, 0.4822]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 58/203 [2m0:00:22 â€¢ 0:00:56[0m [2;4m2.61it/s[0m  
[2KAttention weights: tensor([[0.5221, 0.4779]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 58/203 [2m0:00:22 â€¢ 0:00:56[0m [2;4m2.61it/s[0m  
[2KAttention weights: tensor([[0.5238, 0.4762]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 58/203 [2m0:00:22 â€¢ 0:00:56[0m [2;4m2.61it/s[0m  
[2KAttention weights: tensor([[0.5274, 0.4726]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 58/203 [2m0:00:22 â€¢ 0:00:56[0m [2;4m2.61it/s[0m  
[2KAttention weights: tensor([[0.5296, 0.4704]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 58/203 [2m0:00:22 â€¢ 0:00:56[0m [2;4m2.61it/s[0m  
[2KAttention weights: tensor([[0.5209, 0.4791]], device='cuda:0')â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 58/203 [2m0:00:22 â€¢ 0:00:56[0m [2;4m2.61it/s[0m  
[2KAttention weights: tensor([[0.5857, 0.4143],7mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 58/203 [2m0:00:22 â€¢ 0:00:56[0m [2;4m2.61it/s[0m  
        [0.4331, 0.5669],
        [0.4885, 0.5115],
        [0.5824, 0.4176],
        [0.5302, 0.4698],
        [0.7704, 0.2296],
        [0.6928, 0.3072],
        [0.6194, 0.3806],
        [0.5436, 0.4564],
[2K        [0.5815, 0.4185]], device='cuda:0')37mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 58/203 [2m0:00:22 â€¢ 0:00:56[0m [2;4m2.61it/s[0m  
[2KAttention weights: tensor([[0.5211, 0.4789],2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 59/203 [2m0:00:23 â€¢ 0:00:56[0m [2;4m2.60it/s[0m  
        [0.5127, 0.4873],
        [0.5147, 0.4853],
        [0.5203, 0.4797],
        [0.5222, 0.4778],
        [0.5248, 0.4752],
        [0.5222, 0.4778],
        [0.5191, 0.4809],
        [0.5161, 0.4839],
[2K        [0.5224, 0.4776]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 59/203 [2m0:00:23 â€¢ 0:00:56[0m [2;4m2.60it/s[0m  
[2KClass label: Billiardsâ”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 59/203 [2m0:00:23 â€¢ 0:00:56[0m [2;4m2.60it/s[0m  
[2KAttention weights: tensor([[0.4436, 0.5564]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 59/203 [2m0:00:23 â€¢ 0:00:56[0m [2;4m2.60it/s[0m  
[2KStep 0 - TTA Loss: 0.6606â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 59/203 [2m0:00:23 â€¢ 0:00:56[0m [2;4m2.60it/s[0m  
[2KAttention weights: tensor([[0.4436, 0.5564]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 59/203 [2m0:00:23 â€¢ 0:00:56[0m [2;4m2.60it/s[0m  
[2KAttention weights: tensor([[0.4438, 0.5562]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 59/203 [2m0:00:23 â€¢ 0:00:56[0m [2;4m2.60it/s[0m  
[2KAttention weights: tensor([[0.4444, 0.5556]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 59/203 [2m0:00:23 â€¢ 0:00:56[0m [2;4m2.60it/s[0m  
[2KAttention weights: tensor([[0.4457, 0.5543]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 59/203 [2m0:00:23 â€¢ 0:00:56[0m [2;4m2.60it/s[0m  
[2KAttention weights: tensor([[0.4516, 0.5484]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 59/203 [2m0:00:23 â€¢ 0:00:56[0m [2;4m2.60it/s[0m  
[2KAttention weights: tensor([[0.4595, 0.5405]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 59/203 [2m0:00:23 â€¢ 0:00:56[0m [2;4m2.60it/s[0m  
[2KAttention weights: tensor([[0.4685, 0.5315]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 59/203 [2m0:00:23 â€¢ 0:00:56[0m [2;4m2.60it/s[0m  
[2KAttention weights: tensor([[0.4858, 0.5142]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 59/203 [2m0:00:23 â€¢ 0:00:56[0m [2;4m2.60it/s[0m  
[2KAttention weights: tensor([[0.5108, 0.4892]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 59/203 [2m0:00:23 â€¢ 0:00:56[0m [2;4m2.60it/s[0m  
[2KAttention weights: tensor([[0.5158, 0.4842]], device='cuda:0');237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 59/203 [2m0:00:23 â€¢ 0:00:56[0m [2;4m2.60it/s[0m  
[2KAttention weights: tensor([[0.6340, 0.3660],;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 59/203 [2m0:00:23 â€¢ 0:00:56[0m [2;4m2.60it/s[0m  
        [0.5337, 0.4663],
        [0.5069, 0.4931],
        [0.6389, 0.3611],
        [0.6325, 0.3675],
        [0.7320, 0.2680],
        [0.6767, 0.3233],
        [0.6313, 0.3687],
        [0.5419, 0.4581],
[2K        [0.6294, 0.3706]], device='cuda:0')8;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 59/203 [2m0:00:23 â€¢ 0:00:56[0m [2;4m2.60it/s[0m  
[2KAttention weights: tensor([[0.5211, 0.4789],2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 60/203 [2m0:00:23 â€¢ 0:00:56[0m [2;4m2.60it/s[0m  
        [0.5128, 0.4872],
        [0.5147, 0.4853],
        [0.5204, 0.4796],
        [0.5223, 0.4777],
        [0.5248, 0.4752],
        [0.5222, 0.4778],
        [0.5191, 0.4809],
        [0.5161, 0.4839],
[2K        [0.5224, 0.4776]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 60/203 [2m0:00:23 â€¢ 0:00:56[0m [2;4m2.60it/s[0m  
[2KClass label: CleanAndJerkâ”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 60/203 [2m0:00:23 â€¢ 0:00:56[0m [2;4m2.60it/s[0m  
[2KAttention weights: tensor([[0.4972, 0.5028]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 60/203 [2m0:00:23 â€¢ 0:00:56[0m [2;4m2.60it/s[0m  
[2KStep 0 - TTA Loss: 1.2269â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 60/203 [2m0:00:23 â€¢ 0:00:56[0m [2;4m2.60it/s[0m  
[2KAttention weights: tensor([[0.5014, 0.4986]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 60/203 [2m0:00:23 â€¢ 0:00:56[0m [2;4m2.60it/s[0m  
[2KAttention weights: tensor([[0.5066, 0.4934]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 60/203 [2m0:00:23 â€¢ 0:00:56[0m [2;4m2.60it/s[0m  
[2KAttention weights: tensor([[0.5206, 0.4794]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 60/203 [2m0:00:23 â€¢ 0:00:56[0m [2;4m2.60it/s[0m  
[2KAttention weights: tensor([[0.5331, 0.4669]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 60/203 [2m0:00:23 â€¢ 0:00:56[0m [2;4m2.60it/s[0m  
[2KAttention weights: tensor([[0.5435, 0.4565]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 60/203 [2m0:00:23 â€¢ 0:00:56[0m [2;4m2.60it/s[0m  
[2KAttention weights: tensor([[0.5415, 0.4585]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 60/203 [2m0:00:23 â€¢ 0:00:56[0m [2;4m2.60it/s[0m  
[2KAttention weights: tensor([[0.5393, 0.4607]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 60/203 [2m0:00:23 â€¢ 0:00:56[0m [2;4m2.60it/s[0m  
[2KAttention weights: tensor([[0.5385, 0.4615]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 60/203 [2m0:00:23 â€¢ 0:00:56[0m [2;4m2.60it/s[0m  
[2KAttention weights: tensor([[0.5373, 0.4627]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 60/203 [2m0:00:23 â€¢ 0:00:56[0m [2;4m2.60it/s[0m  
[2KAttention weights: tensor([[0.5160, 0.4840]], device='cuda:0');237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 60/203 [2m0:00:23 â€¢ 0:00:56[0m [2;4m2.60it/s[0m  
[2KAttention weights: tensor([[0.6267, 0.3733],;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 60/203 [2m0:00:23 â€¢ 0:00:56[0m [2;4m2.60it/s[0m  
        [0.5358, 0.4642],
        [0.5371, 0.4629],
        [0.6348, 0.3652],
        [0.6227, 0.3773],
        [0.7207, 0.2793],
        [0.6697, 0.3303],
        [0.6318, 0.3682],
        [0.5400, 0.4600],
[2K        [0.6248, 0.3752]], device='cuda:0')8;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 60/203 [2m0:00:23 â€¢ 0:00:56[0m [2;4m2.60it/s[0m  
[2KAttention weights: tensor([[0.5212, 0.4788],;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 61/203 [2m0:00:24 â€¢ 0:00:55[0m [2;4m2.59it/s[0m   
        [0.5128, 0.4872],
        [0.5148, 0.4852],
        [0.5204, 0.4796],
        [0.5223, 0.4777],
        [0.5248, 0.4752],
        [0.5222, 0.4778],
        [0.5192, 0.4808],
        [0.5161, 0.4839],
[2K        [0.5224, 0.4776]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 61/203 [2m0:00:24 â€¢ 0:00:55[0m [2;4m2.59it/s[0m  
[2KClass label: Billiardsâ”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 61/203 [2m0:00:24 â€¢ 0:00:55[0m [2;4m2.59it/s[0m  
[2KAttention weights: tensor([[0.4415, 0.5585]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 61/203 [2m0:00:24 â€¢ 0:00:55[0m [2;4m2.59it/s[0m  
[2KStep 0 - TTA Loss: 0.8125â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 61/203 [2m0:00:24 â€¢ 0:00:55[0m [2;4m2.59it/s[0m  
[2KAttention weights: tensor([[0.4415, 0.5585]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 61/203 [2m0:00:24 â€¢ 0:00:55[0m [2;4m2.59it/s[0m  
[2KAttention weights: tensor([[0.4416, 0.5584]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 61/203 [2m0:00:24 â€¢ 0:00:55[0m [2;4m2.59it/s[0m  
[2KAttention weights: tensor([[0.4424, 0.5576]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 61/203 [2m0:00:24 â€¢ 0:00:55[0m [2;4m2.59it/s[0m  
[2KAttention weights: tensor([[0.4443, 0.5557]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 61/203 [2m0:00:24 â€¢ 0:00:55[0m [2;4m2.59it/s[0m  
[2KAttention weights: tensor([[0.4492, 0.5508]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 61/203 [2m0:00:24 â€¢ 0:00:55[0m [2;4m2.59it/s[0m  
[2KAttention weights: tensor([[0.4570, 0.5430]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 61/203 [2m0:00:24 â€¢ 0:00:55[0m [2;4m2.59it/s[0m  
[2KAttention weights: tensor([[0.4656, 0.5344]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 61/203 [2m0:00:24 â€¢ 0:00:55[0m [2;4m2.59it/s[0m  
[2KAttention weights: tensor([[0.4784, 0.5216]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 61/203 [2m0:00:24 â€¢ 0:00:55[0m [2;4m2.59it/s[0m  
[2KAttention weights: tensor([[0.4946, 0.5054]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 61/203 [2m0:00:24 â€¢ 0:00:55[0m [2;4m2.59it/s[0m  
[2KAttention weights: tensor([[0.5152, 0.4848]], device='cuda:0')mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 61/203 [2m0:00:24 â€¢ 0:00:55[0m [2;4m2.59it/s[0m  
[2KAttention weights: tensor([[0.6066, 0.3934],37mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 61/203 [2m0:00:24 â€¢ 0:00:55[0m [2;4m2.59it/s[0m  
        [0.5134, 0.4866],
        [0.4742, 0.5258],
        [0.6160, 0.3840],
        [0.5864, 0.4136],
        [0.6905, 0.3095],
        [0.6407, 0.3593],
        [0.6155, 0.3845],
        [0.5204, 0.4796],
[2K        [0.5879, 0.4121]], device='cuda:0')237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 61/203 [2m0:00:24 â€¢ 0:00:55[0m [2;4m2.59it/s[0m  
[2KAttention weights: tensor([[0.5212, 0.4788],;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 62/203 [2m0:00:24 â€¢ 0:00:55[0m [2;4m2.60it/s[0m  
        [0.5128, 0.4872],
        [0.5148, 0.4852],
        [0.5204, 0.4796],
        [0.5223, 0.4777],
        [0.5249, 0.4751],
        [0.5222, 0.4778],
        [0.5192, 0.4808],
        [0.5161, 0.4839],
[2K        [0.5224, 0.4776]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 62/203 [2m0:00:24 â€¢ 0:00:55[0m [2;4m2.60it/s[0m  
[2KClass label: Billiardsâ”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 62/203 [2m0:00:24 â€¢ 0:00:55[0m [2;4m2.60it/s[0m  
[2KAttention weights: tensor([[0.4489, 0.5511]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 62/203 [2m0:00:24 â€¢ 0:00:55[0m [2;4m2.60it/s[0m  
[2KStep 0 - TTA Loss: 0.8294â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 62/203 [2m0:00:24 â€¢ 0:00:55[0m [2;4m2.60it/s[0m  
[2KAttention weights: tensor([[0.4653, 0.5347]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 62/203 [2m0:00:24 â€¢ 0:00:55[0m [2;4m2.60it/s[0m  
[2KAttention weights: tensor([[0.4800, 0.5200]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 62/203 [2m0:00:24 â€¢ 0:00:55[0m [2;4m2.60it/s[0m  
[2KAttention weights: tensor([[0.4908, 0.5092]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 62/203 [2m0:00:24 â€¢ 0:00:55[0m [2;4m2.60it/s[0m  
[2KAttention weights: tensor([[0.4958, 0.5042]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 62/203 [2m0:00:24 â€¢ 0:00:55[0m [2;4m2.60it/s[0m  
[2KAttention weights: tensor([[0.4914, 0.5086]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 62/203 [2m0:00:24 â€¢ 0:00:55[0m [2;4m2.60it/s[0m  
[2KAttention weights: tensor([[0.4869, 0.5131]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 62/203 [2m0:00:24 â€¢ 0:00:55[0m [2;4m2.60it/s[0m  
[2KAttention weights: tensor([[0.4812, 0.5188]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 62/203 [2m0:00:24 â€¢ 0:00:55[0m [2;4m2.60it/s[0m  
[2KAttention weights: tensor([[0.4756, 0.5244]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 62/203 [2m0:00:24 â€¢ 0:00:55[0m [2;4m2.60it/s[0m  
[2KAttention weights: tensor([[0.4731, 0.5269]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 62/203 [2m0:00:24 â€¢ 0:00:55[0m [2;4m2.60it/s[0m  
[2KAttention weights: tensor([[0.5139, 0.4861]], device='cuda:0')mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 62/203 [2m0:00:24 â€¢ 0:00:55[0m [2;4m2.60it/s[0m  
[2KAttention weights: tensor([[0.6025, 0.3975],37mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 62/203 [2m0:00:24 â€¢ 0:00:55[0m [2;4m2.60it/s[0m  
        [0.4723, 0.5277],
        [0.4745, 0.5255],
        [0.6050, 0.3950],
        [0.5793, 0.4207],
        [0.6916, 0.3084],
        [0.6410, 0.3590],
        [0.6108, 0.3892],
        [0.5213, 0.4787],
[2K        [0.5838, 0.4162]], device='cuda:0')237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 62/203 [2m0:00:24 â€¢ 0:00:55[0m [2;4m2.60it/s[0m  
[2KAttention weights: tensor([[0.5212, 0.4788],;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 63/203 [2m0:00:24 â€¢ 0:00:54[0m [2;4m2.60it/s[0m  
        [0.5128, 0.4872],
        [0.5148, 0.4852],
        [0.5204, 0.4796],
        [0.5223, 0.4777],
        [0.5249, 0.4751],
        [0.5222, 0.4778],
        [0.5192, 0.4808],
        [0.5161, 0.4839],
[2K        [0.5224, 0.4776]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 63/203 [2m0:00:24 â€¢ 0:00:54[0m [2;4m2.60it/s[0m  
[2KClass label: CleanAndJerkâ”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 63/203 [2m0:00:24 â€¢ 0:00:54[0m [2;4m2.60it/s[0m  
[2KAttention weights: tensor([[0.4920, 0.5080]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 63/203 [2m0:00:24 â€¢ 0:00:54[0m [2;4m2.60it/s[0m  
[2KStep 0 - TTA Loss: 0.7021â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 63/203 [2m0:00:24 â€¢ 0:00:54[0m [2;4m2.60it/s[0m  
[2KAttention weights: tensor([[0.4920, 0.5080]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 63/203 [2m0:00:24 â€¢ 0:00:54[0m [2;4m2.60it/s[0m  
[2KAttention weights: tensor([[0.4920, 0.5080]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 63/203 [2m0:00:24 â€¢ 0:00:54[0m [2;4m2.60it/s[0m  
[2KAttention weights: tensor([[0.4906, 0.5094]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 63/203 [2m0:00:24 â€¢ 0:00:54[0m [2;4m2.60it/s[0m  
[2KAttention weights: tensor([[0.4865, 0.5135]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 63/203 [2m0:00:24 â€¢ 0:00:54[0m [2;4m2.60it/s[0m  
[2KAttention weights: tensor([[0.4787, 0.5213]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 63/203 [2m0:00:24 â€¢ 0:00:54[0m [2;4m2.60it/s[0m  
[2KAttention weights: tensor([[0.4639, 0.5361]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 63/203 [2m0:00:24 â€¢ 0:00:54[0m [2;4m2.60it/s[0m  
[2KAttention weights: tensor([[0.4378, 0.5622]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 63/203 [2m0:00:24 â€¢ 0:00:54[0m [2;4m2.60it/s[0m  
[2KAttention weights: tensor([[0.4077, 0.5923]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 63/203 [2m0:00:24 â€¢ 0:00:54[0m [2;4m2.60it/s[0m  
[2KAttention weights: tensor([[0.3797, 0.6203]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 63/203 [2m0:00:24 â€¢ 0:00:54[0m [2;4m2.60it/s[0m  
[2KAttention weights: tensor([[0.5101, 0.4899]], device='cuda:0')mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 63/203 [2m0:00:24 â€¢ 0:00:54[0m [2;4m2.60it/s[0m  
[2KAttention weights: tensor([[0.5784, 0.4216],37mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 63/203 [2m0:00:24 â€¢ 0:00:54[0m [2;4m2.60it/s[0m  
        [0.3729, 0.6271],
        [0.3538, 0.6462],
        [0.5625, 0.4375],
        [0.5510, 0.4490],
        [0.6724, 0.3276],
        [0.6227, 0.3773],
        [0.5939, 0.4061],
        [0.5010, 0.4990],
[2K        [0.5541, 0.4459]], device='cuda:0')237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 63/203 [2m0:00:24 â€¢ 0:00:54[0m [2;4m2.60it/s[0m  
[2KAttention weights: tensor([[0.5212, 0.4788],;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 64/203 [2m0:00:25 â€¢ 0:00:54[0m [2;4m2.60it/s[0m  
        [0.5129, 0.4871],
        [0.5148, 0.4852],
        [0.5204, 0.4796],
        [0.5223, 0.4777],
        [0.5249, 0.4751],
        [0.5222, 0.4778],
        [0.5192, 0.4808],
        [0.5161, 0.4839],
[2K        [0.5224, 0.4776]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 64/203 [2m0:00:25 â€¢ 0:00:54[0m [2;4m2.60it/s[0m  
[2KClass label: BaseballPitchâ”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 64/203 [2m0:00:25 â€¢ 0:00:54[0m [2;4m2.60it/s[0m  
[2KAttention weights: tensor([[0.6010, 0.3990]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 64/203 [2m0:00:25 â€¢ 0:00:54[0m [2;4m2.60it/s[0m  
[2KStep 0 - TTA Loss: 1.2820â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 64/203 [2m0:00:25 â€¢ 0:00:54[0m [2;4m2.60it/s[0m  
[2KAttention weights: tensor([[0.6147, 0.3853]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 64/203 [2m0:00:25 â€¢ 0:00:54[0m [2;4m2.60it/s[0m  
[2KAttention weights: tensor([[0.6423, 0.3577]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 64/203 [2m0:00:25 â€¢ 0:00:54[0m [2;4m2.60it/s[0m  
[2KAttention weights: tensor([[0.6755, 0.3245]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 64/203 [2m0:00:25 â€¢ 0:00:54[0m [2;4m2.60it/s[0m  
[2KAttention weights: tensor([[0.7044, 0.2956]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 64/203 [2m0:00:25 â€¢ 0:00:54[0m [2;4m2.60it/s[0m  
[2KAttention weights: tensor([[0.7264, 0.2736]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 64/203 [2m0:00:25 â€¢ 0:00:54[0m [2;4m2.60it/s[0m  
[2KAttention weights: tensor([[0.7433, 0.2567]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 64/203 [2m0:00:25 â€¢ 0:00:54[0m [2;4m2.60it/s[0m  
[2KAttention weights: tensor([[0.7519, 0.2481]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 64/203 [2m0:00:25 â€¢ 0:00:54[0m [2;4m2.60it/s[0m  
[2KAttention weights: tensor([[0.7566, 0.2434]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 64/203 [2m0:00:25 â€¢ 0:00:54[0m [2;4m2.60it/s[0m  
[2KAttention weights: tensor([[0.7585, 0.2415]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 64/203 [2m0:00:25 â€¢ 0:00:54[0m [2;4m2.60it/s[0m  
[2KAttention weights: tensor([[0.5270, 0.4730]], device='cuda:0')5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 64/203 [2m0:00:25 â€¢ 0:00:54[0m [2;4m2.60it/s[0m  
[2KAttention weights: tensor([[0.7594, 0.2406],8;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 64/203 [2m0:00:25 â€¢ 0:00:54[0m [2;4m2.60it/s[0m  
        [0.4108, 0.5892],
        [0.4184, 0.5816],
        [0.6451, 0.3549],
        [0.6396, 0.3604],
        [0.7271, 0.2729],
        [0.6762, 0.3238],
        [0.6028, 0.3972],
        [0.5496, 0.4504],
[2K        [0.6516, 0.3484]], device='cuda:0')98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 64/203 [2m0:00:25 â€¢ 0:00:54[0m [2;4m2.60it/s[0m  
[2KAttention weights: tensor([[0.5212, 0.4788],;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 65/203 [2m0:00:25 â€¢ 0:00:54[0m [2;4m2.59it/s[0m  
        [0.5129, 0.4871],
        [0.5148, 0.4852],
        [0.5204, 0.4796],
        [0.5224, 0.4776],
        [0.5249, 0.4751],
        [0.5223, 0.4777],
        [0.5192, 0.4808],
        [0.5162, 0.4838],
[2K        [0.5224, 0.4776]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 65/203 [2m0:00:25 â€¢ 0:00:54[0m [2;4m2.59it/s[0m  
[2KClass label: BaseballPitchâ”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 65/203 [2m0:00:25 â€¢ 0:00:54[0m [2;4m2.59it/s[0m  
[2KAttention weights: tensor([[0.5980, 0.4020]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 65/203 [2m0:00:25 â€¢ 0:00:54[0m [2;4m2.59it/s[0m  
[2KStep 0 - TTA Loss: 1.8230â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 65/203 [2m0:00:25 â€¢ 0:00:54[0m [2;4m2.59it/s[0m  
[2KAttention weights: tensor([[0.5980, 0.4020]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 65/203 [2m0:00:25 â€¢ 0:00:54[0m [2;4m2.59it/s[0m  
[2KAttention weights: tensor([[0.5989, 0.4011]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 65/203 [2m0:00:25 â€¢ 0:00:54[0m [2;4m2.59it/s[0m  
[2KAttention weights: tensor([[0.6016, 0.3984]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 65/203 [2m0:00:25 â€¢ 0:00:54[0m [2;4m2.59it/s[0m  
[2KAttention weights: tensor([[0.6075, 0.3925]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 65/203 [2m0:00:25 â€¢ 0:00:54[0m [2;4m2.59it/s[0m  
[2KAttention weights: tensor([[0.6156, 0.3844]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 65/203 [2m0:00:25 â€¢ 0:00:54[0m [2;4m2.59it/s[0m  
[2KAttention weights: tensor([[0.6269, 0.3731]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 65/203 [2m0:00:25 â€¢ 0:00:54[0m [2;4m2.59it/s[0m  
[2KAttention weights: tensor([[0.6417, 0.3583]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 65/203 [2m0:00:25 â€¢ 0:00:54[0m [2;4m2.59it/s[0m  
[2KAttention weights: tensor([[0.6586, 0.3414]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 65/203 [2m0:00:25 â€¢ 0:00:54[0m [2;4m2.59it/s[0m  
[2KAttention weights: tensor([[0.6729, 0.3271]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 65/203 [2m0:00:25 â€¢ 0:00:54[0m [2;4m2.59it/s[0m  
[2KAttention weights: tensor([[0.5235, 0.4765]], device='cuda:0')5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 65/203 [2m0:00:25 â€¢ 0:00:54[0m [2;4m2.59it/s[0m  
[2KAttention weights: tensor([[0.6865, 0.3135],8;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 65/203 [2m0:00:25 â€¢ 0:00:54[0m [2;4m2.59it/s[0m  
        [0.4376, 0.5624],
        [0.4919, 0.5081],
        [0.6297, 0.3703],
        [0.6138, 0.3862],
        [0.7106, 0.2894],
        [0.6616, 0.3384],
        [0.6079, 0.3921],
        [0.5368, 0.4632],
[2K        [0.6239, 0.3761]], device='cuda:0')98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 65/203 [2m0:00:25 â€¢ 0:00:54[0m [2;4m2.59it/s[0m  
[2KAttention weights: tensor([[0.5212, 0.4788],8;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 66/203 [2m0:00:25 â€¢ 0:00:53[0m [2;4m2.60it/s[0m   
        [0.5129, 0.4871],
        [0.5148, 0.4852],
        [0.5204, 0.4796],
        [0.5224, 0.4776],
        [0.5249, 0.4751],
        [0.5223, 0.4777],
        [0.5192, 0.4808],
        [0.5162, 0.4838],
[2K        [0.5225, 0.4775]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 66/203 [2m0:00:25 â€¢ 0:00:53[0m [2;4m2.60it/s[0m  
[2KClass label: SoccerPenaltyâ”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 66/203 [2m0:00:25 â€¢ 0:00:53[0m [2;4m2.60it/s[0m  
[2KAttention weights: tensor([[0.6064, 0.3936]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 66/203 [2m0:00:25 â€¢ 0:00:53[0m [2;4m2.60it/s[0m  
[2KStep 0 - TTA Loss: 1.6845â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 66/203 [2m0:00:25 â€¢ 0:00:53[0m [2;4m2.60it/s[0m  
[2KAttention weights: tensor([[0.6192, 0.3808]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 66/203 [2m0:00:25 â€¢ 0:00:53[0m [2;4m2.60it/s[0m  
[2KAttention weights: tensor([[0.6334, 0.3666]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 66/203 [2m0:00:25 â€¢ 0:00:53[0m [2;4m2.60it/s[0m  
[2KAttention weights: tensor([[0.6463, 0.3537]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 66/203 [2m0:00:25 â€¢ 0:00:53[0m [2;4m2.60it/s[0m  
[2KAttention weights: tensor([[0.6557, 0.3443]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 66/203 [2m0:00:25 â€¢ 0:00:53[0m [2;4m2.60it/s[0m  
[2KAttention weights: tensor([[0.6694, 0.3306]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 66/203 [2m0:00:25 â€¢ 0:00:53[0m [2;4m2.60it/s[0m  
[2KAttention weights: tensor([[0.6778, 0.3222]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 66/203 [2m0:00:25 â€¢ 0:00:53[0m [2;4m2.60it/s[0m  
[2KAttention weights: tensor([[0.6858, 0.3142]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 66/203 [2m0:00:25 â€¢ 0:00:53[0m [2;4m2.60it/s[0m  
[2KAttention weights: tensor([[0.6894, 0.3106]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 66/203 [2m0:00:25 â€¢ 0:00:53[0m [2;4m2.60it/s[0m  
[2KAttention weights: tensor([[0.6907, 0.3093]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 66/203 [2m0:00:25 â€¢ 0:00:53[0m [2;4m2.60it/s[0m  
[2KAttention weights: tensor([[0.5225, 0.4775]], device='cuda:0')7mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 66/203 [2m0:00:25 â€¢ 0:00:53[0m [2;4m2.60it/s[0m  
[2KAttention weights: tensor([[0.6577, 0.3423],237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 66/203 [2m0:00:25 â€¢ 0:00:53[0m [2;4m2.60it/s[0m  
        [0.4582, 0.5418],
        [0.4946, 0.5054],
        [0.6347, 0.3653],
        [0.6201, 0.3799],
        [0.7230, 0.2770],
        [0.6729, 0.3271],
        [0.6910, 0.3090],
        [0.5514, 0.4486],
[2K        [0.6228, 0.3772]], device='cuda:0');237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 66/203 [2m0:00:25 â€¢ 0:00:53[0m [2;4m2.60it/s[0m  
[2KAttention weights: tensor([[0.5213, 0.4787],8;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 67/203 [2m0:00:26 â€¢ 0:00:53[0m [2;4m2.60it/s[0m  
        [0.5129, 0.4871],
        [0.5148, 0.4852],
        [0.5204, 0.4796],
        [0.5224, 0.4776],
        [0.5249, 0.4751],
        [0.5223, 0.4777],
        [0.5192, 0.4808],
        [0.5162, 0.4838],
[2K        [0.5225, 0.4775]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 67/203 [2m0:00:26 â€¢ 0:00:53[0m [2;4m2.60it/s[0m  
[2KClass label: HighJumpâ”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 67/203 [2m0:00:26 â€¢ 0:00:53[0m [2;4m2.60it/s[0m  
[2KAttention weights: tensor([[0.6861, 0.3139]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 67/203 [2m0:00:26 â€¢ 0:00:53[0m [2;4m2.60it/s[0m  
[2KStep 0 - TTA Loss: 1.1069â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 67/203 [2m0:00:26 â€¢ 0:00:53[0m [2;4m2.60it/s[0m  
[2KAttention weights: tensor([[0.6861, 0.3139]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 67/203 [2m0:00:26 â€¢ 0:00:53[0m [2;4m2.60it/s[0m  
[2KAttention weights: tensor([[0.6866, 0.3134]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 67/203 [2m0:00:26 â€¢ 0:00:53[0m [2;4m2.60it/s[0m  
[2KAttention weights: tensor([[0.6888, 0.3112]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 67/203 [2m0:00:26 â€¢ 0:00:53[0m [2;4m2.60it/s[0m  
[2KAttention weights: tensor([[0.6927, 0.3073]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 67/203 [2m0:00:26 â€¢ 0:00:53[0m [2;4m2.60it/s[0m  
[2KAttention weights: tensor([[0.6983, 0.3017]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 67/203 [2m0:00:26 â€¢ 0:00:53[0m [2;4m2.60it/s[0m  
[2KAttention weights: tensor([[0.7059, 0.2941]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 67/203 [2m0:00:26 â€¢ 0:00:53[0m [2;4m2.60it/s[0m  
[2KAttention weights: tensor([[0.7176, 0.2824]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 67/203 [2m0:00:26 â€¢ 0:00:53[0m [2;4m2.60it/s[0m  
[2KAttention weights: tensor([[0.7346, 0.2654]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 67/203 [2m0:00:26 â€¢ 0:00:53[0m [2;4m2.60it/s[0m  
[2KAttention weights: tensor([[0.7586, 0.2414]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 67/203 [2m0:00:26 â€¢ 0:00:53[0m [2;4m2.60it/s[0m  
[2KAttention weights: tensor([[0.5280, 0.4720]], device='cuda:0')7mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 67/203 [2m0:00:26 â€¢ 0:00:53[0m [2;4m2.60it/s[0m  
[2KAttention weights: tensor([[0.6424, 0.3576],237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 67/203 [2m0:00:26 â€¢ 0:00:53[0m [2;4m2.60it/s[0m  
        [0.4499, 0.5501],
        [0.5112, 0.4888],
        [0.6293, 0.3707],
        [0.6453, 0.3547],
        [0.7820, 0.2180],
        [0.7163, 0.2837],
        [0.6569, 0.3431],
        [0.5631, 0.4369],
[2K        [0.6570, 0.3430]], device='cuda:0');237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 67/203 [2m0:00:26 â€¢ 0:00:53[0m [2;4m2.60it/s[0m  
[2KAttention weights: tensor([[0.5213, 0.4787],8;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 68/203 [2m0:00:26 â€¢ 0:00:53[0m [2;4m2.59it/s[0m  
        [0.5129, 0.4871],
        [0.5148, 0.4852],
        [0.5205, 0.4795],
        [0.5224, 0.4776],
        [0.5249, 0.4751],
        [0.5223, 0.4777],
        [0.5193, 0.4807],
        [0.5162, 0.4838],
[2K        [0.5225, 0.4775]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 68/203 [2m0:00:26 â€¢ 0:00:53[0m [2;4m2.59it/s[0m  
[2KClass label: TennisSwingâ”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 68/203 [2m0:00:26 â€¢ 0:00:53[0m [2;4m2.59it/s[0m  
[2KAttention weights: tensor([[0.5180, 0.4820]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 68/203 [2m0:00:26 â€¢ 0:00:53[0m [2;4m2.59it/s[0m  
[2KStep 0 - TTA Loss: 1.6372â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 68/203 [2m0:00:26 â€¢ 0:00:53[0m [2;4m2.59it/s[0m  
[2KAttention weights: tensor([[0.5364, 0.4636]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 68/203 [2m0:00:26 â€¢ 0:00:53[0m [2;4m2.59it/s[0m  
[2KAttention weights: tensor([[0.5656, 0.4344]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 68/203 [2m0:00:26 â€¢ 0:00:53[0m [2;4m2.59it/s[0m  
[2KAttention weights: tensor([[0.5980, 0.4020]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 68/203 [2m0:00:26 â€¢ 0:00:53[0m [2;4m2.59it/s[0m  
[2KAttention weights: tensor([[0.6278, 0.3722]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 68/203 [2m0:00:26 â€¢ 0:00:53[0m [2;4m2.59it/s[0m  
[2KAttention weights: tensor([[0.6524, 0.3476]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 68/203 [2m0:00:26 â€¢ 0:00:53[0m [2;4m2.59it/s[0m  
[2KAttention weights: tensor([[0.6679, 0.3321]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 68/203 [2m0:00:26 â€¢ 0:00:53[0m [2;4m2.59it/s[0m  
[2KAttention weights: tensor([[0.6790, 0.3210]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 68/203 [2m0:00:26 â€¢ 0:00:53[0m [2;4m2.59it/s[0m  
[2KAttention weights: tensor([[0.6844, 0.3156]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 68/203 [2m0:00:26 â€¢ 0:00:53[0m [2;4m2.59it/s[0m  
[2KAttention weights: tensor([[0.6858, 0.3142]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 68/203 [2m0:00:26 â€¢ 0:00:53[0m [2;4m2.59it/s[0m  
[2KAttention weights: tensor([[0.5213, 0.4787]], device='cuda:0')7mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 68/203 [2m0:00:26 â€¢ 0:00:53[0m [2;4m2.59it/s[0m  
[2KAttention weights: tensor([[0.6674, 0.3326],237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 68/203 [2m0:00:26 â€¢ 0:00:53[0m [2;4m2.59it/s[0m  
        [0.4580, 0.5420],
        [0.5309, 0.4691],
        [0.6547, 0.3453],
        [0.6714, 0.3286],
        [0.8099, 0.1901],
        [0.7308, 0.2692],
        [0.6759, 0.3241],
        [0.6862, 0.3138],
[2K        [0.6973, 0.3027]], device='cuda:0');237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 68/203 [2m0:00:26 â€¢ 0:00:53[0m [2;4m2.59it/s[0m  
[2KAttention weights: tensor([[0.5213, 0.4787],8;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 69/203 [2m0:00:27 â€¢ 0:00:52[0m [2;4m2.59it/s[0m  
        [0.5130, 0.4870],
        [0.5149, 0.4851],
        [0.5205, 0.4795],
        [0.5224, 0.4776],
        [0.5250, 0.4750],
        [0.5224, 0.4776],
        [0.5193, 0.4807],
        [0.5163, 0.4837],
[2K        [0.5225, 0.4775]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 69/203 [2m0:00:27 â€¢ 0:00:52[0m [2;4m2.59it/s[0m  
[2KClass label: Billiardsâ”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 69/203 [2m0:00:27 â€¢ 0:00:52[0m [2;4m2.59it/s[0m  
[2KAttention weights: tensor([[0.4415, 0.5585]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 69/203 [2m0:00:27 â€¢ 0:00:52[0m [2;4m2.59it/s[0m  
[2KStep 0 - TTA Loss: 2.3584â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 69/203 [2m0:00:27 â€¢ 0:00:52[0m [2;4m2.59it/s[0m  
[2KAttention weights: tensor([[0.4415, 0.5585]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 69/203 [2m0:00:27 â€¢ 0:00:52[0m [2;4m2.59it/s[0m  
[2KAttention weights: tensor([[0.4436, 0.5564]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 69/203 [2m0:00:27 â€¢ 0:00:52[0m [2;4m2.59it/s[0m  
[2KAttention weights: tensor([[0.4607, 0.5393]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 69/203 [2m0:00:27 â€¢ 0:00:52[0m [2;4m2.59it/s[0m  
[2KAttention weights: tensor([[0.4875, 0.5125]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 69/203 [2m0:00:27 â€¢ 0:00:52[0m [2;4m2.59it/s[0m  
[2KAttention weights: tensor([[0.5062, 0.4938]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 69/203 [2m0:00:27 â€¢ 0:00:52[0m [2;4m2.59it/s[0m  
[2KAttention weights: tensor([[0.5374, 0.4626]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 69/203 [2m0:00:27 â€¢ 0:00:52[0m [2;4m2.59it/s[0m  
[2KAttention weights: tensor([[0.5773, 0.4227]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 69/203 [2m0:00:27 â€¢ 0:00:52[0m [2;4m2.59it/s[0m  
[2KAttention weights: tensor([[0.6262, 0.3738]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 69/203 [2m0:00:27 â€¢ 0:00:52[0m [2;4m2.59it/s[0m  
[2KAttention weights: tensor([[0.6743, 0.3257]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 69/203 [2m0:00:27 â€¢ 0:00:52[0m [2;4m2.59it/s[0m  
[2KAttention weights: tensor([[0.5181, 0.4819]], device='cuda:0');5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 69/203 [2m0:00:27 â€¢ 0:00:52[0m [2;4m2.59it/s[0m  
[2KAttention weights: tensor([[0.6311, 0.3689],98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 69/203 [2m0:00:27 â€¢ 0:00:52[0m [2;4m2.59it/s[0m  
        [0.7137, 0.2863],
        [0.5134, 0.4866],
        [0.6589, 0.3411],
        [0.6153, 0.3847],
        [0.7140, 0.2860],
        [0.6540, 0.3460],
        [0.6514, 0.3486],
        [0.5576, 0.4424],
[2K        [0.6136, 0.3864]], device='cuda:0');98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 69/203 [2m0:00:27 â€¢ 0:00:52[0m [2;4m2.59it/s[0m  
[2KAttention weights: tensor([[0.5213, 0.4787],8;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 70/203 [2m0:00:27 â€¢ 0:00:52[0m [2;4m2.60it/s[0m  
        [0.5130, 0.4870],
        [0.5149, 0.4851],
        [0.5205, 0.4795],
        [0.5225, 0.4775],
        [0.5250, 0.4750],
        [0.5224, 0.4776],
        [0.5193, 0.4807],
        [0.5163, 0.4837],
[2K        [0.5225, 0.4775]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 70/203 [2m0:00:27 â€¢ 0:00:52[0m [2;4m2.60it/s[0m  
[2KClass label: HammerThrowâ”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 70/203 [2m0:00:27 â€¢ 0:00:52[0m [2;4m2.60it/s[0m  
[2KAttention weights: tensor([[0.5798, 0.4202]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 70/203 [2m0:00:27 â€¢ 0:00:52[0m [2;4m2.60it/s[0m  
[2KStep 0 - TTA Loss: 1.2750â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 70/203 [2m0:00:27 â€¢ 0:00:52[0m [2;4m2.60it/s[0m  
[2KAttention weights: tensor([[0.5834, 0.4166]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 70/203 [2m0:00:27 â€¢ 0:00:52[0m [2;4m2.60it/s[0m  
[2KAttention weights: tensor([[0.5899, 0.4101]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 70/203 [2m0:00:27 â€¢ 0:00:52[0m [2;4m2.60it/s[0m  
[2KAttention weights: tensor([[0.5997, 0.4003]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 70/203 [2m0:00:27 â€¢ 0:00:52[0m [2;4m2.60it/s[0m  
[2KAttention weights: tensor([[0.6078, 0.3922]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 70/203 [2m0:00:27 â€¢ 0:00:52[0m [2;4m2.60it/s[0m  
[2KAttention weights: tensor([[0.6067, 0.3933]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 70/203 [2m0:00:27 â€¢ 0:00:52[0m [2;4m2.60it/s[0m  
[2KAttention weights: tensor([[0.6076, 0.3924]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 70/203 [2m0:00:27 â€¢ 0:00:52[0m [2;4m2.60it/s[0m  
[2KAttention weights: tensor([[0.6158, 0.3842]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 70/203 [2m0:00:27 â€¢ 0:00:52[0m [2;4m2.60it/s[0m  
[2KAttention weights: tensor([[0.6188, 0.3812]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 70/203 [2m0:00:27 â€¢ 0:00:52[0m [2;4m2.60it/s[0m  
[2KAttention weights: tensor([[0.6200, 0.3800]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 70/203 [2m0:00:27 â€¢ 0:00:52[0m [2;4m2.60it/s[0m  
[2KAttention weights: tensor([[0.5239, 0.4761]], device='cuda:0');5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 70/203 [2m0:00:27 â€¢ 0:00:52[0m [2;4m2.60it/s[0m  
[2KAttention weights: tensor([[0.6289, 0.3711],98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 70/203 [2m0:00:27 â€¢ 0:00:52[0m [2;4m2.60it/s[0m  
        [0.6288, 0.3712],
        [0.5106, 0.4894],
        [0.6467, 0.3533],
        [0.6206, 0.3794],
        [0.7137, 0.2863],
        [0.6583, 0.3417],
        [0.6404, 0.3596],
        [0.5484, 0.4516],
[2K        [0.6182, 0.3818]], device='cuda:0');98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 70/203 [2m0:00:27 â€¢ 0:00:52[0m [2;4m2.60it/s[0m  
[2KAttention weights: tensor([[0.5213, 0.4787],8;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 71/203 [2m0:00:27 â€¢ 0:00:51[0m [2;4m2.60it/s[0m  
        [0.5130, 0.4870],
        [0.5149, 0.4851],
        [0.5205, 0.4795],
        [0.5224, 0.4776],
        [0.5250, 0.4750],
        [0.5224, 0.4776],
        [0.5193, 0.4807],
        [0.5163, 0.4837],
[2K        [0.5225, 0.4775]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 71/203 [2m0:00:27 â€¢ 0:00:51[0m [2;4m2.60it/s[0m  
[2KClass label: HighJumpâ”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 71/203 [2m0:00:27 â€¢ 0:00:51[0m [2;4m2.60it/s[0m  
[2KAttention weights: tensor([[0.6898, 0.3102]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 71/203 [2m0:00:27 â€¢ 0:00:51[0m [2;4m2.60it/s[0m  
[2KStep 0 - TTA Loss: 1.6246â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 71/203 [2m0:00:27 â€¢ 0:00:51[0m [2;4m2.60it/s[0m  
[2KAttention weights: tensor([[0.6898, 0.3102]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 71/203 [2m0:00:27 â€¢ 0:00:51[0m [2;4m2.60it/s[0m  
[2KAttention weights: tensor([[0.6899, 0.3101]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 71/203 [2m0:00:27 â€¢ 0:00:51[0m [2;4m2.60it/s[0m  
[2KAttention weights: tensor([[0.6906, 0.3094]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 71/203 [2m0:00:27 â€¢ 0:00:51[0m [2;4m2.60it/s[0m  
[2KAttention weights: tensor([[0.6918, 0.3082]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 71/203 [2m0:00:27 â€¢ 0:00:51[0m [2;4m2.60it/s[0m  
[2KAttention weights: tensor([[0.6965, 0.3035]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 71/203 [2m0:00:27 â€¢ 0:00:51[0m [2;4m2.60it/s[0m  
[2KAttention weights: tensor([[0.7023, 0.2977]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 71/203 [2m0:00:27 â€¢ 0:00:51[0m [2;4m2.60it/s[0m  
[2KAttention weights: tensor([[0.7070, 0.2930]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 71/203 [2m0:00:27 â€¢ 0:00:51[0m [2;4m2.60it/s[0m  
[2KAttention weights: tensor([[0.7123, 0.2877]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 71/203 [2m0:00:27 â€¢ 0:00:51[0m [2;4m2.60it/s[0m  
[2KAttention weights: tensor([[0.7134, 0.2866]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 71/203 [2m0:00:27 â€¢ 0:00:51[0m [2;4m2.60it/s[0m  
[2KAttention weights: tensor([[0.5260, 0.4740]], device='cuda:0');5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 71/203 [2m0:00:27 â€¢ 0:00:51[0m [2;4m2.60it/s[0m  
[2KAttention weights: tensor([[0.6216, 0.3784],98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 71/203 [2m0:00:27 â€¢ 0:00:51[0m [2;4m2.60it/s[0m  
        [0.4774, 0.5226],
        [0.5090, 0.4910],
        [0.6269, 0.3731],
        [0.6182, 0.3818],
        [0.7149, 0.2851],
        [0.6639, 0.3361],
        [0.6239, 0.3761],
        [0.5368, 0.4632],
[2K        [0.6187, 0.3813]], device='cuda:0');98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 71/203 [2m0:00:27 â€¢ 0:00:51[0m [2;4m2.60it/s[0m  
[2KAttention weights: tensor([[0.5214, 0.4786],38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 72/203 [2m0:00:28 â€¢ 0:00:51[0m [2;4m2.59it/s[0m   
        [0.5130, 0.4870],
        [0.5149, 0.4851],
        [0.5205, 0.4795],
        [0.5224, 0.4776],
        [0.5251, 0.4749],
        [0.5224, 0.4776],
        [0.5193, 0.4807],
        [0.5163, 0.4837],
[2K        [0.5225, 0.4775]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 72/203 [2m0:00:28 â€¢ 0:00:51[0m [2;4m2.59it/s[0m  
[2KClass label: HammerThrowâ”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 72/203 [2m0:00:28 â€¢ 0:00:51[0m [2;4m2.59it/s[0m  
[2KAttention weights: tensor([[0.5785, 0.4215]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 72/203 [2m0:00:28 â€¢ 0:00:51[0m [2;4m2.59it/s[0m  
[2KStep 0 - TTA Loss: 0.9606â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 72/203 [2m0:00:28 â€¢ 0:00:51[0m [2;4m2.59it/s[0m  
[2KAttention weights: tensor([[0.5812, 0.4188]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 72/203 [2m0:00:28 â€¢ 0:00:51[0m [2;4m2.59it/s[0m  
[2KAttention weights: tensor([[0.5717, 0.4283]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 72/203 [2m0:00:28 â€¢ 0:00:51[0m [2;4m2.59it/s[0m  
[2KAttention weights: tensor([[0.5641, 0.4359]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 72/203 [2m0:00:28 â€¢ 0:00:51[0m [2;4m2.59it/s[0m  
[2KAttention weights: tensor([[0.5551, 0.4449]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 72/203 [2m0:00:28 â€¢ 0:00:51[0m [2;4m2.59it/s[0m  
[2KAttention weights: tensor([[0.5438, 0.4562]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 72/203 [2m0:00:28 â€¢ 0:00:51[0m [2;4m2.59it/s[0m  
[2KAttention weights: tensor([[0.5362, 0.4638]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 72/203 [2m0:00:28 â€¢ 0:00:51[0m [2;4m2.59it/s[0m  
[2KAttention weights: tensor([[0.5332, 0.4668]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 72/203 [2m0:00:28 â€¢ 0:00:51[0m [2;4m2.59it/s[0m  
[2KAttention weights: tensor([[0.5314, 0.4686]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 72/203 [2m0:00:28 â€¢ 0:00:51[0m [2;4m2.59it/s[0m  
[2KAttention weights: tensor([[0.5307, 0.4693]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 72/203 [2m0:00:28 â€¢ 0:00:51[0m [2;4m2.59it/s[0m  
[2KAttention weights: tensor([[0.5211, 0.4789]], device='cuda:0')37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 72/203 [2m0:00:28 â€¢ 0:00:51[0m [2;4m2.59it/s[0m  
[2KAttention weights: tensor([[0.5787, 0.4213],;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 72/203 [2m0:00:28 â€¢ 0:00:51[0m [2;4m2.59it/s[0m  
        [0.4651, 0.5349],
        [0.4843, 0.5157],
        [0.5907, 0.4093],
        [0.5307, 0.4693],
        [0.6616, 0.3384],
        [0.6174, 0.3826],
        [0.5924, 0.4076],
        [0.5028, 0.4972],
[2K        [0.5457, 0.4543]], device='cuda:0')5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 72/203 [2m0:00:28 â€¢ 0:00:51[0m [2;4m2.59it/s[0m  
[2KAttention weights: tensor([[0.5214, 0.4786],38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 73/203 [2m0:00:28 â€¢ 0:00:51[0m [2;4m2.59it/s[0m  
        [0.5131, 0.4869],
        [0.5149, 0.4851],
        [0.5206, 0.4794],
        [0.5225, 0.4775],
        [0.5251, 0.4749],
        [0.5225, 0.4775],
        [0.5194, 0.4806],
        [0.5163, 0.4837],
[2K        [0.5226, 0.4774]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 73/203 [2m0:00:28 â€¢ 0:00:51[0m [2;4m2.59it/s[0m  
[2KClass label: GolfSwingâ”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 73/203 [2m0:00:28 â€¢ 0:00:51[0m [2;4m2.59it/s[0m  
[2KAttention weights: tensor([[0.6051, 0.3949]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 73/203 [2m0:00:28 â€¢ 0:00:51[0m [2;4m2.59it/s[0m  
[2KStep 0 - TTA Loss: 1.7638â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 73/203 [2m0:00:28 â€¢ 0:00:51[0m [2;4m2.59it/s[0m  
[2KAttention weights: tensor([[0.6051, 0.3949]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 73/203 [2m0:00:28 â€¢ 0:00:51[0m [2;4m2.59it/s[0m  
[2KAttention weights: tensor([[0.6054, 0.3946]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 73/203 [2m0:00:28 â€¢ 0:00:51[0m [2;4m2.59it/s[0m  
[2KAttention weights: tensor([[0.6069, 0.3931]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 73/203 [2m0:00:28 â€¢ 0:00:51[0m [2;4m2.59it/s[0m  
[2KAttention weights: tensor([[0.6097, 0.3903]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 73/203 [2m0:00:28 â€¢ 0:00:51[0m [2;4m2.59it/s[0m  
[2KAttention weights: tensor([[0.6142, 0.3858]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 73/203 [2m0:00:28 â€¢ 0:00:51[0m [2;4m2.59it/s[0m  
[2KAttention weights: tensor([[0.6209, 0.3791]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 73/203 [2m0:00:28 â€¢ 0:00:51[0m [2;4m2.59it/s[0m  
[2KAttention weights: tensor([[0.6286, 0.3714]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 73/203 [2m0:00:28 â€¢ 0:00:51[0m [2;4m2.59it/s[0m  
[2KAttention weights: tensor([[0.6375, 0.3625]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 73/203 [2m0:00:28 â€¢ 0:00:51[0m [2;4m2.59it/s[0m  
[2KAttention weights: tensor([[0.6470, 0.3530]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 73/203 [2m0:00:28 â€¢ 0:00:51[0m [2;4m2.59it/s[0m  
[2KAttention weights: tensor([[0.5233, 0.4767]], device='cuda:0')37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 73/203 [2m0:00:28 â€¢ 0:00:51[0m [2;4m2.59it/s[0m  
[2KAttention weights: tensor([[0.6172, 0.3828],;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 73/203 [2m0:00:28 â€¢ 0:00:51[0m [2;4m2.59it/s[0m  
        [0.4594, 0.5406],
        [0.5045, 0.4955],
        [0.6569, 0.3431],
        [0.5931, 0.4069],
        [0.6962, 0.3038],
        [0.6533, 0.3467],
        [0.6154, 0.3846],
        [0.5273, 0.4727],
[2K        [0.6018, 0.3982]], device='cuda:0')5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 73/203 [2m0:00:28 â€¢ 0:00:51[0m [2;4m2.59it/s[0m  
[2KAttention weights: tensor([[0.5214, 0.4786],38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 74/203 [2m0:00:29 â€¢ 0:00:50[0m [2;4m2.59it/s[0m  
        [0.5131, 0.4869],
        [0.5150, 0.4850],
        [0.5206, 0.4794],
        [0.5225, 0.4775],
        [0.5252, 0.4748],
        [0.5225, 0.4775],
        [0.5194, 0.4806],
        [0.5164, 0.4836],
[2K        [0.5226, 0.4774]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 74/203 [2m0:00:29 â€¢ 0:00:50[0m [2;4m2.59it/s[0m  
[2KClass label: HammerThrowâ”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 74/203 [2m0:00:29 â€¢ 0:00:50[0m [2;4m2.59it/s[0m  
[2KAttention weights: tensor([[0.5775, 0.4225]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 74/203 [2m0:00:29 â€¢ 0:00:50[0m [2;4m2.59it/s[0m  
[2KStep 0 - TTA Loss: 2.0714â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 74/203 [2m0:00:29 â€¢ 0:00:50[0m [2;4m2.59it/s[0m  
[2KAttention weights: tensor([[0.5885, 0.4115]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 74/203 [2m0:00:29 â€¢ 0:00:50[0m [2;4m2.59it/s[0m  
[2KAttention weights: tensor([[0.5942, 0.4058]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 74/203 [2m0:00:29 â€¢ 0:00:50[0m [2;4m2.59it/s[0m  
[2KAttention weights: tensor([[0.6050, 0.3950]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 74/203 [2m0:00:29 â€¢ 0:00:50[0m [2;4m2.59it/s[0m  
[2KAttention weights: tensor([[0.6127, 0.3873]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 74/203 [2m0:00:29 â€¢ 0:00:50[0m [2;4m2.59it/s[0m  
[2KAttention weights: tensor([[0.6252, 0.3748]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 74/203 [2m0:00:29 â€¢ 0:00:50[0m [2;4m2.59it/s[0m  
[2KAttention weights: tensor([[0.6307, 0.3693]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 74/203 [2m0:00:29 â€¢ 0:00:50[0m [2;4m2.59it/s[0m  
[2KAttention weights: tensor([[0.6349, 0.3651]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 74/203 [2m0:00:29 â€¢ 0:00:50[0m [2;4m2.59it/s[0m  
[2KAttention weights: tensor([[0.6368, 0.3632]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 74/203 [2m0:00:29 â€¢ 0:00:50[0m [2;4m2.59it/s[0m  
[2KAttention weights: tensor([[0.6379, 0.3621]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 74/203 [2m0:00:29 â€¢ 0:00:50[0m [2;4m2.59it/s[0m  
[2KAttention weights: tensor([[0.5247, 0.4753]], device='cuda:0')8;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 74/203 [2m0:00:29 â€¢ 0:00:50[0m [2;4m2.59it/s[0m  
[2KAttention weights: tensor([[0.6339, 0.3661],;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 74/203 [2m0:00:29 â€¢ 0:00:50[0m [2;4m2.59it/s[0m  
        [0.4577, 0.5423],
        [0.5098, 0.4902],
        [0.6637, 0.3363],
        [0.6383, 0.3617],
        [0.7191, 0.2809],
        [0.6753, 0.3247],
        [0.6242, 0.3758],
        [0.5386, 0.4614],
[2K        [0.6364, 0.3636]], device='cuda:0')2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 74/203 [2m0:00:29 â€¢ 0:00:50[0m [2;4m2.59it/s[0m  
[2KAttention weights: tensor([[0.5215, 0.4785],38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 75/203 [2m0:00:29 â€¢ 0:00:50[0m [2;4m2.59it/s[0m  
        [0.5131, 0.4869],
        [0.5150, 0.4850],
        [0.5206, 0.4794],
        [0.5226, 0.4774],
        [0.5252, 0.4748],
        [0.5225, 0.4775],
        [0.5194, 0.4806],
        [0.5164, 0.4836],
[2K        [0.5226, 0.4774]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 75/203 [2m0:00:29 â€¢ 0:00:50[0m [2;4m2.59it/s[0m  
[2KClass label: BaseballPitchâ”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 75/203 [2m0:00:29 â€¢ 0:00:50[0m [2;4m2.59it/s[0m  
[2KAttention weights: tensor([[0.5979, 0.4021]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 75/203 [2m0:00:29 â€¢ 0:00:50[0m [2;4m2.59it/s[0m  
[2KStep 0 - TTA Loss: 1.5619â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 75/203 [2m0:00:29 â€¢ 0:00:50[0m [2;4m2.59it/s[0m  
[2KAttention weights: tensor([[0.5979, 0.4021]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 75/203 [2m0:00:29 â€¢ 0:00:50[0m [2;4m2.59it/s[0m  
[2KAttention weights: tensor([[0.5981, 0.4019]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 75/203 [2m0:00:29 â€¢ 0:00:50[0m [2;4m2.59it/s[0m  
[2KAttention weights: tensor([[0.5986, 0.4014]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 75/203 [2m0:00:29 â€¢ 0:00:50[0m [2;4m2.59it/s[0m  
[2KAttention weights: tensor([[0.6004, 0.3996]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 75/203 [2m0:00:29 â€¢ 0:00:50[0m [2;4m2.59it/s[0m  
[2KAttention weights: tensor([[0.6032, 0.3968]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 75/203 [2m0:00:29 â€¢ 0:00:50[0m [2;4m2.59it/s[0m  
[2KAttention weights: tensor([[0.6070, 0.3930]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 75/203 [2m0:00:29 â€¢ 0:00:50[0m [2;4m2.59it/s[0m  
[2KAttention weights: tensor([[0.6151, 0.3849]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 75/203 [2m0:00:29 â€¢ 0:00:50[0m [2;4m2.59it/s[0m  
[2KAttention weights: tensor([[0.6255, 0.3745]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 75/203 [2m0:00:29 â€¢ 0:00:50[0m [2;4m2.59it/s[0m  
[2KAttention weights: tensor([[0.6361, 0.3639]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 75/203 [2m0:00:29 â€¢ 0:00:50[0m [2;4m2.59it/s[0m  
[2KAttention weights: tensor([[0.5236, 0.4764]], device='cuda:0')8;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 75/203 [2m0:00:29 â€¢ 0:00:50[0m [2;4m2.59it/s[0m  
[2KAttention weights: tensor([[0.6436, 0.3564],;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 75/203 [2m0:00:29 â€¢ 0:00:50[0m [2;4m2.59it/s[0m  
        [0.4535, 0.5465],
        [0.5015, 0.4985],
        [0.6289, 0.3711],
        [0.6070, 0.3930],
        [0.7033, 0.2967],
        [0.6551, 0.3449],
        [0.6136, 0.3864],
        [0.5329, 0.4671],
[2K        [0.6121, 0.3879]], device='cuda:0')2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 75/203 [2m0:00:29 â€¢ 0:00:50[0m [2;4m2.59it/s[0m  
[2KAttention weights: tensor([[0.5214, 0.4786],38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 76/203 [2m0:00:29 â€¢ 0:00:50[0m [2;4m2.59it/s[0m  
        [0.5131, 0.4869],
        [0.5150, 0.4850],
        [0.5206, 0.4794],
        [0.5226, 0.4774],
        [0.5252, 0.4748],
        [0.5225, 0.4775],
        [0.5194, 0.4806],
        [0.5164, 0.4836],
[2K        [0.5226, 0.4774]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 76/203 [2m0:00:29 â€¢ 0:00:50[0m [2;4m2.59it/s[0m  
[2KClass label: Billiardsâ”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 76/203 [2m0:00:29 â€¢ 0:00:50[0m [2;4m2.59it/s[0m  
[2KAttention weights: tensor([[0.4470, 0.5530]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 76/203 [2m0:00:29 â€¢ 0:00:50[0m [2;4m2.59it/s[0m  
[2KStep 0 - TTA Loss: 0.6776â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 76/203 [2m0:00:29 â€¢ 0:00:50[0m [2;4m2.59it/s[0m  
[2KAttention weights: tensor([[0.4456, 0.5544]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 76/203 [2m0:00:29 â€¢ 0:00:50[0m [2;4m2.59it/s[0m  
[2KAttention weights: tensor([[0.4367, 0.5633]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 76/203 [2m0:00:29 â€¢ 0:00:50[0m [2;4m2.59it/s[0m  
[2KAttention weights: tensor([[0.4288, 0.5712]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 76/203 [2m0:00:29 â€¢ 0:00:50[0m [2;4m2.59it/s[0m  
[2KAttention weights: tensor([[0.4184, 0.5816]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 76/203 [2m0:00:29 â€¢ 0:00:50[0m [2;4m2.59it/s[0m  
[2KAttention weights: tensor([[0.4110, 0.5890]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 76/203 [2m0:00:29 â€¢ 0:00:50[0m [2;4m2.59it/s[0m  
[2KAttention weights: tensor([[0.4053, 0.5947]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 76/203 [2m0:00:29 â€¢ 0:00:50[0m [2;4m2.59it/s[0m  
[2KAttention weights: tensor([[0.4011, 0.5989]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 76/203 [2m0:00:29 â€¢ 0:00:50[0m [2;4m2.59it/s[0m  
[2KAttention weights: tensor([[0.3990, 0.6010]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 76/203 [2m0:00:29 â€¢ 0:00:50[0m [2;4m2.59it/s[0m  
[2KAttention weights: tensor([[0.3981, 0.6019]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 76/203 [2m0:00:29 â€¢ 0:00:50[0m [2;4m2.59it/s[0m  
[2KAttention weights: tensor([[0.5114, 0.4886]], device='cuda:0')8;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 76/203 [2m0:00:29 â€¢ 0:00:50[0m [2;4m2.59it/s[0m  
[2KAttention weights: tensor([[0.6254, 0.3746],;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 76/203 [2m0:00:29 â€¢ 0:00:50[0m [2;4m2.59it/s[0m  
        [0.3978, 0.6022],
        [0.4999, 0.5001],
        [0.6108, 0.3892],
        [0.5903, 0.4097],
        [0.6977, 0.3023],
        [0.6538, 0.3462],
        [0.6044, 0.3956],
        [0.5225, 0.4775],
[2K        [0.5998, 0.4002]], device='cuda:0')2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 76/203 [2m0:00:29 â€¢ 0:00:50[0m [2;4m2.59it/s[0m  
[2KAttention weights: tensor([[0.5214, 0.4786],[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 77/203 [2m0:00:30 â€¢ 0:00:49[0m [2;4m2.59it/s[0m   
        [0.5131, 0.4869],
        [0.5150, 0.4850],
        [0.5206, 0.4794],
        [0.5226, 0.4774],
        [0.5252, 0.4748],
        [0.5225, 0.4775],
        [0.5194, 0.4806],
        [0.5164, 0.4836],
[2K        [0.5226, 0.4774]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 77/203 [2m0:00:30 â€¢ 0:00:49[0m [2;4m2.59it/s[0m  
[2KClass label: SoccerPenaltyâ”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 77/203 [2m0:00:30 â€¢ 0:00:49[0m [2;4m2.59it/s[0m  
[2KAttention weights: tensor([[0.6064, 0.3936]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 77/203 [2m0:00:30 â€¢ 0:00:49[0m [2;4m2.59it/s[0m  
[2KStep 0 - TTA Loss: 2.5461â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 77/203 [2m0:00:30 â€¢ 0:00:49[0m [2;4m2.59it/s[0m  
[2KAttention weights: tensor([[0.6064, 0.3936]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 77/203 [2m0:00:30 â€¢ 0:00:49[0m [2;4m2.59it/s[0m  
[2KAttention weights: tensor([[0.6074, 0.3926]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 77/203 [2m0:00:30 â€¢ 0:00:49[0m [2;4m2.59it/s[0m  
[2KAttention weights: tensor([[0.6122, 0.3878]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 77/203 [2m0:00:30 â€¢ 0:00:49[0m [2;4m2.59it/s[0m  
[2KAttention weights: tensor([[0.6224, 0.3776]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 77/203 [2m0:00:30 â€¢ 0:00:49[0m [2;4m2.59it/s[0m  
[2KAttention weights: tensor([[0.6346, 0.3654]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 77/203 [2m0:00:30 â€¢ 0:00:49[0m [2;4m2.59it/s[0m  
[2KAttention weights: tensor([[0.6547, 0.3453]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 77/203 [2m0:00:30 â€¢ 0:00:49[0m [2;4m2.59it/s[0m  
[2KAttention weights: tensor([[0.6790, 0.3210]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 77/203 [2m0:00:30 â€¢ 0:00:49[0m [2;4m2.59it/s[0m  
[2KAttention weights: tensor([[0.7049, 0.2951]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 77/203 [2m0:00:30 â€¢ 0:00:49[0m [2;4m2.59it/s[0m  
[2KAttention weights: tensor([[0.7277, 0.2723]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 77/203 [2m0:00:30 â€¢ 0:00:49[0m [2;4m2.59it/s[0m  
[2KAttention weights: tensor([[0.5203, 0.4797]], device='cuda:0')237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 77/203 [2m0:00:30 â€¢ 0:00:49[0m [2;4m2.59it/s[0m  
[2KAttention weights: tensor([[0.6094, 0.3906],5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 77/203 [2m0:00:30 â€¢ 0:00:49[0m [2;4m2.59it/s[0m  
        [0.4368, 0.5632],
        [0.4964, 0.5036],
        [0.6228, 0.3772],
        [0.6144, 0.3856],
        [0.7334, 0.2666],
        [0.6792, 0.3208],
        [0.7488, 0.2512],
        [0.5488, 0.4512],
[2K        [0.6109, 0.3891]], device='cuda:0');5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 77/203 [2m0:00:30 â€¢ 0:00:49[0m [2;4m2.59it/s[0m  
[2KAttention weights: tensor([[0.5215, 0.4785],[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 78/203 [2m0:00:30 â€¢ 0:00:49[0m [2;4m2.58it/s[0m  
        [0.5131, 0.4869],
        [0.5150, 0.4850],
        [0.5206, 0.4794],
        [0.5226, 0.4774],
        [0.5252, 0.4748],
        [0.5225, 0.4775],
        [0.5194, 0.4806],
        [0.5164, 0.4836],
[2K        [0.5226, 0.4774]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 78/203 [2m0:00:30 â€¢ 0:00:49[0m [2;4m2.58it/s[0m  
[2KClass label: PoleVaultâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 78/203 [2m0:00:30 â€¢ 0:00:49[0m [2;4m2.58it/s[0m  
[2KAttention weights: tensor([[0.6421, 0.3579]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 78/203 [2m0:00:30 â€¢ 0:00:49[0m [2;4m2.58it/s[0m  
[2KStep 0 - TTA Loss: 1.1783â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 78/203 [2m0:00:30 â€¢ 0:00:49[0m [2;4m2.58it/s[0m  
[2KAttention weights: tensor([[0.6513, 0.3487]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 78/203 [2m0:00:30 â€¢ 0:00:49[0m [2;4m2.58it/s[0m  
[2KAttention weights: tensor([[0.6648, 0.3352]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 78/203 [2m0:00:30 â€¢ 0:00:49[0m [2;4m2.58it/s[0m  
[2KAttention weights: tensor([[0.6876, 0.3124]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 78/203 [2m0:00:30 â€¢ 0:00:49[0m [2;4m2.58it/s[0m  
[2KAttention weights: tensor([[0.7056, 0.2944]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 78/203 [2m0:00:30 â€¢ 0:00:49[0m [2;4m2.58it/s[0m  
[2KAttention weights: tensor([[0.7176, 0.2824]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 78/203 [2m0:00:30 â€¢ 0:00:49[0m [2;4m2.58it/s[0m  
[2KAttention weights: tensor([[0.7234, 0.2766]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 78/203 [2m0:00:30 â€¢ 0:00:49[0m [2;4m2.58it/s[0m  
[2KAttention weights: tensor([[0.7286, 0.2714]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 78/203 [2m0:00:30 â€¢ 0:00:49[0m [2;4m2.58it/s[0m  
[2KAttention weights: tensor([[0.7314, 0.2686]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 78/203 [2m0:00:30 â€¢ 0:00:49[0m [2;4m2.58it/s[0m  
[2KAttention weights: tensor([[0.7328, 0.2672]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 78/203 [2m0:00:30 â€¢ 0:00:49[0m [2;4m2.58it/s[0m  
[2KAttention weights: tensor([[0.5261, 0.4739]], device='cuda:0')237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 78/203 [2m0:00:30 â€¢ 0:00:49[0m [2;4m2.58it/s[0m  
[2KAttention weights: tensor([[0.6232, 0.3768],5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 78/203 [2m0:00:30 â€¢ 0:00:49[0m [2;4m2.58it/s[0m  
        [0.4391, 0.5609],
        [0.5105, 0.4895],
        [0.6335, 0.3665],
        [0.6388, 0.3612],
        [0.7583, 0.2417],
        [0.7340, 0.2660],
        [0.7207, 0.2793],
        [0.5502, 0.4498],
[2K        [0.6419, 0.3581]], device='cuda:0');5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 78/203 [2m0:00:30 â€¢ 0:00:49[0m [2;4m2.58it/s[0m  
[2KAttention weights: tensor([[0.5214, 0.4786],[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 79/203 [2m0:00:31 â€¢ 0:00:49[0m [2;4m2.57it/s[0m  
        [0.5131, 0.4869],
        [0.5150, 0.4850],
        [0.5206, 0.4794],
        [0.5226, 0.4774],
        [0.5252, 0.4748],
        [0.5225, 0.4775],
        [0.5194, 0.4806],
        [0.5164, 0.4836],
[2K        [0.5226, 0.4774]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 79/203 [2m0:00:31 â€¢ 0:00:49[0m [2;4m2.57it/s[0m  
[2KClass label: ThrowDiscusâ”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 79/203 [2m0:00:31 â€¢ 0:00:49[0m [2;4m2.57it/s[0m  
[2KAttention weights: tensor([[0.5840, 0.4160]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 79/203 [2m0:00:31 â€¢ 0:00:49[0m [2;4m2.57it/s[0m  
[2KStep 0 - TTA Loss: 2.6780â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 79/203 [2m0:00:31 â€¢ 0:00:49[0m [2;4m2.57it/s[0m  
[2KAttention weights: tensor([[0.5840, 0.4160]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 79/203 [2m0:00:31 â€¢ 0:00:49[0m [2;4m2.57it/s[0m  
[2KAttention weights: tensor([[0.5846, 0.4154]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 79/203 [2m0:00:31 â€¢ 0:00:49[0m [2;4m2.57it/s[0m  
[2KAttention weights: tensor([[0.5881, 0.4119]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 79/203 [2m0:00:31 â€¢ 0:00:49[0m [2;4m2.57it/s[0m  
[2KAttention weights: tensor([[0.5986, 0.4014]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 79/203 [2m0:00:31 â€¢ 0:00:49[0m [2;4m2.57it/s[0m  
[2KAttention weights: tensor([[0.6185, 0.3815]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 79/203 [2m0:00:31 â€¢ 0:00:49[0m [2;4m2.57it/s[0m  
[2KAttention weights: tensor([[0.6441, 0.3559]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 79/203 [2m0:00:31 â€¢ 0:00:49[0m [2;4m2.57it/s[0m  
[2KAttention weights: tensor([[0.6752, 0.3248]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 79/203 [2m0:00:31 â€¢ 0:00:49[0m [2;4m2.57it/s[0m  
[2KAttention weights: tensor([[0.7045, 0.2955]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 79/203 [2m0:00:31 â€¢ 0:00:49[0m [2;4m2.57it/s[0m  
[2KAttention weights: tensor([[0.7317, 0.2683]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 79/203 [2m0:00:31 â€¢ 0:00:49[0m [2;4m2.57it/s[0m  
[2KAttention weights: tensor([[0.5257, 0.4743]], device='cuda:0')38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 79/203 [2m0:00:31 â€¢ 0:00:49[0m [2;4m2.57it/s[0m  
[2KAttention weights: tensor([[0.6897, 0.3103],2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 79/203 [2m0:00:31 â€¢ 0:00:49[0m [2;4m2.57it/s[0m  
        [0.4508, 0.5492],
        [0.5445, 0.4555],
        [0.6877, 0.3123],
        [0.7196, 0.2804],
        [0.7949, 0.2051],
        [0.7648, 0.2352],
        [0.6636, 0.3364],
        [0.5842, 0.4158],
[2K        [0.7568, 0.2432]], device='cuda:0');2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 79/203 [2m0:00:31 â€¢ 0:00:49[0m [2;4m2.57it/s[0m  
[2KAttention weights: tensor([[0.5215, 0.4785],[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 80/203 [2m0:00:31 â€¢ 0:00:48[0m [2;4m2.57it/s[0m  
        [0.5132, 0.4868],
        [0.5151, 0.4849],
        [0.5207, 0.4793],
        [0.5227, 0.4773],
        [0.5252, 0.4748],
        [0.5226, 0.4774],
        [0.5195, 0.4805],
        [0.5165, 0.4835],
[2K        [0.5228, 0.4772]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 80/203 [2m0:00:31 â€¢ 0:00:48[0m [2;4m2.57it/s[0m  
[2KClass label: BaseballPitchâ”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 80/203 [2m0:00:31 â€¢ 0:00:48[0m [2;4m2.57it/s[0m  
[2KAttention weights: tensor([[0.6019, 0.3981]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 80/203 [2m0:00:31 â€¢ 0:00:48[0m [2;4m2.57it/s[0m  
[2KStep 0 - TTA Loss: 1.8510â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 80/203 [2m0:00:31 â€¢ 0:00:48[0m [2;4m2.57it/s[0m  
[2KAttention weights: tensor([[0.6335, 0.3665]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 80/203 [2m0:00:31 â€¢ 0:00:48[0m [2;4m2.57it/s[0m  
[2KAttention weights: tensor([[0.6743, 0.3257]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 80/203 [2m0:00:31 â€¢ 0:00:48[0m [2;4m2.57it/s[0m  
[2KAttention weights: tensor([[0.7104, 0.2896]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 80/203 [2m0:00:31 â€¢ 0:00:48[0m [2;4m2.57it/s[0m  
[2KAttention weights: tensor([[0.7407, 0.2593]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 80/203 [2m0:00:31 â€¢ 0:00:48[0m [2;4m2.57it/s[0m  
[2KAttention weights: tensor([[0.7621, 0.2379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 80/203 [2m0:00:31 â€¢ 0:00:48[0m [2;4m2.57it/s[0m  
[2KAttention weights: tensor([[0.7763, 0.2237]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 80/203 [2m0:00:31 â€¢ 0:00:48[0m [2;4m2.57it/s[0m  
[2KAttention weights: tensor([[0.7831, 0.2169]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 80/203 [2m0:00:31 â€¢ 0:00:48[0m [2;4m2.57it/s[0m  
[2KAttention weights: tensor([[0.7865, 0.2135]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 80/203 [2m0:00:31 â€¢ 0:00:48[0m [2;4m2.57it/s[0m  
[2KAttention weights: tensor([[0.7874, 0.2126]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 80/203 [2m0:00:31 â€¢ 0:00:48[0m [2;4m2.57it/s[0m  
[2KAttention weights: tensor([[0.5277, 0.4723]], device='cuda:0')38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 80/203 [2m0:00:31 â€¢ 0:00:48[0m [2;4m2.57it/s[0m  
[2KAttention weights: tensor([[0.7880, 0.2120],2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 80/203 [2m0:00:31 â€¢ 0:00:48[0m [2;4m2.57it/s[0m  
        [0.4576, 0.5424],
        [0.5542, 0.4458],
        [0.7023, 0.2977],
        [0.7264, 0.2736],
        [0.7880, 0.2120],
        [0.7525, 0.2475],
        [0.6447, 0.3553],
        [0.6020, 0.3980],
[2K        [0.7581, 0.2419]], device='cuda:0');2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 80/203 [2m0:00:31 â€¢ 0:00:48[0m [2;4m2.57it/s[0m  
[2KAttention weights: tensor([[0.5216, 0.4784],[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 81/203 [2m0:00:32 â€¢ 0:00:48[0m [2;4m2.56it/s[0m  
        [0.5132, 0.4868],
        [0.5152, 0.4848],
        [0.5207, 0.4793],
        [0.5228, 0.4772],
        [0.5253, 0.4747],
        [0.5226, 0.4774],
        [0.5196, 0.4804],
        [0.5165, 0.4835],
[2K        [0.5229, 0.4771]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 81/203 [2m0:00:32 â€¢ 0:00:48[0m [2;4m2.56it/s[0m  
[2KClass label: TennisSwingâ”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 81/203 [2m0:00:32 â€¢ 0:00:48[0m [2;4m2.56it/s[0m  
[2KAttention weights: tensor([[0.5188, 0.4812]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 81/203 [2m0:00:32 â€¢ 0:00:48[0m [2;4m2.56it/s[0m  
[2KStep 0 - TTA Loss: 1.0102â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 81/203 [2m0:00:32 â€¢ 0:00:48[0m [2;4m2.56it/s[0m  
[2KAttention weights: tensor([[0.5188, 0.4812]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 81/203 [2m0:00:32 â€¢ 0:00:48[0m [2;4m2.56it/s[0m  
[2KAttention weights: tensor([[0.5189, 0.4811]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 81/203 [2m0:00:32 â€¢ 0:00:48[0m [2;4m2.56it/s[0m  
[2KAttention weights: tensor([[0.5194, 0.4806]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 81/203 [2m0:00:32 â€¢ 0:00:48[0m [2;4m2.56it/s[0m  
[2KAttention weights: tensor([[0.5202, 0.4798]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 81/203 [2m0:00:32 â€¢ 0:00:48[0m [2;4m2.56it/s[0m  
[2KAttention weights: tensor([[0.5213, 0.4787]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 81/203 [2m0:00:32 â€¢ 0:00:48[0m [2;4m2.56it/s[0m  
[2KAttention weights: tensor([[0.5224, 0.4776]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 81/203 [2m0:00:32 â€¢ 0:00:48[0m [2;4m2.56it/s[0m  
[2KAttention weights: tensor([[0.5237, 0.4763]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 81/203 [2m0:00:32 â€¢ 0:00:48[0m [2;4m2.56it/s[0m  
[2KAttention weights: tensor([[0.5263, 0.4737]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 81/203 [2m0:00:32 â€¢ 0:00:48[0m [2;4m2.56it/s[0m  
[2KAttention weights: tensor([[0.5295, 0.4705]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 81/203 [2m0:00:32 â€¢ 0:00:48[0m [2;4m2.56it/s[0m  
[2KAttention weights: tensor([[0.5171, 0.4829]], device='cuda:0')38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 81/203 [2m0:00:32 â€¢ 0:00:48[0m [2;4m2.56it/s[0m  
[2KAttention weights: tensor([[0.6078, 0.3922],2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 81/203 [2m0:00:32 â€¢ 0:00:48[0m [2;4m2.56it/s[0m  
        [0.4475, 0.5525],
        [0.5033, 0.4967],
        [0.6101, 0.3899],
        [0.5919, 0.4081],
        [0.7031, 0.2969],
        [0.6565, 0.3435],
        [0.6168, 0.3832],
        [0.5340, 0.4660],
[2K        [0.6059, 0.3941]], device='cuda:0');2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 81/203 [2m0:00:32 â€¢ 0:00:48[0m [2;4m2.56it/s[0m  
[2KAttention weights: tensor([[0.5216, 0.4784],[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 82/203 [2m0:00:32 â€¢ 0:00:48[0m [2;4m2.56it/s[0m   
        [0.5132, 0.4868],
        [0.5152, 0.4848],
        [0.5208, 0.4792],
        [0.5228, 0.4772],
        [0.5253, 0.4747],
        [0.5226, 0.4774],
        [0.5196, 0.4804],
        [0.5165, 0.4835],
[2K        [0.5229, 0.4771]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 82/203 [2m0:00:32 â€¢ 0:00:48[0m [2;4m2.56it/s[0m  
[2KClass label: SoccerPenaltyâ”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 82/203 [2m0:00:32 â€¢ 0:00:48[0m [2;4m2.56it/s[0m  
[2KAttention weights: tensor([[0.6017, 0.3983]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 82/203 [2m0:00:32 â€¢ 0:00:48[0m [2;4m2.56it/s[0m  
[2KStep 0 - TTA Loss: 2.1896â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 82/203 [2m0:00:32 â€¢ 0:00:48[0m [2;4m2.56it/s[0m  
[2KAttention weights: tensor([[0.6204, 0.3796]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 82/203 [2m0:00:32 â€¢ 0:00:48[0m [2;4m2.56it/s[0m  
[2KAttention weights: tensor([[0.6356, 0.3644]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 82/203 [2m0:00:32 â€¢ 0:00:48[0m [2;4m2.56it/s[0m  
[2KAttention weights: tensor([[0.6503, 0.3497]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 82/203 [2m0:00:32 â€¢ 0:00:48[0m [2;4m2.56it/s[0m  
[2KAttention weights: tensor([[0.6621, 0.3379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 82/203 [2m0:00:32 â€¢ 0:00:48[0m [2;4m2.56it/s[0m  
[2KAttention weights: tensor([[0.6722, 0.3278]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 82/203 [2m0:00:32 â€¢ 0:00:48[0m [2;4m2.56it/s[0m  
[2KAttention weights: tensor([[0.6851, 0.3149]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 82/203 [2m0:00:32 â€¢ 0:00:48[0m [2;4m2.56it/s[0m  
[2KAttention weights: tensor([[0.6918, 0.3082]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 82/203 [2m0:00:32 â€¢ 0:00:48[0m [2;4m2.56it/s[0m  
[2KAttention weights: tensor([[0.6975, 0.3025]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 82/203 [2m0:00:32 â€¢ 0:00:48[0m [2;4m2.56it/s[0m  
[2KAttention weights: tensor([[0.7012, 0.2988]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 82/203 [2m0:00:32 â€¢ 0:00:48[0m [2;4m2.56it/s[0m  
[2KAttention weights: tensor([[0.5233, 0.4767]], device='cuda:0');237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 82/203 [2m0:00:32 â€¢ 0:00:48[0m [2;4m2.56it/s[0m  
[2KAttention weights: tensor([[0.6140, 0.3860],;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 82/203 [2m0:00:32 â€¢ 0:00:48[0m [2;4m2.56it/s[0m  
        [0.4611, 0.5389],
        [0.5036, 0.4964],
        [0.6262, 0.3738],
        [0.6133, 0.3867],
        [0.7234, 0.2766],
        [0.6713, 0.3287],
        [0.7025, 0.2975],
        [0.5546, 0.4454],
[2K        [0.6166, 0.3834]], device='cuda:0')8;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 82/203 [2m0:00:32 â€¢ 0:00:48[0m [2;4m2.56it/s[0m  
[2KAttention weights: tensor([[0.5216, 0.4784],[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 83/203 [2m0:00:32 â€¢ 0:00:47[0m [2;4m2.56it/s[0m  
        [0.5132, 0.4868],
        [0.5152, 0.4848],
        [0.5208, 0.4792],
        [0.5228, 0.4772],
        [0.5253, 0.4747],
        [0.5226, 0.4774],
        [0.5196, 0.4804],
        [0.5166, 0.4834],
[2K        [0.5230, 0.4770]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 83/203 [2m0:00:32 â€¢ 0:00:47[0m [2;4m2.56it/s[0m  
[2KClass label: HighJumpâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 83/203 [2m0:00:32 â€¢ 0:00:47[0m [2;4m2.56it/s[0m  
[2KAttention weights: tensor([[0.6868, 0.3132]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 83/203 [2m0:00:32 â€¢ 0:00:47[0m [2;4m2.56it/s[0m  
[2KStep 0 - TTA Loss: 2.9322â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 83/203 [2m0:00:32 â€¢ 0:00:47[0m [2;4m2.56it/s[0m  
[2KAttention weights: tensor([[0.6868, 0.3132]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 83/203 [2m0:00:32 â€¢ 0:00:47[0m [2;4m2.56it/s[0m  
[2KAttention weights: tensor([[0.6864, 0.3136]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 83/203 [2m0:00:32 â€¢ 0:00:47[0m [2;4m2.56it/s[0m  
[2KAttention weights: tensor([[0.6851, 0.3149]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 83/203 [2m0:00:32 â€¢ 0:00:47[0m [2;4m2.56it/s[0m  
[2KAttention weights: tensor([[0.6812, 0.3188]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 83/203 [2m0:00:32 â€¢ 0:00:47[0m [2;4m2.56it/s[0m  
[2KAttention weights: tensor([[0.6734, 0.3266]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 83/203 [2m0:00:32 â€¢ 0:00:47[0m [2;4m2.56it/s[0m  
[2KAttention weights: tensor([[0.6619, 0.3381]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 83/203 [2m0:00:32 â€¢ 0:00:47[0m [2;4m2.56it/s[0m  
[2KAttention weights: tensor([[0.6438, 0.3562]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 83/203 [2m0:00:32 â€¢ 0:00:47[0m [2;4m2.56it/s[0m  
[2KAttention weights: tensor([[0.6251, 0.3749]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 83/203 [2m0:00:32 â€¢ 0:00:47[0m [2;4m2.56it/s[0m  
[2KAttention weights: tensor([[0.6135, 0.3865]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 83/203 [2m0:00:32 â€¢ 0:00:47[0m [2;4m2.56it/s[0m  
[2KAttention weights: tensor([[0.5228, 0.4772]], device='cuda:0');237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 83/203 [2m0:00:32 â€¢ 0:00:47[0m [2;4m2.56it/s[0m  
[2KAttention weights: tensor([[0.5716, 0.4284],;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 83/203 [2m0:00:32 â€¢ 0:00:47[0m [2;4m2.56it/s[0m  
        [0.4540, 0.5460],
        [0.4772, 0.5228],
        [0.5965, 0.4035],
        [0.5421, 0.4579],
        [0.6081, 0.3919],
        [0.5862, 0.4138],
        [0.6709, 0.3291],
        [0.4974, 0.5026],
[2K        [0.5372, 0.4628]], device='cuda:0')8;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 83/203 [2m0:00:32 â€¢ 0:00:47[0m [2;4m2.56it/s[0m  
[2KAttention weights: tensor([[0.5217, 0.4783],[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 84/203 [2m0:00:33 â€¢ 0:00:47[0m [2;4m2.56it/s[0m  
        [0.5133, 0.4867],
        [0.5152, 0.4848],
        [0.5208, 0.4792],
        [0.5228, 0.4772],
        [0.5254, 0.4746],
        [0.5227, 0.4773],
        [0.5196, 0.4804],
        [0.5166, 0.4834],
[2K        [0.5230, 0.4770]], device='cuda:0', grad_fn=<SoftmaxBackward0>)mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 84/203 [2m0:00:33 â€¢ 0:00:47[0m [2;4m2.56it/s[0m  
[2KClass label: HighJumpâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 84/203 [2m0:00:33 â€¢ 0:00:47[0m [2;4m2.56it/s[0m  
[2KAttention weights: tensor([[0.6899, 0.3101]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 84/203 [2m0:00:33 â€¢ 0:00:47[0m [2;4m2.56it/s[0m  
[2KStep 0 - TTA Loss: 2.4299â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 84/203 [2m0:00:33 â€¢ 0:00:47[0m [2;4m2.56it/s[0m  
[2KAttention weights: tensor([[0.6984, 0.3016]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 84/203 [2m0:00:33 â€¢ 0:00:47[0m [2;4m2.56it/s[0m  
[2KAttention weights: tensor([[0.7140, 0.2860]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 84/203 [2m0:00:33 â€¢ 0:00:47[0m [2;4m2.56it/s[0m  
[2KAttention weights: tensor([[0.7339, 0.2661]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 84/203 [2m0:00:33 â€¢ 0:00:47[0m [2;4m2.56it/s[0m  
[2KAttention weights: tensor([[0.7494, 0.2506]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 84/203 [2m0:00:33 â€¢ 0:00:47[0m [2;4m2.56it/s[0m  
[2KAttention weights: tensor([[0.7622, 0.2378]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 84/203 [2m0:00:33 â€¢ 0:00:47[0m [2;4m2.56it/s[0m  
[2KAttention weights: tensor([[0.7700, 0.2300]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 84/203 [2m0:00:33 â€¢ 0:00:47[0m [2;4m2.56it/s[0m  
[2KAttention weights: tensor([[0.7745, 0.2255]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 84/203 [2m0:00:33 â€¢ 0:00:47[0m [2;4m2.56it/s[0m  
[2KAttention weights: tensor([[0.7766, 0.2234]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 84/203 [2m0:00:33 â€¢ 0:00:47[0m [2;4m2.56it/s[0m  
[2KAttention weights: tensor([[0.7773, 0.2227]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 84/203 [2m0:00:33 â€¢ 0:00:47[0m [2;4m2.56it/s[0m  
[2KAttention weights: tensor([[0.5274, 0.4726]], device='cuda:0')[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 84/203 [2m0:00:33 â€¢ 0:00:47[0m [2;4m2.56it/s[0m  
[2KAttention weights: tensor([[0.6311, 0.3689],;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 84/203 [2m0:00:33 â€¢ 0:00:47[0m [2;4m2.56it/s[0m  
        [0.4548, 0.5452],
        [0.5139, 0.4861],
        [0.6338, 0.3662],
        [0.6462, 0.3538],
        [0.7782, 0.2218],
        [0.7159, 0.2841],
        [0.7018, 0.2982],
        [0.5665, 0.4335],
[2K        [0.6511, 0.3489]], device='cuda:0')8;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 84/203 [2m0:00:33 â€¢ 0:00:47[0m [2;4m2.56it/s[0m  
[2KAttention weights: tensor([[0.5218, 0.4782],[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 85/203 [2m0:00:33 â€¢ 0:00:47[0m [2;4m2.56it/s[0m  
        [0.5133, 0.4867],
        [0.5153, 0.4847],
        [0.5209, 0.4791],
        [0.5229, 0.4771],
        [0.5255, 0.4745],
        [0.5228, 0.4772],
        [0.5197, 0.4803],
        [0.5167, 0.4833],
[2K        [0.5231, 0.4769]], device='cuda:0', grad_fn=<SoftmaxBackward0>)mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 85/203 [2m0:00:33 â€¢ 0:00:47[0m [2;4m2.56it/s[0m  
[2KClass label: TennisSwingâ”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 85/203 [2m0:00:33 â€¢ 0:00:47[0m [2;4m2.56it/s[0m  
[2KAttention weights: tensor([[0.5186, 0.4814]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 85/203 [2m0:00:33 â€¢ 0:00:47[0m [2;4m2.56it/s[0m  
[2KStep 0 - TTA Loss: 1.1543â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 85/203 [2m0:00:33 â€¢ 0:00:47[0m [2;4m2.56it/s[0m  
[2KAttention weights: tensor([[0.5186, 0.4814]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 85/203 [2m0:00:33 â€¢ 0:00:47[0m [2;4m2.56it/s[0m  
[2KAttention weights: tensor([[0.5186, 0.4814]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 85/203 [2m0:00:33 â€¢ 0:00:47[0m [2;4m2.56it/s[0m  
[2KAttention weights: tensor([[0.5179, 0.4821]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 85/203 [2m0:00:33 â€¢ 0:00:47[0m [2;4m2.56it/s[0m  
[2KAttention weights: tensor([[0.5158, 0.4842]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 85/203 [2m0:00:33 â€¢ 0:00:47[0m [2;4m2.56it/s[0m  
[2KAttention weights: tensor([[0.5129, 0.4871]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 85/203 [2m0:00:33 â€¢ 0:00:47[0m [2;4m2.56it/s[0m  
[2KAttention weights: tensor([[0.5074, 0.4926]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 85/203 [2m0:00:33 â€¢ 0:00:47[0m [2;4m2.56it/s[0m  
[2KAttention weights: tensor([[0.4993, 0.5007]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 85/203 [2m0:00:33 â€¢ 0:00:47[0m [2;4m2.56it/s[0m  
[2KAttention weights: tensor([[0.4904, 0.5096]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 85/203 [2m0:00:33 â€¢ 0:00:47[0m [2;4m2.56it/s[0m  
[2KAttention weights: tensor([[0.4794, 0.5206]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 85/203 [2m0:00:33 â€¢ 0:00:47[0m [2;4m2.56it/s[0m  
[2KAttention weights: tensor([[0.5155, 0.4845]], device='cuda:0')[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 85/203 [2m0:00:33 â€¢ 0:00:47[0m [2;4m2.56it/s[0m  
[2KAttention weights: tensor([[0.5954, 0.4046],;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 85/203 [2m0:00:33 â€¢ 0:00:47[0m [2;4m2.56it/s[0m  
        [0.4450, 0.5550],
        [0.4913, 0.5087],
        [0.5953, 0.4047],
        [0.5752, 0.4248],
        [0.6858, 0.3142],
        [0.6471, 0.3529],
        [0.6150, 0.3850],
        [0.4820, 0.5180],
[2K        [0.5792, 0.4208]], device='cuda:0')8;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 85/203 [2m0:00:33 â€¢ 0:00:47[0m [2;4m2.56it/s[0m  
[2KAttention weights: tensor([[0.5218, 0.4782],[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 86/203 [2m0:00:33 â€¢ 0:00:46[0m [2;4m2.56it/s[0m  
        [0.5133, 0.4867],
        [0.5153, 0.4847],
        [0.5209, 0.4791],
        [0.5230, 0.4770],
        [0.5256, 0.4744],
        [0.5228, 0.4772],
        [0.5198, 0.4802],
        [0.5167, 0.4833],
[2K        [0.5231, 0.4769]], device='cuda:0', grad_fn=<SoftmaxBackward0>)mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 86/203 [2m0:00:33 â€¢ 0:00:46[0m [2;4m2.56it/s[0m  
[2KClass label: HammerThrowâ”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 86/203 [2m0:00:33 â€¢ 0:00:46[0m [2;4m2.56it/s[0m  
[2KAttention weights: tensor([[0.5786, 0.4214]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 86/203 [2m0:00:33 â€¢ 0:00:46[0m [2;4m2.56it/s[0m  
[2KStep 0 - TTA Loss: 1.4084â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 86/203 [2m0:00:33 â€¢ 0:00:46[0m [2;4m2.56it/s[0m  
[2KAttention weights: tensor([[0.5858, 0.4142]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 86/203 [2m0:00:33 â€¢ 0:00:46[0m [2;4m2.56it/s[0m  
[2KAttention weights: tensor([[0.5960, 0.4040]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 86/203 [2m0:00:33 â€¢ 0:00:46[0m [2;4m2.56it/s[0m  
[2KAttention weights: tensor([[0.6077, 0.3923]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 86/203 [2m0:00:33 â€¢ 0:00:46[0m [2;4m2.56it/s[0m  
[2KAttention weights: tensor([[0.6151, 0.3849]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 86/203 [2m0:00:33 â€¢ 0:00:46[0m [2;4m2.56it/s[0m  
[2KAttention weights: tensor([[0.6218, 0.3782]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 86/203 [2m0:00:33 â€¢ 0:00:46[0m [2;4m2.56it/s[0m  
[2KAttention weights: tensor([[0.6269, 0.3731]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 86/203 [2m0:00:33 â€¢ 0:00:46[0m [2;4m2.56it/s[0m  
[2KAttention weights: tensor([[0.6302, 0.3698]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 86/203 [2m0:00:33 â€¢ 0:00:46[0m [2;4m2.56it/s[0m  
[2KAttention weights: tensor([[0.6328, 0.3672]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 86/203 [2m0:00:33 â€¢ 0:00:46[0m [2;4m2.56it/s[0m  
[2KAttention weights: tensor([[0.6342, 0.3658]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 86/203 [2m0:00:33 â€¢ 0:00:46[0m [2;4m2.56it/s[0m  
[2KAttention weights: tensor([[0.5253, 0.4747]], device='cuda:0')[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 86/203 [2m0:00:33 â€¢ 0:00:46[0m [2;4m2.56it/s[0m  
[2KAttention weights: tensor([[0.6277, 0.3723],;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 86/203 [2m0:00:33 â€¢ 0:00:46[0m [2;4m2.56it/s[0m  
        [0.4502, 0.5498],
        [0.5078, 0.4922],
        [0.6271, 0.3729],
        [0.6350, 0.3650],
        [0.7225, 0.2775],
        [0.6735, 0.3265],
        [0.6324, 0.3676],
        [0.5426, 0.4574],
[2K        [0.6300, 0.3700]], device='cuda:0')8;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 86/203 [2m0:00:33 â€¢ 0:00:46[0m [2;4m2.56it/s[0m  
[2KAttention weights: tensor([[0.5218, 0.4782],m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 87/203 [2m0:00:34 â€¢ 0:00:46[0m [2;4m2.56it/s[0m   
        [0.5133, 0.4867],
        [0.5153, 0.4847],
        [0.5209, 0.4791],
        [0.5230, 0.4770],
        [0.5256, 0.4744],
        [0.5228, 0.4772],
        [0.5198, 0.4802],
        [0.5167, 0.4833],
[2K        [0.5231, 0.4769]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 87/203 [2m0:00:34 â€¢ 0:00:46[0m [2;4m2.56it/s[0m  
[2KClass label: SoccerPenaltyâ”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 87/203 [2m0:00:34 â€¢ 0:00:46[0m [2;4m2.56it/s[0m  
[2KAttention weights: tensor([[0.6090, 0.3910]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 87/203 [2m0:00:34 â€¢ 0:00:46[0m [2;4m2.56it/s[0m  
[2KStep 0 - TTA Loss: 1.3962â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 87/203 [2m0:00:34 â€¢ 0:00:46[0m [2;4m2.56it/s[0m  
[2KAttention weights: tensor([[0.6090, 0.3910]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 87/203 [2m0:00:34 â€¢ 0:00:46[0m [2;4m2.56it/s[0m  
[2KAttention weights: tensor([[0.6087, 0.3913]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 87/203 [2m0:00:34 â€¢ 0:00:46[0m [2;4m2.56it/s[0m  
[2KAttention weights: tensor([[0.6072, 0.3928]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 87/203 [2m0:00:34 â€¢ 0:00:46[0m [2;4m2.56it/s[0m  
[2KAttention weights: tensor([[0.6028, 0.3972]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 87/203 [2m0:00:34 â€¢ 0:00:46[0m [2;4m2.56it/s[0m  
[2KAttention weights: tensor([[0.5945, 0.4055]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 87/203 [2m0:00:34 â€¢ 0:00:46[0m [2;4m2.56it/s[0m  
[2KAttention weights: tensor([[0.5829, 0.4171]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 87/203 [2m0:00:34 â€¢ 0:00:46[0m [2;4m2.56it/s[0m  
[2KAttention weights: tensor([[0.5650, 0.4350]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 87/203 [2m0:00:34 â€¢ 0:00:46[0m [2;4m2.56it/s[0m  
[2KAttention weights: tensor([[0.5465, 0.4535]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 87/203 [2m0:00:34 â€¢ 0:00:46[0m [2;4m2.56it/s[0m  
[2KAttention weights: tensor([[0.5272, 0.4728]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 87/203 [2m0:00:34 â€¢ 0:00:46[0m [2;4m2.56it/s[0m  
[2KAttention weights: tensor([[0.5165, 0.4835]], device='cuda:0')5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 87/203 [2m0:00:34 â€¢ 0:00:46[0m [2;4m2.56it/s[0m  
[2KAttention weights: tensor([[0.6171, 0.3829],8;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 87/203 [2m0:00:34 â€¢ 0:00:46[0m [2;4m2.56it/s[0m  
        [0.4347, 0.5653],
        [0.4991, 0.5009],
        [0.5989, 0.4011],
        [0.5941, 0.4059],
        [0.6798, 0.3202],
        [0.6367, 0.3633],
        [0.5078, 0.4922],
        [0.5084, 0.4916],
[2K        [0.5990, 0.4010]], device='cuda:0')38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 87/203 [2m0:00:34 â€¢ 0:00:46[0m [2;4m2.56it/s[0m  
[2KAttention weights: tensor([[0.5218, 0.4782],m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 88/203 [2m0:00:34 â€¢ 0:00:45[0m [2;4m2.56it/s[0m  
        [0.5133, 0.4867],
        [0.5153, 0.4847],
        [0.5209, 0.4791],
        [0.5229, 0.4771],
        [0.5256, 0.4744],
        [0.5228, 0.4772],
        [0.5197, 0.4803],
        [0.5167, 0.4833],
[2K        [0.5231, 0.4769]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 88/203 [2m0:00:34 â€¢ 0:00:45[0m [2;4m2.56it/s[0m  
[2KClass label: CleanAndJerkâ”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 88/203 [2m0:00:34 â€¢ 0:00:45[0m [2;4m2.56it/s[0m  
[2KAttention weights: tensor([[0.4946, 0.5054]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 88/203 [2m0:00:34 â€¢ 0:00:45[0m [2;4m2.56it/s[0m  
[2KStep 0 - TTA Loss: 1.0433â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 88/203 [2m0:00:34 â€¢ 0:00:45[0m [2;4m2.56it/s[0m  
[2KAttention weights: tensor([[0.4898, 0.5102]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 88/203 [2m0:00:34 â€¢ 0:00:45[0m [2;4m2.56it/s[0m  
[2KAttention weights: tensor([[0.4773, 0.5227]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 88/203 [2m0:00:34 â€¢ 0:00:45[0m [2;4m2.56it/s[0m  
[2KAttention weights: tensor([[0.4735, 0.5265]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 88/203 [2m0:00:34 â€¢ 0:00:45[0m [2;4m2.56it/s[0m  
[2KAttention weights: tensor([[0.4795, 0.5205]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 88/203 [2m0:00:34 â€¢ 0:00:45[0m [2;4m2.56it/s[0m  
[2KAttention weights: tensor([[0.4912, 0.5088]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 88/203 [2m0:00:34 â€¢ 0:00:45[0m [2;4m2.56it/s[0m  
[2KAttention weights: tensor([[0.5008, 0.4992]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 88/203 [2m0:00:34 â€¢ 0:00:45[0m [2;4m2.56it/s[0m  
[2KAttention weights: tensor([[0.5044, 0.4956]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 88/203 [2m0:00:34 â€¢ 0:00:45[0m [2;4m2.56it/s[0m  
[2KAttention weights: tensor([[0.5059, 0.4941]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 88/203 [2m0:00:34 â€¢ 0:00:45[0m [2;4m2.56it/s[0m  
[2KAttention weights: tensor([[0.5073, 0.4927]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 88/203 [2m0:00:34 â€¢ 0:00:45[0m [2;4m2.56it/s[0m  
[2KAttention weights: tensor([[0.5157, 0.4843]], device='cuda:0')5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 88/203 [2m0:00:34 â€¢ 0:00:45[0m [2;4m2.56it/s[0m  
[2KAttention weights: tensor([[0.6155, 0.3845],8;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 88/203 [2m0:00:34 â€¢ 0:00:45[0m [2;4m2.56it/s[0m  
        [0.4419, 0.5581],
        [0.5079, 0.4921],
        [0.6054, 0.3946],
        [0.5939, 0.4061],
        [0.6838, 0.3162],
        [0.6403, 0.3597],
        [0.5335, 0.4665],
        [0.5107, 0.4893],
[2K        [0.5988, 0.4012]], device='cuda:0')38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 88/203 [2m0:00:34 â€¢ 0:00:45[0m [2;4m2.56it/s[0m  
[2KAttention weights: tensor([[0.5218, 0.4782],m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 89/203 [2m0:00:35 â€¢ 0:00:45[0m [2;4m2.55it/s[0m  
        [0.5133, 0.4867],
        [0.5153, 0.4847],
        [0.5209, 0.4791],
        [0.5229, 0.4771],
        [0.5255, 0.4745],
        [0.5228, 0.4772],
        [0.5197, 0.4803],
        [0.5167, 0.4833],
[2K        [0.5231, 0.4769]], device='cuda:0', grad_fn=<SoftmaxBackward0>)7mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 89/203 [2m0:00:35 â€¢ 0:00:45[0m [2;4m2.55it/s[0m  
[2KClass label: ThrowDiscusâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 89/203 [2m0:00:35 â€¢ 0:00:45[0m [2;4m2.55it/s[0m  
[2KAttention weights: tensor([[0.5849, 0.4151]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 89/203 [2m0:00:35 â€¢ 0:00:45[0m [2;4m2.55it/s[0m  
[2KStep 0 - TTA Loss: 1.3890â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 89/203 [2m0:00:35 â€¢ 0:00:45[0m [2;4m2.55it/s[0m  
[2KAttention weights: tensor([[0.5849, 0.4151]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 89/203 [2m0:00:35 â€¢ 0:00:45[0m [2;4m2.55it/s[0m  
[2KAttention weights: tensor([[0.5855, 0.4145]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 89/203 [2m0:00:35 â€¢ 0:00:45[0m [2;4m2.55it/s[0m  
[2KAttention weights: tensor([[0.5886, 0.4114]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 89/203 [2m0:00:35 â€¢ 0:00:45[0m [2;4m2.55it/s[0m  
[2KAttention weights: tensor([[0.5976, 0.4024]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 89/203 [2m0:00:35 â€¢ 0:00:45[0m [2;4m2.55it/s[0m  
[2KAttention weights: tensor([[0.6160, 0.3840]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 89/203 [2m0:00:35 â€¢ 0:00:45[0m [2;4m2.55it/s[0m  
[2KAttention weights: tensor([[0.6404, 0.3596]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 89/203 [2m0:00:35 â€¢ 0:00:45[0m [2;4m2.55it/s[0m  
[2KAttention weights: tensor([[0.6738, 0.3262]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 89/203 [2m0:00:35 â€¢ 0:00:45[0m [2;4m2.55it/s[0m  
[2KAttention weights: tensor([[0.7091, 0.2909]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 89/203 [2m0:00:35 â€¢ 0:00:45[0m [2;4m2.55it/s[0m  
[2KAttention weights: tensor([[0.7327, 0.2673]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 89/203 [2m0:00:35 â€¢ 0:00:45[0m [2;4m2.55it/s[0m  
[2KAttention weights: tensor([[0.5277, 0.4723]], device='cuda:0')[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 89/203 [2m0:00:35 â€¢ 0:00:45[0m [2;4m2.55it/s[0m  
[2KAttention weights: tensor([[0.6991, 0.3009],8;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 89/203 [2m0:00:35 â€¢ 0:00:45[0m [2;4m2.55it/s[0m  
        [0.4517, 0.5483],
        [0.5961, 0.4039],
        [0.6894, 0.3106],
        [0.7203, 0.2797],
        [0.7849, 0.2151],
        [0.7420, 0.2580],
        [0.6296, 0.3704],
        [0.5946, 0.4054],
[2K        [0.7637, 0.2363]], device='cuda:0')38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 89/203 [2m0:00:35 â€¢ 0:00:45[0m [2;4m2.55it/s[0m  
[2KAttention weights: tensor([[0.5217, 0.4783],m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 90/203 [2m0:00:35 â€¢ 0:00:45[0m [2;4m2.54it/s[0m  
        [0.5133, 0.4867],
        [0.5152, 0.4848],
        [0.5208, 0.4792],
        [0.5228, 0.4772],
        [0.5255, 0.4745],
        [0.5228, 0.4772],
        [0.5197, 0.4803],
        [0.5166, 0.4834],
[2K        [0.5230, 0.4770]], device='cuda:0', grad_fn=<SoftmaxBackward0>)7mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 90/203 [2m0:00:35 â€¢ 0:00:45[0m [2;4m2.54it/s[0m  
[2KClass label: HammerThrowâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 90/203 [2m0:00:35 â€¢ 0:00:45[0m [2;4m2.54it/s[0m  
[2KAttention weights: tensor([[0.5783, 0.4217]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 90/203 [2m0:00:35 â€¢ 0:00:45[0m [2;4m2.54it/s[0m  
[2KStep 0 - TTA Loss: 1.2770â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 90/203 [2m0:00:35 â€¢ 0:00:45[0m [2;4m2.54it/s[0m  
[2KAttention weights: tensor([[0.6061, 0.3939]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 90/203 [2m0:00:35 â€¢ 0:00:45[0m [2;4m2.54it/s[0m  
[2KAttention weights: tensor([[0.6298, 0.3702]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 90/203 [2m0:00:35 â€¢ 0:00:45[0m [2;4m2.54it/s[0m  
[2KAttention weights: tensor([[0.6494, 0.3506]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 90/203 [2m0:00:35 â€¢ 0:00:45[0m [2;4m2.54it/s[0m  
[2KAttention weights: tensor([[0.6649, 0.3351]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 90/203 [2m0:00:35 â€¢ 0:00:45[0m [2;4m2.54it/s[0m  
[2KAttention weights: tensor([[0.6768, 0.3232]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 90/203 [2m0:00:35 â€¢ 0:00:45[0m [2;4m2.54it/s[0m  
[2KAttention weights: tensor([[0.6856, 0.3144]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 90/203 [2m0:00:35 â€¢ 0:00:45[0m [2;4m2.54it/s[0m  
[2KAttention weights: tensor([[0.6909, 0.3091]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 90/203 [2m0:00:35 â€¢ 0:00:45[0m [2;4m2.54it/s[0m  
[2KAttention weights: tensor([[0.6936, 0.3064]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 90/203 [2m0:00:35 â€¢ 0:00:45[0m [2;4m2.54it/s[0m  
[2KAttention weights: tensor([[0.6947, 0.3053]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 90/203 [2m0:00:35 â€¢ 0:00:45[0m [2;4m2.54it/s[0m  
[2KAttention weights: tensor([[0.5266, 0.4734]], device='cuda:0')[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 90/203 [2m0:00:35 â€¢ 0:00:45[0m [2;4m2.54it/s[0m  
[2KAttention weights: tensor([[0.6781, 0.3219],8;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 90/203 [2m0:00:35 â€¢ 0:00:45[0m [2;4m2.54it/s[0m  
        [0.4533, 0.5467],
        [0.5667, 0.4333],
        [0.6705, 0.3295],
        [0.6954, 0.3046],
        [0.7663, 0.2337],
        [0.7237, 0.2763],
        [0.6205, 0.3795],
        [0.5748, 0.4252],
[2K        [0.7303, 0.2697]], device='cuda:0')38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 90/203 [2m0:00:35 â€¢ 0:00:45[0m [2;4m2.54it/s[0m  
[2KAttention weights: tensor([[0.5217, 0.4783],m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 91/203 [2m0:00:35 â€¢ 0:00:45[0m [2;4m2.54it/s[0m  
        [0.5133, 0.4867],
        [0.5152, 0.4848],
        [0.5208, 0.4792],
        [0.5228, 0.4772],
        [0.5255, 0.4745],
        [0.5227, 0.4773],
        [0.5197, 0.4803],
        [0.5166, 0.4834],
[2K        [0.5229, 0.4771]], device='cuda:0', grad_fn=<SoftmaxBackward0>)7mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 91/203 [2m0:00:35 â€¢ 0:00:45[0m [2;4m2.54it/s[0m  
[2KClass label: SoccerPenaltyâ”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 91/203 [2m0:00:35 â€¢ 0:00:45[0m [2;4m2.54it/s[0m  
[2KAttention weights: tensor([[0.6049, 0.3951]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 91/203 [2m0:00:35 â€¢ 0:00:45[0m [2;4m2.54it/s[0m  
[2KStep 0 - TTA Loss: 1.3714â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 91/203 [2m0:00:35 â€¢ 0:00:45[0m [2;4m2.54it/s[0m  
[2KAttention weights: tensor([[0.6049, 0.3951]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 91/203 [2m0:00:35 â€¢ 0:00:45[0m [2;4m2.54it/s[0m  
[2KAttention weights: tensor([[0.6048, 0.3952]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 91/203 [2m0:00:35 â€¢ 0:00:45[0m [2;4m2.54it/s[0m  
[2KAttention weights: tensor([[0.6040, 0.3960]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 91/203 [2m0:00:35 â€¢ 0:00:45[0m [2;4m2.54it/s[0m  
[2KAttention weights: tensor([[0.6022, 0.3978]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 91/203 [2m0:00:35 â€¢ 0:00:45[0m [2;4m2.54it/s[0m  
[2KAttention weights: tensor([[0.5982, 0.4018]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 91/203 [2m0:00:35 â€¢ 0:00:45[0m [2;4m2.54it/s[0m  
[2KAttention weights: tensor([[0.5885, 0.4115]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 91/203 [2m0:00:35 â€¢ 0:00:45[0m [2;4m2.54it/s[0m  
[2KAttention weights: tensor([[0.5778, 0.4222]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 91/203 [2m0:00:35 â€¢ 0:00:45[0m [2;4m2.54it/s[0m  
[2KAttention weights: tensor([[0.5641, 0.4359]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 91/203 [2m0:00:35 â€¢ 0:00:45[0m [2;4m2.54it/s[0m  
[2KAttention weights: tensor([[0.5520, 0.4480]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 91/203 [2m0:00:35 â€¢ 0:00:45[0m [2;4m2.54it/s[0m  
[2KAttention weights: tensor([[0.5174, 0.4826]], device='cuda:0')[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 91/203 [2m0:00:35 â€¢ 0:00:45[0m [2;4m2.54it/s[0m  
[2KAttention weights: tensor([[0.6193, 0.3807],8;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 91/203 [2m0:00:35 â€¢ 0:00:45[0m [2;4m2.54it/s[0m  
        [0.4394, 0.5606],
        [0.5087, 0.4913],
        [0.6128, 0.3872],
        [0.5890, 0.4110],
        [0.6917, 0.3083],
        [0.6502, 0.3498],
        [0.5410, 0.4590],
        [0.5171, 0.4829],
[2K        [0.6080, 0.3920]], device='cuda:0')38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 91/203 [2m0:00:35 â€¢ 0:00:45[0m [2;4m2.54it/s[0m  
[2KAttention weights: tensor([[0.5217, 0.4783],0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 92/203 [2m0:00:36 â€¢ 0:00:44[0m [2;4m2.54it/s[0m   
        [0.5133, 0.4867],
        [0.5152, 0.4848],
        [0.5208, 0.4792],
        [0.5228, 0.4772],
        [0.5255, 0.4745],
        [0.5227, 0.4773],
        [0.5197, 0.4803],
        [0.5166, 0.4834],
[2K        [0.5229, 0.4771]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 92/203 [2m0:00:36 â€¢ 0:00:44[0m [2;4m2.54it/s[0m  
[2KClass label: BaseballPitchâ”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 92/203 [2m0:00:36 â€¢ 0:00:44[0m [2;4m2.54it/s[0m  
[2KAttention weights: tensor([[0.6012, 0.3988]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 92/203 [2m0:00:36 â€¢ 0:00:44[0m [2;4m2.54it/s[0m  
[2KStep 0 - TTA Loss: 1.6401â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 92/203 [2m0:00:36 â€¢ 0:00:44[0m [2;4m2.54it/s[0m  
[2KAttention weights: tensor([[0.6046, 0.3954]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 92/203 [2m0:00:36 â€¢ 0:00:44[0m [2;4m2.54it/s[0m  
[2KAttention weights: tensor([[0.6021, 0.3979]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 92/203 [2m0:00:36 â€¢ 0:00:44[0m [2;4m2.54it/s[0m  
[2KAttention weights: tensor([[0.5995, 0.4005]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 92/203 [2m0:00:36 â€¢ 0:00:44[0m [2;4m2.54it/s[0m  
[2KAttention weights: tensor([[0.5990, 0.4010]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 92/203 [2m0:00:36 â€¢ 0:00:44[0m [2;4m2.54it/s[0m  
[2KAttention weights: tensor([[0.5989, 0.4011]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 92/203 [2m0:00:36 â€¢ 0:00:44[0m [2;4m2.54it/s[0m  
[2KAttention weights: tensor([[0.5982, 0.4018]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 92/203 [2m0:00:36 â€¢ 0:00:44[0m [2;4m2.54it/s[0m  
[2KAttention weights: tensor([[0.5991, 0.4009]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 92/203 [2m0:00:36 â€¢ 0:00:44[0m [2;4m2.54it/s[0m  
[2KAttention weights: tensor([[0.5989, 0.4011]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 92/203 [2m0:00:36 â€¢ 0:00:44[0m [2;4m2.54it/s[0m  
[2KAttention weights: tensor([[0.5990, 0.4010]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 92/203 [2m0:00:36 â€¢ 0:00:44[0m [2;4m2.54it/s[0m  
[2KAttention weights: tensor([[0.5222, 0.4778]], device='cuda:0');5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 92/203 [2m0:00:36 â€¢ 0:00:44[0m [2;4m2.54it/s[0m  
[2KAttention weights: tensor([[0.5993, 0.4007],38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 92/203 [2m0:00:36 â€¢ 0:00:44[0m [2;4m2.54it/s[0m  
        [0.4406, 0.5594],
        [0.5018, 0.4982],
        [0.6051, 0.3949],
        [0.5790, 0.4210],
        [0.6851, 0.3149],
        [0.6440, 0.3560],
        [0.5635, 0.4365],
        [0.5140, 0.4860],
[2K        [0.5937, 0.4063]], device='cuda:0')[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 92/203 [2m0:00:36 â€¢ 0:00:44[0m [2;4m2.54it/s[0m  
[2KAttention weights: tensor([[0.5217, 0.4783],0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 93/203 [2m0:00:36 â€¢ 0:00:44[0m [2;4m2.53it/s[0m  
        [0.5133, 0.4867],
        [0.5152, 0.4848],
        [0.5208, 0.4792],
        [0.5228, 0.4772],
        [0.5255, 0.4745],
        [0.5227, 0.4773],
        [0.5197, 0.4803],
        [0.5166, 0.4834],
[2K        [0.5229, 0.4771]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 93/203 [2m0:00:36 â€¢ 0:00:44[0m [2;4m2.53it/s[0m  
[2KClass label: SoccerPenaltyâ”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 93/203 [2m0:00:36 â€¢ 0:00:44[0m [2;4m2.53it/s[0m  
[2KAttention weights: tensor([[0.6055, 0.3945]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 93/203 [2m0:00:36 â€¢ 0:00:44[0m [2;4m2.53it/s[0m  
[2KStep 0 - TTA Loss: 1.2791â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 93/203 [2m0:00:36 â€¢ 0:00:44[0m [2;4m2.53it/s[0m  
[2KAttention weights: tensor([[0.6055, 0.3945]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 93/203 [2m0:00:36 â€¢ 0:00:44[0m [2;4m2.53it/s[0m  
[2KAttention weights: tensor([[0.6054, 0.3946]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 93/203 [2m0:00:36 â€¢ 0:00:44[0m [2;4m2.53it/s[0m  
[2KAttention weights: tensor([[0.6053, 0.3947]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 93/203 [2m0:00:36 â€¢ 0:00:44[0m [2;4m2.53it/s[0m  
[2KAttention weights: tensor([[0.6060, 0.3940]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 93/203 [2m0:00:36 â€¢ 0:00:44[0m [2;4m2.53it/s[0m  
[2KAttention weights: tensor([[0.6067, 0.3933]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 93/203 [2m0:00:36 â€¢ 0:00:44[0m [2;4m2.53it/s[0m  
[2KAttention weights: tensor([[0.6070, 0.3930]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 93/203 [2m0:00:36 â€¢ 0:00:44[0m [2;4m2.53it/s[0m  
[2KAttention weights: tensor([[0.6083, 0.3917]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 93/203 [2m0:00:36 â€¢ 0:00:44[0m [2;4m2.53it/s[0m  
[2KAttention weights: tensor([[0.6103, 0.3897]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 93/203 [2m0:00:36 â€¢ 0:00:44[0m [2;4m2.53it/s[0m  
[2KAttention weights: tensor([[0.6096, 0.3904]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 93/203 [2m0:00:36 â€¢ 0:00:44[0m [2;4m2.53it/s[0m  
[2KAttention weights: tensor([[0.5199, 0.4801]], device='cuda:0');5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 93/203 [2m0:00:36 â€¢ 0:00:44[0m [2;4m2.53it/s[0m  
[2KAttention weights: tensor([[0.6051, 0.3949],38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 93/203 [2m0:00:36 â€¢ 0:00:44[0m [2;4m2.53it/s[0m  
        [0.4488, 0.5512],
        [0.5009, 0.4991],
        [0.6094, 0.3906],
        [0.5899, 0.4101],
        [0.6958, 0.3042],
        [0.6501, 0.3499],
        [0.6168, 0.3832],
        [0.5231, 0.4769],
[2K        [0.5947, 0.4053]], device='cuda:0')[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 93/203 [2m0:00:36 â€¢ 0:00:44[0m [2;4m2.53it/s[0m  
[2KAttention weights: tensor([[0.5217, 0.4783],0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 94/203 [2m0:00:36 â€¢ 0:00:44[0m [2;4m2.53it/s[0m  
        [0.5133, 0.4867],
        [0.5152, 0.4848],
        [0.5208, 0.4792],
        [0.5228, 0.4772],
        [0.5255, 0.4745],
        [0.5227, 0.4773],
        [0.5197, 0.4803],
        [0.5166, 0.4834],
[2K        [0.5229, 0.4771]], device='cuda:0', grad_fn=<SoftmaxBackward0>)37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 94/203 [2m0:00:36 â€¢ 0:00:44[0m [2;4m2.53it/s[0m  
[2KClass label: SoccerPenaltyâ”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 94/203 [2m0:00:36 â€¢ 0:00:44[0m [2;4m2.53it/s[0m  
[2KAttention weights: tensor([[0.6024, 0.3976]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 94/203 [2m0:00:36 â€¢ 0:00:44[0m [2;4m2.53it/s[0m  
[2KStep 0 - TTA Loss: 1.1741â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 94/203 [2m0:00:36 â€¢ 0:00:44[0m [2;4m2.53it/s[0m  
[2KAttention weights: tensor([[0.6054, 0.3946]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 94/203 [2m0:00:36 â€¢ 0:00:44[0m [2;4m2.53it/s[0m  
[2KAttention weights: tensor([[0.6039, 0.3961]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 94/203 [2m0:00:36 â€¢ 0:00:44[0m [2;4m2.53it/s[0m  
[2KAttention weights: tensor([[0.5968, 0.4032]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 94/203 [2m0:00:36 â€¢ 0:00:44[0m [2;4m2.53it/s[0m  
[2KAttention weights: tensor([[0.5959, 0.4041]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 94/203 [2m0:00:36 â€¢ 0:00:44[0m [2;4m2.53it/s[0m  
[2KAttention weights: tensor([[0.5974, 0.4026]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 94/203 [2m0:00:36 â€¢ 0:00:44[0m [2;4m2.53it/s[0m  
[2KAttention weights: tensor([[0.5967, 0.4033]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 94/203 [2m0:00:36 â€¢ 0:00:44[0m [2;4m2.53it/s[0m  
[2KAttention weights: tensor([[0.5939, 0.4061]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 94/203 [2m0:00:36 â€¢ 0:00:44[0m [2;4m2.53it/s[0m  
[2KAttention weights: tensor([[0.5923, 0.4077]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 94/203 [2m0:00:36 â€¢ 0:00:44[0m [2;4m2.53it/s[0m  
[2KAttention weights: tensor([[0.5925, 0.4075]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 94/203 [2m0:00:36 â€¢ 0:00:44[0m [2;4m2.53it/s[0m  
[2KAttention weights: tensor([[0.5191, 0.4809]], device='cuda:0')m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 94/203 [2m0:00:36 â€¢ 0:00:44[0m [2;4m2.53it/s[0m  
[2KAttention weights: tensor([[0.6037, 0.3963],38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 94/203 [2m0:00:36 â€¢ 0:00:44[0m [2;4m2.53it/s[0m  
        [0.4481, 0.5519],
        [0.4955, 0.5045],
        [0.6049, 0.3951],
        [0.5806, 0.4194],
        [0.6900, 0.3100],
        [0.6445, 0.3555],
        [0.5925, 0.4075],
        [0.5186, 0.4814],
[2K        [0.5900, 0.4100]], device='cuda:0')[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 94/203 [2m0:00:36 â€¢ 0:00:44[0m [2;4m2.53it/s[0m  
[2KAttention weights: tensor([[0.5217, 0.4783],0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 95/203 [2m0:00:37 â€¢ 0:00:43[0m [2;4m2.53it/s[0m  
        [0.5133, 0.4867],
        [0.5152, 0.4848],
        [0.5208, 0.4792],
        [0.5228, 0.4772],
        [0.5255, 0.4745],
        [0.5228, 0.4772],
        [0.5197, 0.4803],
        [0.5166, 0.4834],
[2K        [0.5229, 0.4771]], device='cuda:0', grad_fn=<SoftmaxBackward0>)37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 95/203 [2m0:00:37 â€¢ 0:00:43[0m [2;4m2.53it/s[0m  
[2KClass label: HammerThrowâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 95/203 [2m0:00:37 â€¢ 0:00:43[0m [2;4m2.53it/s[0m  
[2KAttention weights: tensor([[0.5811, 0.4189]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 95/203 [2m0:00:37 â€¢ 0:00:43[0m [2;4m2.53it/s[0m  
[2KStep 0 - TTA Loss: 1.3461â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 95/203 [2m0:00:37 â€¢ 0:00:43[0m [2;4m2.53it/s[0m  
[2KAttention weights: tensor([[0.5811, 0.4189]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 95/203 [2m0:00:37 â€¢ 0:00:43[0m [2;4m2.53it/s[0m  
[2KAttention weights: tensor([[0.5818, 0.4182]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 95/203 [2m0:00:37 â€¢ 0:00:43[0m [2;4m2.53it/s[0m  
[2KAttention weights: tensor([[0.5846, 0.4154]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 95/203 [2m0:00:37 â€¢ 0:00:43[0m [2;4m2.53it/s[0m  
[2KAttention weights: tensor([[0.5925, 0.4075]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 95/203 [2m0:00:37 â€¢ 0:00:43[0m [2;4m2.53it/s[0m  
[2KAttention weights: tensor([[0.6021, 0.3979]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 95/203 [2m0:00:37 â€¢ 0:00:43[0m [2;4m2.53it/s[0m  
[2KAttention weights: tensor([[0.6197, 0.3803]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 95/203 [2m0:00:37 â€¢ 0:00:43[0m [2;4m2.53it/s[0m  
[2KAttention weights: tensor([[0.6391, 0.3609]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 95/203 [2m0:00:37 â€¢ 0:00:43[0m [2;4m2.53it/s[0m  
[2KAttention weights: tensor([[0.6667, 0.3333]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 95/203 [2m0:00:37 â€¢ 0:00:43[0m [2;4m2.53it/s[0m  
[2KAttention weights: tensor([[0.6942, 0.3058]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 95/203 [2m0:00:37 â€¢ 0:00:43[0m [2;4m2.53it/s[0m  
[2KAttention weights: tensor([[0.5274, 0.4726]], device='cuda:0')m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 95/203 [2m0:00:37 â€¢ 0:00:43[0m [2;4m2.53it/s[0m  
[2KAttention weights: tensor([[0.6757, 0.3243],38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 95/203 [2m0:00:37 â€¢ 0:00:43[0m [2;4m2.53it/s[0m  
        [0.4562, 0.5438],
        [0.5338, 0.4662],
        [0.6657, 0.3343],
        [0.7253, 0.2747],
        [0.7642, 0.2358],
        [0.7166, 0.2834],
        [0.6487, 0.3513],
        [0.5596, 0.4404],
[2K        [0.7017, 0.2983]], device='cuda:0')[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 95/203 [2m0:00:37 â€¢ 0:00:43[0m [2;4m2.53it/s[0m  
[2KAttention weights: tensor([[0.5217, 0.4783],0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 96/203 [2m0:00:37 â€¢ 0:00:43[0m [2;4m2.53it/s[0m  
        [0.5133, 0.4867],
        [0.5152, 0.4848],
        [0.5208, 0.4792],
        [0.5228, 0.4772],
        [0.5255, 0.4745],
        [0.5227, 0.4773],
        [0.5197, 0.4803],
        [0.5166, 0.4834],
[2K        [0.5229, 0.4771]], device='cuda:0', grad_fn=<SoftmaxBackward0>)37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 96/203 [2m0:00:37 â€¢ 0:00:43[0m [2;4m2.53it/s[0m  
[2KClass label: PoleVaultâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 96/203 [2m0:00:37 â€¢ 0:00:43[0m [2;4m2.53it/s[0m  
[2KAttention weights: tensor([[0.6439, 0.3561]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 96/203 [2m0:00:37 â€¢ 0:00:43[0m [2;4m2.53it/s[0m  
[2KStep 0 - TTA Loss: 2.0157â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 96/203 [2m0:00:37 â€¢ 0:00:43[0m [2;4m2.53it/s[0m  
[2KAttention weights: tensor([[0.6611, 0.3389]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 96/203 [2m0:00:37 â€¢ 0:00:43[0m [2;4m2.53it/s[0m  
[2KAttention weights: tensor([[0.6826, 0.3174]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 96/203 [2m0:00:37 â€¢ 0:00:43[0m [2;4m2.53it/s[0m  
[2KAttention weights: tensor([[0.7004, 0.2996]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 96/203 [2m0:00:37 â€¢ 0:00:43[0m [2;4m2.53it/s[0m  
[2KAttention weights: tensor([[0.7182, 0.2818]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 96/203 [2m0:00:37 â€¢ 0:00:43[0m [2;4m2.53it/s[0m  
[2KAttention weights: tensor([[0.7343, 0.2657]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 96/203 [2m0:00:37 â€¢ 0:00:43[0m [2;4m2.53it/s[0m  
[2KAttention weights: tensor([[0.7435, 0.2565]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 96/203 [2m0:00:37 â€¢ 0:00:43[0m [2;4m2.53it/s[0m  
[2KAttention weights: tensor([[0.7502, 0.2498]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 96/203 [2m0:00:37 â€¢ 0:00:43[0m [2;4m2.53it/s[0m  
[2KAttention weights: tensor([[0.7545, 0.2455]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 96/203 [2m0:00:37 â€¢ 0:00:43[0m [2;4m2.53it/s[0m  
[2KAttention weights: tensor([[0.7565, 0.2435]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 96/203 [2m0:00:37 â€¢ 0:00:43[0m [2;4m2.53it/s[0m  
[2KAttention weights: tensor([[0.5269, 0.4731]], device='cuda:0')m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 96/203 [2m0:00:37 â€¢ 0:00:43[0m [2;4m2.53it/s[0m  
[2KAttention weights: tensor([[0.6830, 0.3170],38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 96/203 [2m0:00:37 â€¢ 0:00:43[0m [2;4m2.53it/s[0m  
        [0.4531, 0.5469],
        [0.5353, 0.4647],
        [0.6755, 0.3245],
        [0.7358, 0.2642],
        [0.7847, 0.2153],
        [0.7577, 0.2423],
        [0.6599, 0.3401],
        [0.5696, 0.4304],
[2K        [0.7175, 0.2825]], device='cuda:0')[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 96/203 [2m0:00:37 â€¢ 0:00:43[0m [2;4m2.53it/s[0m  
[2KAttention weights: tensor([[0.5217, 0.4783],[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 97/203 [2m0:00:38 â€¢ 0:00:42[0m [2;4m2.54it/s[0m   
        [0.5133, 0.4867],
        [0.5152, 0.4848],
        [0.5209, 0.4791],
        [0.5228, 0.4772],
        [0.5255, 0.4745],
        [0.5228, 0.4772],
        [0.5197, 0.4803],
        [0.5166, 0.4834],
[2K        [0.5229, 0.4771]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 97/203 [2m0:00:38 â€¢ 0:00:42[0m [2;4m2.54it/s[0m  
[2KClass label: TennisSwingâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 97/203 [2m0:00:38 â€¢ 0:00:42[0m [2;4m2.54it/s[0m  
[2KAttention weights: tensor([[0.5179, 0.4821]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 97/203 [2m0:00:38 â€¢ 0:00:42[0m [2;4m2.54it/s[0m  
[2KStep 0 - TTA Loss: 4.5042â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 97/203 [2m0:00:38 â€¢ 0:00:42[0m [2;4m2.54it/s[0m  
[2KAttention weights: tensor([[0.5179, 0.4821]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 97/203 [2m0:00:38 â€¢ 0:00:42[0m [2;4m2.54it/s[0m  
[2KAttention weights: tensor([[0.5175, 0.4825]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 97/203 [2m0:00:38 â€¢ 0:00:42[0m [2;4m2.54it/s[0m  
[2KAttention weights: tensor([[0.5160, 0.4840]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 97/203 [2m0:00:38 â€¢ 0:00:42[0m [2;4m2.54it/s[0m  
[2KAttention weights: tensor([[0.5085, 0.4915]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 97/203 [2m0:00:38 â€¢ 0:00:42[0m [2;4m2.54it/s[0m  
[2KAttention weights: tensor([[0.4999, 0.5001]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 97/203 [2m0:00:38 â€¢ 0:00:42[0m [2;4m2.54it/s[0m  
[2KAttention weights: tensor([[0.4892, 0.5108]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 97/203 [2m0:00:38 â€¢ 0:00:42[0m [2;4m2.54it/s[0m  
[2KAttention weights: tensor([[0.4739, 0.5261]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 97/203 [2m0:00:38 â€¢ 0:00:42[0m [2;4m2.54it/s[0m  
[2KAttention weights: tensor([[0.4566, 0.5434]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 97/203 [2m0:00:38 â€¢ 0:00:42[0m [2;4m2.54it/s[0m  
[2KAttention weights: tensor([[0.4401, 0.5599]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 97/203 [2m0:00:38 â€¢ 0:00:42[0m [2;4m2.54it/s[0m  
[2KAttention weights: tensor([[0.5161, 0.4839]], device='cuda:0')8;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 97/203 [2m0:00:38 â€¢ 0:00:42[0m [2;4m2.54it/s[0m  
[2KAttention weights: tensor([[0.5876, 0.4124],[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 97/203 [2m0:00:38 â€¢ 0:00:42[0m [2;4m2.54it/s[0m  
        [0.4398, 0.5602],
        [0.4852, 0.5148],
        [0.5945, 0.4055],
        [0.5778, 0.4222],
        [0.6766, 0.3234],
        [0.6505, 0.3495],
        [0.5919, 0.4081],
        [0.4222, 0.5778],
[2K        [0.5713, 0.4287]], device='cuda:0')[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 97/203 [2m0:00:38 â€¢ 0:00:42[0m [2;4m2.54it/s[0m  
[2KAttention weights: tensor([[0.5219, 0.4781],[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 98/203 [2m0:00:38 â€¢ 0:00:42[0m [2;4m2.53it/s[0m  
        [0.5135, 0.4865],
        [0.5154, 0.4846],
        [0.5211, 0.4789],
        [0.5230, 0.4770],
        [0.5257, 0.4743],
        [0.5230, 0.4770],
        [0.5199, 0.4801],
        [0.5169, 0.4831],
[2K        [0.5231, 0.4769]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 98/203 [2m0:00:38 â€¢ 0:00:42[0m [2;4m2.53it/s[0m  
[2KClass label: HammerThrowâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 98/203 [2m0:00:38 â€¢ 0:00:42[0m [2;4m2.53it/s[0m  
[2KAttention weights: tensor([[0.5775, 0.4225]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 98/203 [2m0:00:38 â€¢ 0:00:42[0m [2;4m2.53it/s[0m  
[2KStep 0 - TTA Loss: 1.9996â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 98/203 [2m0:00:38 â€¢ 0:00:42[0m [2;4m2.53it/s[0m  
[2KAttention weights: tensor([[0.5846, 0.4154]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 98/203 [2m0:00:38 â€¢ 0:00:42[0m [2;4m2.53it/s[0m  
[2KAttention weights: tensor([[0.6038, 0.3962]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 98/203 [2m0:00:38 â€¢ 0:00:42[0m [2;4m2.53it/s[0m  
[2KAttention weights: tensor([[0.6299, 0.3701]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 98/203 [2m0:00:38 â€¢ 0:00:42[0m [2;4m2.53it/s[0m  
[2KAttention weights: tensor([[0.6514, 0.3486]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 98/203 [2m0:00:38 â€¢ 0:00:42[0m [2;4m2.53it/s[0m  
[2KAttention weights: tensor([[0.6690, 0.3310]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 98/203 [2m0:00:38 â€¢ 0:00:42[0m [2;4m2.53it/s[0m  
[2KAttention weights: tensor([[0.6820, 0.3180]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 98/203 [2m0:00:38 â€¢ 0:00:42[0m [2;4m2.53it/s[0m  
[2KAttention weights: tensor([[0.6909, 0.3091]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 98/203 [2m0:00:38 â€¢ 0:00:42[0m [2;4m2.53it/s[0m  
[2KAttention weights: tensor([[0.6943, 0.3057]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 98/203 [2m0:00:38 â€¢ 0:00:42[0m [2;4m2.53it/s[0m  
[2KAttention weights: tensor([[0.6955, 0.3045]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 98/203 [2m0:00:38 â€¢ 0:00:42[0m [2;4m2.53it/s[0m  
[2KAttention weights: tensor([[0.5264, 0.4736]], device='cuda:0')8;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 98/203 [2m0:00:38 â€¢ 0:00:42[0m [2;4m2.53it/s[0m  
[2KAttention weights: tensor([[0.6537, 0.3463],[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 98/203 [2m0:00:38 â€¢ 0:00:42[0m [2;4m2.53it/s[0m  
        [0.4545, 0.5455],
        [0.5173, 0.4827],
        [0.6479, 0.3521],
        [0.6960, 0.3040],
        [0.7395, 0.2605],
        [0.7048, 0.2952],
        [0.6284, 0.3716],
        [0.4749, 0.5251],
[2K        [0.6677, 0.3323]], device='cuda:0')[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 98/203 [2m0:00:38 â€¢ 0:00:42[0m [2;4m2.53it/s[0m  
[2KAttention weights: tensor([[0.5221, 0.4779],[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 99/203 [2m0:00:38 â€¢ 0:00:42[0m [2;4m2.52it/s[0m  
        [0.5136, 0.4864],
        [0.5155, 0.4845],
        [0.5213, 0.4787],
        [0.5232, 0.4768],
        [0.5259, 0.4741],
        [0.5231, 0.4769],
        [0.5201, 0.4799],
        [0.5172, 0.4828],
[2K        [0.5233, 0.4767]], device='cuda:0', grad_fn=<SoftmaxBackward0>)237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 99/203 [2m0:00:38 â€¢ 0:00:42[0m [2;4m2.52it/s[0m  
[2KClass label: HighJumpâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 99/203 [2m0:00:38 â€¢ 0:00:42[0m [2;4m2.52it/s[0m  
[2KAttention weights: tensor([[0.6916, 0.3084]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 99/203 [2m0:00:38 â€¢ 0:00:42[0m [2;4m2.52it/s[0m  
[2KStep 0 - TTA Loss: 1.5731â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 99/203 [2m0:00:38 â€¢ 0:00:42[0m [2;4m2.52it/s[0m  
[2KAttention weights: tensor([[0.6916, 0.3084]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 99/203 [2m0:00:38 â€¢ 0:00:42[0m [2;4m2.52it/s[0m  
[2KAttention weights: tensor([[0.6916, 0.3084]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 99/203 [2m0:00:38 â€¢ 0:00:42[0m [2;4m2.52it/s[0m  
[2KAttention weights: tensor([[0.6912, 0.3088]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 99/203 [2m0:00:38 â€¢ 0:00:42[0m [2;4m2.52it/s[0m  
[2KAttention weights: tensor([[0.6902, 0.3098]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 99/203 [2m0:00:38 â€¢ 0:00:42[0m [2;4m2.52it/s[0m  
[2KAttention weights: tensor([[0.6865, 0.3135]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 99/203 [2m0:00:38 â€¢ 0:00:42[0m [2;4m2.52it/s[0m  
[2KAttention weights: tensor([[0.6809, 0.3191]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 99/203 [2m0:00:38 â€¢ 0:00:42[0m [2;4m2.52it/s[0m  
[2KAttention weights: tensor([[0.6752, 0.3248]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 99/203 [2m0:00:38 â€¢ 0:00:42[0m [2;4m2.52it/s[0m  
[2KAttention weights: tensor([[0.6712, 0.3288]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 99/203 [2m0:00:38 â€¢ 0:00:42[0m [2;4m2.52it/s[0m  
[2KAttention weights: tensor([[0.6652, 0.3348]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 99/203 [2m0:00:38 â€¢ 0:00:42[0m [2;4m2.52it/s[0m  
[2KAttention weights: tensor([[0.5256, 0.4744]], device='cuda:0')0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 99/203 [2m0:00:38 â€¢ 0:00:42[0m [2;4m2.52it/s[0m  
[2KAttention weights: tensor([[0.5898, 0.4102],[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 99/203 [2m0:00:38 â€¢ 0:00:42[0m [2;4m2.52it/s[0m  
        [0.4461, 0.5539],
        [0.4887, 0.5113],
        [0.5976, 0.4024],
        [0.5663, 0.4337],
        [0.6605, 0.3395],
        [0.6239, 0.3761],
        [0.5959, 0.4041],
        [0.4928, 0.5072],
[2K        [0.5681, 0.4319]], device='cuda:0')[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 99/203 [2m0:00:38 â€¢ 0:00:42[0m [2;4m2.52it/s[0m  
[2KAttention weights: tensor([[0.5221, 0.4779],[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 100/203 [2m0:00:39 â€¢ 0:00:41[0m [2;4m2.52it/s[0m  
        [0.5136, 0.4864],
        [0.5155, 0.4845],
        [0.5213, 0.4787],
        [0.5232, 0.4768],
        [0.5259, 0.4741],
        [0.5231, 0.4769],
        [0.5201, 0.4799],
        [0.5172, 0.4828],
[2K        [0.5233, 0.4767]], device='cuda:0', grad_fn=<SoftmaxBackward0>)237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 100/203 [2m0:00:39 â€¢ 0:00:41[0m [2;4m2.52it/s[0m  
[2KClass label: HighJumpâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 100/203 [2m0:00:39 â€¢ 0:00:41[0m [2;4m2.52it/s[0m  
[2KAttention weights: tensor([[0.6849, 0.3151]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 100/203 [2m0:00:39 â€¢ 0:00:41[0m [2;4m2.52it/s[0m  
[2KStep 0 - TTA Loss: 1.6716â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 100/203 [2m0:00:39 â€¢ 0:00:41[0m [2;4m2.52it/s[0m  
[2KAttention weights: tensor([[0.6765, 0.3235]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 100/203 [2m0:00:39 â€¢ 0:00:41[0m [2;4m2.52it/s[0m  
[2KAttention weights: tensor([[0.6724, 0.3276]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 100/203 [2m0:00:39 â€¢ 0:00:41[0m [2;4m2.52it/s[0m  
[2KAttention weights: tensor([[0.6642, 0.3358]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 100/203 [2m0:00:39 â€¢ 0:00:41[0m [2;4m2.52it/s[0m  
[2KAttention weights: tensor([[0.6614, 0.3386]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 100/203 [2m0:00:39 â€¢ 0:00:41[0m [2;4m2.52it/s[0m  
[2KAttention weights: tensor([[0.6587, 0.3413]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 100/203 [2m0:00:39 â€¢ 0:00:41[0m [2;4m2.52it/s[0m  
[2KAttention weights: tensor([[0.6532, 0.3468]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 100/203 [2m0:00:39 â€¢ 0:00:41[0m [2;4m2.52it/s[0m  
[2KAttention weights: tensor([[0.6515, 0.3485]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 100/203 [2m0:00:39 â€¢ 0:00:41[0m [2;4m2.52it/s[0m  
[2KAttention weights: tensor([[0.6501, 0.3499]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 100/203 [2m0:00:39 â€¢ 0:00:41[0m [2;4m2.52it/s[0m  
[2KAttention weights: tensor([[0.6495, 0.3505]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 100/203 [2m0:00:39 â€¢ 0:00:41[0m [2;4m2.52it/s[0m  
[2KAttention weights: tensor([[0.5251, 0.4749]], device='cuda:0')0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 100/203 [2m0:00:39 â€¢ 0:00:41[0m [2;4m2.52it/s[0m  
[2KAttention weights: tensor([[0.5895, 0.4105],[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 100/203 [2m0:00:39 â€¢ 0:00:41[0m [2;4m2.52it/s[0m  
        [0.4467, 0.5533],
        [0.4884, 0.5116],
        [0.5958, 0.4042],
        [0.5620, 0.4380],
        [0.6498, 0.3502],
        [0.6169, 0.3831],
        [0.5935, 0.4065],
        [0.4914, 0.5086],
[2K        [0.5629, 0.4371]], device='cuda:0')[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 100/203 [2m0:00:39 â€¢ 0:00:41[0m [2;4m2.52it/s[0m  
[2KAttention weights: tensor([[0.5221, 0.4779],[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 101/203 [2m0:00:39 â€¢ 0:00:41[0m [2;4m2.51it/s[0m  
        [0.5137, 0.4863],
        [0.5156, 0.4844],
        [0.5213, 0.4787],
        [0.5233, 0.4767],
        [0.5259, 0.4741],
        [0.5232, 0.4768],
        [0.5201, 0.4799],
        [0.5173, 0.4827],
[2K        [0.5233, 0.4767]], device='cuda:0', grad_fn=<SoftmaxBackward0>)237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 101/203 [2m0:00:39 â€¢ 0:00:41[0m [2;4m2.51it/s[0m  
[2KClass label: Billiardsâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 101/203 [2m0:00:39 â€¢ 0:00:41[0m [2;4m2.51it/s[0m  
[2KAttention weights: tensor([[0.4495, 0.5505]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 101/203 [2m0:00:39 â€¢ 0:00:41[0m [2;4m2.51it/s[0m  
[2KStep 0 - TTA Loss: 1.3906â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 101/203 [2m0:00:39 â€¢ 0:00:41[0m [2;4m2.51it/s[0m  
[2KAttention weights: tensor([[0.4495, 0.5505]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 101/203 [2m0:00:39 â€¢ 0:00:41[0m [2;4m2.51it/s[0m  
[2KAttention weights: tensor([[0.4498, 0.5502]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 101/203 [2m0:00:39 â€¢ 0:00:41[0m [2;4m2.51it/s[0m  
[2KAttention weights: tensor([[0.4511, 0.5489]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 101/203 [2m0:00:39 â€¢ 0:00:41[0m [2;4m2.51it/s[0m  
[2KAttention weights: tensor([[0.4543, 0.5457]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 101/203 [2m0:00:39 â€¢ 0:00:41[0m [2;4m2.51it/s[0m  
[2KAttention weights: tensor([[0.4605, 0.5395]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 101/203 [2m0:00:39 â€¢ 0:00:41[0m [2;4m2.51it/s[0m  
[2KAttention weights: tensor([[0.4708, 0.5292]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 101/203 [2m0:00:39 â€¢ 0:00:41[0m [2;4m2.51it/s[0m  
[2KAttention weights: tensor([[0.4859, 0.5141]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 101/203 [2m0:00:39 â€¢ 0:00:41[0m [2;4m2.51it/s[0m  
[2KAttention weights: tensor([[0.5062, 0.4938]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 101/203 [2m0:00:39 â€¢ 0:00:41[0m [2;4m2.51it/s[0m  
[2KAttention weights: tensor([[0.5292, 0.4708]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 101/203 [2m0:00:39 â€¢ 0:00:41[0m [2;4m2.51it/s[0m  
[2KAttention weights: tensor([[0.5174, 0.4826]], device='cuda:0')0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 101/203 [2m0:00:39 â€¢ 0:00:41[0m [2;4m2.51it/s[0m  
[2KAttention weights: tensor([[0.6012, 0.3988],[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 101/203 [2m0:00:39 â€¢ 0:00:41[0m [2;4m2.51it/s[0m  
        [0.5535, 0.4465],
        [0.4952, 0.5048],
        [0.6163, 0.3837],
        [0.5802, 0.4198],
        [0.6782, 0.3218],
        [0.6309, 0.3691],
        [0.6126, 0.3874],
        [0.5196, 0.4804],
[2K        [0.5804, 0.4196]], device='cuda:0')[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 101/203 [2m0:00:39 â€¢ 0:00:41[0m [2;4m2.51it/s[0m  
[2KAttention weights: tensor([[0.5222, 0.4778],[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 102/203 [2m0:00:39 â€¢ 0:00:41[0m [2;4m2.52it/s[0m   
        [0.5137, 0.4863],
        [0.5156, 0.4844],
        [0.5213, 0.4787],
        [0.5233, 0.4767],
        [0.5260, 0.4740],
        [0.5232, 0.4768],
        [0.5202, 0.4798],
        [0.5173, 0.4827],
[2K        [0.5233, 0.4767]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 102/203 [2m0:00:39 â€¢ 0:00:41[0m [2;4m2.52it/s[0m  
[2KClass label: CleanAndJerkâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 102/203 [2m0:00:39 â€¢ 0:00:41[0m [2;4m2.52it/s[0m  
[2KAttention weights: tensor([[0.4925, 0.5075]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 102/203 [2m0:00:39 â€¢ 0:00:41[0m [2;4m2.52it/s[0m  
[2KStep 0 - TTA Loss: 0.8221â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 102/203 [2m0:00:39 â€¢ 0:00:41[0m [2;4m2.52it/s[0m  
[2KAttention weights: tensor([[0.4942, 0.5058]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 102/203 [2m0:00:39 â€¢ 0:00:41[0m [2;4m2.52it/s[0m  
[2KAttention weights: tensor([[0.4955, 0.5045]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 102/203 [2m0:00:39 â€¢ 0:00:41[0m [2;4m2.52it/s[0m  
[2KAttention weights: tensor([[0.4971, 0.5029]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 102/203 [2m0:00:39 â€¢ 0:00:41[0m [2;4m2.52it/s[0m  
[2KAttention weights: tensor([[0.4981, 0.5019]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 102/203 [2m0:00:39 â€¢ 0:00:41[0m [2;4m2.52it/s[0m  
[2KAttention weights: tensor([[0.4990, 0.5010]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 102/203 [2m0:00:39 â€¢ 0:00:41[0m [2;4m2.52it/s[0m  
[2KAttention weights: tensor([[0.4998, 0.5002]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 102/203 [2m0:00:39 â€¢ 0:00:41[0m [2;4m2.52it/s[0m  
[2KAttention weights: tensor([[0.5027, 0.4973]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 102/203 [2m0:00:39 â€¢ 0:00:41[0m [2;4m2.52it/s[0m  
[2KAttention weights: tensor([[0.5054, 0.4946]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 102/203 [2m0:00:39 â€¢ 0:00:41[0m [2;4m2.52it/s[0m  
[2KAttention weights: tensor([[0.5073, 0.4927]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 102/203 [2m0:00:39 â€¢ 0:00:41[0m [2;4m2.52it/s[0m  
[2KAttention weights: tensor([[0.5160, 0.4840]], device='cuda:0')38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 102/203 [2m0:00:39 â€¢ 0:00:41[0m [2;4m2.52it/s[0m  
[2KAttention weights: tensor([[0.6067, 0.3933],[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 102/203 [2m0:00:39 â€¢ 0:00:41[0m [2;4m2.52it/s[0m  
        [0.5417, 0.4583],
        [0.5077, 0.4923],
        [0.6225, 0.3775],
        [0.5810, 0.4190],
        [0.6820, 0.3180],
        [0.6350, 0.3650],
        [0.6178, 0.3822],
        [0.5185, 0.4815],
[2K        [0.5849, 0.4151]], device='cuda:0')m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 102/203 [2m0:00:39 â€¢ 0:00:41[0m [2;4m2.52it/s[0m  
[2KAttention weights: tensor([[0.5222, 0.4778],[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 103/203 [2m0:00:40 â€¢ 0:00:40[0m [2;4m2.52it/s[0m  
        [0.5137, 0.4863],
        [0.5156, 0.4844],
        [0.5214, 0.4786],
        [0.5233, 0.4767],
        [0.5260, 0.4740],
        [0.5233, 0.4767],
        [0.5202, 0.4798],
        [0.5173, 0.4827],
[2K        [0.5234, 0.4766]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 103/203 [2m0:00:40 â€¢ 0:00:40[0m [2;4m2.52it/s[0m  
[2KClass label: TennisSwingâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 103/203 [2m0:00:40 â€¢ 0:00:40[0m [2;4m2.52it/s[0m  
[2KAttention weights: tensor([[0.5224, 0.4776]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 103/203 [2m0:00:40 â€¢ 0:00:40[0m [2;4m2.52it/s[0m  
[2KStep 0 - TTA Loss: 1.4084â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 103/203 [2m0:00:40 â€¢ 0:00:40[0m [2;4m2.52it/s[0m  
[2KAttention weights: tensor([[0.5224, 0.4776]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 103/203 [2m0:00:40 â€¢ 0:00:40[0m [2;4m2.52it/s[0m  
[2KAttention weights: tensor([[0.5226, 0.4774]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 103/203 [2m0:00:40 â€¢ 0:00:40[0m [2;4m2.52it/s[0m  
[2KAttention weights: tensor([[0.5236, 0.4764]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 103/203 [2m0:00:40 â€¢ 0:00:40[0m [2;4m2.52it/s[0m  
[2KAttention weights: tensor([[0.5260, 0.4740]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 103/203 [2m0:00:40 â€¢ 0:00:40[0m [2;4m2.52it/s[0m  
[2KAttention weights: tensor([[0.5305, 0.4695]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 103/203 [2m0:00:40 â€¢ 0:00:40[0m [2;4m2.52it/s[0m  
[2KAttention weights: tensor([[0.5376, 0.4624]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 103/203 [2m0:00:40 â€¢ 0:00:40[0m [2;4m2.52it/s[0m  
[2KAttention weights: tensor([[0.5485, 0.4515]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 103/203 [2m0:00:40 â€¢ 0:00:40[0m [2;4m2.52it/s[0m  
[2KAttention weights: tensor([[0.5631, 0.4369]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 103/203 [2m0:00:40 â€¢ 0:00:40[0m [2;4m2.52it/s[0m  
[2KAttention weights: tensor([[0.5818, 0.4182]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 103/203 [2m0:00:40 â€¢ 0:00:40[0m [2;4m2.52it/s[0m  
[2KAttention weights: tensor([[0.5202, 0.4798]], device='cuda:0')38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 103/203 [2m0:00:40 â€¢ 0:00:40[0m [2;4m2.52it/s[0m  
[2KAttention weights: tensor([[0.6312, 0.3688],[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 103/203 [2m0:00:40 â€¢ 0:00:40[0m [2;4m2.52it/s[0m  
        [0.4687, 0.5313],
        [0.5430, 0.4570],
        [0.6250, 0.3750],
        [0.6059, 0.3941],
        [0.7113, 0.2887],
        [0.6566, 0.3434],
        [0.6245, 0.3755],
        [0.6020, 0.3980],
[2K        [0.6202, 0.3798]], device='cuda:0')m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 103/203 [2m0:00:40 â€¢ 0:00:40[0m [2;4m2.52it/s[0m  
[2KAttention weights: tensor([[0.5222, 0.4778],[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 104/203 [2m0:00:40 â€¢ 0:00:40[0m [2;4m2.52it/s[0m  
        [0.5138, 0.4862],
        [0.5157, 0.4843],
        [0.5214, 0.4786],
        [0.5233, 0.4767],
        [0.5260, 0.4740],
        [0.5233, 0.4767],
        [0.5202, 0.4798],
        [0.5173, 0.4827],
[2K        [0.5234, 0.4766]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 104/203 [2m0:00:40 â€¢ 0:00:40[0m [2;4m2.52it/s[0m  
[2KClass label: HammerThrowâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 104/203 [2m0:00:40 â€¢ 0:00:40[0m [2;4m2.52it/s[0m  
[2KAttention weights: tensor([[0.5734, 0.4266]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 104/203 [2m0:00:40 â€¢ 0:00:40[0m [2;4m2.52it/s[0m  
[2KStep 0 - TTA Loss: 1.0779â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 104/203 [2m0:00:40 â€¢ 0:00:40[0m [2;4m2.52it/s[0m  
[2KAttention weights: tensor([[0.5789, 0.4211]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 104/203 [2m0:00:40 â€¢ 0:00:40[0m [2;4m2.52it/s[0m  
[2KAttention weights: tensor([[0.5786, 0.4214]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 104/203 [2m0:00:40 â€¢ 0:00:40[0m [2;4m2.52it/s[0m  
[2KAttention weights: tensor([[0.5759, 0.4241]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 104/203 [2m0:00:40 â€¢ 0:00:40[0m [2;4m2.52it/s[0m  
[2KAttention weights: tensor([[0.5722, 0.4278]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 104/203 [2m0:00:40 â€¢ 0:00:40[0m [2;4m2.52it/s[0m  
[2KAttention weights: tensor([[0.5691, 0.4309]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 104/203 [2m0:00:40 â€¢ 0:00:40[0m [2;4m2.52it/s[0m  
[2KAttention weights: tensor([[0.5675, 0.4325]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 104/203 [2m0:00:40 â€¢ 0:00:40[0m [2;4m2.52it/s[0m  
[2KAttention weights: tensor([[0.5653, 0.4347]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 104/203 [2m0:00:40 â€¢ 0:00:40[0m [2;4m2.52it/s[0m  
[2KAttention weights: tensor([[0.5628, 0.4372]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 104/203 [2m0:00:40 â€¢ 0:00:40[0m [2;4m2.52it/s[0m  
[2KAttention weights: tensor([[0.5615, 0.4385]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 104/203 [2m0:00:40 â€¢ 0:00:40[0m [2;4m2.52it/s[0m  
[2KAttention weights: tensor([[0.5231, 0.4769]], device='cuda:0')38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 104/203 [2m0:00:40 â€¢ 0:00:40[0m [2;4m2.52it/s[0m  
[2KAttention weights: tensor([[0.6049, 0.3951],[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 104/203 [2m0:00:40 â€¢ 0:00:40[0m [2;4m2.52it/s[0m  
        [0.4551, 0.5449],
        [0.5172, 0.4828],
        [0.6050, 0.3950],
        [0.5612, 0.4388],
        [0.6917, 0.3083],
        [0.6320, 0.3680],
        [0.6109, 0.3891],
        [0.5914, 0.4086],
[2K        [0.5846, 0.4154]], device='cuda:0')m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 104/203 [2m0:00:40 â€¢ 0:00:40[0m [2;4m2.52it/s[0m  
[2KAttention weights: tensor([[0.5222, 0.4778],[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 105/203 [2m0:00:41 â€¢ 0:00:39[0m [2;4m2.53it/s[0m  
        [0.5138, 0.4862],
        [0.5157, 0.4843],
        [0.5214, 0.4786],
        [0.5233, 0.4767],
        [0.5261, 0.4739],
        [0.5233, 0.4767],
        [0.5202, 0.4798],
        [0.5174, 0.4826],
[2K        [0.5234, 0.4766]], device='cuda:0', grad_fn=<SoftmaxBackward0>);237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 105/203 [2m0:00:41 â€¢ 0:00:39[0m [2;4m2.53it/s[0m  
[2KClass label: HighJumpâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 105/203 [2m0:00:41 â€¢ 0:00:39[0m [2;4m2.53it/s[0m  
[2KAttention weights: tensor([[0.6874, 0.3126]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 105/203 [2m0:00:41 â€¢ 0:00:39[0m [2;4m2.53it/s[0m  
[2KStep 0 - TTA Loss: 1.4045â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 105/203 [2m0:00:41 â€¢ 0:00:39[0m [2;4m2.53it/s[0m  
[2KAttention weights: tensor([[0.6874, 0.3126]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 105/203 [2m0:00:41 â€¢ 0:00:39[0m [2;4m2.53it/s[0m  
[2KAttention weights: tensor([[0.6871, 0.3129]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 105/203 [2m0:00:41 â€¢ 0:00:39[0m [2;4m2.53it/s[0m  
[2KAttention weights: tensor([[0.6861, 0.3139]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 105/203 [2m0:00:41 â€¢ 0:00:39[0m [2;4m2.53it/s[0m  
[2KAttention weights: tensor([[0.6826, 0.3174]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 105/203 [2m0:00:41 â€¢ 0:00:39[0m [2;4m2.53it/s[0m  
[2KAttention weights: tensor([[0.6751, 0.3249]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 105/203 [2m0:00:41 â€¢ 0:00:39[0m [2;4m2.53it/s[0m  
[2KAttention weights: tensor([[0.6636, 0.3364]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 105/203 [2m0:00:41 â€¢ 0:00:39[0m [2;4m2.53it/s[0m  
[2KAttention weights: tensor([[0.6503, 0.3497]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 105/203 [2m0:00:41 â€¢ 0:00:39[0m [2;4m2.53it/s[0m  
[2KAttention weights: tensor([[0.6393, 0.3607]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 105/203 [2m0:00:41 â€¢ 0:00:39[0m [2;4m2.53it/s[0m  
[2KAttention weights: tensor([[0.6289, 0.3711]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 105/203 [2m0:00:41 â€¢ 0:00:39[0m [2;4m2.53it/s[0m  
[2KAttention weights: tensor([[0.5244, 0.4756]], device='cuda:0')[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 105/203 [2m0:00:41 â€¢ 0:00:39[0m [2;4m2.53it/s[0m  
[2KAttention weights: tensor([[0.5689, 0.4311],[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 105/203 [2m0:00:41 â€¢ 0:00:39[0m [2;4m2.53it/s[0m  
        [0.4448, 0.5552],
        [0.4817, 0.5183],
        [0.5757, 0.4243],
        [0.5071, 0.4929],
        [0.6193, 0.3807],
        [0.5854, 0.4146],
        [0.5783, 0.4217],
        [0.5126, 0.4874],
[2K        [0.5211, 0.4789]], device='cuda:0')m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 105/203 [2m0:00:41 â€¢ 0:00:39[0m [2;4m2.53it/s[0m  
[2KAttention weights: tensor([[0.5222, 0.4778],[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 106/203 [2m0:00:41 â€¢ 0:00:39[0m [2;4m2.52it/s[0m  
        [0.5138, 0.4862],
        [0.5156, 0.4844],
        [0.5214, 0.4786],
        [0.5233, 0.4767],
        [0.5260, 0.4740],
        [0.5233, 0.4767],
        [0.5202, 0.4798],
        [0.5173, 0.4827],
[2K        [0.5234, 0.4766]], device='cuda:0', grad_fn=<SoftmaxBackward0>);237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 106/203 [2m0:00:41 â€¢ 0:00:39[0m [2;4m2.52it/s[0m  
[2KClass label: TennisSwingâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 106/203 [2m0:00:41 â€¢ 0:00:39[0m [2;4m2.52it/s[0m  
[2KAttention weights: tensor([[0.5187, 0.4813]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 106/203 [2m0:00:41 â€¢ 0:00:39[0m [2;4m2.52it/s[0m  
[2KStep 0 - TTA Loss: 0.9237â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 106/203 [2m0:00:41 â€¢ 0:00:39[0m [2;4m2.52it/s[0m  
[2KAttention weights: tensor([[0.5182, 0.4818]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 106/203 [2m0:00:41 â€¢ 0:00:39[0m [2;4m2.52it/s[0m  
[2KAttention weights: tensor([[0.5175, 0.4825]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 106/203 [2m0:00:41 â€¢ 0:00:39[0m [2;4m2.52it/s[0m  
[2KAttention weights: tensor([[0.5167, 0.4833]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 106/203 [2m0:00:41 â€¢ 0:00:39[0m [2;4m2.52it/s[0m  
[2KAttention weights: tensor([[0.5167, 0.4833]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 106/203 [2m0:00:41 â€¢ 0:00:39[0m [2;4m2.52it/s[0m  
[2KAttention weights: tensor([[0.5175, 0.4825]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 106/203 [2m0:00:41 â€¢ 0:00:39[0m [2;4m2.52it/s[0m  
[2KAttention weights: tensor([[0.5184, 0.4816]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 106/203 [2m0:00:41 â€¢ 0:00:39[0m [2;4m2.52it/s[0m  
[2KAttention weights: tensor([[0.5190, 0.4810]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 106/203 [2m0:00:41 â€¢ 0:00:39[0m [2;4m2.52it/s[0m  
[2KAttention weights: tensor([[0.5194, 0.4806]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 106/203 [2m0:00:41 â€¢ 0:00:39[0m [2;4m2.52it/s[0m  
[2KAttention weights: tensor([[0.5195, 0.4805]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 106/203 [2m0:00:41 â€¢ 0:00:39[0m [2;4m2.52it/s[0m  
[2KAttention weights: tensor([[0.5174, 0.4826]], device='cuda:0')[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 106/203 [2m0:00:41 â€¢ 0:00:39[0m [2;4m2.52it/s[0m  
[2KAttention weights: tensor([[0.5828, 0.4172],[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 106/203 [2m0:00:41 â€¢ 0:00:39[0m [2;4m2.52it/s[0m  
        [0.4455, 0.5545],
        [0.4844, 0.5156],
        [0.5893, 0.4107],
        [0.5350, 0.4650],
        [0.6507, 0.3493],
        [0.6113, 0.3887],
        [0.5925, 0.4075],
        [0.5195, 0.4805],
[2K        [0.5497, 0.4503]], device='cuda:0')m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 106/203 [2m0:00:41 â€¢ 0:00:39[0m [2;4m2.52it/s[0m  
[2KAttention weights: tensor([[0.5222, 0.4778],â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 107/203 [2m0:00:41 â€¢ 0:00:39[0m [2;4m2.52it/s[0m   
        [0.5137, 0.4863],
        [0.5156, 0.4844],
        [0.5214, 0.4786],
        [0.5233, 0.4767],
        [0.5259, 0.4741],
        [0.5232, 0.4768],
        [0.5202, 0.4798],
        [0.5173, 0.4827],
[2K        [0.5233, 0.4767]], device='cuda:0', grad_fn=<SoftmaxBackward0>)mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 107/203 [2m0:00:41 â€¢ 0:00:39[0m [2;4m2.52it/s[0m  
[2KClass label: HammerThrowâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 107/203 [2m0:00:41 â€¢ 0:00:39[0m [2;4m2.52it/s[0m  
[2KAttention weights: tensor([[0.5806, 0.4194]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 107/203 [2m0:00:41 â€¢ 0:00:39[0m [2;4m2.52it/s[0m  
[2KStep 0 - TTA Loss: 1.4493â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 107/203 [2m0:00:41 â€¢ 0:00:39[0m [2;4m2.52it/s[0m  
[2KAttention weights: tensor([[0.5806, 0.4194]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 107/203 [2m0:00:41 â€¢ 0:00:39[0m [2;4m2.52it/s[0m  
[2KAttention weights: tensor([[0.5804, 0.4196]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 107/203 [2m0:00:41 â€¢ 0:00:39[0m [2;4m2.52it/s[0m  
[2KAttention weights: tensor([[0.5807, 0.4193]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 107/203 [2m0:00:41 â€¢ 0:00:39[0m [2;4m2.52it/s[0m  
[2KAttention weights: tensor([[0.5824, 0.4176]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 107/203 [2m0:00:41 â€¢ 0:00:39[0m [2;4m2.52it/s[0m  
[2KAttention weights: tensor([[0.5856, 0.4144]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 107/203 [2m0:00:41 â€¢ 0:00:39[0m [2;4m2.52it/s[0m  
[2KAttention weights: tensor([[0.5899, 0.4101]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 107/203 [2m0:00:41 â€¢ 0:00:39[0m [2;4m2.52it/s[0m  
[2KAttention weights: tensor([[0.5931, 0.4069]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 107/203 [2m0:00:41 â€¢ 0:00:39[0m [2;4m2.52it/s[0m  
[2KAttention weights: tensor([[0.5967, 0.4033]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 107/203 [2m0:00:41 â€¢ 0:00:39[0m [2;4m2.52it/s[0m  
[2KAttention weights: tensor([[0.5955, 0.4045]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 107/203 [2m0:00:41 â€¢ 0:00:39[0m [2;4m2.52it/s[0m  
[2KAttention weights: tensor([[0.5239, 0.4761]], device='cuda:0')[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 107/203 [2m0:00:41 â€¢ 0:00:39[0m [2;4m2.52it/s[0m  
[2KAttention weights: tensor([[0.6075, 0.3925],m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 107/203 [2m0:00:41 â€¢ 0:00:39[0m [2;4m2.52it/s[0m  
        [0.4404, 0.5596],
        [0.4987, 0.5013],
        [0.6119, 0.3881],
        [0.5934, 0.4066],
        [0.6946, 0.3054],
        [0.6477, 0.3523],
        [0.6091, 0.3909],
        [0.5264, 0.4736],
[2K        [0.5969, 0.4031]], device='cuda:0')0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 107/203 [2m0:00:41 â€¢ 0:00:39[0m [2;4m2.52it/s[0m  
[2KAttention weights: tensor([[0.5222, 0.4778],â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 108/203 [2m0:00:42 â€¢ 0:00:38[0m [2;4m2.53it/s[0m  
        [0.5137, 0.4863],
        [0.5156, 0.4844],
        [0.5214, 0.4786],
        [0.5233, 0.4767],
        [0.5259, 0.4741],
        [0.5232, 0.4768],
        [0.5202, 0.4798],
        [0.5173, 0.4827],
[2K        [0.5233, 0.4767]], device='cuda:0', grad_fn=<SoftmaxBackward0>)mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 108/203 [2m0:00:42 â€¢ 0:00:38[0m [2;4m2.53it/s[0m  
[2KClass label: CleanAndJerkâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 108/203 [2m0:00:42 â€¢ 0:00:38[0m [2;4m2.53it/s[0m  
[2KAttention weights: tensor([[0.4959, 0.5041]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 108/203 [2m0:00:42 â€¢ 0:00:38[0m [2;4m2.53it/s[0m  
[2KStep 0 - TTA Loss: 0.8017â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 108/203 [2m0:00:42 â€¢ 0:00:38[0m [2;4m2.53it/s[0m  
[2KAttention weights: tensor([[0.4945, 0.5055]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 108/203 [2m0:00:42 â€¢ 0:00:38[0m [2;4m2.53it/s[0m  
[2KAttention weights: tensor([[0.4896, 0.5104]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 108/203 [2m0:00:42 â€¢ 0:00:38[0m [2;4m2.53it/s[0m  
[2KAttention weights: tensor([[0.4846, 0.5154]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 108/203 [2m0:00:42 â€¢ 0:00:38[0m [2;4m2.53it/s[0m  
[2KAttention weights: tensor([[0.4786, 0.5214]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 108/203 [2m0:00:42 â€¢ 0:00:38[0m [2;4m2.53it/s[0m  
[2KAttention weights: tensor([[0.4741, 0.5259]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 108/203 [2m0:00:42 â€¢ 0:00:38[0m [2;4m2.53it/s[0m  
[2KAttention weights: tensor([[0.4714, 0.5286]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 108/203 [2m0:00:42 â€¢ 0:00:38[0m [2;4m2.53it/s[0m  
[2KAttention weights: tensor([[0.4703, 0.5297]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 108/203 [2m0:00:42 â€¢ 0:00:38[0m [2;4m2.53it/s[0m  
[2KAttention weights: tensor([[0.4697, 0.5303]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 108/203 [2m0:00:42 â€¢ 0:00:38[0m [2;4m2.53it/s[0m  
[2KAttention weights: tensor([[0.4693, 0.5307]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 108/203 [2m0:00:42 â€¢ 0:00:38[0m [2;4m2.53it/s[0m  
[2KAttention weights: tensor([[0.5146, 0.4854]], device='cuda:0')[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 108/203 [2m0:00:42 â€¢ 0:00:38[0m [2;4m2.53it/s[0m  
[2KAttention weights: tensor([[0.5956, 0.4044],m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 108/203 [2m0:00:42 â€¢ 0:00:38[0m [2;4m2.53it/s[0m  
        [0.4442, 0.5558],
        [0.4692, 0.5308],
        [0.5959, 0.4041],
        [0.5612, 0.4388],
        [0.6772, 0.3228],
        [0.6322, 0.3678],
        [0.5995, 0.4005],
        [0.5130, 0.4870],
[2K        [0.5701, 0.4299]], device='cuda:0')0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 108/203 [2m0:00:42 â€¢ 0:00:38[0m [2;4m2.53it/s[0m  
[2KAttention weights: tensor([[0.5222, 0.4778],â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 109/203 [2m0:00:42 â€¢ 0:00:38[0m [2;4m2.53it/s[0m  
        [0.5138, 0.4862],
        [0.5156, 0.4844],
        [0.5214, 0.4786],
        [0.5233, 0.4767],
        [0.5259, 0.4741],
        [0.5232, 0.4768],
        [0.5202, 0.4798],
        [0.5173, 0.4827],
[2K        [0.5233, 0.4767]], device='cuda:0', grad_fn=<SoftmaxBackward0>)mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 109/203 [2m0:00:42 â€¢ 0:00:38[0m [2;4m2.53it/s[0m  
[2KClass label: CleanAndJerkâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 109/203 [2m0:00:42 â€¢ 0:00:38[0m [2;4m2.53it/s[0m  
[2KAttention weights: tensor([[0.4891, 0.5109]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 109/203 [2m0:00:42 â€¢ 0:00:38[0m [2;4m2.53it/s[0m  
[2KStep 0 - TTA Loss: 1.9468â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 109/203 [2m0:00:42 â€¢ 0:00:38[0m [2;4m2.53it/s[0m  
[2KAttention weights: tensor([[0.4891, 0.5109]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 109/203 [2m0:00:42 â€¢ 0:00:38[0m [2;4m2.53it/s[0m  
[2KAttention weights: tensor([[0.4892, 0.5108]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 109/203 [2m0:00:42 â€¢ 0:00:38[0m [2;4m2.53it/s[0m  
[2KAttention weights: tensor([[0.4896, 0.5104]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 109/203 [2m0:00:42 â€¢ 0:00:38[0m [2;4m2.53it/s[0m  
[2KAttention weights: tensor([[0.4896, 0.5104]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 109/203 [2m0:00:42 â€¢ 0:00:38[0m [2;4m2.53it/s[0m  
[2KAttention weights: tensor([[0.4887, 0.5113]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 109/203 [2m0:00:42 â€¢ 0:00:38[0m [2;4m2.53it/s[0m  
[2KAttention weights: tensor([[0.4860, 0.5140]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 109/203 [2m0:00:42 â€¢ 0:00:38[0m [2;4m2.53it/s[0m  
[2KAttention weights: tensor([[0.4882, 0.5118]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 109/203 [2m0:00:42 â€¢ 0:00:38[0m [2;4m2.53it/s[0m  
[2KAttention weights: tensor([[0.4885, 0.5115]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 109/203 [2m0:00:42 â€¢ 0:00:38[0m [2;4m2.53it/s[0m  
[2KAttention weights: tensor([[0.4910, 0.5090]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 109/203 [2m0:00:42 â€¢ 0:00:38[0m [2;4m2.53it/s[0m  
[2KAttention weights: tensor([[0.5154, 0.4846]], device='cuda:0')[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 109/203 [2m0:00:42 â€¢ 0:00:38[0m [2;4m2.53it/s[0m  
[2KAttention weights: tensor([[0.5983, 0.4017],m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 109/203 [2m0:00:42 â€¢ 0:00:38[0m [2;4m2.53it/s[0m  
        [0.4470, 0.5530],
        [0.4891, 0.5109],
        [0.6013, 0.3987],
        [0.5723, 0.4277],
        [0.6835, 0.3165],
        [0.6345, 0.3655],
        [0.6046, 0.3954],
        [0.5138, 0.4862],
[2K        [0.5794, 0.4206]], device='cuda:0')0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 109/203 [2m0:00:42 â€¢ 0:00:38[0m [2;4m2.53it/s[0m  
[2KAttention weights: tensor([[0.5222, 0.4778],â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 110/203 [2m0:00:42 â€¢ 0:00:37[0m [2;4m2.53it/s[0m  
        [0.5138, 0.4862],
        [0.5157, 0.4843],
        [0.5214, 0.4786],
        [0.5233, 0.4767],
        [0.5259, 0.4741],
        [0.5232, 0.4768],
        [0.5202, 0.4798],
        [0.5173, 0.4827],
[2K        [0.5234, 0.4766]], device='cuda:0', grad_fn=<SoftmaxBackward0>)5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 110/203 [2m0:00:42 â€¢ 0:00:37[0m [2;4m2.53it/s[0m  
[2KClass label: HighJumpâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 110/203 [2m0:00:42 â€¢ 0:00:37[0m [2;4m2.53it/s[0m  
[2KAttention weights: tensor([[0.6930, 0.3070]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 110/203 [2m0:00:42 â€¢ 0:00:37[0m [2;4m2.53it/s[0m  
[2KStep 0 - TTA Loss: 2.1112â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 110/203 [2m0:00:42 â€¢ 0:00:37[0m [2;4m2.53it/s[0m  
[2KAttention weights: tensor([[0.7083, 0.2917]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 110/203 [2m0:00:42 â€¢ 0:00:37[0m [2;4m2.53it/s[0m  
[2KAttention weights: tensor([[0.7405, 0.2595]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 110/203 [2m0:00:42 â€¢ 0:00:37[0m [2;4m2.53it/s[0m  
[2KAttention weights: tensor([[0.7788, 0.2212]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 110/203 [2m0:00:42 â€¢ 0:00:37[0m [2;4m2.53it/s[0m  
[2KAttention weights: tensor([[0.8079, 0.1921]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 110/203 [2m0:00:42 â€¢ 0:00:37[0m [2;4m2.53it/s[0m  
[2KAttention weights: tensor([[0.8333, 0.1667]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 110/203 [2m0:00:42 â€¢ 0:00:37[0m [2;4m2.53it/s[0m  
[2KAttention weights: tensor([[0.8470, 0.1530]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 110/203 [2m0:00:42 â€¢ 0:00:37[0m [2;4m2.53it/s[0m  
[2KAttention weights: tensor([[0.8555, 0.1445]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 110/203 [2m0:00:42 â€¢ 0:00:37[0m [2;4m2.53it/s[0m  
[2KAttention weights: tensor([[0.8602, 0.1398]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 110/203 [2m0:00:42 â€¢ 0:00:37[0m [2;4m2.53it/s[0m  
[2KAttention weights: tensor([[0.8630, 0.1370]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 110/203 [2m0:00:42 â€¢ 0:00:37[0m [2;4m2.53it/s[0m  
[2KAttention weights: tensor([[0.5348, 0.4652]], device='cuda:0')[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 110/203 [2m0:00:42 â€¢ 0:00:37[0m [2;4m2.53it/s[0m  
[2KAttention weights: tensor([[0.6796, 0.3204],m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 110/203 [2m0:00:42 â€¢ 0:00:37[0m [2;4m2.53it/s[0m  
        [0.4516, 0.5484],
        [0.5325, 0.4675],
        [0.6668, 0.3332],
        [0.7162, 0.2838],
        [0.8644, 0.1356],
        [0.7924, 0.2076],
        [0.6837, 0.3163],
        [0.5897, 0.4103],
[2K        [0.7270, 0.2730]], device='cuda:0')0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 110/203 [2m0:00:42 â€¢ 0:00:37[0m [2;4m2.53it/s[0m  
[2KAttention weights: tensor([[0.5223, 0.4777],â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 111/203 [2m0:00:43 â€¢ 0:00:37[0m [2;4m2.54it/s[0m  
        [0.5138, 0.4862],
        [0.5157, 0.4843],
        [0.5214, 0.4786],
        [0.5234, 0.4766],
        [0.5261, 0.4739],
        [0.5234, 0.4766],
        [0.5203, 0.4797],
        [0.5174, 0.4826],
[2K        [0.5235, 0.4765]], device='cuda:0', grad_fn=<SoftmaxBackward0>)5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 111/203 [2m0:00:43 â€¢ 0:00:37[0m [2;4m2.54it/s[0m  
[2KClass label: HammerThrowâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 111/203 [2m0:00:43 â€¢ 0:00:37[0m [2;4m2.54it/s[0m  
[2KAttention weights: tensor([[0.5758, 0.4242]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 111/203 [2m0:00:43 â€¢ 0:00:37[0m [2;4m2.54it/s[0m  
[2KStep 0 - TTA Loss: 1.4312â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 111/203 [2m0:00:43 â€¢ 0:00:37[0m [2;4m2.54it/s[0m  
[2KAttention weights: tensor([[0.5758, 0.4242]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 111/203 [2m0:00:43 â€¢ 0:00:37[0m [2;4m2.54it/s[0m  
[2KAttention weights: tensor([[0.5763, 0.4237]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 111/203 [2m0:00:43 â€¢ 0:00:37[0m [2;4m2.54it/s[0m  
[2KAttention weights: tensor([[0.5782, 0.4218]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 111/203 [2m0:00:43 â€¢ 0:00:37[0m [2;4m2.54it/s[0m  
[2KAttention weights: tensor([[0.5823, 0.4177]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 111/203 [2m0:00:43 â€¢ 0:00:37[0m [2;4m2.54it/s[0m  
[2KAttention weights: tensor([[0.5894, 0.4106]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 111/203 [2m0:00:43 â€¢ 0:00:37[0m [2;4m2.54it/s[0m  
[2KAttention weights: tensor([[0.5989, 0.4011]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 111/203 [2m0:00:43 â€¢ 0:00:37[0m [2;4m2.54it/s[0m  
[2KAttention weights: tensor([[0.6140, 0.3860]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 111/203 [2m0:00:43 â€¢ 0:00:37[0m [2;4m2.54it/s[0m  
[2KAttention weights: tensor([[0.6293, 0.3707]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 111/203 [2m0:00:43 â€¢ 0:00:37[0m [2;4m2.54it/s[0m  
[2KAttention weights: tensor([[0.6500, 0.3500]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 111/203 [2m0:00:43 â€¢ 0:00:37[0m [2;4m2.54it/s[0m  
[2KAttention weights: tensor([[0.5264, 0.4736]], device='cuda:0')[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 111/203 [2m0:00:43 â€¢ 0:00:37[0m [2;4m2.54it/s[0m  
[2KAttention weights: tensor([[0.6490, 0.3510],m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 111/203 [2m0:00:43 â€¢ 0:00:37[0m [2;4m2.54it/s[0m  
        [0.4501, 0.5499],
        [0.5192, 0.4808],
        [0.6437, 0.3563],
        [0.6708, 0.3292],
        [0.7872, 0.2128],
        [0.7235, 0.2765],
        [0.6534, 0.3466],
        [0.5537, 0.4463],
[2K        [0.6713, 0.3287]], device='cuda:0')0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 111/203 [2m0:00:43 â€¢ 0:00:37[0m [2;4m2.54it/s[0m  
[2KAttention weights: tensor([[0.5223, 0.4777],â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 112/203 [2m0:00:43 â€¢ 0:00:36[0m [2;4m2.54it/s[0m   
        [0.5138, 0.4862],
        [0.5158, 0.4842],
        [0.5215, 0.4785],
        [0.5234, 0.4766],
        [0.5261, 0.4739],
        [0.5234, 0.4766],
        [0.5203, 0.4797],
        [0.5174, 0.4826],
[2K        [0.5235, 0.4765]], device='cuda:0', grad_fn=<SoftmaxBackward0>)7mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 112/203 [2m0:00:43 â€¢ 0:00:36[0m [2;4m2.54it/s[0m  
[2KClass label: GolfSwingâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 112/203 [2m0:00:43 â€¢ 0:00:36[0m [2;4m2.54it/s[0m  
[2KAttention weights: tensor([[0.6014, 0.3986]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 112/203 [2m0:00:43 â€¢ 0:00:36[0m [2;4m2.54it/s[0m  
[2KStep 0 - TTA Loss: 1.0272â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 112/203 [2m0:00:43 â€¢ 0:00:36[0m [2;4m2.54it/s[0m  
[2KAttention weights: tensor([[0.6101, 0.3899]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 112/203 [2m0:00:43 â€¢ 0:00:36[0m [2;4m2.54it/s[0m  
[2KAttention weights: tensor([[0.6244, 0.3756]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 112/203 [2m0:00:43 â€¢ 0:00:36[0m [2;4m2.54it/s[0m  
[2KAttention weights: tensor([[0.6370, 0.3630]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 112/203 [2m0:00:43 â€¢ 0:00:36[0m [2;4m2.54it/s[0m  
[2KAttention weights: tensor([[0.6524, 0.3476]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 112/203 [2m0:00:43 â€¢ 0:00:36[0m [2;4m2.54it/s[0m  
[2KAttention weights: tensor([[0.6679, 0.3321]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 112/203 [2m0:00:43 â€¢ 0:00:36[0m [2;4m2.54it/s[0m  
[2KAttention weights: tensor([[0.6804, 0.3196]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 112/203 [2m0:00:43 â€¢ 0:00:36[0m [2;4m2.54it/s[0m  
[2KAttention weights: tensor([[0.6876, 0.3124]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 112/203 [2m0:00:43 â€¢ 0:00:36[0m [2;4m2.54it/s[0m  
[2KAttention weights: tensor([[0.6912, 0.3088]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 112/203 [2m0:00:43 â€¢ 0:00:36[0m [2;4m2.54it/s[0m  
[2KAttention weights: tensor([[0.6924, 0.3076]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 112/203 [2m0:00:43 â€¢ 0:00:36[0m [2;4m2.54it/s[0m  
[2KAttention weights: tensor([[0.5255, 0.4745]], device='cuda:0')[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 112/203 [2m0:00:43 â€¢ 0:00:36[0m [2;4m2.54it/s[0m  
[2KAttention weights: tensor([[0.6592, 0.3408],0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 112/203 [2m0:00:43 â€¢ 0:00:36[0m [2;4m2.54it/s[0m  
        [0.4659, 0.5341],
        [0.5283, 0.4717],
        [0.6932, 0.3068],
        [0.6801, 0.3199],
        [0.7737, 0.2263],
        [0.7185, 0.2815],
        [0.6460, 0.3540],
        [0.5596, 0.4404],
[2K        [0.6801, 0.3199]], device='cuda:0')[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 112/203 [2m0:00:43 â€¢ 0:00:36[0m [2;4m2.54it/s[0m  
[2KAttention weights: tensor([[0.5223, 0.4777],â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 113/203 [2m0:00:43 â€¢ 0:00:36[0m [2;4m2.54it/s[0m  
        [0.5139, 0.4861],
        [0.5158, 0.4842],
        [0.5215, 0.4785],
        [0.5235, 0.4765],
        [0.5262, 0.4738],
        [0.5234, 0.4766],
        [0.5203, 0.4797],
        [0.5175, 0.4825],
[2K        [0.5235, 0.4765]], device='cuda:0', grad_fn=<SoftmaxBackward0>)7mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 113/203 [2m0:00:43 â€¢ 0:00:36[0m [2;4m2.54it/s[0m  
[2KClass label: TennisSwingâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 113/203 [2m0:00:43 â€¢ 0:00:36[0m [2;4m2.54it/s[0m  
[2KAttention weights: tensor([[0.5198, 0.4802]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 113/203 [2m0:00:43 â€¢ 0:00:36[0m [2;4m2.54it/s[0m  
[2KStep 0 - TTA Loss: 0.6563â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 113/203 [2m0:00:43 â€¢ 0:00:36[0m [2;4m2.54it/s[0m  
[2KAttention weights: tensor([[0.5198, 0.4802]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 113/203 [2m0:00:43 â€¢ 0:00:36[0m [2;4m2.54it/s[0m  
[2KAttention weights: tensor([[0.5198, 0.4802]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 113/203 [2m0:00:43 â€¢ 0:00:36[0m [2;4m2.54it/s[0m  
[2KAttention weights: tensor([[0.5197, 0.4803]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 113/203 [2m0:00:43 â€¢ 0:00:36[0m [2;4m2.54it/s[0m  
[2KAttention weights: tensor([[0.5192, 0.4808]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 113/203 [2m0:00:43 â€¢ 0:00:36[0m [2;4m2.54it/s[0m  
[2KAttention weights: tensor([[0.5179, 0.4821]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 113/203 [2m0:00:43 â€¢ 0:00:36[0m [2;4m2.54it/s[0m  
[2KAttention weights: tensor([[0.5158, 0.4842]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 113/203 [2m0:00:43 â€¢ 0:00:36[0m [2;4m2.54it/s[0m  
[2KAttention weights: tensor([[0.5124, 0.4876]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 113/203 [2m0:00:43 â€¢ 0:00:36[0m [2;4m2.54it/s[0m  
[2KAttention weights: tensor([[0.5082, 0.4918]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 113/203 [2m0:00:43 â€¢ 0:00:36[0m [2;4m2.54it/s[0m  
[2KAttention weights: tensor([[0.5048, 0.4952]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 113/203 [2m0:00:43 â€¢ 0:00:36[0m [2;4m2.54it/s[0m  
[2KAttention weights: tensor([[0.5168, 0.4832]], device='cuda:0')[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 113/203 [2m0:00:43 â€¢ 0:00:36[0m [2;4m2.54it/s[0m  
[2KAttention weights: tensor([[0.6114, 0.3886],0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 113/203 [2m0:00:43 â€¢ 0:00:36[0m [2;4m2.54it/s[0m  
        [0.4501, 0.5499],
        [0.4968, 0.5032],
        [0.6229, 0.3771],
        [0.5996, 0.4004],
        [0.6989, 0.3011],
        [0.6575, 0.3425],
        [0.6077, 0.3923],
        [0.5009, 0.4991],
[2K        [0.6007, 0.3993]], device='cuda:0')[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 113/203 [2m0:00:43 â€¢ 0:00:36[0m [2;4m2.54it/s[0m  
[2KAttention weights: tensor([[0.5223, 0.4777],â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 114/203 [2m0:00:44 â€¢ 0:00:36[0m [2;4m2.54it/s[0m  
        [0.5139, 0.4861],
        [0.5158, 0.4842],
        [0.5215, 0.4785],
        [0.5235, 0.4765],
        [0.5262, 0.4738],
        [0.5234, 0.4766],
        [0.5203, 0.4797],
        [0.5175, 0.4825],
[2K        [0.5235, 0.4765]], device='cuda:0', grad_fn=<SoftmaxBackward0>)7mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 114/203 [2m0:00:44 â€¢ 0:00:36[0m [2;4m2.54it/s[0m  
[2KClass label: HammerThrowâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 114/203 [2m0:00:44 â€¢ 0:00:36[0m [2;4m2.54it/s[0m  
[2KAttention weights: tensor([[0.5846, 0.4154]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 114/203 [2m0:00:44 â€¢ 0:00:36[0m [2;4m2.54it/s[0m  
[2KStep 0 - TTA Loss: 1.1991â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 114/203 [2m0:00:44 â€¢ 0:00:36[0m [2;4m2.54it/s[0m  
[2KAttention weights: tensor([[0.5861, 0.4139]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 114/203 [2m0:00:44 â€¢ 0:00:36[0m [2;4m2.54it/s[0m  
[2KAttention weights: tensor([[0.5834, 0.4166]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 114/203 [2m0:00:44 â€¢ 0:00:36[0m [2;4m2.54it/s[0m  
[2KAttention weights: tensor([[0.5784, 0.4216]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 114/203 [2m0:00:44 â€¢ 0:00:36[0m [2;4m2.54it/s[0m  
[2KAttention weights: tensor([[0.5729, 0.4271]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 114/203 [2m0:00:44 â€¢ 0:00:36[0m [2;4m2.54it/s[0m  
[2KAttention weights: tensor([[0.5692, 0.4308]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 114/203 [2m0:00:44 â€¢ 0:00:36[0m [2;4m2.54it/s[0m  
[2KAttention weights: tensor([[0.5708, 0.4292]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 114/203 [2m0:00:44 â€¢ 0:00:36[0m [2;4m2.54it/s[0m  
[2KAttention weights: tensor([[0.5751, 0.4249]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 114/203 [2m0:00:44 â€¢ 0:00:36[0m [2;4m2.54it/s[0m  
[2KAttention weights: tensor([[0.5779, 0.4221]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 114/203 [2m0:00:44 â€¢ 0:00:36[0m [2;4m2.54it/s[0m  
[2KAttention weights: tensor([[0.5789, 0.4211]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 114/203 [2m0:00:44 â€¢ 0:00:36[0m [2;4m2.54it/s[0m  
[2KAttention weights: tensor([[0.5238, 0.4762]], device='cuda:0')[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 114/203 [2m0:00:44 â€¢ 0:00:36[0m [2;4m2.54it/s[0m  
[2KAttention weights: tensor([[0.6031, 0.3969],0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 114/203 [2m0:00:44 â€¢ 0:00:36[0m [2;4m2.54it/s[0m  
        [0.4467, 0.5533],
        [0.4938, 0.5062],
        [0.6089, 0.3911],
        [0.5793, 0.4207],
        [0.6931, 0.3069],
        [0.6471, 0.3529],
        [0.6066, 0.3934],
        [0.5113, 0.4887],
[2K        [0.5880, 0.4120]], device='cuda:0')[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 114/203 [2m0:00:44 â€¢ 0:00:36[0m [2;4m2.54it/s[0m  
[2KAttention weights: tensor([[0.5223, 0.4777],â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 115/203 [2m0:00:44 â€¢ 0:00:35[0m [2;4m2.55it/s[0m  
        [0.5139, 0.4861],
        [0.5158, 0.4842],
        [0.5215, 0.4785],
        [0.5235, 0.4765],
        [0.5262, 0.4738],
        [0.5234, 0.4766],
        [0.5203, 0.4797],
        [0.5175, 0.4825],
[2K        [0.5235, 0.4765]], device='cuda:0', grad_fn=<SoftmaxBackward0>);5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 115/203 [2m0:00:44 â€¢ 0:00:35[0m [2;4m2.55it/s[0m  
[2KClass label: HammerThrowâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 115/203 [2m0:00:44 â€¢ 0:00:35[0m [2;4m2.55it/s[0m  
[2KAttention weights: tensor([[0.5825, 0.4175]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 115/203 [2m0:00:44 â€¢ 0:00:35[0m [2;4m2.55it/s[0m  
[2KStep 0 - TTA Loss: 1.2347â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 115/203 [2m0:00:44 â€¢ 0:00:35[0m [2;4m2.55it/s[0m  
[2KAttention weights: tensor([[0.5825, 0.4175]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 115/203 [2m0:00:44 â€¢ 0:00:35[0m [2;4m2.55it/s[0m  
[2KAttention weights: tensor([[0.5827, 0.4173]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 115/203 [2m0:00:44 â€¢ 0:00:35[0m [2;4m2.55it/s[0m  
[2KAttention weights: tensor([[0.5835, 0.4165]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 115/203 [2m0:00:44 â€¢ 0:00:35[0m [2;4m2.55it/s[0m  
[2KAttention weights: tensor([[0.5850, 0.4150]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 115/203 [2m0:00:44 â€¢ 0:00:35[0m [2;4m2.55it/s[0m  
[2KAttention weights: tensor([[0.5872, 0.4128]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 115/203 [2m0:00:44 â€¢ 0:00:35[0m [2;4m2.55it/s[0m  
[2KAttention weights: tensor([[0.5895, 0.4105]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 115/203 [2m0:00:44 â€¢ 0:00:35[0m [2;4m2.55it/s[0m  
[2KAttention weights: tensor([[0.5926, 0.4074]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 115/203 [2m0:00:44 â€¢ 0:00:35[0m [2;4m2.55it/s[0m  
[2KAttention weights: tensor([[0.5960, 0.4040]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 115/203 [2m0:00:44 â€¢ 0:00:35[0m [2;4m2.55it/s[0m  
[2KAttention weights: tensor([[0.5993, 0.4007]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 115/203 [2m0:00:44 â€¢ 0:00:35[0m [2;4m2.55it/s[0m  
[2KAttention weights: tensor([[0.5247, 0.4753]], device='cuda:0')â•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 115/203 [2m0:00:44 â€¢ 0:00:35[0m [2;4m2.55it/s[0m  
[2KAttention weights: tensor([[0.6163, 0.3837],0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 115/203 [2m0:00:44 â€¢ 0:00:35[0m [2;4m2.55it/s[0m  
        [0.4454, 0.5546],
        [0.5049, 0.4951],
        [0.6156, 0.3844],
        [0.6018, 0.3982],
        [0.7030, 0.2970],
        [0.6573, 0.3427],
        [0.6142, 0.3858],
        [0.5213, 0.4787],
[2K        [0.6028, 0.3972]], device='cuda:0')[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 115/203 [2m0:00:44 â€¢ 0:00:35[0m [2;4m2.55it/s[0m  
[2KAttention weights: tensor([[0.5224, 0.4776],â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 116/203 [2m0:00:45 â€¢ 0:00:35[0m [2;4m2.54it/s[0m  
        [0.5139, 0.4861],
        [0.5158, 0.4842],
        [0.5215, 0.4785],
        [0.5235, 0.4765],
        [0.5262, 0.4738],
        [0.5234, 0.4766],
        [0.5203, 0.4797],
        [0.5175, 0.4825],
[2K        [0.5235, 0.4765]], device='cuda:0', grad_fn=<SoftmaxBackward0>);5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 116/203 [2m0:00:45 â€¢ 0:00:35[0m [2;4m2.54it/s[0m  
[2KClass label: HammerThrowâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 116/203 [2m0:00:45 â€¢ 0:00:35[0m [2;4m2.54it/s[0m  
[2KAttention weights: tensor([[0.5745, 0.4255]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 116/203 [2m0:00:45 â€¢ 0:00:35[0m [2;4m2.54it/s[0m  
[2KStep 0 - TTA Loss: 1.9147â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 116/203 [2m0:00:45 â€¢ 0:00:35[0m [2;4m2.54it/s[0m  
[2KAttention weights: tensor([[0.5908, 0.4092]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 116/203 [2m0:00:45 â€¢ 0:00:35[0m [2;4m2.54it/s[0m  
[2KAttention weights: tensor([[0.6031, 0.3969]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 116/203 [2m0:00:45 â€¢ 0:00:35[0m [2;4m2.54it/s[0m  
[2KAttention weights: tensor([[0.6225, 0.3775]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 116/203 [2m0:00:45 â€¢ 0:00:35[0m [2;4m2.54it/s[0m  
[2KAttention weights: tensor([[0.6415, 0.3585]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 116/203 [2m0:00:45 â€¢ 0:00:35[0m [2;4m2.54it/s[0m  
[2KAttention weights: tensor([[0.6626, 0.3374]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 116/203 [2m0:00:45 â€¢ 0:00:35[0m [2;4m2.54it/s[0m  
[2KAttention weights: tensor([[0.6786, 0.3214]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 116/203 [2m0:00:45 â€¢ 0:00:35[0m [2;4m2.54it/s[0m  
[2KAttention weights: tensor([[0.6906, 0.3094]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 116/203 [2m0:00:45 â€¢ 0:00:35[0m [2;4m2.54it/s[0m  
[2KAttention weights: tensor([[0.6974, 0.3026]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 116/203 [2m0:00:45 â€¢ 0:00:35[0m [2;4m2.54it/s[0m  
[2KAttention weights: tensor([[0.7004, 0.2996]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 116/203 [2m0:00:45 â€¢ 0:00:35[0m [2;4m2.54it/s[0m  
[2KAttention weights: tensor([[0.5283, 0.4717]], device='cuda:0')â•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 116/203 [2m0:00:45 â€¢ 0:00:35[0m [2;4m2.54it/s[0m  
[2KAttention weights: tensor([[0.6658, 0.3342],0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 116/203 [2m0:00:45 â€¢ 0:00:35[0m [2;4m2.54it/s[0m  
        [0.4587, 0.5413],
        [0.5261, 0.4739],
        [0.6566, 0.3434],
        [0.7014, 0.2986],
        [0.7514, 0.2486],
        [0.7053, 0.2947],
        [0.6384, 0.3616],
        [0.5418, 0.4582],
[2K        [0.6804, 0.3196]], device='cuda:0')[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 116/203 [2m0:00:45 â€¢ 0:00:35[0m [2;4m2.54it/s[0m  
[2KAttention weights: tensor([[0.5224, 0.4776],â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 117/203 [2m0:00:45 â€¢ 0:00:34[0m [2;4m2.54it/s[0m   
        [0.5139, 0.4861],
        [0.5158, 0.4842],
        [0.5215, 0.4785],
        [0.5235, 0.4765],
        [0.5262, 0.4738],
        [0.5234, 0.4766],
        [0.5203, 0.4797],
        [0.5175, 0.4825],
[2K        [0.5235, 0.4765]], device='cuda:0', grad_fn=<SoftmaxBackward0>)37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 117/203 [2m0:00:45 â€¢ 0:00:34[0m [2;4m2.54it/s[0m  
[2KClass label: HammerThrowâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 117/203 [2m0:00:45 â€¢ 0:00:34[0m [2;4m2.54it/s[0m  
[2KAttention weights: tensor([[0.5811, 0.4189]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 117/203 [2m0:00:45 â€¢ 0:00:34[0m [2;4m2.54it/s[0m  
[2KStep 0 - TTA Loss: 1.6556â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 117/203 [2m0:00:45 â€¢ 0:00:34[0m [2;4m2.54it/s[0m  
[2KAttention weights: tensor([[0.5811, 0.4189]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 117/203 [2m0:00:45 â€¢ 0:00:34[0m [2;4m2.54it/s[0m  
[2KAttention weights: tensor([[0.5821, 0.4179]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 117/203 [2m0:00:45 â€¢ 0:00:34[0m [2;4m2.54it/s[0m  
[2KAttention weights: tensor([[0.5863, 0.4137]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 117/203 [2m0:00:45 â€¢ 0:00:34[0m [2;4m2.54it/s[0m  
[2KAttention weights: tensor([[0.5959, 0.4041]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 117/203 [2m0:00:45 â€¢ 0:00:34[0m [2;4m2.54it/s[0m  
[2KAttention weights: tensor([[0.6134, 0.3866]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 117/203 [2m0:00:45 â€¢ 0:00:34[0m [2;4m2.54it/s[0m  
[2KAttention weights: tensor([[0.6366, 0.3634]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 117/203 [2m0:00:45 â€¢ 0:00:34[0m [2;4m2.54it/s[0m  
[2KAttention weights: tensor([[0.6644, 0.3356]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 117/203 [2m0:00:45 â€¢ 0:00:34[0m [2;4m2.54it/s[0m  
[2KAttention weights: tensor([[0.7038, 0.2962]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 117/203 [2m0:00:45 â€¢ 0:00:34[0m [2;4m2.54it/s[0m  
[2KAttention weights: tensor([[0.7358, 0.2642]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 117/203 [2m0:00:45 â€¢ 0:00:34[0m [2;4m2.54it/s[0m  
[2KAttention weights: tensor([[0.5304, 0.4696]], device='cuda:0')m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 117/203 [2m0:00:45 â€¢ 0:00:34[0m [2;4m2.54it/s[0m  
[2KAttention weights: tensor([[0.6914, 0.3086],[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 117/203 [2m0:00:45 â€¢ 0:00:34[0m [2;4m2.54it/s[0m  
        [0.4653, 0.5347],
        [0.5378, 0.4622],
        [0.6859, 0.3141],
        [0.7565, 0.2435],
        [0.7812, 0.2188],
        [0.7347, 0.2653],
        [0.6587, 0.3413],
        [0.5586, 0.4414],
[2K        [0.7259, 0.2741]], device='cuda:0')[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 117/203 [2m0:00:45 â€¢ 0:00:34[0m [2;4m2.54it/s[0m  
[2KAttention weights: tensor([[0.5224, 0.4776],â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 118/203 [2m0:00:46 â€¢ 0:00:34[0m [2;4m2.54it/s[0m  
        [0.5139, 0.4861],
        [0.5159, 0.4841],
        [0.5215, 0.4785],
        [0.5236, 0.4764],
        [0.5262, 0.4738],
        [0.5235, 0.4765],
        [0.5203, 0.4797],
        [0.5175, 0.4825],
[2K        [0.5236, 0.4764]], device='cuda:0', grad_fn=<SoftmaxBackward0>)37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 118/203 [2m0:00:46 â€¢ 0:00:34[0m [2;4m2.54it/s[0m  
[2KClass label: Billiardsâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 118/203 [2m0:00:46 â€¢ 0:00:34[0m [2;4m2.54it/s[0m  
[2KAttention weights: tensor([[0.4474, 0.5526]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 118/203 [2m0:00:46 â€¢ 0:00:34[0m [2;4m2.54it/s[0m  
[2KStep 0 - TTA Loss: 0.7646â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 118/203 [2m0:00:46 â€¢ 0:00:34[0m [2;4m2.54it/s[0m  
[2KAttention weights: tensor([[0.4481, 0.5519]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 118/203 [2m0:00:46 â€¢ 0:00:34[0m [2;4m2.54it/s[0m  
[2KAttention weights: tensor([[0.4477, 0.5523]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 118/203 [2m0:00:46 â€¢ 0:00:34[0m [2;4m2.54it/s[0m  
[2KAttention weights: tensor([[0.4473, 0.5527]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 118/203 [2m0:00:46 â€¢ 0:00:34[0m [2;4m2.54it/s[0m  
[2KAttention weights: tensor([[0.4468, 0.5532]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 118/203 [2m0:00:46 â€¢ 0:00:34[0m [2;4m2.54it/s[0m  
[2KAttention weights: tensor([[0.4459, 0.5541]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 118/203 [2m0:00:46 â€¢ 0:00:34[0m [2;4m2.54it/s[0m  
[2KAttention weights: tensor([[0.4450, 0.5550]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 118/203 [2m0:00:46 â€¢ 0:00:34[0m [2;4m2.54it/s[0m  
[2KAttention weights: tensor([[0.4443, 0.5557]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 118/203 [2m0:00:46 â€¢ 0:00:34[0m [2;4m2.54it/s[0m  
[2KAttention weights: tensor([[0.4438, 0.5562]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 118/203 [2m0:00:46 â€¢ 0:00:34[0m [2;4m2.54it/s[0m  
[2KAttention weights: tensor([[0.4436, 0.5564]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 118/203 [2m0:00:46 â€¢ 0:00:34[0m [2;4m2.54it/s[0m  
[2KAttention weights: tensor([[0.5137, 0.4863]], device='cuda:0')m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 118/203 [2m0:00:46 â€¢ 0:00:34[0m [2;4m2.54it/s[0m  
[2KAttention weights: tensor([[0.6485, 0.3515],[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 118/203 [2m0:00:46 â€¢ 0:00:34[0m [2;4m2.54it/s[0m  
        [0.4435, 0.5565],
        [0.5172, 0.4828],
        [0.6418, 0.3582],
        [0.6760, 0.3240],
        [0.7394, 0.2606],
        [0.6909, 0.3091],
        [0.6306, 0.3694],
        [0.5387, 0.4613],
[2K        [0.6597, 0.3403]], device='cuda:0')[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 118/203 [2m0:00:46 â€¢ 0:00:34[0m [2;4m2.54it/s[0m  
[2KAttention weights: tensor([[0.5224, 0.4776],â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 119/203 [2m0:00:46 â€¢ 0:00:34[0m [2;4m2.54it/s[0m  
        [0.5139, 0.4861],
        [0.5159, 0.4841],
        [0.5215, 0.4785],
        [0.5236, 0.4764],
        [0.5262, 0.4738],
        [0.5235, 0.4765],
        [0.5203, 0.4797],
        [0.5175, 0.4825],
[2K        [0.5236, 0.4764]], device='cuda:0', grad_fn=<SoftmaxBackward0>)37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 119/203 [2m0:00:46 â€¢ 0:00:34[0m [2;4m2.54it/s[0m  
[2KClass label: HammerThrowâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 119/203 [2m0:00:46 â€¢ 0:00:34[0m [2;4m2.54it/s[0m  
[2KAttention weights: tensor([[0.5797, 0.4203]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 119/203 [2m0:00:46 â€¢ 0:00:34[0m [2;4m2.54it/s[0m  
[2KStep 0 - TTA Loss: 1.2139â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 119/203 [2m0:00:46 â€¢ 0:00:34[0m [2;4m2.54it/s[0m  
[2KAttention weights: tensor([[0.5797, 0.4203]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 119/203 [2m0:00:46 â€¢ 0:00:34[0m [2;4m2.54it/s[0m  
[2KAttention weights: tensor([[0.5798, 0.4202]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 119/203 [2m0:00:46 â€¢ 0:00:34[0m [2;4m2.54it/s[0m  
[2KAttention weights: tensor([[0.5795, 0.4205]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 119/203 [2m0:00:46 â€¢ 0:00:34[0m [2;4m2.54it/s[0m  
[2KAttention weights: tensor([[0.5790, 0.4210]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 119/203 [2m0:00:46 â€¢ 0:00:34[0m [2;4m2.54it/s[0m  
[2KAttention weights: tensor([[0.5784, 0.4216]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 119/203 [2m0:00:46 â€¢ 0:00:34[0m [2;4m2.54it/s[0m  
[2KAttention weights: tensor([[0.5765, 0.4235]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 119/203 [2m0:00:46 â€¢ 0:00:34[0m [2;4m2.54it/s[0m  
[2KAttention weights: tensor([[0.5733, 0.4267]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 119/203 [2m0:00:46 â€¢ 0:00:34[0m [2;4m2.54it/s[0m  
[2KAttention weights: tensor([[0.5672, 0.4328]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 119/203 [2m0:00:46 â€¢ 0:00:34[0m [2;4m2.54it/s[0m  
[2KAttention weights: tensor([[0.5601, 0.4399]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 119/203 [2m0:00:46 â€¢ 0:00:34[0m [2;4m2.54it/s[0m  
[2KAttention weights: tensor([[0.5229, 0.4771]], device='cuda:0')m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 119/203 [2m0:00:46 â€¢ 0:00:34[0m [2;4m2.54it/s[0m  
[2KAttention weights: tensor([[0.5884, 0.4116],[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 119/203 [2m0:00:46 â€¢ 0:00:34[0m [2;4m2.54it/s[0m  
        [0.4366, 0.5634],
        [0.4879, 0.5121],
        [0.5924, 0.4076],
        [0.5520, 0.4480],
        [0.6765, 0.3235],
        [0.6274, 0.3726],
        [0.6008, 0.3992],
        [0.5078, 0.4922],
[2K        [0.5661, 0.4339]], device='cuda:0')[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 119/203 [2m0:00:46 â€¢ 0:00:34[0m [2;4m2.54it/s[0m  
[2KAttention weights: tensor([[0.5224, 0.4776],â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 120/203 [2m0:00:46 â€¢ 0:00:33[0m [2;4m2.54it/s[0m  
        [0.5139, 0.4861],
        [0.5159, 0.4841],
        [0.5216, 0.4784],
        [0.5236, 0.4764],
        [0.5262, 0.4738],
        [0.5235, 0.4765],
        [0.5204, 0.4796],
        [0.5175, 0.4825],
[2K        [0.5236, 0.4764]], device='cuda:0', grad_fn=<SoftmaxBackward0>)8;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 120/203 [2m0:00:46 â€¢ 0:00:33[0m [2;4m2.54it/s[0m  
[2KClass label: SoccerPenaltyâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 120/203 [2m0:00:46 â€¢ 0:00:33[0m [2;4m2.54it/s[0m  
[2KAttention weights: tensor([[0.6108, 0.3892]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 120/203 [2m0:00:46 â€¢ 0:00:33[0m [2;4m2.54it/s[0m  
[2KStep 0 - TTA Loss: 2.6259â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 120/203 [2m0:00:46 â€¢ 0:00:33[0m [2;4m2.54it/s[0m  
[2KAttention weights: tensor([[0.6144, 0.3856]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 120/203 [2m0:00:46 â€¢ 0:00:33[0m [2;4m2.54it/s[0m  
[2KAttention weights: tensor([[0.6232, 0.3768]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 120/203 [2m0:00:46 â€¢ 0:00:33[0m [2;4m2.54it/s[0m  
[2KAttention weights: tensor([[0.6390, 0.3610]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 120/203 [2m0:00:46 â€¢ 0:00:33[0m [2;4m2.54it/s[0m  
[2KAttention weights: tensor([[0.6534, 0.3466]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 120/203 [2m0:00:46 â€¢ 0:00:33[0m [2;4m2.54it/s[0m  
[2KAttention weights: tensor([[0.6651, 0.3349]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 120/203 [2m0:00:46 â€¢ 0:00:33[0m [2;4m2.54it/s[0m  
[2KAttention weights: tensor([[0.6758, 0.3242]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 120/203 [2m0:00:46 â€¢ 0:00:33[0m [2;4m2.54it/s[0m  
[2KAttention weights: tensor([[0.6824, 0.3176]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 120/203 [2m0:00:46 â€¢ 0:00:33[0m [2;4m2.54it/s[0m  
[2KAttention weights: tensor([[0.6856, 0.3144]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 120/203 [2m0:00:46 â€¢ 0:00:33[0m [2;4m2.54it/s[0m  
[2KAttention weights: tensor([[0.6871, 0.3129]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 120/203 [2m0:00:46 â€¢ 0:00:33[0m [2;4m2.54it/s[0m  
[2KAttention weights: tensor([[0.5227, 0.4773]], device='cuda:0')mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 120/203 [2m0:00:46 â€¢ 0:00:33[0m [2;4m2.54it/s[0m  
[2KAttention weights: tensor([[0.5910, 0.4090],[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 120/203 [2m0:00:46 â€¢ 0:00:33[0m [2;4m2.54it/s[0m  
        [0.4468, 0.5532],
        [0.4952, 0.5048],
        [0.6021, 0.3979],
        [0.5733, 0.4267],
        [0.7022, 0.2978],
        [0.6507, 0.3493],
        [0.6875, 0.3125],
        [0.5226, 0.4774],
[2K        [0.5758, 0.4242]], device='cuda:0')[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 120/203 [2m0:00:46 â€¢ 0:00:33[0m [2;4m2.54it/s[0m  
[2KAttention weights: tensor([[0.5225, 0.4775],â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 121/203 [2m0:00:47 â€¢ 0:00:33[0m [2;4m2.55it/s[0m  
        [0.5140, 0.4860],
        [0.5159, 0.4841],
        [0.5216, 0.4784],
        [0.5237, 0.4763],
        [0.5263, 0.4737],
        [0.5236, 0.4764],
        [0.5205, 0.4795],
        [0.5176, 0.4824],
[2K        [0.5237, 0.4763]], device='cuda:0', grad_fn=<SoftmaxBackward0>)8;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 121/203 [2m0:00:47 â€¢ 0:00:33[0m [2;4m2.55it/s[0m  
[2KClass label: SoccerPenaltyâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 121/203 [2m0:00:47 â€¢ 0:00:33[0m [2;4m2.55it/s[0m  
[2KAttention weights: tensor([[0.6074, 0.3926]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 121/203 [2m0:00:47 â€¢ 0:00:33[0m [2;4m2.55it/s[0m  
[2KStep 0 - TTA Loss: 1.5706â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 121/203 [2m0:00:47 â€¢ 0:00:33[0m [2;4m2.55it/s[0m  
[2KAttention weights: tensor([[0.6074, 0.3926]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 121/203 [2m0:00:47 â€¢ 0:00:33[0m [2;4m2.55it/s[0m  
[2KAttention weights: tensor([[0.6081, 0.3919]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 121/203 [2m0:00:47 â€¢ 0:00:33[0m [2;4m2.55it/s[0m  
[2KAttention weights: tensor([[0.6114, 0.3886]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 121/203 [2m0:00:47 â€¢ 0:00:33[0m [2;4m2.55it/s[0m  
[2KAttention weights: tensor([[0.6174, 0.3826]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 121/203 [2m0:00:47 â€¢ 0:00:33[0m [2;4m2.55it/s[0m  
[2KAttention weights: tensor([[0.6322, 0.3678]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 121/203 [2m0:00:47 â€¢ 0:00:33[0m [2;4m2.55it/s[0m  
[2KAttention weights: tensor([[0.6614, 0.3386]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 121/203 [2m0:00:47 â€¢ 0:00:33[0m [2;4m2.55it/s[0m  
[2KAttention weights: tensor([[0.6961, 0.3039]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 121/203 [2m0:00:47 â€¢ 0:00:33[0m [2;4m2.55it/s[0m  
[2KAttention weights: tensor([[0.7363, 0.2637]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 121/203 [2m0:00:47 â€¢ 0:00:33[0m [2;4m2.55it/s[0m  
[2KAttention weights: tensor([[0.7712, 0.2288]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 121/203 [2m0:00:47 â€¢ 0:00:33[0m [2;4m2.55it/s[0m  
[2KAttention weights: tensor([[0.5275, 0.4725]], device='cuda:0')mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 121/203 [2m0:00:47 â€¢ 0:00:33[0m [2;4m2.55it/s[0m  
[2KAttention weights: tensor([[0.6067, 0.3933],[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 121/203 [2m0:00:47 â€¢ 0:00:33[0m [2;4m2.55it/s[0m  
        [0.4715, 0.5285],
        [0.5048, 0.4952],
        [0.6343, 0.3657],
        [0.6269, 0.3731],
        [0.7467, 0.2533],
        [0.6905, 0.3095],
        [0.8039, 0.1961],
        [0.5567, 0.4433],
[2K        [0.6142, 0.3858]], device='cuda:0')[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 121/203 [2m0:00:47 â€¢ 0:00:33[0m [2;4m2.55it/s[0m  
[2KAttention weights: tensor([[0.5225, 0.4775],â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 122/203 [2m0:00:47 â€¢ 0:00:32[0m [2;4m2.56it/s[0m   
        [0.5140, 0.4860],
        [0.5160, 0.4840],
        [0.5216, 0.4784],
        [0.5238, 0.4762],
        [0.5263, 0.4737],
        [0.5236, 0.4764],
        [0.5205, 0.4795],
        [0.5176, 0.4824],
[2K        [0.5237, 0.4763]], device='cuda:0', grad_fn=<SoftmaxBackward0>)237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 122/203 [2m0:00:47 â€¢ 0:00:32[0m [2;4m2.56it/s[0m  
[2KClass label: SoccerPenaltyâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 122/203 [2m0:00:47 â€¢ 0:00:32[0m [2;4m2.56it/s[0m  
[2KAttention weights: tensor([[0.6066, 0.3934]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 122/203 [2m0:00:47 â€¢ 0:00:32[0m [2;4m2.56it/s[0m  
[2KStep 0 - TTA Loss: 2.2353â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 122/203 [2m0:00:47 â€¢ 0:00:32[0m [2;4m2.56it/s[0m  
[2KAttention weights: tensor([[0.6595, 0.3405]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 122/203 [2m0:00:47 â€¢ 0:00:32[0m [2;4m2.56it/s[0m  
[2KAttention weights: tensor([[0.7130, 0.2870]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 122/203 [2m0:00:47 â€¢ 0:00:32[0m [2;4m2.56it/s[0m  
[2KAttention weights: tensor([[0.7577, 0.2423]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 122/203 [2m0:00:47 â€¢ 0:00:32[0m [2;4m2.56it/s[0m  
[2KAttention weights: tensor([[0.7959, 0.2041]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 122/203 [2m0:00:47 â€¢ 0:00:32[0m [2;4m2.56it/s[0m  
[2KAttention weights: tensor([[0.8203, 0.1797]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 122/203 [2m0:00:47 â€¢ 0:00:32[0m [2;4m2.56it/s[0m  
[2KAttention weights: tensor([[0.8353, 0.1647]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 122/203 [2m0:00:47 â€¢ 0:00:32[0m [2;4m2.56it/s[0m  
[2KAttention weights: tensor([[0.8452, 0.1548]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 122/203 [2m0:00:47 â€¢ 0:00:32[0m [2;4m2.56it/s[0m  
[2KAttention weights: tensor([[0.8501, 0.1499]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 122/203 [2m0:00:47 â€¢ 0:00:32[0m [2;4m2.56it/s[0m  
[2KAttention weights: tensor([[0.8523, 0.1477]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 122/203 [2m0:00:47 â€¢ 0:00:32[0m [2;4m2.56it/s[0m  
[2KAttention weights: tensor([[0.5283, 0.4717]], device='cuda:0')0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 122/203 [2m0:00:47 â€¢ 0:00:32[0m [2;4m2.56it/s[0m  
[2KAttention weights: tensor([[0.6068, 0.3932],[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 122/203 [2m0:00:47 â€¢ 0:00:32[0m [2;4m2.56it/s[0m  
        [0.4855, 0.5145],
        [0.5133, 0.4867],
        [0.6408, 0.3592],
        [0.6490, 0.3510],
        [0.7620, 0.2380],
        [0.7055, 0.2945],
        [0.8529, 0.1471],
        [0.5698, 0.4302],
[2K        [0.6268, 0.3732]], device='cuda:0')â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 122/203 [2m0:00:47 â€¢ 0:00:32[0m [2;4m2.56it/s[0m  
[2KAttention weights: tensor([[0.5226, 0.4774],â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 123/203 [2m0:00:47 â€¢ 0:00:32[0m [2;4m2.56it/s[0m  
        [0.5141, 0.4859],
        [0.5160, 0.4839],
        [0.5217, 0.4783],
        [0.5238, 0.4762],
        [0.5264, 0.4736],
        [0.5237, 0.4763],
        [0.5207, 0.4793],
        [0.5177, 0.4823],
[2K        [0.5238, 0.4762]], device='cuda:0', grad_fn=<SoftmaxBackward0>)237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 123/203 [2m0:00:47 â€¢ 0:00:32[0m [2;4m2.56it/s[0m  
[2KClass label: TennisSwingâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 123/203 [2m0:00:47 â€¢ 0:00:32[0m [2;4m2.56it/s[0m  
[2KAttention weights: tensor([[0.5151, 0.4849]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 123/203 [2m0:00:47 â€¢ 0:00:32[0m [2;4m2.56it/s[0m  
[2KStep 0 - TTA Loss: 0.9412â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 123/203 [2m0:00:47 â€¢ 0:00:32[0m [2;4m2.56it/s[0m  
[2KAttention weights: tensor([[0.5151, 0.4849]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 123/203 [2m0:00:47 â€¢ 0:00:32[0m [2;4m2.56it/s[0m  
[2KAttention weights: tensor([[0.5151, 0.4849]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 123/203 [2m0:00:47 â€¢ 0:00:32[0m [2;4m2.56it/s[0m  
[2KAttention weights: tensor([[0.5161, 0.4839]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 123/203 [2m0:00:47 â€¢ 0:00:32[0m [2;4m2.56it/s[0m  
[2KAttention weights: tensor([[0.5186, 0.4814]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 123/203 [2m0:00:47 â€¢ 0:00:32[0m [2;4m2.56it/s[0m  
[2KAttention weights: tensor([[0.5252, 0.4748]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 123/203 [2m0:00:47 â€¢ 0:00:32[0m [2;4m2.56it/s[0m  
[2KAttention weights: tensor([[0.5331, 0.4669]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 123/203 [2m0:00:47 â€¢ 0:00:32[0m [2;4m2.56it/s[0m  
[2KAttention weights: tensor([[0.5401, 0.4599]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 123/203 [2m0:00:47 â€¢ 0:00:32[0m [2;4m2.56it/s[0m  
[2KAttention weights: tensor([[0.5518, 0.4482]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 123/203 [2m0:00:47 â€¢ 0:00:32[0m [2;4m2.56it/s[0m  
[2KAttention weights: tensor([[0.5601, 0.4399]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 123/203 [2m0:00:47 â€¢ 0:00:32[0m [2;4m2.56it/s[0m  
[2KAttention weights: tensor([[0.5193, 0.4807]], device='cuda:0')0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 123/203 [2m0:00:47 â€¢ 0:00:32[0m [2;4m2.56it/s[0m  
[2KAttention weights: tensor([[0.6132, 0.3868],[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 123/203 [2m0:00:47 â€¢ 0:00:32[0m [2;4m2.56it/s[0m  
        [0.4588, 0.5412],
        [0.5048, 0.4952],
        [0.6185, 0.3815],
        [0.6081, 0.3919],
        [0.7176, 0.2824],
        [0.6641, 0.3359],
        [0.6859, 0.3141],
        [0.5689, 0.4311],
[2K        [0.6112, 0.3888]], device='cuda:0')â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 123/203 [2m0:00:47 â€¢ 0:00:32[0m [2;4m2.56it/s[0m  
[2KAttention weights: tensor([[0.5226, 0.4774],â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 124/203 [2m0:00:48 â€¢ 0:00:31[0m [2;4m2.57it/s[0m  
        [0.5141, 0.4859],
        [0.5161, 0.4839],
        [0.5217, 0.4783],
        [0.5238, 0.4762],
        [0.5264, 0.4736],
        [0.5237, 0.4763],
        [0.5207, 0.4793],
        [0.5177, 0.4823],
[2K        [0.5238, 0.4762]], device='cuda:0', grad_fn=<SoftmaxBackward0>)237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 124/203 [2m0:00:48 â€¢ 0:00:31[0m [2;4m2.57it/s[0m  
[2KClass label: SoccerPenaltyâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 124/203 [2m0:00:48 â€¢ 0:00:31[0m [2;4m2.57it/s[0m  
[2KAttention weights: tensor([[0.6061, 0.3939]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 124/203 [2m0:00:48 â€¢ 0:00:31[0m [2;4m2.57it/s[0m  
[2KStep 0 - TTA Loss: 1.4772â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 124/203 [2m0:00:48 â€¢ 0:00:31[0m [2;4m2.57it/s[0m  
[2KAttention weights: tensor([[0.6243, 0.3757]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 124/203 [2m0:00:48 â€¢ 0:00:31[0m [2;4m2.57it/s[0m  
[2KAttention weights: tensor([[0.6410, 0.3590]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 124/203 [2m0:00:48 â€¢ 0:00:31[0m [2;4m2.57it/s[0m  
[2KAttention weights: tensor([[0.6553, 0.3447]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 124/203 [2m0:00:48 â€¢ 0:00:31[0m [2;4m2.57it/s[0m  
[2KAttention weights: tensor([[0.6862, 0.3138]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 124/203 [2m0:00:48 â€¢ 0:00:31[0m [2;4m2.57it/s[0m  
[2KAttention weights: tensor([[0.7119, 0.2881]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 124/203 [2m0:00:48 â€¢ 0:00:31[0m [2;4m2.57it/s[0m  
[2KAttention weights: tensor([[0.7251, 0.2749]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 124/203 [2m0:00:48 â€¢ 0:00:31[0m [2;4m2.57it/s[0m  
[2KAttention weights: tensor([[0.7345, 0.2655]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 124/203 [2m0:00:48 â€¢ 0:00:31[0m [2;4m2.57it/s[0m  
[2KAttention weights: tensor([[0.7356, 0.2644]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 124/203 [2m0:00:48 â€¢ 0:00:31[0m [2;4m2.57it/s[0m  
[2KAttention weights: tensor([[0.7367, 0.2633]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 124/203 [2m0:00:48 â€¢ 0:00:31[0m [2;4m2.57it/s[0m  
[2KAttention weights: tensor([[0.5254, 0.4746]], device='cuda:0')0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 124/203 [2m0:00:48 â€¢ 0:00:31[0m [2;4m2.57it/s[0m  
[2KAttention weights: tensor([[0.6135, 0.3865],[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 124/203 [2m0:00:48 â€¢ 0:00:31[0m [2;4m2.57it/s[0m  
        [0.4624, 0.5376],
        [0.5103, 0.4897],
        [0.6292, 0.3708],
        [0.6192, 0.3808],
        [0.7297, 0.2703],
        [0.6796, 0.3204],
        [0.7369, 0.2631],
        [0.5634, 0.4366],
[2K        [0.6174, 0.3826]], device='cuda:0')â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 124/203 [2m0:00:48 â€¢ 0:00:31[0m [2;4m2.57it/s[0m  
[2KAttention weights: tensor([[0.5227, 0.4773],â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 125/203 [2m0:00:48 â€¢ 0:00:31[0m [2;4m2.57it/s[0m  
        [0.5141, 0.4859],
        [0.5161, 0.4839],
        [0.5218, 0.4782],
        [0.5239, 0.4761],
        [0.5264, 0.4736],
        [0.5237, 0.4763],
        [0.5207, 0.4793],
        [0.5177, 0.4823],
[2K        [0.5238, 0.4762]], device='cuda:0', grad_fn=<SoftmaxBackward0>)38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 125/203 [2m0:00:48 â€¢ 0:00:31[0m [2;4m2.57it/s[0m  
[2KClass label: Billiardsâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 125/203 [2m0:00:48 â€¢ 0:00:31[0m [2;4m2.57it/s[0m  
[2KAttention weights: tensor([[0.4469, 0.5531]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 125/203 [2m0:00:48 â€¢ 0:00:31[0m [2;4m2.57it/s[0m  
[2KStep 0 - TTA Loss: 1.7714â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 125/203 [2m0:00:48 â€¢ 0:00:31[0m [2;4m2.57it/s[0m  
[2KAttention weights: tensor([[0.4469, 0.5531]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 125/203 [2m0:00:48 â€¢ 0:00:31[0m [2;4m2.57it/s[0m  
[2KAttention weights: tensor([[0.4471, 0.5529]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 125/203 [2m0:00:48 â€¢ 0:00:31[0m [2;4m2.57it/s[0m  
[2KAttention weights: tensor([[0.4479, 0.5521]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 125/203 [2m0:00:48 â€¢ 0:00:31[0m [2;4m2.57it/s[0m  
[2KAttention weights: tensor([[0.4495, 0.5505]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 125/203 [2m0:00:48 â€¢ 0:00:31[0m [2;4m2.57it/s[0m  
[2KAttention weights: tensor([[0.4525, 0.5475]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 125/203 [2m0:00:48 â€¢ 0:00:31[0m [2;4m2.57it/s[0m  
[2KAttention weights: tensor([[0.4565, 0.5435]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 125/203 [2m0:00:48 â€¢ 0:00:31[0m [2;4m2.57it/s[0m  
[2KAttention weights: tensor([[0.4643, 0.5357]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 125/203 [2m0:00:48 â€¢ 0:00:31[0m [2;4m2.57it/s[0m  
[2KAttention weights: tensor([[0.4766, 0.5234]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 125/203 [2m0:00:48 â€¢ 0:00:31[0m [2;4m2.57it/s[0m  
[2KAttention weights: tensor([[0.4899, 0.5101]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 125/203 [2m0:00:48 â€¢ 0:00:31[0m [2;4m2.57it/s[0m  
[2KAttention weights: tensor([[0.5162, 0.4838]], device='cuda:0')4mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 125/203 [2m0:00:48 â€¢ 0:00:31[0m [2;4m2.57it/s[0m  
[2KAttention weights: tensor([[0.6069, 0.3931],[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 125/203 [2m0:00:48 â€¢ 0:00:31[0m [2;4m2.57it/s[0m  
        [0.5054, 0.4946],
        [0.4982, 0.5018],
        [0.6176, 0.3824],
        [0.5852, 0.4148],
        [0.6906, 0.3094],
        [0.6426, 0.3574],
        [0.6237, 0.3763],
        [0.5280, 0.4720],
[2K        [0.5918, 0.4082]], device='cuda:0')â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 125/203 [2m0:00:48 â€¢ 0:00:31[0m [2;4m2.57it/s[0m  
[2KAttention weights: tensor([[0.5226, 0.4774],â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 126/203 [2m0:00:49 â€¢ 0:00:30[0m [2;4m2.57it/s[0m  
        [0.5141, 0.4859],
        [0.5161, 0.4839],
        [0.5217, 0.4783],
        [0.5239, 0.4761],
        [0.5264, 0.4736],
        [0.5237, 0.4763],
        [0.5207, 0.4793],
        [0.5177, 0.4823],
[2K        [0.5238, 0.4762]], device='cuda:0', grad_fn=<SoftmaxBackward0>)38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 126/203 [2m0:00:49 â€¢ 0:00:30[0m [2;4m2.57it/s[0m  
[2KClass label: BaseballPitchâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 126/203 [2m0:00:49 â€¢ 0:00:30[0m [2;4m2.57it/s[0m  
[2KAttention weights: tensor([[0.5972, 0.4028]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 126/203 [2m0:00:49 â€¢ 0:00:30[0m [2;4m2.57it/s[0m  
[2KStep 0 - TTA Loss: 1.4900â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 126/203 [2m0:00:49 â€¢ 0:00:30[0m [2;4m2.57it/s[0m  
[2KAttention weights: tensor([[0.6074, 0.3926]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 126/203 [2m0:00:49 â€¢ 0:00:30[0m [2;4m2.57it/s[0m  
[2KAttention weights: tensor([[0.6286, 0.3714]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 126/203 [2m0:00:49 â€¢ 0:00:30[0m [2;4m2.57it/s[0m  
[2KAttention weights: tensor([[0.6460, 0.3540]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 126/203 [2m0:00:49 â€¢ 0:00:30[0m [2;4m2.57it/s[0m  
[2KAttention weights: tensor([[0.6598, 0.3402]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 126/203 [2m0:00:49 â€¢ 0:00:30[0m [2;4m2.57it/s[0m  
[2KAttention weights: tensor([[0.6667, 0.3333]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 126/203 [2m0:00:49 â€¢ 0:00:30[0m [2;4m2.57it/s[0m  
[2KAttention weights: tensor([[0.6707, 0.3293]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 126/203 [2m0:00:49 â€¢ 0:00:30[0m [2;4m2.57it/s[0m  
[2KAttention weights: tensor([[0.6743, 0.3257]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 126/203 [2m0:00:49 â€¢ 0:00:30[0m [2;4m2.57it/s[0m  
[2KAttention weights: tensor([[0.6768, 0.3232]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 126/203 [2m0:00:49 â€¢ 0:00:30[0m [2;4m2.57it/s[0m  
[2KAttention weights: tensor([[0.6781, 0.3219]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 126/203 [2m0:00:49 â€¢ 0:00:30[0m [2;4m2.57it/s[0m  
[2KAttention weights: tensor([[0.5260, 0.4740]], device='cuda:0')4mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 126/203 [2m0:00:49 â€¢ 0:00:30[0m [2;4m2.57it/s[0m  
[2KAttention weights: tensor([[0.6789, 0.3211],[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 126/203 [2m0:00:49 â€¢ 0:00:30[0m [2;4m2.57it/s[0m  
        [0.5121, 0.4879],
        [0.5087, 0.4913],
        [0.6377, 0.3623],
        [0.6161, 0.3839],
        [0.7096, 0.2904],
        [0.6640, 0.3360],
        [0.6217, 0.3783],
        [0.5407, 0.4593],
[2K        [0.6236, 0.3764]], device='cuda:0')â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 126/203 [2m0:00:49 â€¢ 0:00:30[0m [2;4m2.57it/s[0m  
[2KAttention weights: tensor([[0.5226, 0.4774],â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 127/203 [2m0:00:49 â€¢ 0:00:30[0m [2;4m2.57it/s[0m   
        [0.5141, 0.4859],
        [0.5161, 0.4839],
        [0.5217, 0.4783],
        [0.5239, 0.4761],
        [0.5264, 0.4736],
        [0.5237, 0.4763],
        [0.5207, 0.4793],
        [0.5177, 0.4823],
[2K        [0.5238, 0.4762]], device='cuda:0', grad_fn=<SoftmaxBackward0>);237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 127/203 [2m0:00:49 â€¢ 0:00:30[0m [2;4m2.57it/s[0m  
[2KClass label: HammerThrowâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 127/203 [2m0:00:49 â€¢ 0:00:30[0m [2;4m2.57it/s[0m  
[2KAttention weights: tensor([[0.5841, 0.4159]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 127/203 [2m0:00:49 â€¢ 0:00:30[0m [2;4m2.57it/s[0m  
[2KStep 0 - TTA Loss: 1.5765â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 127/203 [2m0:00:49 â€¢ 0:00:30[0m [2;4m2.57it/s[0m  
[2KAttention weights: tensor([[0.5841, 0.4159]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 127/203 [2m0:00:49 â€¢ 0:00:30[0m [2;4m2.57it/s[0m  
[2KAttention weights: tensor([[0.5847, 0.4153]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 127/203 [2m0:00:49 â€¢ 0:00:30[0m [2;4m2.57it/s[0m  
[2KAttention weights: tensor([[0.5872, 0.4128]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 127/203 [2m0:00:49 â€¢ 0:00:30[0m [2;4m2.57it/s[0m  
[2KAttention weights: tensor([[0.5957, 0.4043]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 127/203 [2m0:00:49 â€¢ 0:00:30[0m [2;4m2.57it/s[0m  
[2KAttention weights: tensor([[0.6088, 0.3912]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 127/203 [2m0:00:49 â€¢ 0:00:30[0m [2;4m2.57it/s[0m  
[2KAttention weights: tensor([[0.6253, 0.3747]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 127/203 [2m0:00:49 â€¢ 0:00:30[0m [2;4m2.57it/s[0m  
[2KAttention weights: tensor([[0.6418, 0.3582]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 127/203 [2m0:00:49 â€¢ 0:00:30[0m [2;4m2.57it/s[0m  
[2KAttention weights: tensor([[0.6776, 0.3224]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 127/203 [2m0:00:49 â€¢ 0:00:30[0m [2;4m2.57it/s[0m  
[2KAttention weights: tensor([[0.7105, 0.2895]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 127/203 [2m0:00:49 â€¢ 0:00:30[0m [2;4m2.57it/s[0m  
[2KAttention weights: tensor([[0.5291, 0.4709]], device='cuda:0')[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 127/203 [2m0:00:49 â€¢ 0:00:30[0m [2;4m2.57it/s[0m  
[2KAttention weights: tensor([[0.7023, 0.2977],â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 127/203 [2m0:00:49 â€¢ 0:00:30[0m [2;4m2.57it/s[0m  
        [0.4772, 0.5228],
        [0.5409, 0.4591],
        [0.6824, 0.3176],
        [0.7387, 0.2613],
        [0.7710, 0.2290],
        [0.7223, 0.2777],
        [0.6505, 0.3495],
        [0.5667, 0.4333],
[2K        [0.7150, 0.2850]], device='cuda:0')â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 127/203 [2m0:00:49 â€¢ 0:00:30[0m [2;4m2.57it/s[0m  
[2KAttention weights: tensor([[0.5227, 0.4773],â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 128/203 [2m0:00:49 â€¢ 0:00:30[0m [2;4m2.57it/s[0m  
        [0.5141, 0.4859],
        [0.5161, 0.4839],
        [0.5218, 0.4782],
        [0.5239, 0.4761],
        [0.5265, 0.4735],
        [0.5237, 0.4763],
        [0.5207, 0.4793],
        [0.5178, 0.4822],
[2K        [0.5238, 0.4762]], device='cuda:0', grad_fn=<SoftmaxBackward0>);237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 128/203 [2m0:00:49 â€¢ 0:00:30[0m [2;4m2.57it/s[0m  
[2KClass label: Billiardsâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 128/203 [2m0:00:49 â€¢ 0:00:30[0m [2;4m2.57it/s[0m  
[2KAttention weights: tensor([[0.4461, 0.5539]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 128/203 [2m0:00:49 â€¢ 0:00:30[0m [2;4m2.57it/s[0m  
[2KStep 0 - TTA Loss: 1.3845â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 128/203 [2m0:00:49 â€¢ 0:00:30[0m [2;4m2.57it/s[0m  
[2KAttention weights: tensor([[0.4478, 0.5522]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 128/203 [2m0:00:49 â€¢ 0:00:30[0m [2;4m2.57it/s[0m  
[2KAttention weights: tensor([[0.4538, 0.5462]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 128/203 [2m0:00:49 â€¢ 0:00:30[0m [2;4m2.57it/s[0m  
[2KAttention weights: tensor([[0.4581, 0.5419]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 128/203 [2m0:00:49 â€¢ 0:00:30[0m [2;4m2.57it/s[0m  
[2KAttention weights: tensor([[0.4565, 0.5435]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 128/203 [2m0:00:49 â€¢ 0:00:30[0m [2;4m2.57it/s[0m  
[2KAttention weights: tensor([[0.4561, 0.5439]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 128/203 [2m0:00:49 â€¢ 0:00:30[0m [2;4m2.57it/s[0m  
[2KAttention weights: tensor([[0.4545, 0.5455]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 128/203 [2m0:00:49 â€¢ 0:00:30[0m [2;4m2.57it/s[0m  
[2KAttention weights: tensor([[0.4531, 0.5469]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 128/203 [2m0:00:49 â€¢ 0:00:30[0m [2;4m2.57it/s[0m  
[2KAttention weights: tensor([[0.4521, 0.5479]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 128/203 [2m0:00:49 â€¢ 0:00:30[0m [2;4m2.57it/s[0m  
[2KAttention weights: tensor([[0.4517, 0.5483]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 128/203 [2m0:00:49 â€¢ 0:00:30[0m [2;4m2.57it/s[0m  
[2KAttention weights: tensor([[0.5143, 0.4857]], device='cuda:0')[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 128/203 [2m0:00:49 â€¢ 0:00:30[0m [2;4m2.57it/s[0m  
[2KAttention weights: tensor([[0.6773, 0.3227],â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 128/203 [2m0:00:49 â€¢ 0:00:30[0m [2;4m2.57it/s[0m  
        [0.4516, 0.5484],
        [0.5308, 0.4692],
        [0.6581, 0.3419],
        [0.7016, 0.2984],
        [0.7538, 0.2462],
        [0.7054, 0.2946],
        [0.6431, 0.3569],
        [0.5516, 0.4484],
[2K        [0.6825, 0.3175]], device='cuda:0')â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 128/203 [2m0:00:49 â€¢ 0:00:30[0m [2;4m2.57it/s[0m  
[2KAttention weights: tensor([[0.5227, 0.4773],â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 129/203 [2m0:00:50 â€¢ 0:00:29[0m [2;4m2.57it/s[0m  
        [0.5141, 0.4859],
        [0.5161, 0.4839],
        [0.5218, 0.4782],
        [0.5240, 0.4760],
        [0.5265, 0.4735],
        [0.5238, 0.4762],
        [0.5207, 0.4793],
        [0.5178, 0.4822],
[2K        [0.5239, 0.4761]], device='cuda:0', grad_fn=<SoftmaxBackward0>);237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 129/203 [2m0:00:50 â€¢ 0:00:29[0m [2;4m2.57it/s[0m  
[2KClass label: Billiardsâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 129/203 [2m0:00:50 â€¢ 0:00:29[0m [2;4m2.57it/s[0m  
[2KAttention weights: tensor([[0.4442, 0.5558]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 129/203 [2m0:00:50 â€¢ 0:00:29[0m [2;4m2.57it/s[0m  
[2KStep 0 - TTA Loss: 0.5712â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 129/203 [2m0:00:50 â€¢ 0:00:29[0m [2;4m2.57it/s[0m  
[2KAttention weights: tensor([[0.4442, 0.5558]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 129/203 [2m0:00:50 â€¢ 0:00:29[0m [2;4m2.57it/s[0m  
[2KAttention weights: tensor([[0.4441, 0.5559]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 129/203 [2m0:00:50 â€¢ 0:00:29[0m [2;4m2.57it/s[0m  
[2KAttention weights: tensor([[0.4444, 0.5556]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 129/203 [2m0:00:50 â€¢ 0:00:29[0m [2;4m2.57it/s[0m  
[2KAttention weights: tensor([[0.4447, 0.5553]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 129/203 [2m0:00:50 â€¢ 0:00:29[0m [2;4m2.57it/s[0m  
[2KAttention weights: tensor([[0.4446, 0.5554]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 129/203 [2m0:00:50 â€¢ 0:00:29[0m [2;4m2.57it/s[0m  
[2KAttention weights: tensor([[0.4444, 0.5556]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 129/203 [2m0:00:50 â€¢ 0:00:29[0m [2;4m2.57it/s[0m  
[2KAttention weights: tensor([[0.4440, 0.5560]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 129/203 [2m0:00:50 â€¢ 0:00:29[0m [2;4m2.57it/s[0m  
[2KAttention weights: tensor([[0.4434, 0.5566]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 129/203 [2m0:00:50 â€¢ 0:00:29[0m [2;4m2.57it/s[0m  
[2KAttention weights: tensor([[0.4425, 0.5575]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 129/203 [2m0:00:50 â€¢ 0:00:29[0m [2;4m2.57it/s[0m  
[2KAttention weights: tensor([[0.5139, 0.4861]], device='cuda:0')[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 129/203 [2m0:00:50 â€¢ 0:00:29[0m [2;4m2.57it/s[0m  
[2KAttention weights: tensor([[0.6177, 0.3823],â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 129/203 [2m0:00:50 â€¢ 0:00:29[0m [2;4m2.57it/s[0m  
        [0.4415, 0.5585],
        [0.4985, 0.5015],
        [0.6090, 0.3910],
        [0.6022, 0.3978],
        [0.7000, 0.3000],
        [0.6532, 0.3468],
        [0.6141, 0.3859],
        [0.5229, 0.4771],
[2K        [0.6040, 0.3960]], device='cuda:0')â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 129/203 [2m0:00:50 â€¢ 0:00:29[0m [2;4m2.57it/s[0m  
[2KAttention weights: tensor([[0.5227, 0.4773],â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 130/203 [2m0:00:50 â€¢ 0:00:29[0m [2;4m2.58it/s[0m  
        [0.5141, 0.4859],
        [0.5161, 0.4839],
        [0.5218, 0.4782],
        [0.5240, 0.4760],
        [0.5265, 0.4735],
        [0.5238, 0.4762],
        [0.5207, 0.4793],
        [0.5178, 0.4822],
[2K        [0.5239, 0.4761]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 130/203 [2m0:00:50 â€¢ 0:00:29[0m [2;4m2.58it/s[0m  
[2KClass label: ThrowDiscusâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 130/203 [2m0:00:50 â€¢ 0:00:29[0m [2;4m2.58it/s[0m  
[2KAttention weights: tensor([[0.5849, 0.4151]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 130/203 [2m0:00:50 â€¢ 0:00:29[0m [2;4m2.58it/s[0m  
[2KStep 0 - TTA Loss: 2.5802â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 130/203 [2m0:00:50 â€¢ 0:00:29[0m [2;4m2.58it/s[0m  
[2KAttention weights: tensor([[0.6307, 0.3693]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 130/203 [2m0:00:50 â€¢ 0:00:29[0m [2;4m2.58it/s[0m  
[2KAttention weights: tensor([[0.6837, 0.3163]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 130/203 [2m0:00:50 â€¢ 0:00:29[0m [2;4m2.58it/s[0m  
[2KAttention weights: tensor([[0.7249, 0.2751]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 130/203 [2m0:00:50 â€¢ 0:00:29[0m [2;4m2.58it/s[0m  
[2KAttention weights: tensor([[0.7505, 0.2495]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 130/203 [2m0:00:50 â€¢ 0:00:29[0m [2;4m2.58it/s[0m  
[2KAttention weights: tensor([[0.7647, 0.2353]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 130/203 [2m0:00:50 â€¢ 0:00:29[0m [2;4m2.58it/s[0m  
[2KAttention weights: tensor([[0.7694, 0.2306]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 130/203 [2m0:00:50 â€¢ 0:00:29[0m [2;4m2.58it/s[0m  
[2KAttention weights: tensor([[0.7713, 0.2287]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 130/203 [2m0:00:50 â€¢ 0:00:29[0m [2;4m2.58it/s[0m  
[2KAttention weights: tensor([[0.7713, 0.2287]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 130/203 [2m0:00:50 â€¢ 0:00:29[0m [2;4m2.58it/s[0m  
[2KAttention weights: tensor([[0.7708, 0.2292]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 130/203 [2m0:00:50 â€¢ 0:00:29[0m [2;4m2.58it/s[0m  
[2KAttention weights: tensor([[0.5307, 0.4693]], device='cuda:0')24mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 130/203 [2m0:00:50 â€¢ 0:00:29[0m [2;4m2.58it/s[0m  
[2KAttention weights: tensor([[0.7050, 0.2950],â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 130/203 [2m0:00:50 â€¢ 0:00:29[0m [2;4m2.58it/s[0m  
        [0.4539, 0.5461],
        [0.5460, 0.4540],
        [0.6924, 0.3076],
        [0.7329, 0.2671],
        [0.7946, 0.2054],
        [0.7518, 0.2482],
        [0.6452, 0.3548],
        [0.5813, 0.4187],
[2K        [0.7711, 0.2289]], device='cuda:0')â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 130/203 [2m0:00:50 â€¢ 0:00:29[0m [2;4m2.58it/s[0m  
[2KAttention weights: tensor([[0.5227, 0.4773],â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 131/203 [2m0:00:50 â€¢ 0:00:28[0m [2;4m2.58it/s[0m  
        [0.5142, 0.4858],
        [0.5162, 0.4838],
        [0.5218, 0.4782],
        [0.5240, 0.4760],
        [0.5265, 0.4735],
        [0.5238, 0.4762],
        [0.5208, 0.4792],
        [0.5178, 0.4822],
[2K        [0.5240, 0.4760]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 131/203 [2m0:00:50 â€¢ 0:00:28[0m [2;4m2.58it/s[0m  
[2KClass label: CleanAndJerkâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 131/203 [2m0:00:50 â€¢ 0:00:28[0m [2;4m2.58it/s[0m  
[2KAttention weights: tensor([[0.4977, 0.5023]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 131/203 [2m0:00:50 â€¢ 0:00:28[0m [2;4m2.58it/s[0m  
[2KStep 0 - TTA Loss: 2.3488â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 131/203 [2m0:00:50 â€¢ 0:00:28[0m [2;4m2.58it/s[0m  
[2KAttention weights: tensor([[0.4977, 0.5023]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 131/203 [2m0:00:50 â€¢ 0:00:28[0m [2;4m2.58it/s[0m  
[2KAttention weights: tensor([[0.4979, 0.5021]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 131/203 [2m0:00:50 â€¢ 0:00:28[0m [2;4m2.58it/s[0m  
[2KAttention weights: tensor([[0.4993, 0.5007]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 131/203 [2m0:00:50 â€¢ 0:00:28[0m [2;4m2.58it/s[0m  
[2KAttention weights: tensor([[0.5041, 0.4959]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 131/203 [2m0:00:50 â€¢ 0:00:28[0m [2;4m2.58it/s[0m  
[2KAttention weights: tensor([[0.5136, 0.4864]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 131/203 [2m0:00:50 â€¢ 0:00:28[0m [2;4m2.58it/s[0m  
[2KAttention weights: tensor([[0.5263, 0.4737]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 131/203 [2m0:00:50 â€¢ 0:00:28[0m [2;4m2.58it/s[0m  
[2KAttention weights: tensor([[0.5403, 0.4597]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 131/203 [2m0:00:50 â€¢ 0:00:28[0m [2;4m2.58it/s[0m  
[2KAttention weights: tensor([[0.5659, 0.4341]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 131/203 [2m0:00:50 â€¢ 0:00:28[0m [2;4m2.58it/s[0m  
[2KAttention weights: tensor([[0.5878, 0.4122]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 131/203 [2m0:00:50 â€¢ 0:00:28[0m [2;4m2.58it/s[0m  
[2KAttention weights: tensor([[0.5194, 0.4806]], device='cuda:0')24mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 131/203 [2m0:00:50 â€¢ 0:00:28[0m [2;4m2.58it/s[0m  
[2KAttention weights: tensor([[0.5928, 0.4072],â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 131/203 [2m0:00:50 â€¢ 0:00:28[0m [2;4m2.58it/s[0m  
        [0.4465, 0.5535],
        [0.6158, 0.3842],
        [0.6078, 0.3922],
        [0.5687, 0.4313],
        [0.6785, 0.3215],
        [0.6387, 0.3613],
        [0.6077, 0.3923],
        [0.5152, 0.4848],
[2K        [0.5600, 0.4400]], device='cuda:0')â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 131/203 [2m0:00:50 â€¢ 0:00:28[0m [2;4m2.58it/s[0m  
[2KAttention weights: tensor([[0.5228, 0.4772],â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m 132/203 [2m0:00:51 â€¢ 0:00:28[0m [2;4m2.59it/s[0m   
        [0.5142, 0.4858],
        [0.5162, 0.4838],
        [0.5218, 0.4782],
        [0.5240, 0.4760],
        [0.5266, 0.4734],
        [0.5238, 0.4762],
        [0.5208, 0.4792],
        [0.5178, 0.4822],
[2K        [0.5240, 0.4760]], device='cuda:0', grad_fn=<SoftmaxBackward0>)5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m 132/203 [2m0:00:51 â€¢ 0:00:28[0m [2;4m2.59it/s[0m  
[2KClass label: Billiardsâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m 132/203 [2m0:00:51 â€¢ 0:00:28[0m [2;4m2.59it/s[0m  
[2KAttention weights: tensor([[0.4480, 0.5520]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 132/203 [2m0:00:51 â€¢ 0:00:28[0m [2;4m2.59it/s[0m  
[2KStep 0 - TTA Loss: 0.4102â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m 132/203 [2m0:00:51 â€¢ 0:00:28[0m [2;4m2.59it/s[0m  
[2KAttention weights: tensor([[0.4486, 0.5514]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 132/203 [2m0:00:51 â€¢ 0:00:28[0m [2;4m2.59it/s[0m  
[2KAttention weights: tensor([[0.4500, 0.5500]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 132/203 [2m0:00:51 â€¢ 0:00:28[0m [2;4m2.59it/s[0m  
[2KAttention weights: tensor([[0.4489, 0.5511]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 132/203 [2m0:00:51 â€¢ 0:00:28[0m [2;4m2.59it/s[0m  
[2KAttention weights: tensor([[0.4481, 0.5519]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 132/203 [2m0:00:51 â€¢ 0:00:28[0m [2;4m2.59it/s[0m  
[2KAttention weights: tensor([[0.4488, 0.5512]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 132/203 [2m0:00:51 â€¢ 0:00:28[0m [2;4m2.59it/s[0m  
[2KAttention weights: tensor([[0.4465, 0.5535]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 132/203 [2m0:00:51 â€¢ 0:00:28[0m [2;4m2.59it/s[0m  
[2KAttention weights: tensor([[0.4455, 0.5545]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 132/203 [2m0:00:51 â€¢ 0:00:28[0m [2;4m2.59it/s[0m  
[2KAttention weights: tensor([[0.4452, 0.5548]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 132/203 [2m0:00:51 â€¢ 0:00:28[0m [2;4m2.59it/s[0m  
[2KAttention weights: tensor([[0.4453, 0.5547]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 132/203 [2m0:00:51 â€¢ 0:00:28[0m [2;4m2.59it/s[0m  
[2KAttention weights: tensor([[0.5141, 0.4859]], device='cuda:0')[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m 132/203 [2m0:00:51 â€¢ 0:00:28[0m [2;4m2.59it/s[0m  
[2KAttention weights: tensor([[0.6054, 0.3946],â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m 132/203 [2m0:00:51 â€¢ 0:00:28[0m [2;4m2.59it/s[0m  
        [0.4452, 0.5548],
        [0.6065, 0.3935],
        [0.6104, 0.3896],
        [0.5764, 0.4236],
        [0.6857, 0.3143],
        [0.6446, 0.3554],
        [0.6069, 0.3931],
        [0.5204, 0.4796],
[2K        [0.5765, 0.4235]], device='cuda:0')â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m 132/203 [2m0:00:51 â€¢ 0:00:28[0m [2;4m2.59it/s[0m  
[2KAttention weights: tensor([[0.5228, 0.4772],â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m 133/203 [2m0:00:51 â€¢ 0:00:28[0m [2;4m2.59it/s[0m  
        [0.5142, 0.4858],
        [0.5163, 0.4837],
        [0.5218, 0.4782],
        [0.5241, 0.4759],
        [0.5266, 0.4734],
        [0.5238, 0.4762],
        [0.5208, 0.4792],
        [0.5178, 0.4822],
[2K        [0.5240, 0.4760]], device='cuda:0', grad_fn=<SoftmaxBackward0>)5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m 133/203 [2m0:00:51 â€¢ 0:00:28[0m [2;4m2.59it/s[0m  
[2KClass label: TennisSwingâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m 133/203 [2m0:00:51 â€¢ 0:00:28[0m [2;4m2.59it/s[0m  
[2KAttention weights: tensor([[0.5197, 0.4803]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 133/203 [2m0:00:51 â€¢ 0:00:28[0m [2;4m2.59it/s[0m  
[2KStep 0 - TTA Loss: 0.8220â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m 133/203 [2m0:00:51 â€¢ 0:00:28[0m [2;4m2.59it/s[0m  
[2KAttention weights: tensor([[0.5197, 0.4803]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 133/203 [2m0:00:51 â€¢ 0:00:28[0m [2;4m2.59it/s[0m  
[2KAttention weights: tensor([[0.5197, 0.4803]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 133/203 [2m0:00:51 â€¢ 0:00:28[0m [2;4m2.59it/s[0m  
[2KAttention weights: tensor([[0.5197, 0.4803]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 133/203 [2m0:00:51 â€¢ 0:00:28[0m [2;4m2.59it/s[0m  
[2KAttention weights: tensor([[0.5200, 0.4800]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 133/203 [2m0:00:51 â€¢ 0:00:28[0m [2;4m2.59it/s[0m  
[2KAttention weights: tensor([[0.5207, 0.4793]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 133/203 [2m0:00:51 â€¢ 0:00:28[0m [2;4m2.59it/s[0m  
[2KAttention weights: tensor([[0.5221, 0.4779]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 133/203 [2m0:00:51 â€¢ 0:00:28[0m [2;4m2.59it/s[0m  
[2KAttention weights: tensor([[0.5239, 0.4761]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 133/203 [2m0:00:51 â€¢ 0:00:28[0m [2;4m2.59it/s[0m  
[2KAttention weights: tensor([[0.5266, 0.4734]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 133/203 [2m0:00:51 â€¢ 0:00:28[0m [2;4m2.59it/s[0m  
[2KAttention weights: tensor([[0.5287, 0.4713]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 133/203 [2m0:00:51 â€¢ 0:00:28[0m [2;4m2.59it/s[0m  
[2KAttention weights: tensor([[0.5183, 0.4817]], device='cuda:0')[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m 133/203 [2m0:00:51 â€¢ 0:00:28[0m [2;4m2.59it/s[0m  
[2KAttention weights: tensor([[0.6073, 0.3927],â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m 133/203 [2m0:00:51 â€¢ 0:00:28[0m [2;4m2.59it/s[0m  
        [0.4409, 0.5591],
        [0.5189, 0.4811],
        [0.6108, 0.3892],
        [0.5839, 0.4161],
        [0.6960, 0.3040],
        [0.6480, 0.3520],
        [0.6131, 0.3869],
        [0.5315, 0.4685],
[2K        [0.5905, 0.4095]], device='cuda:0')â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m 133/203 [2m0:00:51 â€¢ 0:00:28[0m [2;4m2.59it/s[0m  
[2KAttention weights: tensor([[0.5228, 0.4772],â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m 134/203 [2m0:00:52 â€¢ 0:00:27[0m [2;4m2.59it/s[0m  
        [0.5142, 0.4858],
        [0.5163, 0.4837],
        [0.5219, 0.4781],
        [0.5241, 0.4759],
        [0.5266, 0.4734],
        [0.5239, 0.4761],
        [0.5208, 0.4792],
        [0.5179, 0.4821],
[2K        [0.5240, 0.4760]], device='cuda:0', grad_fn=<SoftmaxBackward0>)5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m 134/203 [2m0:00:52 â€¢ 0:00:27[0m [2;4m2.59it/s[0m  
[2KClass label: HammerThrowâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m 134/203 [2m0:00:52 â€¢ 0:00:27[0m [2;4m2.59it/s[0m  
[2KAttention weights: tensor([[0.5771, 0.4229]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 134/203 [2m0:00:52 â€¢ 0:00:27[0m [2;4m2.59it/s[0m  
[2KStep 0 - TTA Loss: 1.2418â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m 134/203 [2m0:00:52 â€¢ 0:00:27[0m [2;4m2.59it/s[0m  
[2KAttention weights: tensor([[0.5777, 0.4223]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 134/203 [2m0:00:52 â€¢ 0:00:27[0m [2;4m2.59it/s[0m  
[2KAttention weights: tensor([[0.5749, 0.4251]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 134/203 [2m0:00:52 â€¢ 0:00:27[0m [2;4m2.59it/s[0m  
[2KAttention weights: tensor([[0.5667, 0.4333]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 134/203 [2m0:00:52 â€¢ 0:00:27[0m [2;4m2.59it/s[0m  
[2KAttention weights: tensor([[0.5668, 0.4332]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 134/203 [2m0:00:52 â€¢ 0:00:27[0m [2;4m2.59it/s[0m  
[2KAttention weights: tensor([[0.5617, 0.4383]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 134/203 [2m0:00:52 â€¢ 0:00:27[0m [2;4m2.59it/s[0m  
[2KAttention weights: tensor([[0.5587, 0.4413]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 134/203 [2m0:00:52 â€¢ 0:00:27[0m [2;4m2.59it/s[0m  
[2KAttention weights: tensor([[0.5554, 0.4446]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 134/203 [2m0:00:52 â€¢ 0:00:27[0m [2;4m2.59it/s[0m  
[2KAttention weights: tensor([[0.5543, 0.4457]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 134/203 [2m0:00:52 â€¢ 0:00:27[0m [2;4m2.59it/s[0m  
[2KAttention weights: tensor([[0.5530, 0.4470]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 134/203 [2m0:00:52 â€¢ 0:00:27[0m [2;4m2.59it/s[0m  
[2KAttention weights: tensor([[0.5235, 0.4765]], device='cuda:0')[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m 134/203 [2m0:00:52 â€¢ 0:00:27[0m [2;4m2.59it/s[0m  
[2KAttention weights: tensor([[0.5940, 0.4060],â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m 134/203 [2m0:00:52 â€¢ 0:00:27[0m [2;4m2.59it/s[0m  
        [0.4431, 0.5569],
        [0.5048, 0.4952],
        [0.5959, 0.4041],
        [0.5527, 0.4473],
        [0.6779, 0.3221],
        [0.6282, 0.3718],
        [0.6055, 0.3945],
        [0.5262, 0.4738],
[2K        [0.5680, 0.4320]], device='cuda:0')â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m 134/203 [2m0:00:52 â€¢ 0:00:27[0m [2;4m2.59it/s[0m  
[2KAttention weights: tensor([[0.5228, 0.4772],â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m 135/203 [2m0:00:52 â€¢ 0:00:27[0m [2;4m2.59it/s[0m  
        [0.5142, 0.4858],
        [0.5163, 0.4837],
        [0.5219, 0.4781],
        [0.5241, 0.4759],
        [0.5266, 0.4734],
        [0.5239, 0.4761],
        [0.5208, 0.4792],
        [0.5179, 0.4821],
[2K        [0.5240, 0.4760]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m 135/203 [2m0:00:52 â€¢ 0:00:27[0m [2;4m2.59it/s[0m  
[2KClass label: CleanAndJerkâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m 135/203 [2m0:00:52 â€¢ 0:00:27[0m [2;4m2.59it/s[0m  
[2KAttention weights: tensor([[0.4977, 0.5023]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 135/203 [2m0:00:52 â€¢ 0:00:27[0m [2;4m2.59it/s[0m  
[2KStep 0 - TTA Loss: 0.8126â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m 135/203 [2m0:00:52 â€¢ 0:00:27[0m [2;4m2.59it/s[0m  
[2KAttention weights: tensor([[0.4977, 0.5023]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 135/203 [2m0:00:52 â€¢ 0:00:27[0m [2;4m2.59it/s[0m  
[2KAttention weights: tensor([[0.4976, 0.5024]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 135/203 [2m0:00:52 â€¢ 0:00:27[0m [2;4m2.59it/s[0m  
[2KAttention weights: tensor([[0.4971, 0.5029]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 135/203 [2m0:00:52 â€¢ 0:00:27[0m [2;4m2.59it/s[0m  
[2KAttention weights: tensor([[0.4960, 0.5040]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 135/203 [2m0:00:52 â€¢ 0:00:27[0m [2;4m2.59it/s[0m  
[2KAttention weights: tensor([[0.4934, 0.5066]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 135/203 [2m0:00:52 â€¢ 0:00:27[0m [2;4m2.59it/s[0m  
[2KAttention weights: tensor([[0.4873, 0.5127]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 135/203 [2m0:00:52 â€¢ 0:00:27[0m [2;4m2.59it/s[0m  
[2KAttention weights: tensor([[0.4796, 0.5204]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 135/203 [2m0:00:52 â€¢ 0:00:27[0m [2;4m2.59it/s[0m  
[2KAttention weights: tensor([[0.4714, 0.5286]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 135/203 [2m0:00:52 â€¢ 0:00:27[0m [2;4m2.59it/s[0m  
[2KAttention weights: tensor([[0.4607, 0.5393]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 135/203 [2m0:00:52 â€¢ 0:00:27[0m [2;4m2.59it/s[0m  
[2KAttention weights: tensor([[0.5146, 0.4854]], device='cuda:0')224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m 135/203 [2m0:00:52 â€¢ 0:00:27[0m [2;4m2.59it/s[0m  
[2KAttention weights: tensor([[0.5817, 0.4183],â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m 135/203 [2m0:00:52 â€¢ 0:00:27[0m [2;4m2.59it/s[0m  
        [0.4420, 0.5580],
        [0.4487, 0.5513],
        [0.5829, 0.4171],
        [0.5407, 0.4593],
        [0.6676, 0.3324],
        [0.6206, 0.3794],
        [0.6007, 0.3993],
        [0.5169, 0.4831],
[2K        [0.5551, 0.4449]], device='cuda:0')â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m 135/203 [2m0:00:52 â€¢ 0:00:27[0m [2;4m2.59it/s[0m  
[2KAttention weights: tensor([[0.5228, 0.4772],â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m 136/203 [2m0:00:52 â€¢ 0:00:26[0m [2;4m2.59it/s[0m  
        [0.5142, 0.4858],
        [0.5164, 0.4836],
        [0.5219, 0.4781],
        [0.5241, 0.4759],
        [0.5266, 0.4734],
        [0.5239, 0.4761],
        [0.5208, 0.4792],
        [0.5179, 0.4821],
[2K        [0.5240, 0.4760]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m 136/203 [2m0:00:52 â€¢ 0:00:26[0m [2;4m2.59it/s[0m  
[2KClass label: GolfSwingâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m 136/203 [2m0:00:52 â€¢ 0:00:26[0m [2;4m2.59it/s[0m  
[2KAttention weights: tensor([[0.6060, 0.3940]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 136/203 [2m0:00:52 â€¢ 0:00:26[0m [2;4m2.59it/s[0m  
[2KStep 0 - TTA Loss: 1.2487â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m 136/203 [2m0:00:52 â€¢ 0:00:26[0m [2;4m2.59it/s[0m  
[2KAttention weights: tensor([[0.5957, 0.4043]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 136/203 [2m0:00:52 â€¢ 0:00:26[0m [2;4m2.59it/s[0m  
[2KAttention weights: tensor([[0.5812, 0.4188]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 136/203 [2m0:00:52 â€¢ 0:00:26[0m [2;4m2.59it/s[0m  
[2KAttention weights: tensor([[0.5630, 0.4370]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 136/203 [2m0:00:52 â€¢ 0:00:26[0m [2;4m2.59it/s[0m  
[2KAttention weights: tensor([[0.5499, 0.4501]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 136/203 [2m0:00:52 â€¢ 0:00:26[0m [2;4m2.59it/s[0m  
[2KAttention weights: tensor([[0.5392, 0.4608]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 136/203 [2m0:00:52 â€¢ 0:00:26[0m [2;4m2.59it/s[0m  
[2KAttention weights: tensor([[0.5293, 0.4707]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 136/203 [2m0:00:52 â€¢ 0:00:26[0m [2;4m2.59it/s[0m  
[2KAttention weights: tensor([[0.5216, 0.4784]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 136/203 [2m0:00:52 â€¢ 0:00:26[0m [2;4m2.59it/s[0m  
[2KAttention weights: tensor([[0.5169, 0.4831]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 136/203 [2m0:00:52 â€¢ 0:00:26[0m [2;4m2.59it/s[0m  
[2KAttention weights: tensor([[0.5150, 0.4850]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 136/203 [2m0:00:52 â€¢ 0:00:26[0m [2;4m2.59it/s[0m  
[2KAttention weights: tensor([[0.5195, 0.4805]], device='cuda:0')224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m 136/203 [2m0:00:52 â€¢ 0:00:26[0m [2;4m2.59it/s[0m  
[2KAttention weights: tensor([[0.5664, 0.4336],â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m 136/203 [2m0:00:52 â€¢ 0:00:26[0m [2;4m2.59it/s[0m  
        [0.4301, 0.5699],
        [0.4370, 0.5630],
        [0.5145, 0.4855],
        [0.5266, 0.4734],
        [0.6616, 0.3384],
        [0.6120, 0.3880],
        [0.5947, 0.4053],
        [0.5028, 0.4972],
[2K        [0.5342, 0.4658]], device='cuda:0')â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m 136/203 [2m0:00:52 â€¢ 0:00:26[0m [2;4m2.59it/s[0m  
[2KAttention weights: tensor([[0.5228, 0.4772],â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m 137/203 [2m0:00:53 â€¢ 0:00:26[0m [2;4m2.59it/s[0m  
        [0.5142, 0.4858],
        [0.5164, 0.4836],
        [0.5219, 0.4781],
        [0.5242, 0.4758],
        [0.5266, 0.4734],
        [0.5239, 0.4761],
        [0.5208, 0.4792],
        [0.5179, 0.4821],
[2K        [0.5241, 0.4759]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m 137/203 [2m0:00:53 â€¢ 0:00:26[0m [2;4m2.59it/s[0m  
[2KClass label: SoccerPenaltyâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m 137/203 [2m0:00:53 â€¢ 0:00:26[0m [2;4m2.59it/s[0m  
[2KAttention weights: tensor([[0.6110, 0.3890]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 137/203 [2m0:00:53 â€¢ 0:00:26[0m [2;4m2.59it/s[0m  
[2KStep 0 - TTA Loss: 1.9793â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m 137/203 [2m0:00:53 â€¢ 0:00:26[0m [2;4m2.59it/s[0m  
[2KAttention weights: tensor([[0.6110, 0.3890]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 137/203 [2m0:00:53 â€¢ 0:00:26[0m [2;4m2.59it/s[0m  
[2KAttention weights: tensor([[0.6116, 0.3884]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 137/203 [2m0:00:53 â€¢ 0:00:26[0m [2;4m2.59it/s[0m  
[2KAttention weights: tensor([[0.6148, 0.3852]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 137/203 [2m0:00:53 â€¢ 0:00:26[0m [2;4m2.59it/s[0m  
[2KAttention weights: tensor([[0.6237, 0.3763]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 137/203 [2m0:00:53 â€¢ 0:00:26[0m [2;4m2.59it/s[0m  
[2KAttention weights: tensor([[0.6404, 0.3596]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 137/203 [2m0:00:53 â€¢ 0:00:26[0m [2;4m2.59it/s[0m  
[2KAttention weights: tensor([[0.6652, 0.3348]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 137/203 [2m0:00:53 â€¢ 0:00:26[0m [2;4m2.59it/s[0m  
[2KAttention weights: tensor([[0.7002, 0.2998]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 137/203 [2m0:00:53 â€¢ 0:00:26[0m [2;4m2.59it/s[0m  
[2KAttention weights: tensor([[0.7386, 0.2614]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 137/203 [2m0:00:53 â€¢ 0:00:26[0m [2;4m2.59it/s[0m  
[2KAttention weights: tensor([[0.7819, 0.2181]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 137/203 [2m0:00:53 â€¢ 0:00:26[0m [2;4m2.59it/s[0m  
[2KAttention weights: tensor([[0.5280, 0.4720]], device='cuda:0')224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m 137/203 [2m0:00:53 â€¢ 0:00:26[0m [2;4m2.59it/s[0m  
[2KAttention weights: tensor([[0.5925, 0.4075],â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m 137/203 [2m0:00:53 â€¢ 0:00:26[0m [2;4m2.59it/s[0m  
        [0.4726, 0.5274],
        [0.4913, 0.5087],
        [0.5947, 0.4053],
        [0.6229, 0.3771],
        [0.7449, 0.2551],
        [0.6843, 0.3157],
        [0.8152, 0.1848],
        [0.5557, 0.4443],
[2K        [0.6064, 0.3936]], device='cuda:0')â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m 137/203 [2m0:00:53 â€¢ 0:00:26[0m [2;4m2.59it/s[0m  
[2KAttention weights: tensor([[0.5229, 0.4771],â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”[0m 138/203 [2m0:00:53 â€¢ 0:00:26[0m [2;4m2.60it/s[0m   
        [0.5143, 0.4857],
        [0.5164, 0.4836],
        [0.5219, 0.4781],
        [0.5242, 0.4758],
        [0.5267, 0.4733],
        [0.5239, 0.4761],
        [0.5209, 0.4791],
        [0.5179, 0.4821],
[2K        [0.5241, 0.4759]], device='cuda:0', grad_fn=<SoftmaxBackward0>);5;237mâ”â”â”â”â”â”â”â”â”â”â”â”[0m 138/203 [2m0:00:53 â€¢ 0:00:26[0m [2;4m2.60it/s[0m  
[2KClass label: HighJumpâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”[0m 138/203 [2m0:00:53 â€¢ 0:00:26[0m [2;4m2.60it/s[0m  
[2KAttention weights: tensor([[0.6905, 0.3095]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 138/203 [2m0:00:53 â€¢ 0:00:26[0m [2;4m2.60it/s[0m  
[2KStep 0 - TTA Loss: 1.3788â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”[0m 138/203 [2m0:00:53 â€¢ 0:00:26[0m [2;4m2.60it/s[0m  
[2KAttention weights: tensor([[0.7046, 0.2954]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 138/203 [2m0:00:53 â€¢ 0:00:26[0m [2;4m2.60it/s[0m  
[2KAttention weights: tensor([[0.7183, 0.2817]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 138/203 [2m0:00:53 â€¢ 0:00:26[0m [2;4m2.60it/s[0m  
[2KAttention weights: tensor([[0.7302, 0.2698]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 138/203 [2m0:00:53 â€¢ 0:00:26[0m [2;4m2.60it/s[0m  
[2KAttention weights: tensor([[0.7398, 0.2602]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 138/203 [2m0:00:53 â€¢ 0:00:26[0m [2;4m2.60it/s[0m  
[2KAttention weights: tensor([[0.7502, 0.2498]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 138/203 [2m0:00:53 â€¢ 0:00:26[0m [2;4m2.60it/s[0m  
[2KAttention weights: tensor([[0.7699, 0.2301]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 138/203 [2m0:00:53 â€¢ 0:00:26[0m [2;4m2.60it/s[0m  
[2KAttention weights: tensor([[0.7809, 0.2191]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 138/203 [2m0:00:53 â€¢ 0:00:26[0m [2;4m2.60it/s[0m  
[2KAttention weights: tensor([[0.7855, 0.2145]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 138/203 [2m0:00:53 â€¢ 0:00:26[0m [2;4m2.60it/s[0m  
[2KAttention weights: tensor([[0.7866, 0.2134]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 138/203 [2m0:00:53 â€¢ 0:00:26[0m [2;4m2.60it/s[0m  
[2KAttention weights: tensor([[0.5319, 0.4681]], device='cuda:0')â•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”[0m 138/203 [2m0:00:53 â€¢ 0:00:26[0m [2;4m2.60it/s[0m  
[2KAttention weights: tensor([[0.6192, 0.3808],â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”[0m 138/203 [2m0:00:53 â€¢ 0:00:26[0m [2;4m2.60it/s[0m  
        [0.4646, 0.5354],
        [0.5086, 0.4914],
        [0.6194, 0.3806],
        [0.6523, 0.3477],
        [0.7878, 0.2122],
        [0.7215, 0.2785],
        [0.7930, 0.2070],
        [0.5695, 0.4305],
[2K        [0.6477, 0.3523]], device='cuda:0')â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”[0m 138/203 [2m0:00:53 â€¢ 0:00:26[0m [2;4m2.60it/s[0m  
[2KAttention weights: tensor([[0.5229, 0.4771],â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”[0m 139/203 [2m0:00:54 â€¢ 0:00:25[0m [2;4m2.59it/s[0m  
        [0.5143, 0.4857],
        [0.5164, 0.4836],
        [0.5220, 0.4780],
        [0.5242, 0.4758],
        [0.5267, 0.4733],
        [0.5240, 0.4760],
        [0.5210, 0.4790],
        [0.5180, 0.4820],
[2K        [0.5241, 0.4759]], device='cuda:0', grad_fn=<SoftmaxBackward0>);5;237mâ”â”â”â”â”â”â”â”â”â”â”â”[0m 139/203 [2m0:00:54 â€¢ 0:00:25[0m [2;4m2.59it/s[0m  
[2KClass label: HighJumpâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”[0m 139/203 [2m0:00:54 â€¢ 0:00:25[0m [2;4m2.59it/s[0m  
[2KAttention weights: tensor([[0.6907, 0.3093]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 139/203 [2m0:00:54 â€¢ 0:00:25[0m [2;4m2.59it/s[0m  
[2KStep 0 - TTA Loss: 1.5101â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”[0m 139/203 [2m0:00:54 â€¢ 0:00:25[0m [2;4m2.59it/s[0m  
[2KAttention weights: tensor([[0.6907, 0.3093]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 139/203 [2m0:00:54 â€¢ 0:00:25[0m [2;4m2.59it/s[0m  
[2KAttention weights: tensor([[0.6909, 0.3091]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 139/203 [2m0:00:54 â€¢ 0:00:25[0m [2;4m2.59it/s[0m  
[2KAttention weights: tensor([[0.6915, 0.3085]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 139/203 [2m0:00:54 â€¢ 0:00:25[0m [2;4m2.59it/s[0m  
[2KAttention weights: tensor([[0.6918, 0.3082]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 139/203 [2m0:00:54 â€¢ 0:00:25[0m [2;4m2.59it/s[0m  
[2KAttention weights: tensor([[0.6931, 0.3069]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 139/203 [2m0:00:54 â€¢ 0:00:25[0m [2;4m2.59it/s[0m  
[2KAttention weights: tensor([[0.6970, 0.3030]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 139/203 [2m0:00:54 â€¢ 0:00:25[0m [2;4m2.59it/s[0m  
[2KAttention weights: tensor([[0.7013, 0.2987]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 139/203 [2m0:00:54 â€¢ 0:00:25[0m [2;4m2.59it/s[0m  
[2KAttention weights: tensor([[0.7064, 0.2936]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 139/203 [2m0:00:54 â€¢ 0:00:25[0m [2;4m2.59it/s[0m  
[2KAttention weights: tensor([[0.7065, 0.2935]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 139/203 [2m0:00:54 â€¢ 0:00:25[0m [2;4m2.59it/s[0m  
[2KAttention weights: tensor([[0.5283, 0.4717]], device='cuda:0')â•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”[0m 139/203 [2m0:00:54 â€¢ 0:00:25[0m [2;4m2.59it/s[0m  
[2KAttention weights: tensor([[0.6039, 0.3961],â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”[0m 139/203 [2m0:00:54 â€¢ 0:00:25[0m [2;4m2.59it/s[0m  
        [0.4524, 0.5476],
        [0.4948, 0.5052],
        [0.6080, 0.3920],
        [0.5906, 0.4094],
        [0.7039, 0.2961],
        [0.6544, 0.3456],
        [0.6439, 0.3561],
        [0.5305, 0.4695],
[2K        [0.5946, 0.4054]], device='cuda:0')â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”[0m 139/203 [2m0:00:54 â€¢ 0:00:25[0m [2;4m2.59it/s[0m  
[2KAttention weights: tensor([[0.5229, 0.4771],â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”[0m 140/203 [2m0:00:54 â€¢ 0:00:25[0m [2;4m2.59it/s[0m  
        [0.5143, 0.4857],
        [0.5165, 0.4835],
        [0.5220, 0.4780],
        [0.5242, 0.4758],
        [0.5268, 0.4732],
        [0.5240, 0.4760],
        [0.5210, 0.4790],
        [0.5180, 0.4820],
[2K        [0.5241, 0.4759]], device='cuda:0', grad_fn=<SoftmaxBackward0>)m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”[0m 140/203 [2m0:00:54 â€¢ 0:00:25[0m [2;4m2.59it/s[0m  
[2KClass label: HammerThrowâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”[0m 140/203 [2m0:00:54 â€¢ 0:00:25[0m [2;4m2.59it/s[0m  
[2KAttention weights: tensor([[0.5759, 0.4241]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 140/203 [2m0:00:54 â€¢ 0:00:25[0m [2;4m2.59it/s[0m  
[2KStep 0 - TTA Loss: 1.6928â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”[0m 140/203 [2m0:00:54 â€¢ 0:00:25[0m [2;4m2.59it/s[0m  
[2KAttention weights: tensor([[0.5837, 0.4163]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 140/203 [2m0:00:54 â€¢ 0:00:25[0m [2;4m2.59it/s[0m  
[2KAttention weights: tensor([[0.5949, 0.4051]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 140/203 [2m0:00:54 â€¢ 0:00:25[0m [2;4m2.59it/s[0m  
[2KAttention weights: tensor([[0.6265, 0.3735]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 140/203 [2m0:00:54 â€¢ 0:00:25[0m [2;4m2.59it/s[0m  
[2KAttention weights: tensor([[0.6636, 0.3364]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 140/203 [2m0:00:54 â€¢ 0:00:25[0m [2;4m2.59it/s[0m  
[2KAttention weights: tensor([[0.6925, 0.3075]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 140/203 [2m0:00:54 â€¢ 0:00:25[0m [2;4m2.59it/s[0m  
[2KAttention weights: tensor([[0.7184, 0.2816]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 140/203 [2m0:00:54 â€¢ 0:00:25[0m [2;4m2.59it/s[0m  
[2KAttention weights: tensor([[0.7355, 0.2645]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 140/203 [2m0:00:54 â€¢ 0:00:25[0m [2;4m2.59it/s[0m  
[2KAttention weights: tensor([[0.7421, 0.2579]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 140/203 [2m0:00:54 â€¢ 0:00:25[0m [2;4m2.59it/s[0m  
[2KAttention weights: tensor([[0.7446, 0.2554]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 140/203 [2m0:00:54 â€¢ 0:00:25[0m [2;4m2.59it/s[0m  
[2KAttention weights: tensor([[0.5307, 0.4693]], device='cuda:0');224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”[0m 140/203 [2m0:00:54 â€¢ 0:00:25[0m [2;4m2.59it/s[0m  
[2KAttention weights: tensor([[0.6831, 0.3169],â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”[0m 140/203 [2m0:00:54 â€¢ 0:00:25[0m [2;4m2.59it/s[0m  
        [0.4637, 0.5363],
        [0.5350, 0.4650],
        [0.6725, 0.3275],
        [0.7458, 0.2542],
        [0.7684, 0.2316],
        [0.7244, 0.2756],
        [0.6697, 0.3303],
        [0.5576, 0.4424],
[2K        [0.7148, 0.2852]], device='cuda:0')â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”[0m 140/203 [2m0:00:54 â€¢ 0:00:25[0m [2;4m2.59it/s[0m  
[2KAttention weights: tensor([[0.5230, 0.4770],â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”[0m 141/203 [2m0:00:54 â€¢ 0:00:24[0m [2;4m2.60it/s[0m  
        [0.5143, 0.4857],
        [0.5165, 0.4835],
        [0.5220, 0.4780],
        [0.5243, 0.4757],
        [0.5268, 0.4732],
        [0.5241, 0.4759],
        [0.5210, 0.4790],
        [0.5180, 0.4820],
[2K        [0.5242, 0.4758]], device='cuda:0', grad_fn=<SoftmaxBackward0>)m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”[0m 141/203 [2m0:00:54 â€¢ 0:00:24[0m [2;4m2.60it/s[0m  
[2KClass label: TennisSwingâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”[0m 141/203 [2m0:00:54 â€¢ 0:00:24[0m [2;4m2.60it/s[0m  
[2KAttention weights: tensor([[0.5137, 0.4863]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 141/203 [2m0:00:54 â€¢ 0:00:24[0m [2;4m2.60it/s[0m  
[2KStep 0 - TTA Loss: 2.4220â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”[0m 141/203 [2m0:00:54 â€¢ 0:00:24[0m [2;4m2.60it/s[0m  
[2KAttention weights: tensor([[0.5137, 0.4863]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 141/203 [2m0:00:54 â€¢ 0:00:24[0m [2;4m2.60it/s[0m  
[2KAttention weights: tensor([[0.5138, 0.4862]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 141/203 [2m0:00:54 â€¢ 0:00:24[0m [2;4m2.60it/s[0m  
[2KAttention weights: tensor([[0.5142, 0.4858]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 141/203 [2m0:00:54 â€¢ 0:00:24[0m [2;4m2.60it/s[0m  
[2KAttention weights: tensor([[0.5153, 0.4847]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 141/203 [2m0:00:54 â€¢ 0:00:24[0m [2;4m2.60it/s[0m  
[2KAttention weights: tensor([[0.5184, 0.4816]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 141/203 [2m0:00:54 â€¢ 0:00:24[0m [2;4m2.60it/s[0m  
[2KAttention weights: tensor([[0.5245, 0.4755]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 141/203 [2m0:00:54 â€¢ 0:00:24[0m [2;4m2.60it/s[0m  
[2KAttention weights: tensor([[0.5346, 0.4654]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 141/203 [2m0:00:54 â€¢ 0:00:24[0m [2;4m2.60it/s[0m  
[2KAttention weights: tensor([[0.5486, 0.4514]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 141/203 [2m0:00:54 â€¢ 0:00:24[0m [2;4m2.60it/s[0m  
[2KAttention weights: tensor([[0.5620, 0.4380]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 141/203 [2m0:00:54 â€¢ 0:00:24[0m [2;4m2.60it/s[0m  
[2KAttention weights: tensor([[0.5196, 0.4804]], device='cuda:0');224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”[0m 141/203 [2m0:00:54 â€¢ 0:00:24[0m [2;4m2.60it/s[0m  
[2KAttention weights: tensor([[0.6440, 0.3560],â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”[0m 141/203 [2m0:00:54 â€¢ 0:00:24[0m [2;4m2.60it/s[0m  
        [0.4577, 0.5423],
        [0.5159, 0.4841],
        [0.6431, 0.3569],
        [0.6575, 0.3425],
        [0.7342, 0.2658],
        [0.6818, 0.3182],
        [0.6395, 0.3605],
        [0.5720, 0.4280],
[2K        [0.6488, 0.3512]], device='cuda:0')â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”[0m 141/203 [2m0:00:54 â€¢ 0:00:24[0m [2;4m2.60it/s[0m  
[2KAttention weights: tensor([[0.5230, 0.4770],â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”[0m 142/203 [2m0:00:55 â€¢ 0:00:24[0m [2;4m2.60it/s[0m  
        [0.5144, 0.4856],
        [0.5165, 0.4835],
        [0.5220, 0.4780],
        [0.5244, 0.4756],
        [0.5269, 0.4731],
        [0.5241, 0.4759],
        [0.5211, 0.4789],
        [0.5181, 0.4819],
[2K        [0.5242, 0.4758]], device='cuda:0', grad_fn=<SoftmaxBackward0>)m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”[0m 142/203 [2m0:00:55 â€¢ 0:00:24[0m [2;4m2.60it/s[0m  
[2KClass label: HighJumpâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”[0m 142/203 [2m0:00:55 â€¢ 0:00:24[0m [2;4m2.60it/s[0m  
[2KAttention weights: tensor([[0.6948, 0.3052]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 142/203 [2m0:00:55 â€¢ 0:00:24[0m [2;4m2.60it/s[0m  
[2KStep 0 - TTA Loss: 1.7976â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”[0m 142/203 [2m0:00:55 â€¢ 0:00:24[0m [2;4m2.60it/s[0m  
[2KAttention weights: tensor([[0.7006, 0.2994]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 142/203 [2m0:00:55 â€¢ 0:00:24[0m [2;4m2.60it/s[0m  
[2KAttention weights: tensor([[0.7025, 0.2975]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 142/203 [2m0:00:55 â€¢ 0:00:24[0m [2;4m2.60it/s[0m  
[2KAttention weights: tensor([[0.7120, 0.2880]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 142/203 [2m0:00:55 â€¢ 0:00:24[0m [2;4m2.60it/s[0m  
[2KAttention weights: tensor([[0.7214, 0.2786]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 142/203 [2m0:00:55 â€¢ 0:00:24[0m [2;4m2.60it/s[0m  
[2KAttention weights: tensor([[0.7273, 0.2727]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 142/203 [2m0:00:55 â€¢ 0:00:24[0m [2;4m2.60it/s[0m  
[2KAttention weights: tensor([[0.7285, 0.2715]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 142/203 [2m0:00:55 â€¢ 0:00:24[0m [2;4m2.60it/s[0m  
[2KAttention weights: tensor([[0.7271, 0.2729]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 142/203 [2m0:00:55 â€¢ 0:00:24[0m [2;4m2.60it/s[0m  
[2KAttention weights: tensor([[0.7273, 0.2727]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 142/203 [2m0:00:55 â€¢ 0:00:24[0m [2;4m2.60it/s[0m  
[2KAttention weights: tensor([[0.7274, 0.2726]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 142/203 [2m0:00:55 â€¢ 0:00:24[0m [2;4m2.60it/s[0m  
[2KAttention weights: tensor([[0.5294, 0.4706]], device='cuda:0');224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”[0m 142/203 [2m0:00:55 â€¢ 0:00:24[0m [2;4m2.60it/s[0m  
[2KAttention weights: tensor([[0.6383, 0.3617],â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”[0m 142/203 [2m0:00:55 â€¢ 0:00:24[0m [2;4m2.60it/s[0m  
        [0.4492, 0.5508],
        [0.5097, 0.4903],
        [0.6309, 0.3691],
        [0.6380, 0.3620],
        [0.7280, 0.2720],
        [0.6755, 0.3245],
        [0.6256, 0.3744],
        [0.5599, 0.4401],
[2K        [0.6353, 0.3647]], device='cuda:0')â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”[0m 142/203 [2m0:00:55 â€¢ 0:00:24[0m [2;4m2.60it/s[0m  
[2KAttention weights: tensor([[0.5230, 0.4770],â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”[0m 143/203 [2m0:00:55 â€¢ 0:00:24[0m [2;4m2.61it/s[0m   
        [0.5144, 0.4856],
        [0.5166, 0.4834],
        [0.5221, 0.4779],
        [0.5244, 0.4756],
        [0.5269, 0.4731],
        [0.5241, 0.4759],
        [0.5211, 0.4789],
        [0.5181, 0.4819],
[2K        [0.5243, 0.4757]], device='cuda:0', grad_fn=<SoftmaxBackward0>)8;5;237mâ”â”â”â”â”â”â”â”â”â”â”[0m 143/203 [2m0:00:55 â€¢ 0:00:24[0m [2;4m2.61it/s[0m  
[2KClass label: HammerThrowâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”[0m 143/203 [2m0:00:55 â€¢ 0:00:24[0m [2;4m2.61it/s[0m  
[2KAttention weights: tensor([[0.5826, 0.4174]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 143/203 [2m0:00:55 â€¢ 0:00:24[0m [2;4m2.61it/s[0m  
[2KStep 0 - TTA Loss: 1.1423â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”[0m 143/203 [2m0:00:55 â€¢ 0:00:24[0m [2;4m2.61it/s[0m  
[2KAttention weights: tensor([[0.5826, 0.4174]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 143/203 [2m0:00:55 â€¢ 0:00:24[0m [2;4m2.61it/s[0m  
[2KAttention weights: tensor([[0.5825, 0.4175]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 143/203 [2m0:00:55 â€¢ 0:00:24[0m [2;4m2.61it/s[0m  
[2KAttention weights: tensor([[0.5821, 0.4179]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 143/203 [2m0:00:55 â€¢ 0:00:24[0m [2;4m2.61it/s[0m  
[2KAttention weights: tensor([[0.5809, 0.4191]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 143/203 [2m0:00:55 â€¢ 0:00:24[0m [2;4m2.61it/s[0m  
[2KAttention weights: tensor([[0.5769, 0.4231]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 143/203 [2m0:00:55 â€¢ 0:00:24[0m [2;4m2.61it/s[0m  
[2KAttention weights: tensor([[0.5683, 0.4317]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 143/203 [2m0:00:55 â€¢ 0:00:24[0m [2;4m2.61it/s[0m  
[2KAttention weights: tensor([[0.5533, 0.4467]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 143/203 [2m0:00:55 â€¢ 0:00:24[0m [2;4m2.61it/s[0m  
[2KAttention weights: tensor([[0.5382, 0.4618]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 143/203 [2m0:00:55 â€¢ 0:00:24[0m [2;4m2.61it/s[0m  
[2KAttention weights: tensor([[0.5190, 0.4810]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 143/203 [2m0:00:55 â€¢ 0:00:24[0m [2;4m2.61it/s[0m  
[2KAttention weights: tensor([[0.5221, 0.4779]], device='cuda:0')mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”[0m 143/203 [2m0:00:55 â€¢ 0:00:24[0m [2;4m2.61it/s[0m  
[2KAttention weights: tensor([[0.5629, 0.4371],â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”[0m 143/203 [2m0:00:55 â€¢ 0:00:24[0m [2;4m2.61it/s[0m  
        [0.4422, 0.5578],
        [0.4775, 0.5225],
        [0.5734, 0.4266],
        [0.4985, 0.5015],
        [0.6354, 0.3646],
        [0.5947, 0.4053],
        [0.5828, 0.4172],
        [0.4980, 0.5020],
[2K        [0.5225, 0.4775]], device='cuda:0')â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”[0m 143/203 [2m0:00:55 â€¢ 0:00:24[0m [2;4m2.61it/s[0m  
[2KAttention weights: tensor([[0.5231, 0.4769],â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”[0m 144/203 [2m0:00:55 â€¢ 0:00:23[0m [2;4m2.59it/s[0m  
        [0.5144, 0.4856],
        [0.5166, 0.4834],
        [0.5221, 0.4779],
        [0.5245, 0.4755],
        [0.5269, 0.4731],
        [0.5242, 0.4758],
        [0.5211, 0.4789],
        [0.5181, 0.4819],
[2K        [0.5243, 0.4757]], device='cuda:0', grad_fn=<SoftmaxBackward0>)8;5;237mâ”â”â”â”â”â”â”â”â”â”â”[0m 144/203 [2m0:00:55 â€¢ 0:00:23[0m [2;4m2.59it/s[0m  
[2KClass label: HammerThrowâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”[0m 144/203 [2m0:00:55 â€¢ 0:00:23[0m [2;4m2.59it/s[0m  
[2KAttention weights: tensor([[0.5806, 0.4194]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 144/203 [2m0:00:55 â€¢ 0:00:23[0m [2;4m2.59it/s[0m  
[2KStep 0 - TTA Loss: 1.0273â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”[0m 144/203 [2m0:00:55 â€¢ 0:00:23[0m [2;4m2.59it/s[0m  
[2KAttention weights: tensor([[0.5573, 0.4427]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 144/203 [2m0:00:55 â€¢ 0:00:23[0m [2;4m2.59it/s[0m  
[2KAttention weights: tensor([[0.5352, 0.4648]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 144/203 [2m0:00:55 â€¢ 0:00:23[0m [2;4m2.59it/s[0m  
[2KAttention weights: tensor([[0.5205, 0.4795]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 144/203 [2m0:00:55 â€¢ 0:00:23[0m [2;4m2.59it/s[0m  
[2KAttention weights: tensor([[0.5083, 0.4917]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 144/203 [2m0:00:55 â€¢ 0:00:23[0m [2;4m2.59it/s[0m  
[2KAttention weights: tensor([[0.4996, 0.5004]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 144/203 [2m0:00:55 â€¢ 0:00:23[0m [2;4m2.59it/s[0m  
[2KAttention weights: tensor([[0.4938, 0.5062]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 144/203 [2m0:00:55 â€¢ 0:00:23[0m [2;4m2.59it/s[0m  
[2KAttention weights: tensor([[0.4908, 0.5092]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 144/203 [2m0:00:55 â€¢ 0:00:23[0m [2;4m2.59it/s[0m  
[2KAttention weights: tensor([[0.4897, 0.5103]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 144/203 [2m0:00:55 â€¢ 0:00:23[0m [2;4m2.59it/s[0m  
[2KAttention weights: tensor([[0.4892, 0.5108]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 144/203 [2m0:00:55 â€¢ 0:00:23[0m [2;4m2.59it/s[0m  
[2KAttention weights: tensor([[0.5219, 0.4781]], device='cuda:0')mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”[0m 144/203 [2m0:00:55 â€¢ 0:00:23[0m [2;4m2.59it/s[0m  
[2KAttention weights: tensor([[0.5630, 0.4370],â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”[0m 144/203 [2m0:00:55 â€¢ 0:00:23[0m [2;4m2.59it/s[0m  
        [0.4414, 0.5586],
        [0.4773, 0.5227],
        [0.5691, 0.4309],
        [0.4891, 0.5109],
        [0.6385, 0.3615],
        [0.5967, 0.4033],
        [0.5881, 0.4119],
        [0.4998, 0.5002],
[2K        [0.5161, 0.4839]], device='cuda:0')â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”[0m 144/203 [2m0:00:55 â€¢ 0:00:23[0m [2;4m2.59it/s[0m  
[2KAttention weights: tensor([[0.5231, 0.4769],â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”[0m 145/203 [2m0:00:56 â€¢ 0:00:23[0m [2;4m2.60it/s[0m  
        [0.5144, 0.4856],
        [0.5166, 0.4834],
        [0.5221, 0.4779],
        [0.5245, 0.4755],
        [0.5269, 0.4731],
        [0.5242, 0.4758],
        [0.5211, 0.4789],
        [0.5181, 0.4819],
[2K        [0.5243, 0.4757]], device='cuda:0', grad_fn=<SoftmaxBackward0>)0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”[0m 145/203 [2m0:00:56 â€¢ 0:00:23[0m [2;4m2.60it/s[0m  
[2KClass label: TennisSwingâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”[0m 145/203 [2m0:00:56 â€¢ 0:00:23[0m [2;4m2.60it/s[0m  
[2KAttention weights: tensor([[0.5161, 0.4839]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 145/203 [2m0:00:56 â€¢ 0:00:23[0m [2;4m2.60it/s[0m  
[2KStep 0 - TTA Loss: 2.3600â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”[0m 145/203 [2m0:00:56 â€¢ 0:00:23[0m [2;4m2.60it/s[0m  
[2KAttention weights: tensor([[0.5161, 0.4839]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 145/203 [2m0:00:56 â€¢ 0:00:23[0m [2;4m2.60it/s[0m  
[2KAttention weights: tensor([[0.5166, 0.4834]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 145/203 [2m0:00:56 â€¢ 0:00:23[0m [2;4m2.60it/s[0m  
[2KAttention weights: tensor([[0.5199, 0.4801]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 145/203 [2m0:00:56 â€¢ 0:00:23[0m [2;4m2.60it/s[0m  
[2KAttention weights: tensor([[0.5296, 0.4704]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 145/203 [2m0:00:56 â€¢ 0:00:23[0m [2;4m2.60it/s[0m  
[2KAttention weights: tensor([[0.5494, 0.4506]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 145/203 [2m0:00:56 â€¢ 0:00:23[0m [2;4m2.60it/s[0m  
[2KAttention weights: tensor([[0.5817, 0.4183]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 145/203 [2m0:00:56 â€¢ 0:00:23[0m [2;4m2.60it/s[0m  
[2KAttention weights: tensor([[0.6238, 0.3762]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 145/203 [2m0:00:56 â€¢ 0:00:23[0m [2;4m2.60it/s[0m  
[2KAttention weights: tensor([[0.6739, 0.3261]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 145/203 [2m0:00:56 â€¢ 0:00:23[0m [2;4m2.60it/s[0m  
[2KAttention weights: tensor([[0.7222, 0.2778]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 145/203 [2m0:00:56 â€¢ 0:00:23[0m [2;4m2.60it/s[0m  
[2KAttention weights: tensor([[0.5245, 0.4755]], device='cuda:0')6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”[0m 145/203 [2m0:00:56 â€¢ 0:00:23[0m [2;4m2.60it/s[0m  
[2KAttention weights: tensor([[0.6724, 0.3276],â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”[0m 145/203 [2m0:00:56 â€¢ 0:00:23[0m [2;4m2.60it/s[0m  
        [0.4649, 0.5351],
        [0.5333, 0.4667],
        [0.6553, 0.3447],
        [0.6395, 0.3605],
        [0.7594, 0.2406],
        [0.6721, 0.3279],
        [0.6641, 0.3359],
        [0.7647, 0.2353],
[2K        [0.6714, 0.3286]], device='cuda:0')â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”[0m 145/203 [2m0:00:56 â€¢ 0:00:23[0m [2;4m2.60it/s[0m  
[2KAttention weights: tensor([[0.5231, 0.4769],â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”[0m 146/203 [2m0:00:56 â€¢ 0:00:22[0m [2;4m2.60it/s[0m  
        [0.5144, 0.4856],
        [0.5166, 0.4834],
        [0.5221, 0.4779],
        [0.5245, 0.4755],
        [0.5270, 0.4730],
        [0.5242, 0.4758],
        [0.5211, 0.4789],
        [0.5182, 0.4818],
[2K        [0.5243, 0.4757]], device='cuda:0', grad_fn=<SoftmaxBackward0>)0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”[0m 146/203 [2m0:00:56 â€¢ 0:00:22[0m [2;4m2.60it/s[0m  
[2KClass label: HammerThrowâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”[0m 146/203 [2m0:00:56 â€¢ 0:00:22[0m [2;4m2.60it/s[0m  
[2KAttention weights: tensor([[0.5767, 0.4233]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 146/203 [2m0:00:56 â€¢ 0:00:22[0m [2;4m2.60it/s[0m  
[2KStep 0 - TTA Loss: 1.5074â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”[0m 146/203 [2m0:00:56 â€¢ 0:00:22[0m [2;4m2.60it/s[0m  
[2KAttention weights: tensor([[0.5887, 0.4113]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 146/203 [2m0:00:56 â€¢ 0:00:22[0m [2;4m2.60it/s[0m  
[2KAttention weights: tensor([[0.6027, 0.3973]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 146/203 [2m0:00:56 â€¢ 0:00:22[0m [2;4m2.60it/s[0m  
[2KAttention weights: tensor([[0.6264, 0.3736]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 146/203 [2m0:00:56 â€¢ 0:00:22[0m [2;4m2.60it/s[0m  
[2KAttention weights: tensor([[0.6562, 0.3438]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 146/203 [2m0:00:56 â€¢ 0:00:22[0m [2;4m2.60it/s[0m  
[2KAttention weights: tensor([[0.6846, 0.3154]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 146/203 [2m0:00:56 â€¢ 0:00:22[0m [2;4m2.60it/s[0m  
[2KAttention weights: tensor([[0.7019, 0.2981]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 146/203 [2m0:00:56 â€¢ 0:00:22[0m [2;4m2.60it/s[0m  
[2KAttention weights: tensor([[0.7128, 0.2872]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 146/203 [2m0:00:56 â€¢ 0:00:22[0m [2;4m2.60it/s[0m  
[2KAttention weights: tensor([[0.7178, 0.2822]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 146/203 [2m0:00:56 â€¢ 0:00:22[0m [2;4m2.60it/s[0m  
[2KAttention weights: tensor([[0.7192, 0.2808]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 146/203 [2m0:00:56 â€¢ 0:00:22[0m [2;4m2.60it/s[0m  
[2KAttention weights: tensor([[0.5289, 0.4711]], device='cuda:0')6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”[0m 146/203 [2m0:00:56 â€¢ 0:00:22[0m [2;4m2.60it/s[0m  
[2KAttention weights: tensor([[0.7012, 0.2988],â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”[0m 146/203 [2m0:00:56 â€¢ 0:00:22[0m [2;4m2.60it/s[0m  
        [0.4723, 0.5277],
        [0.5517, 0.4483],
        [0.6881, 0.3119],
        [0.7197, 0.2803],
        [0.7891, 0.2109],
        [0.7153, 0.2847],
        [0.6763, 0.3237],
        [0.7381, 0.2619],
[2K        [0.7235, 0.2765]], device='cuda:0')â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”[0m 146/203 [2m0:00:56 â€¢ 0:00:22[0m [2;4m2.60it/s[0m  
[2KAttention weights: tensor([[0.5231, 0.4769],â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”[0m 147/203 [2m0:00:57 â€¢ 0:00:22[0m [2;4m2.60it/s[0m  
        [0.5144, 0.4856],
        [0.5166, 0.4834],
        [0.5221, 0.4779],
        [0.5245, 0.4755],
        [0.5270, 0.4730],
        [0.5242, 0.4758],
        [0.5211, 0.4789],
        [0.5182, 0.4818],
[2K        [0.5244, 0.4756]], device='cuda:0', grad_fn=<SoftmaxBackward0>)0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”[0m 147/203 [2m0:00:57 â€¢ 0:00:22[0m [2;4m2.60it/s[0m  
[2KClass label: GolfSwingâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”[0m 147/203 [2m0:00:57 â€¢ 0:00:22[0m [2;4m2.60it/s[0m  
[2KAttention weights: tensor([[0.6054, 0.3946]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 147/203 [2m0:00:57 â€¢ 0:00:22[0m [2;4m2.60it/s[0m  
[2KStep 0 - TTA Loss: 2.5752â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”[0m 147/203 [2m0:00:57 â€¢ 0:00:22[0m [2;4m2.60it/s[0m  
[2KAttention weights: tensor([[0.6054, 0.3946]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 147/203 [2m0:00:57 â€¢ 0:00:22[0m [2;4m2.60it/s[0m  
[2KAttention weights: tensor([[0.6069, 0.3931]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 147/203 [2m0:00:57 â€¢ 0:00:22[0m [2;4m2.60it/s[0m  
[2KAttention weights: tensor([[0.6152, 0.3848]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 147/203 [2m0:00:57 â€¢ 0:00:22[0m [2;4m2.60it/s[0m  
[2KAttention weights: tensor([[0.6349, 0.3651]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 147/203 [2m0:00:57 â€¢ 0:00:22[0m [2;4m2.60it/s[0m  
[2KAttention weights: tensor([[0.6629, 0.3371]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 147/203 [2m0:00:57 â€¢ 0:00:22[0m [2;4m2.60it/s[0m  
[2KAttention weights: tensor([[0.7017, 0.2983]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 147/203 [2m0:00:57 â€¢ 0:00:22[0m [2;4m2.60it/s[0m  
[2KAttention weights: tensor([[0.7708, 0.2292]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 147/203 [2m0:00:57 â€¢ 0:00:22[0m [2;4m2.60it/s[0m  
[2KAttention weights: tensor([[0.8367, 0.1633]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 147/203 [2m0:00:57 â€¢ 0:00:22[0m [2;4m2.60it/s[0m  
[2KAttention weights: tensor([[0.8971, 0.1029]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 147/203 [2m0:00:57 â€¢ 0:00:22[0m [2;4m2.60it/s[0m  
[2KAttention weights: tensor([[0.5354, 0.4646]], device='cuda:0')6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”[0m 147/203 [2m0:00:57 â€¢ 0:00:22[0m [2;4m2.60it/s[0m  
[2KAttention weights: tensor([[0.7667, 0.2333],â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”[0m 147/203 [2m0:00:57 â€¢ 0:00:22[0m [2;4m2.60it/s[0m  
        [0.5554, 0.4446],
        [0.6057, 0.3943],
        [0.9412, 0.0588],
        [0.7728, 0.2272],
        [0.7956, 0.2044],
        [0.7737, 0.2263],
        [0.6833, 0.3167],
        [0.6480, 0.3520],
[2K        [0.7881, 0.2119]], device='cuda:0')â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”[0m 147/203 [2m0:00:57 â€¢ 0:00:22[0m [2;4m2.60it/s[0m  
[2KAttention weights: tensor([[0.5232, 0.4768],â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”[0m 148/203 [2m0:00:57 â€¢ 0:00:22[0m [2;4m2.60it/s[0m   
        [0.5145, 0.4855],
        [0.5167, 0.4833],
        [0.5222, 0.4778],
        [0.5245, 0.4755],
        [0.5270, 0.4730],
        [0.5243, 0.4757],
        [0.5212, 0.4788],
        [0.5182, 0.4818],
[2K        [0.5244, 0.4756]], device='cuda:0', grad_fn=<SoftmaxBackward0>)38;5;237mâ”â”â”â”â”â”â”â”â”â”[0m 148/203 [2m0:00:57 â€¢ 0:00:22[0m [2;4m2.60it/s[0m  
[2KClass label: SoccerPenaltyâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”[0m 148/203 [2m0:00:57 â€¢ 0:00:22[0m [2;4m2.60it/s[0m  
[2KAttention weights: tensor([[0.6052, 0.3948]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 148/203 [2m0:00:57 â€¢ 0:00:22[0m [2;4m2.60it/s[0m  
[2KStep 0 - TTA Loss: 1.4318â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”[0m 148/203 [2m0:00:57 â€¢ 0:00:22[0m [2;4m2.60it/s[0m  
[2KAttention weights: tensor([[0.6184, 0.3816]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 148/203 [2m0:00:57 â€¢ 0:00:22[0m [2;4m2.60it/s[0m  
[2KAttention weights: tensor([[0.6273, 0.3727]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 148/203 [2m0:00:57 â€¢ 0:00:22[0m [2;4m2.60it/s[0m  
[2KAttention weights: tensor([[0.6321, 0.3679]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 148/203 [2m0:00:57 â€¢ 0:00:22[0m [2;4m2.60it/s[0m  
[2KAttention weights: tensor([[0.6337, 0.3663]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 148/203 [2m0:00:57 â€¢ 0:00:22[0m [2;4m2.60it/s[0m  
[2KAttention weights: tensor([[0.6338, 0.3662]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 148/203 [2m0:00:57 â€¢ 0:00:22[0m [2;4m2.60it/s[0m  
[2KAttention weights: tensor([[0.6333, 0.3667]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 148/203 [2m0:00:57 â€¢ 0:00:22[0m [2;4m2.60it/s[0m  
[2KAttention weights: tensor([[0.6297, 0.3703]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 148/203 [2m0:00:57 â€¢ 0:00:22[0m [2;4m2.60it/s[0m  
[2KAttention weights: tensor([[0.6271, 0.3729]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 148/203 [2m0:00:57 â€¢ 0:00:22[0m [2;4m2.60it/s[0m  
[2KAttention weights: tensor([[0.6259, 0.3741]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 148/203 [2m0:00:57 â€¢ 0:00:22[0m [2;4m2.60it/s[0m  
[2KAttention weights: tensor([[0.5221, 0.4779]], device='cuda:0')7mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”[0m 148/203 [2m0:00:57 â€¢ 0:00:22[0m [2;4m2.60it/s[0m  
[2KAttention weights: tensor([[0.7617, 0.2383],â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”[0m 148/203 [2m0:00:57 â€¢ 0:00:22[0m [2;4m2.60it/s[0m  
        [0.5485, 0.4515],
        [0.6034, 0.3966],
        [0.9406, 0.0594],
        [0.7612, 0.2388],
        [0.7817, 0.2183],
        [0.7663, 0.2337],
        [0.6256, 0.3744],
        [0.6249, 0.3751],
[2K        [0.7795, 0.2205]], device='cuda:0')â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”[0m 148/203 [2m0:00:57 â€¢ 0:00:22[0m [2;4m2.60it/s[0m  
[2KAttention weights: tensor([[0.5233, 0.4767],â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”[0m 149/203 [2m0:00:57 â€¢ 0:00:21[0m [2;4m2.60it/s[0m  
        [0.5146, 0.4854],
        [0.5167, 0.4833],
        [0.5224, 0.4776],
        [0.5246, 0.4754],
        [0.5271, 0.4729],
        [0.5243, 0.4757],
        [0.5213, 0.4787],
        [0.5184, 0.4816],
[2K        [0.5245, 0.4755]], device='cuda:0', grad_fn=<SoftmaxBackward0>)38;5;237mâ”â”â”â”â”â”â”â”â”â”[0m 149/203 [2m0:00:57 â€¢ 0:00:21[0m [2;4m2.60it/s[0m  
[2KClass label: HighJumpâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”[0m 149/203 [2m0:00:57 â€¢ 0:00:21[0m [2;4m2.60it/s[0m  
[2KAttention weights: tensor([[0.6912, 0.3088]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 149/203 [2m0:00:57 â€¢ 0:00:21[0m [2;4m2.60it/s[0m  
[2KStep 0 - TTA Loss: 1.0527â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”[0m 149/203 [2m0:00:57 â€¢ 0:00:21[0m [2;4m2.60it/s[0m  
[2KAttention weights: tensor([[0.6912, 0.3088]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 149/203 [2m0:00:57 â€¢ 0:00:21[0m [2;4m2.60it/s[0m  
[2KAttention weights: tensor([[0.6913, 0.3087]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 149/203 [2m0:00:57 â€¢ 0:00:21[0m [2;4m2.60it/s[0m  
[2KAttention weights: tensor([[0.6919, 0.3081]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 149/203 [2m0:00:57 â€¢ 0:00:21[0m [2;4m2.60it/s[0m  
[2KAttention weights: tensor([[0.6927, 0.3073]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 149/203 [2m0:00:57 â€¢ 0:00:21[0m [2;4m2.60it/s[0m  
[2KAttention weights: tensor([[0.6938, 0.3062]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 149/203 [2m0:00:57 â€¢ 0:00:21[0m [2;4m2.60it/s[0m  
[2KAttention weights: tensor([[0.6946, 0.3054]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 149/203 [2m0:00:57 â€¢ 0:00:21[0m [2;4m2.60it/s[0m  
[2KAttention weights: tensor([[0.6966, 0.3034]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 149/203 [2m0:00:57 â€¢ 0:00:21[0m [2;4m2.60it/s[0m  
[2KAttention weights: tensor([[0.6996, 0.3004]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 149/203 [2m0:00:57 â€¢ 0:00:21[0m [2;4m2.60it/s[0m  
[2KAttention weights: tensor([[0.7034, 0.2966]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 149/203 [2m0:00:57 â€¢ 0:00:21[0m [2;4m2.60it/s[0m  
[2KAttention weights: tensor([[0.5292, 0.4708]], device='cuda:0')7mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”[0m 149/203 [2m0:00:57 â€¢ 0:00:21[0m [2;4m2.60it/s[0m  
[2KAttention weights: tensor([[0.6369, 0.3631],â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”[0m 149/203 [2m0:00:57 â€¢ 0:00:21[0m [2;4m2.60it/s[0m  
        [0.4604, 0.5396],
        [0.5143, 0.4857],
        [0.7020, 0.2980],
        [0.6171, 0.3829],
        [0.7097, 0.2903],
        [0.6724, 0.3276],
        [0.5861, 0.4139],
        [0.5323, 0.4677],
[2K        [0.6286, 0.3714]], device='cuda:0')â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”[0m 149/203 [2m0:00:57 â€¢ 0:00:21[0m [2;4m2.60it/s[0m  
[2KAttention weights: tensor([[0.5233, 0.4767],â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”[0m 150/203 [2m0:00:58 â€¢ 0:00:21[0m [2;4m2.60it/s[0m  
        [0.5146, 0.4854],
        [0.5167, 0.4833],
        [0.5224, 0.4776],
        [0.5246, 0.4754],
        [0.5271, 0.4729],
        [0.5243, 0.4757],
        [0.5213, 0.4787],
        [0.5184, 0.4816],
[2K        [0.5245, 0.4755]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”[0m 150/203 [2m0:00:58 â€¢ 0:00:21[0m [2;4m2.60it/s[0m  
[2KClass label: BaseballPitchâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”[0m 150/203 [2m0:00:58 â€¢ 0:00:21[0m [2;4m2.60it/s[0m  
[2KAttention weights: tensor([[0.6027, 0.3973]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 150/203 [2m0:00:58 â€¢ 0:00:21[0m [2;4m2.60it/s[0m  
[2KStep 0 - TTA Loss: 2.4581â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”[0m 150/203 [2m0:00:58 â€¢ 0:00:21[0m [2;4m2.60it/s[0m  
[2KAttention weights: tensor([[0.6227, 0.3773]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 150/203 [2m0:00:58 â€¢ 0:00:21[0m [2;4m2.60it/s[0m  
[2KAttention weights: tensor([[0.6414, 0.3586]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 150/203 [2m0:00:58 â€¢ 0:00:21[0m [2;4m2.60it/s[0m  
[2KAttention weights: tensor([[0.6601, 0.3399]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 150/203 [2m0:00:58 â€¢ 0:00:21[0m [2;4m2.60it/s[0m  
[2KAttention weights: tensor([[0.6733, 0.3267]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 150/203 [2m0:00:58 â€¢ 0:00:21[0m [2;4m2.60it/s[0m  
[2KAttention weights: tensor([[0.6878, 0.3122]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 150/203 [2m0:00:58 â€¢ 0:00:21[0m [2;4m2.60it/s[0m  
[2KAttention weights: tensor([[0.6955, 0.3045]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 150/203 [2m0:00:58 â€¢ 0:00:21[0m [2;4m2.60it/s[0m  
[2KAttention weights: tensor([[0.7039, 0.2961]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 150/203 [2m0:00:58 â€¢ 0:00:21[0m [2;4m2.60it/s[0m  
[2KAttention weights: tensor([[0.7098, 0.2902]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 150/203 [2m0:00:58 â€¢ 0:00:21[0m [2;4m2.60it/s[0m  
[2KAttention weights: tensor([[0.7113, 0.2887]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 150/203 [2m0:00:58 â€¢ 0:00:21[0m [2;4m2.60it/s[0m  
[2KAttention weights: tensor([[0.5276, 0.4724]], device='cuda:0');6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”[0m 150/203 [2m0:00:58 â€¢ 0:00:21[0m [2;4m2.60it/s[0m  
[2KAttention weights: tensor([[0.7121, 0.2879],â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”[0m 150/203 [2m0:00:58 â€¢ 0:00:21[0m [2;4m2.60it/s[0m  
        [0.4613, 0.5387],
        [0.5259, 0.4741],
        [0.6949, 0.3051],
        [0.6451, 0.3549],
        [0.7297, 0.2703],
        [0.6860, 0.3140],
        [0.5971, 0.4029],
        [0.5562, 0.4438],
[2K        [0.6570, 0.3430]], device='cuda:0')â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”[0m 150/203 [2m0:00:58 â€¢ 0:00:21[0m [2;4m2.60it/s[0m  
[2KAttention weights: tensor([[0.5234, 0.4766],â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”[0m 151/203 [2m0:00:58 â€¢ 0:00:20[0m [2;4m2.60it/s[0m  
        [0.5146, 0.4854],
        [0.5168, 0.4832],
        [0.5225, 0.4775],
        [0.5247, 0.4753],
        [0.5272, 0.4728],
        [0.5244, 0.4756],
        [0.5213, 0.4787],
        [0.5184, 0.4816],
[2K        [0.5245, 0.4755]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”[0m 151/203 [2m0:00:58 â€¢ 0:00:20[0m [2;4m2.60it/s[0m  
[2KClass label: GolfSwingâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”[0m 151/203 [2m0:00:58 â€¢ 0:00:20[0m [2;4m2.60it/s[0m  
[2KAttention weights: tensor([[0.6010, 0.3990]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 151/203 [2m0:00:58 â€¢ 0:00:20[0m [2;4m2.60it/s[0m  
[2KStep 0 - TTA Loss: 1.7545â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”[0m 151/203 [2m0:00:58 â€¢ 0:00:20[0m [2;4m2.60it/s[0m  
[2KAttention weights: tensor([[0.6010, 0.3990]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 151/203 [2m0:00:58 â€¢ 0:00:20[0m [2;4m2.60it/s[0m  
[2KAttention weights: tensor([[0.6015, 0.3985]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 151/203 [2m0:00:58 â€¢ 0:00:20[0m [2;4m2.60it/s[0m  
[2KAttention weights: tensor([[0.6044, 0.3956]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 151/203 [2m0:00:58 â€¢ 0:00:20[0m [2;4m2.60it/s[0m  
[2KAttention weights: tensor([[0.6128, 0.3872]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 151/203 [2m0:00:58 â€¢ 0:00:20[0m [2;4m2.60it/s[0m  
[2KAttention weights: tensor([[0.6254, 0.3746]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 151/203 [2m0:00:58 â€¢ 0:00:20[0m [2;4m2.60it/s[0m  
[2KAttention weights: tensor([[0.6476, 0.3524]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 151/203 [2m0:00:58 â€¢ 0:00:20[0m [2;4m2.60it/s[0m  
[2KAttention weights: tensor([[0.6796, 0.3204]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 151/203 [2m0:00:58 â€¢ 0:00:20[0m [2;4m2.60it/s[0m  
[2KAttention weights: tensor([[0.7225, 0.2775]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 151/203 [2m0:00:58 â€¢ 0:00:20[0m [2;4m2.60it/s[0m  
[2KAttention weights: tensor([[0.7754, 0.2246]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 151/203 [2m0:00:58 â€¢ 0:00:20[0m [2;4m2.60it/s[0m  
[2KAttention weights: tensor([[0.5320, 0.4680]], device='cuda:0');6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”[0m 151/203 [2m0:00:58 â€¢ 0:00:20[0m [2;4m2.60it/s[0m  
[2KAttention weights: tensor([[0.7082, 0.2918],â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”[0m 151/203 [2m0:00:58 â€¢ 0:00:20[0m [2;4m2.60it/s[0m  
        [0.5001, 0.4999],
        [0.5543, 0.4457],
        [0.8289, 0.1711],
        [0.6873, 0.3127],
        [0.7456, 0.2544],
        [0.7137, 0.2863],
        [0.6388, 0.3612],
        [0.5743, 0.4257],
[2K        [0.7018, 0.2982]], device='cuda:0')â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”[0m 151/203 [2m0:00:58 â€¢ 0:00:20[0m [2;4m2.60it/s[0m  
[2KAttention weights: tensor([[0.5234, 0.4766],â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”[0m 152/203 [2m0:00:58 â€¢ 0:00:20[0m [2;4m2.61it/s[0m  
        [0.5147, 0.4853],
        [0.5168, 0.4832],
        [0.5226, 0.4774],
        [0.5247, 0.4753],
        [0.5272, 0.4728],
        [0.5244, 0.4756],
        [0.5214, 0.4786],
        [0.5185, 0.4815],
[2K        [0.5246, 0.4754]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”[0m 152/203 [2m0:00:58 â€¢ 0:00:20[0m [2;4m2.61it/s[0m  
[2KClass label: HighJumpâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”[0m 152/203 [2m0:00:58 â€¢ 0:00:20[0m [2;4m2.61it/s[0m  
[2KAttention weights: tensor([[0.6883, 0.3117]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 152/203 [2m0:00:58 â€¢ 0:00:20[0m [2;4m2.61it/s[0m  
[2KStep 0 - TTA Loss: 0.9265â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”[0m 152/203 [2m0:00:58 â€¢ 0:00:20[0m [2;4m2.61it/s[0m  
[2KAttention weights: tensor([[0.6988, 0.3012]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 152/203 [2m0:00:58 â€¢ 0:00:20[0m [2;4m2.61it/s[0m  
[2KAttention weights: tensor([[0.7032, 0.2968]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 152/203 [2m0:00:58 â€¢ 0:00:20[0m [2;4m2.61it/s[0m  
[2KAttention weights: tensor([[0.7009, 0.2991]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 152/203 [2m0:00:58 â€¢ 0:00:20[0m [2;4m2.61it/s[0m  
[2KAttention weights: tensor([[0.6968, 0.3032]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 152/203 [2m0:00:58 â€¢ 0:00:20[0m [2;4m2.61it/s[0m  
[2KAttention weights: tensor([[0.6919, 0.3081]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 152/203 [2m0:00:58 â€¢ 0:00:20[0m [2;4m2.61it/s[0m  
[2KAttention weights: tensor([[0.6878, 0.3122]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 152/203 [2m0:00:58 â€¢ 0:00:20[0m [2;4m2.61it/s[0m  
[2KAttention weights: tensor([[0.6848, 0.3152]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 152/203 [2m0:00:58 â€¢ 0:00:20[0m [2;4m2.61it/s[0m  
[2KAttention weights: tensor([[0.6836, 0.3164]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 152/203 [2m0:00:58 â€¢ 0:00:20[0m [2;4m2.61it/s[0m  
[2KAttention weights: tensor([[0.6831, 0.3169]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 152/203 [2m0:00:58 â€¢ 0:00:20[0m [2;4m2.61it/s[0m  
[2KAttention weights: tensor([[0.5283, 0.4717]], device='cuda:0');6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”[0m 152/203 [2m0:00:58 â€¢ 0:00:20[0m [2;4m2.61it/s[0m  
[2KAttention weights: tensor([[0.6890, 0.3110],â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”[0m 152/203 [2m0:00:58 â€¢ 0:00:20[0m [2;4m2.61it/s[0m  
        [0.5066, 0.4934],
        [0.5446, 0.4554],
        [0.8404, 0.1596],
        [0.6578, 0.3422],
        [0.6837, 0.3163],
        [0.6694, 0.3306],
        [0.6181, 0.3819],
        [0.5513, 0.4487],
[2K        [0.6669, 0.3331]], device='cuda:0')â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”[0m 152/203 [2m0:00:58 â€¢ 0:00:20[0m [2;4m2.61it/s[0m  
[2KAttention weights: tensor([[0.5235, 0.4765],â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”[0m 153/203 [2m0:00:59 â€¢ 0:00:20[0m [2;4m2.58it/s[0m   
        [0.5147, 0.4853],
        [0.5169, 0.4831],
        [0.5227, 0.4773],
        [0.5247, 0.4753],
        [0.5272, 0.4728],
        [0.5245, 0.4755],
        [0.5214, 0.4786],
        [0.5185, 0.4815],
[2K        [0.5246, 0.4754]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[38;5;237mâ”â”â”â”â”â”â”â”â”[0m 153/203 [2m0:00:59 â€¢ 0:00:20[0m [2;4m2.58it/s[0m  
[2KClass label: HammerThrowâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”[0m 153/203 [2m0:00:59 â€¢ 0:00:20[0m [2;4m2.58it/s[0m  
[2KAttention weights: tensor([[0.5783, 0.4217]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 153/203 [2m0:00:59 â€¢ 0:00:20[0m [2;4m2.58it/s[0m  
[2KStep 0 - TTA Loss: 1.9190â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”[0m 153/203 [2m0:00:59 â€¢ 0:00:20[0m [2;4m2.58it/s[0m  
[2KAttention weights: tensor([[0.5783, 0.4217]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 153/203 [2m0:00:59 â€¢ 0:00:20[0m [2;4m2.58it/s[0m  
[2KAttention weights: tensor([[0.5789, 0.4211]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 153/203 [2m0:00:59 â€¢ 0:00:20[0m [2;4m2.58it/s[0m  
[2KAttention weights: tensor([[0.5817, 0.4183]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 153/203 [2m0:00:59 â€¢ 0:00:20[0m [2;4m2.58it/s[0m  
[2KAttention weights: tensor([[0.5930, 0.4070]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 153/203 [2m0:00:59 â€¢ 0:00:20[0m [2;4m2.58it/s[0m  
[2KAttention weights: tensor([[0.6077, 0.3923]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 153/203 [2m0:00:59 â€¢ 0:00:20[0m [2;4m2.58it/s[0m  
[2KAttention weights: tensor([[0.6268, 0.3732]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 153/203 [2m0:00:59 â€¢ 0:00:20[0m [2;4m2.58it/s[0m  
[2KAttention weights: tensor([[0.6507, 0.3493]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 153/203 [2m0:00:59 â€¢ 0:00:20[0m [2;4m2.58it/s[0m  
[2KAttention weights: tensor([[0.6683, 0.3317]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 153/203 [2m0:00:59 â€¢ 0:00:20[0m [2;4m2.58it/s[0m  
[2KAttention weights: tensor([[0.6891, 0.3109]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 153/203 [2m0:00:59 â€¢ 0:00:20[0m [2;4m2.58it/s[0m  
[2KAttention weights: tensor([[0.5275, 0.4725]], device='cuda:0')37mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”[0m 153/203 [2m0:00:59 â€¢ 0:00:20[0m [2;4m2.58it/s[0m  
[2KAttention weights: tensor([[0.6700, 0.3300],â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”[0m 153/203 [2m0:00:59 â€¢ 0:00:20[0m [2;4m2.58it/s[0m  
        [0.4669, 0.5331],
        [0.5337, 0.4663],
        [0.7019, 0.2981],
        [0.7017, 0.2983],
        [0.7415, 0.2585],
        [0.7002, 0.2998],
        [0.6402, 0.3598],
        [0.5522, 0.4478],
[2K        [0.6838, 0.3162]], device='cuda:0')â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”[0m 153/203 [2m0:00:59 â€¢ 0:00:20[0m [2;4m2.58it/s[0m  
[2KAttention weights: tensor([[0.5236, 0.4764],â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”[0m 154/203 [2m0:01:00 â€¢ 0:00:20[0m [2;4m2.58it/s[0m  
        [0.5147, 0.4853],
        [0.5169, 0.4831],
        [0.5227, 0.4773],
        [0.5248, 0.4752],
        [0.5273, 0.4727],
        [0.5245, 0.4755],
        [0.5215, 0.4785],
        [0.5186, 0.4814],
[2K        [0.5247, 0.4753]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[38;5;237mâ”â”â”â”â”â”â”â”â”[0m 154/203 [2m0:01:00 â€¢ 0:00:20[0m [2;4m2.58it/s[0m  
[2KClass label: PoleVaultâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”[0m 154/203 [2m0:01:00 â€¢ 0:00:20[0m [2;4m2.58it/s[0m  
[2KAttention weights: tensor([[0.6414, 0.3586]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 154/203 [2m0:01:00 â€¢ 0:00:20[0m [2;4m2.58it/s[0m  
[2KStep 0 - TTA Loss: 2.1277â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”[0m 154/203 [2m0:01:00 â€¢ 0:00:20[0m [2;4m2.58it/s[0m  
[2KAttention weights: tensor([[0.6478, 0.3522]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 154/203 [2m0:01:00 â€¢ 0:00:20[0m [2;4m2.58it/s[0m  
[2KAttention weights: tensor([[0.6614, 0.3386]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 154/203 [2m0:01:00 â€¢ 0:00:20[0m [2;4m2.58it/s[0m  
[2KAttention weights: tensor([[0.6683, 0.3317]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 154/203 [2m0:01:00 â€¢ 0:00:20[0m [2;4m2.58it/s[0m  
[2KAttention weights: tensor([[0.6761, 0.3239]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 154/203 [2m0:01:00 â€¢ 0:00:20[0m [2;4m2.58it/s[0m  
[2KAttention weights: tensor([[0.6875, 0.3125]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 154/203 [2m0:01:00 â€¢ 0:00:20[0m [2;4m2.58it/s[0m  
[2KAttention weights: tensor([[0.6937, 0.3063]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 154/203 [2m0:01:00 â€¢ 0:00:20[0m [2;4m2.58it/s[0m  
[2KAttention weights: tensor([[0.6971, 0.3029]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 154/203 [2m0:01:00 â€¢ 0:00:20[0m [2;4m2.58it/s[0m  
[2KAttention weights: tensor([[0.7000, 0.3000]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 154/203 [2m0:01:00 â€¢ 0:00:20[0m [2;4m2.58it/s[0m  
[2KAttention weights: tensor([[0.7008, 0.2992]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 154/203 [2m0:01:00 â€¢ 0:00:20[0m [2;4m2.58it/s[0m  
[2KAttention weights: tensor([[0.5266, 0.4734]], device='cuda:0')37mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”[0m 154/203 [2m0:01:00 â€¢ 0:00:20[0m [2;4m2.58it/s[0m  
[2KAttention weights: tensor([[0.6475, 0.3525],â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”[0m 154/203 [2m0:01:00 â€¢ 0:00:20[0m [2;4m2.58it/s[0m  
        [0.4591, 0.5409],
        [0.5188, 0.4812],
        [0.6708, 0.3292],
        [0.6544, 0.3456],
        [0.7318, 0.2682],
        [0.7017, 0.2983],
        [0.6308, 0.3692],
        [0.5387, 0.4613],
[2K        [0.6514, 0.3486]], device='cuda:0')â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”[0m 154/203 [2m0:01:00 â€¢ 0:00:20[0m [2;4m2.58it/s[0m  
[2KAttention weights: tensor([[0.5236, 0.4764],â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”[0m 155/203 [2m0:01:00 â€¢ 0:00:19[0m [2;4m2.59it/s[0m  
        [0.5148, 0.4852],
        [0.5170, 0.4830],
        [0.5228, 0.4772],
        [0.5249, 0.4751],
        [0.5273, 0.4727],
        [0.5246, 0.4754],
        [0.5215, 0.4785],
        [0.5186, 0.4814],
[2K        [0.5247, 0.4753]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m[38;5;237mâ”â”â”â”â”â”â”â”â”[0m 155/203 [2m0:01:00 â€¢ 0:00:19[0m [2;4m2.59it/s[0m  
[2KClass label: HighJumpâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”[0m 155/203 [2m0:01:00 â€¢ 0:00:19[0m [2;4m2.59it/s[0m  
[2KAttention weights: tensor([[0.6888, 0.3112]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 155/203 [2m0:01:00 â€¢ 0:00:19[0m [2;4m2.59it/s[0m  
[2KStep 0 - TTA Loss: 1.2365â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”[0m 155/203 [2m0:01:00 â€¢ 0:00:19[0m [2;4m2.59it/s[0m  
[2KAttention weights: tensor([[0.6888, 0.3112]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 155/203 [2m0:01:00 â€¢ 0:00:19[0m [2;4m2.59it/s[0m  
[2KAttention weights: tensor([[0.6891, 0.3109]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 155/203 [2m0:01:00 â€¢ 0:00:19[0m [2;4m2.59it/s[0m  
[2KAttention weights: tensor([[0.6905, 0.3095]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 155/203 [2m0:01:00 â€¢ 0:00:19[0m [2;4m2.59it/s[0m  
[2KAttention weights: tensor([[0.6937, 0.3063]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 155/203 [2m0:01:00 â€¢ 0:00:19[0m [2;4m2.59it/s[0m  
[2KAttention weights: tensor([[0.6995, 0.3005]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 155/203 [2m0:01:00 â€¢ 0:00:19[0m [2;4m2.59it/s[0m  
[2KAttention weights: tensor([[0.7076, 0.2924]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 155/203 [2m0:01:00 â€¢ 0:00:19[0m [2;4m2.59it/s[0m  
[2KAttention weights: tensor([[0.7191, 0.2809]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 155/203 [2m0:01:00 â€¢ 0:00:19[0m [2;4m2.59it/s[0m  
[2KAttention weights: tensor([[0.7312, 0.2688]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 155/203 [2m0:01:00 â€¢ 0:00:19[0m [2;4m2.59it/s[0m  
[2KAttention weights: tensor([[0.7423, 0.2577]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 155/203 [2m0:01:00 â€¢ 0:00:19[0m [2;4m2.59it/s[0m  
[2KAttention weights: tensor([[0.5313, 0.4687]], device='cuda:0')8;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”[0m 155/203 [2m0:01:00 â€¢ 0:00:19[0m [2;4m2.59it/s[0m  
[2KAttention weights: tensor([[0.6348, 0.3652],â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”[0m 155/203 [2m0:01:00 â€¢ 0:00:19[0m [2;4m2.59it/s[0m  
        [0.4574, 0.5426],
        [0.5118, 0.4882],
        [0.6336, 0.3664],
        [0.6336, 0.3664],
        [0.7558, 0.2442],
        [0.7050, 0.2950],
        [0.6353, 0.3647],
        [0.5428, 0.4572],
[2K        [0.6406, 0.3594]], device='cuda:0')â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”[0m 155/203 [2m0:01:00 â€¢ 0:00:19[0m [2;4m2.59it/s[0m  
[2KAttention weights: tensor([[0.5236, 0.4764],â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”[0m 156/203 [2m0:01:00 â€¢ 0:00:19[0m [2;4m2.60it/s[0m  
        [0.5148, 0.4852],
        [0.5170, 0.4830],
        [0.5228, 0.4772],
        [0.5250, 0.4750],
        [0.5273, 0.4727],
        [0.5246, 0.4754],
        [0.5215, 0.4785],
        [0.5187, 0.4813],
[2K        [0.5248, 0.4752]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m[38;5;237mâ”â”â”â”â”â”â”â”â”[0m 156/203 [2m0:01:00 â€¢ 0:00:19[0m [2;4m2.60it/s[0m  
[2KClass label: CleanAndJerkâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”[0m 156/203 [2m0:01:00 â€¢ 0:00:19[0m [2;4m2.60it/s[0m  
[2KAttention weights: tensor([[0.4948, 0.5052]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 156/203 [2m0:01:00 â€¢ 0:00:19[0m [2;4m2.60it/s[0m  
[2KStep 0 - TTA Loss: 0.6108â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”[0m 156/203 [2m0:01:00 â€¢ 0:00:19[0m [2;4m2.60it/s[0m  
[2KAttention weights: tensor([[0.4976, 0.5024]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 156/203 [2m0:01:00 â€¢ 0:00:19[0m [2;4m2.60it/s[0m  
[2KAttention weights: tensor([[0.4951, 0.5049]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 156/203 [2m0:01:00 â€¢ 0:00:19[0m [2;4m2.60it/s[0m  
[2KAttention weights: tensor([[0.4916, 0.5084]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 156/203 [2m0:01:00 â€¢ 0:00:19[0m [2;4m2.60it/s[0m  
[2KAttention weights: tensor([[0.4852, 0.5148]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 156/203 [2m0:01:00 â€¢ 0:00:19[0m [2;4m2.60it/s[0m  
[2KAttention weights: tensor([[0.4786, 0.5214]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 156/203 [2m0:01:00 â€¢ 0:00:19[0m [2;4m2.60it/s[0m  
[2KAttention weights: tensor([[0.4727, 0.5273]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 156/203 [2m0:01:00 â€¢ 0:00:19[0m [2;4m2.60it/s[0m  
[2KAttention weights: tensor([[0.4690, 0.5310]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 156/203 [2m0:01:00 â€¢ 0:00:19[0m [2;4m2.60it/s[0m  
[2KAttention weights: tensor([[0.4670, 0.5330]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 156/203 [2m0:01:00 â€¢ 0:00:19[0m [2;4m2.60it/s[0m  
[2KAttention weights: tensor([[0.4660, 0.5340]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 156/203 [2m0:01:00 â€¢ 0:00:19[0m [2;4m2.60it/s[0m  
[2KAttention weights: tensor([[0.5159, 0.4841]], device='cuda:0')8;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”[0m 156/203 [2m0:01:00 â€¢ 0:00:19[0m [2;4m2.60it/s[0m  
[2KAttention weights: tensor([[0.6184, 0.3816],â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”[0m 156/203 [2m0:01:00 â€¢ 0:00:19[0m [2;4m2.60it/s[0m  
        [0.4450, 0.5550],
        [0.4656, 0.5344],
        [0.6183, 0.3817],
        [0.6137, 0.3863],
        [0.7402, 0.2598],
        [0.6869, 0.3131],
        [0.6293, 0.3707],
        [0.5316, 0.4684],
[2K        [0.6208, 0.3792]], device='cuda:0')â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”[0m 156/203 [2m0:01:00 â€¢ 0:00:19[0m [2;4m2.60it/s[0m  
[2KAttention weights: tensor([[0.5237, 0.4763],â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”[0m 157/203 [2m0:01:01 â€¢ 0:00:18[0m [2;4m2.60it/s[0m  
        [0.5148, 0.4852],
        [0.5170, 0.4830],
        [0.5228, 0.4772],
        [0.5250, 0.4750],
        [0.5274, 0.4726],
        [0.5246, 0.4754],
        [0.5215, 0.4785],
        [0.5187, 0.4813],
[2K        [0.5248, 0.4752]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m[38;5;237mâ”â”â”â”â”â”â”â”â”[0m 157/203 [2m0:01:01 â€¢ 0:00:18[0m [2;4m2.60it/s[0m  
[2KClass label: GolfSwingâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”[0m 157/203 [2m0:01:01 â€¢ 0:00:18[0m [2;4m2.60it/s[0m  
[2KAttention weights: tensor([[0.6054, 0.3946]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 157/203 [2m0:01:01 â€¢ 0:00:18[0m [2;4m2.60it/s[0m  
[2KStep 0 - TTA Loss: 1.0861â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”[0m 157/203 [2m0:01:01 â€¢ 0:00:18[0m [2;4m2.60it/s[0m  
[2KAttention weights: tensor([[0.6054, 0.3946]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 157/203 [2m0:01:01 â€¢ 0:00:18[0m [2;4m2.60it/s[0m  
[2KAttention weights: tensor([[0.6053, 0.3947]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 157/203 [2m0:01:01 â€¢ 0:00:18[0m [2;4m2.60it/s[0m  
[2KAttention weights: tensor([[0.6052, 0.3948]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 157/203 [2m0:01:01 â€¢ 0:00:18[0m [2;4m2.60it/s[0m  
[2KAttention weights: tensor([[0.6048, 0.3952]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 157/203 [2m0:01:01 â€¢ 0:00:18[0m [2;4m2.60it/s[0m  
[2KAttention weights: tensor([[0.6043, 0.3957]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 157/203 [2m0:01:01 â€¢ 0:00:18[0m [2;4m2.60it/s[0m  
[2KAttention weights: tensor([[0.6038, 0.3962]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 157/203 [2m0:01:01 â€¢ 0:00:18[0m [2;4m2.60it/s[0m  
[2KAttention weights: tensor([[0.6054, 0.3946]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 157/203 [2m0:01:01 â€¢ 0:00:18[0m [2;4m2.60it/s[0m  
[2KAttention weights: tensor([[0.6058, 0.3942]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 157/203 [2m0:01:01 â€¢ 0:00:18[0m [2;4m2.60it/s[0m  
[2KAttention weights: tensor([[0.6076, 0.3924]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 157/203 [2m0:01:01 â€¢ 0:00:18[0m [2;4m2.60it/s[0m  
[2KAttention weights: tensor([[0.5235, 0.4765]], device='cuda:0')8;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”[0m 157/203 [2m0:01:01 â€¢ 0:00:18[0m [2;4m2.60it/s[0m  
[2KAttention weights: tensor([[0.6031, 0.3969],â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”[0m 157/203 [2m0:01:01 â€¢ 0:00:18[0m [2;4m2.60it/s[0m  
        [0.4455, 0.5545],
        [0.4736, 0.5264],
        [0.6088, 0.3912],
        [0.5812, 0.4188],
        [0.6977, 0.3023],
        [0.6494, 0.3506],
        [0.6055, 0.3945],
        [0.5164, 0.4836],
[2K        [0.5902, 0.4098]], device='cuda:0')â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”[0m 157/203 [2m0:01:01 â€¢ 0:00:18[0m [2;4m2.60it/s[0m  
[2KAttention weights: tensor([[0.5237, 0.4763],â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”[0m 158/203 [2m0:01:01 â€¢ 0:00:18[0m [2;4m2.60it/s[0m   
        [0.5148, 0.4852],
        [0.5170, 0.4830],
        [0.5228, 0.4772],
        [0.5250, 0.4750],
        [0.5274, 0.4726],
        [0.5246, 0.4754],
        [0.5215, 0.4785],
        [0.5187, 0.4813],
[2K        [0.5248, 0.4752]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[38;5;237mâ”â”â”â”â”â”â”â”[0m 158/203 [2m0:01:01 â€¢ 0:00:18[0m [2;4m2.60it/s[0m  
[2KClass label: BaseballPitchâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”[0m 158/203 [2m0:01:01 â€¢ 0:00:18[0m [2;4m2.60it/s[0m  
[2KAttention weights: tensor([[0.6034, 0.3966]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 158/203 [2m0:01:01 â€¢ 0:00:18[0m [2;4m2.60it/s[0m  
[2KStep 0 - TTA Loss: 1.8221â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”[0m 158/203 [2m0:01:01 â€¢ 0:00:18[0m [2;4m2.60it/s[0m  
[2KAttention weights: tensor([[0.6104, 0.3896]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 158/203 [2m0:01:01 â€¢ 0:00:18[0m [2;4m2.60it/s[0m  
[2KAttention weights: tensor([[0.6168, 0.3832]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 158/203 [2m0:01:01 â€¢ 0:00:18[0m [2;4m2.60it/s[0m  
[2KAttention weights: tensor([[0.6203, 0.3797]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 158/203 [2m0:01:01 â€¢ 0:00:18[0m [2;4m2.60it/s[0m  
[2KAttention weights: tensor([[0.6237, 0.3763]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 158/203 [2m0:01:01 â€¢ 0:00:18[0m [2;4m2.60it/s[0m  
[2KAttention weights: tensor([[0.6281, 0.3719]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 158/203 [2m0:01:01 â€¢ 0:00:18[0m [2;4m2.60it/s[0m  
[2KAttention weights: tensor([[0.6308, 0.3692]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 158/203 [2m0:01:01 â€¢ 0:00:18[0m [2;4m2.60it/s[0m  
[2KAttention weights: tensor([[0.6322, 0.3678]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 158/203 [2m0:01:01 â€¢ 0:00:18[0m [2;4m2.60it/s[0m  
[2KAttention weights: tensor([[0.6334, 0.3666]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 158/203 [2m0:01:01 â€¢ 0:00:18[0m [2;4m2.60it/s[0m  
[2KAttention weights: tensor([[0.6338, 0.3662]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 158/203 [2m0:01:01 â€¢ 0:00:18[0m [2;4m2.60it/s[0m  
[2KAttention weights: tensor([[0.5252, 0.4748]], device='cuda:0')237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”[0m 158/203 [2m0:01:01 â€¢ 0:00:18[0m [2;4m2.60it/s[0m  
[2KAttention weights: tensor([[0.6343, 0.3657],â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”[0m 158/203 [2m0:01:01 â€¢ 0:00:18[0m [2;4m2.60it/s[0m  
        [0.4502, 0.5498],
        [0.4813, 0.5187],
        [0.6192, 0.3808],
        [0.5987, 0.4013],
        [0.7042, 0.2958],
        [0.6555, 0.3445],
        [0.6136, 0.3864],
        [0.5272, 0.4728],
[2K        [0.6048, 0.3952]], device='cuda:0')â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”[0m 158/203 [2m0:01:01 â€¢ 0:00:18[0m [2;4m2.60it/s[0m  
[2KAttention weights: tensor([[0.5237, 0.4763],â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”[0m 159/203 [2m0:01:01 â€¢ 0:00:17[0m [2;4m2.61it/s[0m  
        [0.5148, 0.4852],
        [0.5170, 0.4830],
        [0.5228, 0.4772],
        [0.5250, 0.4750],
        [0.5274, 0.4726],
        [0.5246, 0.4754],
        [0.5215, 0.4785],
        [0.5187, 0.4813],
[2K        [0.5248, 0.4752]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[38;5;237mâ”â”â”â”â”â”â”â”[0m 159/203 [2m0:01:01 â€¢ 0:00:17[0m [2;4m2.61it/s[0m  
[2KClass label: Billiardsâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”[0m 159/203 [2m0:01:01 â€¢ 0:00:17[0m [2;4m2.61it/s[0m  
[2KAttention weights: tensor([[0.4480, 0.5520]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 159/203 [2m0:01:01 â€¢ 0:00:17[0m [2;4m2.61it/s[0m  
[2KStep 0 - TTA Loss: 1.6111â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”[0m 159/203 [2m0:01:01 â€¢ 0:00:17[0m [2;4m2.61it/s[0m  
[2KAttention weights: tensor([[0.4480, 0.5520]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 159/203 [2m0:01:01 â€¢ 0:00:17[0m [2;4m2.61it/s[0m  
[2KAttention weights: tensor([[0.4484, 0.5516]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 159/203 [2m0:01:01 â€¢ 0:00:17[0m [2;4m2.61it/s[0m  
[2KAttention weights: tensor([[0.4508, 0.5492]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 159/203 [2m0:01:01 â€¢ 0:00:17[0m [2;4m2.61it/s[0m  
[2KAttention weights: tensor([[0.4592, 0.5408]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 159/203 [2m0:01:01 â€¢ 0:00:17[0m [2;4m2.61it/s[0m  
[2KAttention weights: tensor([[0.4724, 0.5276]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 159/203 [2m0:01:01 â€¢ 0:00:17[0m [2;4m2.61it/s[0m  
[2KAttention weights: tensor([[0.4948, 0.5052]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 159/203 [2m0:01:01 â€¢ 0:00:17[0m [2;4m2.61it/s[0m  
[2KAttention weights: tensor([[0.5270, 0.4730]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 159/203 [2m0:01:01 â€¢ 0:00:17[0m [2;4m2.61it/s[0m  
[2KAttention weights: tensor([[0.5749, 0.4251]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 159/203 [2m0:01:01 â€¢ 0:00:17[0m [2;4m2.61it/s[0m  
[2KAttention weights: tensor([[0.6342, 0.3658]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 159/203 [2m0:01:01 â€¢ 0:00:17[0m [2;4m2.61it/s[0m  
[2KAttention weights: tensor([[0.5225, 0.4775]], device='cuda:0')237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”[0m 159/203 [2m0:01:01 â€¢ 0:00:17[0m [2;4m2.61it/s[0m  
[2KAttention weights: tensor([[0.6366, 0.3634],â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”[0m 159/203 [2m0:01:01 â€¢ 0:00:17[0m [2;4m2.61it/s[0m  
        [0.6866, 0.3134],
        [0.5048, 0.4952],
        [0.6539, 0.3461],
        [0.6076, 0.3924],
        [0.6994, 0.3006],
        [0.6487, 0.3513],
        [0.6359, 0.3641],
        [0.5371, 0.4629],
[2K        [0.6069, 0.3931]], device='cuda:0')â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”[0m 159/203 [2m0:01:01 â€¢ 0:00:17[0m [2;4m2.61it/s[0m  
[2KAttention weights: tensor([[0.5237, 0.4763],â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”[0m 160/203 [2m0:01:02 â€¢ 0:00:17[0m [2;4m2.61it/s[0m  
        [0.5148, 0.4852],
        [0.5170, 0.4830],
        [0.5228, 0.4772],
        [0.5250, 0.4750],
        [0.5274, 0.4726],
        [0.5246, 0.4754],
        [0.5216, 0.4784],
        [0.5187, 0.4813],
[2K        [0.5248, 0.4752]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”[0m 160/203 [2m0:01:02 â€¢ 0:00:17[0m [2;4m2.61it/s[0m  
[2KClass label: Billiardsâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”[0m 160/203 [2m0:01:02 â€¢ 0:00:17[0m [2;4m2.61it/s[0m  
[2KAttention weights: tensor([[0.4431, 0.5569]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 160/203 [2m0:01:02 â€¢ 0:00:17[0m [2;4m2.61it/s[0m  
[2KStep 0 - TTA Loss: 1.2158â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”[0m 160/203 [2m0:01:02 â€¢ 0:00:17[0m [2;4m2.61it/s[0m  
[2KAttention weights: tensor([[0.4955, 0.5045]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 160/203 [2m0:01:02 â€¢ 0:00:17[0m [2;4m2.61it/s[0m  
[2KAttention weights: tensor([[0.5490, 0.4510]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 160/203 [2m0:01:02 â€¢ 0:00:17[0m [2;4m2.61it/s[0m  
[2KAttention weights: tensor([[0.5938, 0.4062]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 160/203 [2m0:01:02 â€¢ 0:00:17[0m [2;4m2.61it/s[0m  
[2KAttention weights: tensor([[0.6324, 0.3676]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 160/203 [2m0:01:02 â€¢ 0:00:17[0m [2;4m2.61it/s[0m  
[2KAttention weights: tensor([[0.6649, 0.3351]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 160/203 [2m0:01:02 â€¢ 0:00:17[0m [2;4m2.61it/s[0m  
[2KAttention weights: tensor([[0.6825, 0.3175]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 160/203 [2m0:01:02 â€¢ 0:00:17[0m [2;4m2.61it/s[0m  
[2KAttention weights: tensor([[0.6933, 0.3067]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 160/203 [2m0:01:02 â€¢ 0:00:17[0m [2;4m2.61it/s[0m  
[2KAttention weights: tensor([[0.6989, 0.3011]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 160/203 [2m0:01:02 â€¢ 0:00:17[0m [2;4m2.61it/s[0m  
[2KAttention weights: tensor([[0.7017, 0.2983]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 160/203 [2m0:01:02 â€¢ 0:00:17[0m [2;4m2.61it/s[0m  
[2KAttention weights: tensor([[0.5232, 0.4768]], device='cuda:0')98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”[0m 160/203 [2m0:01:02 â€¢ 0:00:17[0m [2;4m2.61it/s[0m  
[2KAttention weights: tensor([[0.6286, 0.3714],â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”[0m 160/203 [2m0:01:02 â€¢ 0:00:17[0m [2;4m2.61it/s[0m  
        [0.7025, 0.2975],
        [0.5037, 0.4963],
        [0.6528, 0.3472],
        [0.6090, 0.3910],
        [0.7000, 0.3000],
        [0.6462, 0.3538],
        [0.6396, 0.3604],
        [0.5342, 0.4658],
[2K        [0.6061, 0.3939]], device='cuda:0')â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”[0m 160/203 [2m0:01:02 â€¢ 0:00:17[0m [2;4m2.61it/s[0m  
[2KAttention weights: tensor([[0.5237, 0.4763],â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”[0m 161/203 [2m0:01:02 â€¢ 0:00:17[0m [2;4m2.62it/s[0m  
        [0.5149, 0.4851],
        [0.5170, 0.4830],
        [0.5228, 0.4772],
        [0.5250, 0.4750],
        [0.5274, 0.4726],
        [0.5247, 0.4753],
        [0.5216, 0.4784],
        [0.5187, 0.4813],
[2K        [0.5248, 0.4752]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”[0m 161/203 [2m0:01:02 â€¢ 0:00:17[0m [2;4m2.62it/s[0m  
[2KClass label: Billiardsâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”[0m 161/203 [2m0:01:02 â€¢ 0:00:17[0m [2;4m2.62it/s[0m  
[2KAttention weights: tensor([[0.4454, 0.5546]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 161/203 [2m0:01:02 â€¢ 0:00:17[0m [2;4m2.62it/s[0m  
[2KStep 0 - TTA Loss: 2.2377â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”[0m 161/203 [2m0:01:02 â€¢ 0:00:17[0m [2;4m2.62it/s[0m  
[2KAttention weights: tensor([[0.4454, 0.5546]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 161/203 [2m0:01:02 â€¢ 0:00:17[0m [2;4m2.62it/s[0m  
[2KAttention weights: tensor([[0.4465, 0.5535]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 161/203 [2m0:01:02 â€¢ 0:00:17[0m [2;4m2.62it/s[0m  
[2KAttention weights: tensor([[0.4499, 0.5501]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 161/203 [2m0:01:02 â€¢ 0:00:17[0m [2;4m2.62it/s[0m  
[2KAttention weights: tensor([[0.4607, 0.5393]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 161/203 [2m0:01:02 â€¢ 0:00:17[0m [2;4m2.62it/s[0m  
[2KAttention weights: tensor([[0.4813, 0.5187]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 161/203 [2m0:01:02 â€¢ 0:00:17[0m [2;4m2.62it/s[0m  
[2KAttention weights: tensor([[0.5068, 0.4932]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 161/203 [2m0:01:02 â€¢ 0:00:17[0m [2;4m2.62it/s[0m  
[2KAttention weights: tensor([[0.5444, 0.4556]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 161/203 [2m0:01:02 â€¢ 0:00:17[0m [2;4m2.62it/s[0m  
[2KAttention weights: tensor([[0.5877, 0.4123]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 161/203 [2m0:01:02 â€¢ 0:00:17[0m [2;4m2.62it/s[0m  
[2KAttention weights: tensor([[0.6364, 0.3636]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 161/203 [2m0:01:02 â€¢ 0:00:17[0m [2;4m2.62it/s[0m  
[2KAttention weights: tensor([[0.5210, 0.4790]], device='cuda:0')98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”[0m 161/203 [2m0:01:02 â€¢ 0:00:17[0m [2;4m2.62it/s[0m  
[2KAttention weights: tensor([[0.6206, 0.3794],â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”[0m 161/203 [2m0:01:02 â€¢ 0:00:17[0m [2;4m2.62it/s[0m  
        [0.6851, 0.3149],
        [0.5079, 0.4921],
        [0.6457, 0.3543],
        [0.6004, 0.3996],
        [0.6971, 0.3029],
        [0.6449, 0.3551],
        [0.6371, 0.3629],
        [0.5326, 0.4674],
[2K        [0.6006, 0.3994]], device='cuda:0')â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”[0m 161/203 [2m0:01:02 â€¢ 0:00:17[0m [2;4m2.62it/s[0m  
[2KAttention weights: tensor([[0.5238, 0.4762],â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”[0m 162/203 [2m0:01:02 â€¢ 0:00:16[0m [2;4m2.62it/s[0m  
        [0.5150, 0.4850],
        [0.5171, 0.4829],
        [0.5229, 0.4771],
        [0.5251, 0.4749],
        [0.5274, 0.4726],
        [0.5247, 0.4753],
        [0.5216, 0.4784],
        [0.5188, 0.4812],
[2K        [0.5248, 0.4752]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”[0m 162/203 [2m0:01:02 â€¢ 0:00:16[0m [2;4m2.62it/s[0m  
[2KClass label: HighJumpâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”[0m 162/203 [2m0:01:02 â€¢ 0:00:16[0m [2;4m2.62it/s[0m  
[2KAttention weights: tensor([[0.6891, 0.3109]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 162/203 [2m0:01:02 â€¢ 0:00:16[0m [2;4m2.62it/s[0m  
[2KStep 0 - TTA Loss: 1.0054â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”[0m 162/203 [2m0:01:02 â€¢ 0:00:16[0m [2;4m2.62it/s[0m  
[2KAttention weights: tensor([[0.6995, 0.3005]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 162/203 [2m0:01:02 â€¢ 0:00:16[0m [2;4m2.62it/s[0m  
[2KAttention weights: tensor([[0.7088, 0.2912]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 162/203 [2m0:01:02 â€¢ 0:00:16[0m [2;4m2.62it/s[0m  
[2KAttention weights: tensor([[0.7177, 0.2823]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 162/203 [2m0:01:02 â€¢ 0:00:16[0m [2;4m2.62it/s[0m  
[2KAttention weights: tensor([[0.7263, 0.2737]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 162/203 [2m0:01:02 â€¢ 0:00:16[0m [2;4m2.62it/s[0m  
[2KAttention weights: tensor([[0.7351, 0.2649]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 162/203 [2m0:01:02 â€¢ 0:00:16[0m [2;4m2.62it/s[0m  
[2KAttention weights: tensor([[0.7431, 0.2569]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 162/203 [2m0:01:02 â€¢ 0:00:16[0m [2;4m2.62it/s[0m  
[2KAttention weights: tensor([[0.7490, 0.2510]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 162/203 [2m0:01:02 â€¢ 0:00:16[0m [2;4m2.62it/s[0m  
[2KAttention weights: tensor([[0.7518, 0.2482]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 162/203 [2m0:01:02 â€¢ 0:00:16[0m [2;4m2.62it/s[0m  
[2KAttention weights: tensor([[0.7529, 0.2471]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 162/203 [2m0:01:02 â€¢ 0:00:16[0m [2;4m2.62it/s[0m  
[2KAttention weights: tensor([[0.5319, 0.4681]], device='cuda:0')98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”[0m 162/203 [2m0:01:02 â€¢ 0:00:16[0m [2;4m2.62it/s[0m  
[2KAttention weights: tensor([[0.6390, 0.3610],â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”[0m 162/203 [2m0:01:02 â€¢ 0:00:16[0m [2;4m2.62it/s[0m  
        [0.6533, 0.3467],
        [0.5138, 0.4862],
        [0.6565, 0.3435],
        [0.6378, 0.3622],
        [0.7540, 0.2460],
        [0.6906, 0.3094],
        [0.6565, 0.3435],
        [0.5494, 0.4506],
[2K        [0.6394, 0.3606]], device='cuda:0')â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”[0m 162/203 [2m0:01:02 â€¢ 0:00:16[0m [2;4m2.62it/s[0m  
[2KAttention weights: tensor([[0.5238, 0.4762],â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”[0m 163/203 [2m0:01:03 â€¢ 0:00:16[0m [2;4m2.62it/s[0m   
        [0.5151, 0.4849],
        [0.5171, 0.4829],
        [0.5229, 0.4771],
        [0.5251, 0.4749],
        [0.5275, 0.4725],
        [0.5247, 0.4753],
        [0.5216, 0.4784],
        [0.5188, 0.4812],
[2K        [0.5249, 0.4751]], device='cuda:0', grad_fn=<SoftmaxBackward0>)m[38;5;237mâ”â”â”â”â”â”â”[0m 163/203 [2m0:01:03 â€¢ 0:00:16[0m [2;4m2.62it/s[0m  
[2KClass label: BaseballPitchâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”[0m 163/203 [2m0:01:03 â€¢ 0:00:16[0m [2;4m2.62it/s[0m  
[2KAttention weights: tensor([[0.5983, 0.4017]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 163/203 [2m0:01:03 â€¢ 0:00:16[0m [2;4m2.62it/s[0m  
[2KStep 0 - TTA Loss: 1.9540â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”[0m 163/203 [2m0:01:03 â€¢ 0:00:16[0m [2;4m2.62it/s[0m  
[2KAttention weights: tensor([[0.5983, 0.4017]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 163/203 [2m0:01:03 â€¢ 0:00:16[0m [2;4m2.62it/s[0m  
[2KAttention weights: tensor([[0.5990, 0.4010]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 163/203 [2m0:01:03 â€¢ 0:00:16[0m [2;4m2.62it/s[0m  
[2KAttention weights: tensor([[0.6023, 0.3977]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 163/203 [2m0:01:03 â€¢ 0:00:16[0m [2;4m2.62it/s[0m  
[2KAttention weights: tensor([[0.6119, 0.3881]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 163/203 [2m0:01:03 â€¢ 0:00:16[0m [2;4m2.62it/s[0m  
[2KAttention weights: tensor([[0.6306, 0.3694]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 163/203 [2m0:01:03 â€¢ 0:00:16[0m [2;4m2.62it/s[0m  
[2KAttention weights: tensor([[0.6584, 0.3416]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 163/203 [2m0:01:03 â€¢ 0:00:16[0m [2;4m2.62it/s[0m  
[2KAttention weights: tensor([[0.6924, 0.3076]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 163/203 [2m0:01:03 â€¢ 0:00:16[0m [2;4m2.62it/s[0m  
[2KAttention weights: tensor([[0.7252, 0.2748]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 163/203 [2m0:01:03 â€¢ 0:00:16[0m [2;4m2.62it/s[0m  
[2KAttention weights: tensor([[0.7603, 0.2397]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 163/203 [2m0:01:03 â€¢ 0:00:16[0m [2;4m2.62it/s[0m  
[2KAttention weights: tensor([[0.5300, 0.4700]], device='cuda:0');237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”[0m 163/203 [2m0:01:03 â€¢ 0:00:16[0m [2;4m2.62it/s[0m  
[2KAttention weights: tensor([[0.7877, 0.2123],â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”[0m 163/203 [2m0:01:03 â€¢ 0:00:16[0m [2;4m2.62it/s[0m  
        [0.5003, 0.4997],
        [0.5395, 0.4605],
        [0.6794, 0.3206],
        [0.6845, 0.3155],
        [0.7673, 0.2327],
        [0.7146, 0.2854],
        [0.6308, 0.3692],
        [0.5722, 0.4278],
[2K        [0.6960, 0.3040]], device='cuda:0')â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”[0m 163/203 [2m0:01:03 â€¢ 0:00:16[0m [2;4m2.62it/s[0m  
[2KAttention weights: tensor([[0.5238, 0.4762],â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”[0m 164/203 [2m0:01:03 â€¢ 0:00:15[0m [2;4m2.62it/s[0m  
        [0.5151, 0.4849],
        [0.5171, 0.4829],
        [0.5229, 0.4771],
        [0.5251, 0.4749],
        [0.5275, 0.4725],
        [0.5247, 0.4753],
        [0.5217, 0.4783],
        [0.5188, 0.4812],
[2K        [0.5249, 0.4751]], device='cuda:0', grad_fn=<SoftmaxBackward0>)m[38;5;237mâ”â”â”â”â”â”â”[0m 164/203 [2m0:01:03 â€¢ 0:00:15[0m [2;4m2.62it/s[0m  
[2KClass label: Billiardsâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”[0m 164/203 [2m0:01:03 â€¢ 0:00:15[0m [2;4m2.62it/s[0m  
[2KAttention weights: tensor([[0.4471, 0.5529]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 164/203 [2m0:01:03 â€¢ 0:00:15[0m [2;4m2.62it/s[0m  
[2KStep 0 - TTA Loss: 0.6449â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”[0m 164/203 [2m0:01:03 â€¢ 0:00:15[0m [2;4m2.62it/s[0m  
[2KAttention weights: tensor([[0.4563, 0.5437]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 164/203 [2m0:01:03 â€¢ 0:00:15[0m [2;4m2.62it/s[0m  
[2KAttention weights: tensor([[0.4646, 0.5354]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 164/203 [2m0:01:03 â€¢ 0:00:15[0m [2;4m2.62it/s[0m  
[2KAttention weights: tensor([[0.4712, 0.5288]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 164/203 [2m0:01:03 â€¢ 0:00:15[0m [2;4m2.62it/s[0m  
[2KAttention weights: tensor([[0.4761, 0.5239]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 164/203 [2m0:01:03 â€¢ 0:00:15[0m [2;4m2.62it/s[0m  
[2KAttention weights: tensor([[0.4792, 0.5208]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 164/203 [2m0:01:03 â€¢ 0:00:15[0m [2;4m2.62it/s[0m  
[2KAttention weights: tensor([[0.4813, 0.5187]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 164/203 [2m0:01:03 â€¢ 0:00:15[0m [2;4m2.62it/s[0m  
[2KAttention weights: tensor([[0.4817, 0.5183]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 164/203 [2m0:01:03 â€¢ 0:00:15[0m [2;4m2.62it/s[0m  
[2KAttention weights: tensor([[0.4818, 0.5182]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 164/203 [2m0:01:03 â€¢ 0:00:15[0m [2;4m2.62it/s[0m  
[2KAttention weights: tensor([[0.4815, 0.5185]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 164/203 [2m0:01:03 â€¢ 0:00:15[0m [2;4m2.62it/s[0m  
[2KAttention weights: tensor([[0.5163, 0.4837]], device='cuda:0');237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”[0m 164/203 [2m0:01:03 â€¢ 0:00:15[0m [2;4m2.62it/s[0m  
[2KAttention weights: tensor([[0.7358, 0.2642],â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”[0m 164/203 [2m0:01:03 â€¢ 0:00:15[0m [2;4m2.62it/s[0m  
        [0.4814, 0.5186],
        [0.5248, 0.4752],
        [0.6524, 0.3476],
        [0.6545, 0.3455],
        [0.7473, 0.2527],
        [0.6970, 0.3030],
        [0.6213, 0.3787],
        [0.5596, 0.4404],
[2K        [0.6662, 0.3338]], device='cuda:0')â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”[0m 164/203 [2m0:01:03 â€¢ 0:00:15[0m [2;4m2.62it/s[0m  
[2KAttention weights: tensor([[0.5239, 0.4761],â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”[0m 165/203 [2m0:01:04 â€¢ 0:00:15[0m [2;4m2.62it/s[0m  
        [0.5151, 0.4849],
        [0.5171, 0.4829],
        [0.5229, 0.4771],
        [0.5251, 0.4749],
        [0.5275, 0.4725],
        [0.5248, 0.4752],
        [0.5217, 0.4783],
        [0.5188, 0.4812],
[2K        [0.5249, 0.4751]], device='cuda:0', grad_fn=<SoftmaxBackward0>)mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”[0m 165/203 [2m0:01:04 â€¢ 0:00:15[0m [2;4m2.62it/s[0m  
[2KClass label: BaseballPitchâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”[0m 165/203 [2m0:01:04 â€¢ 0:00:15[0m [2;4m2.62it/s[0m  
[2KAttention weights: tensor([[0.6017, 0.3983]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 165/203 [2m0:01:04 â€¢ 0:00:15[0m [2;4m2.62it/s[0m  
[2KStep 0 - TTA Loss: 3.0878â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”[0m 165/203 [2m0:01:04 â€¢ 0:00:15[0m [2;4m2.62it/s[0m  
[2KAttention weights: tensor([[0.6017, 0.3983]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 165/203 [2m0:01:04 â€¢ 0:00:15[0m [2;4m2.62it/s[0m  
[2KAttention weights: tensor([[0.6035, 0.3965]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 165/203 [2m0:01:04 â€¢ 0:00:15[0m [2;4m2.62it/s[0m  
[2KAttention weights: tensor([[0.6170, 0.3830]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 165/203 [2m0:01:04 â€¢ 0:00:15[0m [2;4m2.62it/s[0m  
[2KAttention weights: tensor([[0.6511, 0.3489]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 165/203 [2m0:01:04 â€¢ 0:00:15[0m [2;4m2.62it/s[0m  
[2KAttention weights: tensor([[0.7020, 0.2980]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 165/203 [2m0:01:04 â€¢ 0:00:15[0m [2;4m2.62it/s[0m  
[2KAttention weights: tensor([[0.7790, 0.2210]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 165/203 [2m0:01:04 â€¢ 0:00:15[0m [2;4m2.62it/s[0m  
[2KAttention weights: tensor([[0.8325, 0.1675]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 165/203 [2m0:01:04 â€¢ 0:00:15[0m [2;4m2.62it/s[0m  
[2KAttention weights: tensor([[0.8740, 0.1260]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 165/203 [2m0:01:04 â€¢ 0:00:15[0m [2;4m2.62it/s[0m  
[2KAttention weights: tensor([[0.8918, 0.1082]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 165/203 [2m0:01:04 â€¢ 0:00:15[0m [2;4m2.62it/s[0m  
[2KAttention weights: tensor([[0.5306, 0.4694]], device='cuda:0');98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”[0m 165/203 [2m0:01:04 â€¢ 0:00:15[0m [2;4m2.62it/s[0m  
[2KAttention weights: tensor([[0.9064, 0.0936],â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”[0m 165/203 [2m0:01:04 â€¢ 0:00:15[0m [2;4m2.62it/s[0m  
        [0.4740, 0.5260],
        [0.5771, 0.4229],
        [0.7359, 0.2641],
        [0.7618, 0.2382],
        [0.7981, 0.2019],
        [0.7530, 0.2470],
        [0.6258, 0.3742],
        [0.6283, 0.3717],
[2K        [0.7766, 0.2234]], device='cuda:0')â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”[0m 165/203 [2m0:01:04 â€¢ 0:00:15[0m [2;4m2.62it/s[0m  
[2KAttention weights: tensor([[0.5240, 0.4760],â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”[0m 166/203 [2m0:01:04 â€¢ 0:00:15[0m [2;4m2.62it/s[0m  
        [0.5152, 0.4848],
        [0.5172, 0.4828],
        [0.5230, 0.4770],
        [0.5252, 0.4748],
        [0.5276, 0.4724],
        [0.5248, 0.4752],
        [0.5218, 0.4782],
        [0.5189, 0.4811],
[2K        [0.5250, 0.4750]], device='cuda:0', grad_fn=<SoftmaxBackward0>)mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”[0m 166/203 [2m0:01:04 â€¢ 0:00:15[0m [2;4m2.62it/s[0m  
[2KClass label: SoccerPenaltyâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”[0m 166/203 [2m0:01:04 â€¢ 0:00:15[0m [2;4m2.62it/s[0m  
[2KAttention weights: tensor([[0.6084, 0.3916]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 166/203 [2m0:01:04 â€¢ 0:00:15[0m [2;4m2.62it/s[0m  
[2KStep 0 - TTA Loss: 1.9975â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”[0m 166/203 [2m0:01:04 â€¢ 0:00:15[0m [2;4m2.62it/s[0m  
[2KAttention weights: tensor([[0.6079, 0.3921]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 166/203 [2m0:01:04 â€¢ 0:00:15[0m [2;4m2.62it/s[0m  
[2KAttention weights: tensor([[0.6062, 0.3938]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 166/203 [2m0:01:04 â€¢ 0:00:15[0m [2;4m2.62it/s[0m  
[2KAttention weights: tensor([[0.6032, 0.3968]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 166/203 [2m0:01:04 â€¢ 0:00:15[0m [2;4m2.62it/s[0m  
[2KAttention weights: tensor([[0.6026, 0.3974]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 166/203 [2m0:01:04 â€¢ 0:00:15[0m [2;4m2.62it/s[0m  
[2KAttention weights: tensor([[0.6021, 0.3979]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 166/203 [2m0:01:04 â€¢ 0:00:15[0m [2;4m2.62it/s[0m  
[2KAttention weights: tensor([[0.6023, 0.3977]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 166/203 [2m0:01:04 â€¢ 0:00:15[0m [2;4m2.62it/s[0m  
[2KAttention weights: tensor([[0.6028, 0.3972]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 166/203 [2m0:01:04 â€¢ 0:00:15[0m [2;4m2.62it/s[0m  
[2KAttention weights: tensor([[0.6027, 0.3973]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 166/203 [2m0:01:04 â€¢ 0:00:15[0m [2;4m2.62it/s[0m  
[2KAttention weights: tensor([[0.6029, 0.3971]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 166/203 [2m0:01:04 â€¢ 0:00:15[0m [2;4m2.62it/s[0m  
[2KAttention weights: tensor([[0.5218, 0.4782]], device='cuda:0');98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”[0m 166/203 [2m0:01:04 â€¢ 0:00:15[0m [2;4m2.62it/s[0m  
[2KAttention weights: tensor([[0.7346, 0.2654],â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”[0m 166/203 [2m0:01:04 â€¢ 0:00:15[0m [2;4m2.62it/s[0m  
        [0.4484, 0.5516],
        [0.5192, 0.4808],
        [0.6491, 0.3509],
        [0.6401, 0.3599],
        [0.7250, 0.2750],
        [0.6815, 0.3185],
        [0.6030, 0.3970],
        [0.5491, 0.4509],
[2K        [0.6513, 0.3487]], device='cuda:0')â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”[0m 166/203 [2m0:01:04 â€¢ 0:00:15[0m [2;4m2.62it/s[0m  
[2KAttention weights: tensor([[0.5241, 0.4759],â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”[0m 167/203 [2m0:01:04 â€¢ 0:00:14[0m [2;4m2.62it/s[0m  
        [0.5152, 0.4848],
        [0.5172, 0.4828],
        [0.5231, 0.4769],
        [0.5253, 0.4747],
        [0.5276, 0.4724],
        [0.5249, 0.4751],
        [0.5218, 0.4782],
        [0.5190, 0.4810],
[2K        [0.5250, 0.4750]], device='cuda:0', grad_fn=<SoftmaxBackward0>)mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”[0m 167/203 [2m0:01:04 â€¢ 0:00:14[0m [2;4m2.62it/s[0m  
[2KClass label: BaseballPitchâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”[0m 167/203 [2m0:01:04 â€¢ 0:00:14[0m [2;4m2.62it/s[0m  
[2KAttention weights: tensor([[0.6040, 0.3960]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 167/203 [2m0:01:04 â€¢ 0:00:14[0m [2;4m2.62it/s[0m  
[2KStep 0 - TTA Loss: 2.9685â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”[0m 167/203 [2m0:01:04 â€¢ 0:00:14[0m [2;4m2.62it/s[0m  
[2KAttention weights: tensor([[0.6040, 0.3960]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 167/203 [2m0:01:04 â€¢ 0:00:14[0m [2;4m2.62it/s[0m  
[2KAttention weights: tensor([[0.6057, 0.3943]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 167/203 [2m0:01:04 â€¢ 0:00:14[0m [2;4m2.62it/s[0m  
[2KAttention weights: tensor([[0.6151, 0.3849]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 167/203 [2m0:01:04 â€¢ 0:00:14[0m [2;4m2.62it/s[0m  
[2KAttention weights: tensor([[0.6356, 0.3644]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 167/203 [2m0:01:04 â€¢ 0:00:14[0m [2;4m2.62it/s[0m  
[2KAttention weights: tensor([[0.6741, 0.3259]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 167/203 [2m0:01:04 â€¢ 0:00:14[0m [2;4m2.62it/s[0m  
[2KAttention weights: tensor([[0.7296, 0.2704]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 167/203 [2m0:01:04 â€¢ 0:00:14[0m [2;4m2.62it/s[0m  
[2KAttention weights: tensor([[0.7972, 0.2028]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 167/203 [2m0:01:04 â€¢ 0:00:14[0m [2;4m2.62it/s[0m  
[2KAttention weights: tensor([[0.8599, 0.1401]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 167/203 [2m0:01:04 â€¢ 0:00:14[0m [2;4m2.62it/s[0m  
[2KAttention weights: tensor([[0.9014, 0.0986]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 167/203 [2m0:01:04 â€¢ 0:00:14[0m [2;4m2.62it/s[0m  
[2KAttention weights: tensor([[0.5321, 0.4679]], device='cuda:0');98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”[0m 167/203 [2m0:01:04 â€¢ 0:00:14[0m [2;4m2.62it/s[0m  
[2KAttention weights: tensor([[0.9282, 0.0718],â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”[0m 167/203 [2m0:01:04 â€¢ 0:00:14[0m [2;4m2.62it/s[0m  
        [0.4873, 0.5127],
        [0.5900, 0.4100],
        [0.7547, 0.2453],
        [0.7864, 0.2136],
        [0.8112, 0.1888],
        [0.7667, 0.2333],
        [0.6334, 0.3666],
        [0.6362, 0.3638],
[2K        [0.7992, 0.2008]], device='cuda:0')â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”[0m 167/203 [2m0:01:04 â€¢ 0:00:14[0m [2;4m2.62it/s[0m  
[2KAttention weights: tensor([[0.5242, 0.4758],â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”[0m 168/203 [2m0:01:05 â€¢ 0:00:14[0m [2;4m2.62it/s[0m   
        [0.5152, 0.4848],
        [0.5173, 0.4827],
        [0.5231, 0.4769],
        [0.5253, 0.4747],
        [0.5277, 0.4723],
        [0.5249, 0.4751],
        [0.5218, 0.4782],
        [0.5190, 0.4810],
[2K        [0.5251, 0.4749]], device='cuda:0', grad_fn=<SoftmaxBackward0>)0m[38;5;237mâ”â”â”â”â”â”[0m 168/203 [2m0:01:05 â€¢ 0:00:14[0m [2;4m2.62it/s[0m  
[2KClass label: SoccerPenaltyâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”[0m 168/203 [2m0:01:05 â€¢ 0:00:14[0m [2;4m2.62it/s[0m  
[2KAttention weights: tensor([[0.6129, 0.3871]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 168/203 [2m0:01:05 â€¢ 0:00:14[0m [2;4m2.62it/s[0m  
[2KStep 0 - TTA Loss: 2.4756â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”[0m 168/203 [2m0:01:05 â€¢ 0:00:14[0m [2;4m2.62it/s[0m  
[2KAttention weights: tensor([[0.6801, 0.3199]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 168/203 [2m0:01:05 â€¢ 0:00:14[0m [2;4m2.62it/s[0m  
[2KAttention weights: tensor([[0.7541, 0.2459]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 168/203 [2m0:01:05 â€¢ 0:00:14[0m [2;4m2.62it/s[0m  
[2KAttention weights: tensor([[0.7978, 0.2022]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 168/203 [2m0:01:05 â€¢ 0:00:14[0m [2;4m2.62it/s[0m  
[2KAttention weights: tensor([[0.8308, 0.1692]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 168/203 [2m0:01:05 â€¢ 0:00:14[0m [2;4m2.62it/s[0m  
[2KAttention weights: tensor([[0.8555, 0.1445]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 168/203 [2m0:01:05 â€¢ 0:00:14[0m [2;4m2.62it/s[0m  
[2KAttention weights: tensor([[0.8701, 0.1299]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 168/203 [2m0:01:05 â€¢ 0:00:14[0m [2;4m2.62it/s[0m  
[2KAttention weights: tensor([[0.8758, 0.1242]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 168/203 [2m0:01:05 â€¢ 0:00:14[0m [2;4m2.62it/s[0m  
[2KAttention weights: tensor([[0.8715, 0.1285]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 168/203 [2m0:01:05 â€¢ 0:00:14[0m [2;4m2.62it/s[0m  
[2KAttention weights: tensor([[0.8695, 0.1305]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 168/203 [2m0:01:05 â€¢ 0:00:14[0m [2;4m2.62it/s[0m  
[2KAttention weights: tensor([[0.5320, 0.4680]], device='cuda:0')5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”[0m 168/203 [2m0:01:05 â€¢ 0:00:14[0m [2;4m2.62it/s[0m  
[2KAttention weights: tensor([[0.8559, 0.1441],â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”[0m 168/203 [2m0:01:05 â€¢ 0:00:14[0m [2;4m2.62it/s[0m  
        [0.5113, 0.4887],
        [0.5688, 0.4312],
        [0.7404, 0.2596],
        [0.7785, 0.2215],
        [0.8360, 0.1640],
        [0.7840, 0.2160],
        [0.8692, 0.1308],
        [0.6523, 0.3477],
[2K        [0.7703, 0.2297]], device='cuda:0')â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”[0m 168/203 [2m0:01:05 â€¢ 0:00:14[0m [2;4m2.62it/s[0m  
[2KAttention weights: tensor([[0.5242, 0.4758],â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”[0m 169/203 [2m0:01:05 â€¢ 0:00:13[0m [2;4m2.63it/s[0m  
        [0.5153, 0.4847],
        [0.5173, 0.4827],
        [0.5231, 0.4769],
        [0.5253, 0.4747],
        [0.5277, 0.4723],
        [0.5249, 0.4751],
        [0.5219, 0.4781],
        [0.5190, 0.4810],
[2K        [0.5251, 0.4749]], device='cuda:0', grad_fn=<SoftmaxBackward0>)0m[38;5;237mâ”â”â”â”â”â”[0m 169/203 [2m0:01:05 â€¢ 0:00:13[0m [2;4m2.63it/s[0m  
[2KClass label: HammerThrowâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”[0m 169/203 [2m0:01:05 â€¢ 0:00:13[0m [2;4m2.63it/s[0m  
[2KAttention weights: tensor([[0.5825, 0.4175]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 169/203 [2m0:01:05 â€¢ 0:00:13[0m [2;4m2.63it/s[0m  
[2KStep 0 - TTA Loss: 0.9547â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”[0m 169/203 [2m0:01:05 â€¢ 0:00:13[0m [2;4m2.63it/s[0m  
[2KAttention weights: tensor([[0.5825, 0.4175]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 169/203 [2m0:01:05 â€¢ 0:00:13[0m [2;4m2.63it/s[0m  
[2KAttention weights: tensor([[0.5826, 0.4174]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 169/203 [2m0:01:05 â€¢ 0:00:13[0m [2;4m2.63it/s[0m  
[2KAttention weights: tensor([[0.5835, 0.4165]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 169/203 [2m0:01:05 â€¢ 0:00:13[0m [2;4m2.63it/s[0m  
[2KAttention weights: tensor([[0.5858, 0.4142]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 169/203 [2m0:01:05 â€¢ 0:00:13[0m [2;4m2.63it/s[0m  
[2KAttention weights: tensor([[0.5912, 0.4088]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 169/203 [2m0:01:05 â€¢ 0:00:13[0m [2;4m2.63it/s[0m  
[2KAttention weights: tensor([[0.5987, 0.4013]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 169/203 [2m0:01:05 â€¢ 0:00:13[0m [2;4m2.63it/s[0m  
[2KAttention weights: tensor([[0.6052, 0.3948]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 169/203 [2m0:01:05 â€¢ 0:00:13[0m [2;4m2.63it/s[0m  
[2KAttention weights: tensor([[0.6116, 0.3884]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 169/203 [2m0:01:05 â€¢ 0:00:13[0m [2;4m2.63it/s[0m  
[2KAttention weights: tensor([[0.6382, 0.3618]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 169/203 [2m0:01:05 â€¢ 0:00:13[0m [2;4m2.63it/s[0m  
[2KAttention weights: tensor([[0.5283, 0.4717]], device='cuda:0')5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”[0m 169/203 [2m0:01:05 â€¢ 0:00:13[0m [2;4m2.63it/s[0m  
[2KAttention weights: tensor([[0.6908, 0.3092],â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”[0m 169/203 [2m0:01:05 â€¢ 0:00:13[0m [2;4m2.63it/s[0m  
        [0.4496, 0.5504],
        [0.5196, 0.4804],
        [0.6481, 0.3519],
        [0.6607, 0.3393],
        [0.7245, 0.2755],
        [0.6800, 0.3200],
        [0.5534, 0.4466],
        [0.5391, 0.4609],
[2K        [0.6627, 0.3373]], device='cuda:0')â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”[0m 169/203 [2m0:01:05 â€¢ 0:00:13[0m [2;4m2.63it/s[0m  
[2KAttention weights: tensor([[0.5242, 0.4758],â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”[0m 170/203 [2m0:01:05 â€¢ 0:00:13[0m [2;4m2.62it/s[0m  
        [0.5152, 0.4848],
        [0.5173, 0.4827],
        [0.5231, 0.4769],
        [0.5253, 0.4747],
        [0.5277, 0.4723],
        [0.5249, 0.4751],
        [0.5219, 0.4781],
        [0.5190, 0.4810],
[2K        [0.5251, 0.4749]], device='cuda:0', grad_fn=<SoftmaxBackward0>)0m[38;5;237mâ”â”â”â”â”â”[0m 170/203 [2m0:01:05 â€¢ 0:00:13[0m [2;4m2.62it/s[0m  
[2KClass label: HighJumpâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”[0m 170/203 [2m0:01:05 â€¢ 0:00:13[0m [2;4m2.62it/s[0m  
[2KAttention weights: tensor([[0.6895, 0.3105]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 170/203 [2m0:01:05 â€¢ 0:00:13[0m [2;4m2.62it/s[0m  
[2KStep 0 - TTA Loss: 1.8525â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”[0m 170/203 [2m0:01:05 â€¢ 0:00:13[0m [2;4m2.62it/s[0m  
[2KAttention weights: tensor([[0.6982, 0.3018]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 170/203 [2m0:01:05 â€¢ 0:00:13[0m [2;4m2.62it/s[0m  
[2KAttention weights: tensor([[0.7077, 0.2923]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 170/203 [2m0:01:05 â€¢ 0:00:13[0m [2;4m2.62it/s[0m  
[2KAttention weights: tensor([[0.7109, 0.2891]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 170/203 [2m0:01:05 â€¢ 0:00:13[0m [2;4m2.62it/s[0m  
[2KAttention weights: tensor([[0.7162, 0.2838]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 170/203 [2m0:01:05 â€¢ 0:00:13[0m [2;4m2.62it/s[0m  
[2KAttention weights: tensor([[0.7254, 0.2746]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 170/203 [2m0:01:05 â€¢ 0:00:13[0m [2;4m2.62it/s[0m  
[2KAttention weights: tensor([[0.7317, 0.2683]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 170/203 [2m0:01:05 â€¢ 0:00:13[0m [2;4m2.62it/s[0m  
[2KAttention weights: tensor([[0.7381, 0.2619]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 170/203 [2m0:01:05 â€¢ 0:00:13[0m [2;4m2.62it/s[0m  
[2KAttention weights: tensor([[0.7408, 0.2592]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 170/203 [2m0:01:05 â€¢ 0:00:13[0m [2;4m2.62it/s[0m  
[2KAttention weights: tensor([[0.7420, 0.2580]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 170/203 [2m0:01:05 â€¢ 0:00:13[0m [2;4m2.62it/s[0m  
[2KAttention weights: tensor([[0.5300, 0.4700]], device='cuda:0')5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”[0m 170/203 [2m0:01:05 â€¢ 0:00:13[0m [2;4m2.62it/s[0m  
[2KAttention weights: tensor([[0.6819, 0.3181],â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”[0m 170/203 [2m0:01:05 â€¢ 0:00:13[0m [2;4m2.62it/s[0m  
        [0.4539, 0.5461],
        [0.5206, 0.4794],
        [0.6503, 0.3497],
        [0.6792, 0.3208],
        [0.7429, 0.2571],
        [0.6979, 0.3021],
        [0.5887, 0.4113],
        [0.5454, 0.4546],
[2K        [0.6706, 0.3294]], device='cuda:0')â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”[0m 170/203 [2m0:01:05 â€¢ 0:00:13[0m [2;4m2.62it/s[0m  
[2KAttention weights: tensor([[0.5242, 0.4758],â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”[0m 171/203 [2m0:01:06 â€¢ 0:00:13[0m [2;4m2.63it/s[0m  
        [0.5152, 0.4848],
        [0.5173, 0.4827],
        [0.5231, 0.4769],
        [0.5253, 0.4747],
        [0.5276, 0.4724],
        [0.5249, 0.4751],
        [0.5218, 0.4782],
        [0.5190, 0.4810],
[2K        [0.5251, 0.4749]], device='cuda:0', grad_fn=<SoftmaxBackward0>)4mâ•¸[0m[38;5;237mâ”â”â”â”â”â”[0m 171/203 [2m0:01:06 â€¢ 0:00:13[0m [2;4m2.63it/s[0m  
[2KClass label: BaseballPitchâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”[0m 171/203 [2m0:01:06 â€¢ 0:00:13[0m [2;4m2.63it/s[0m  
[2KAttention weights: tensor([[0.6082, 0.3918]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 171/203 [2m0:01:06 â€¢ 0:00:13[0m [2;4m2.63it/s[0m  
[2KStep 0 - TTA Loss: 1.8825â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”[0m 171/203 [2m0:01:06 â€¢ 0:00:13[0m [2;4m2.63it/s[0m  
[2KAttention weights: tensor([[0.6082, 0.3918]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 171/203 [2m0:01:06 â€¢ 0:00:13[0m [2;4m2.63it/s[0m  
[2KAttention weights: tensor([[0.6104, 0.3896]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 171/203 [2m0:01:06 â€¢ 0:00:13[0m [2;4m2.63it/s[0m  
[2KAttention weights: tensor([[0.6229, 0.3771]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 171/203 [2m0:01:06 â€¢ 0:00:13[0m [2;4m2.63it/s[0m  
[2KAttention weights: tensor([[0.6468, 0.3532]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 171/203 [2m0:01:06 â€¢ 0:00:13[0m [2;4m2.63it/s[0m  
[2KAttention weights: tensor([[0.6931, 0.3069]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 171/203 [2m0:01:06 â€¢ 0:00:13[0m [2;4m2.63it/s[0m  
[2KAttention weights: tensor([[0.7667, 0.2333]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 171/203 [2m0:01:06 â€¢ 0:00:13[0m [2;4m2.63it/s[0m  
[2KAttention weights: tensor([[0.8324, 0.1676]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 171/203 [2m0:01:06 â€¢ 0:00:13[0m [2;4m2.63it/s[0m  
[2KAttention weights: tensor([[0.9049, 0.0951]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 171/203 [2m0:01:06 â€¢ 0:00:13[0m [2;4m2.63it/s[0m  
[2KAttention weights: tensor([[0.9415, 0.0585]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 171/203 [2m0:01:06 â€¢ 0:00:13[0m [2;4m2.63it/s[0m  
[2KAttention weights: tensor([[0.5396, 0.4604]], device='cuda:0')2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”[0m 171/203 [2m0:01:06 â€¢ 0:00:13[0m [2;4m2.63it/s[0m  
[2KAttention weights: tensor([[0.9638, 0.0362],â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”[0m 171/203 [2m0:01:06 â€¢ 0:00:13[0m [2;4m2.63it/s[0m  
        [0.5010, 0.4990],
        [0.6253, 0.3747],
        [0.7976, 0.2024],
        [0.8395, 0.1605],
        [0.8434, 0.1566],
        [0.8045, 0.1955],
        [0.6242, 0.3758],
        [0.6728, 0.3272],
[2K        [0.8524, 0.1476]], device='cuda:0')â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”[0m 171/203 [2m0:01:06 â€¢ 0:00:13[0m [2;4m2.63it/s[0m  
[2KAttention weights: tensor([[0.5244, 0.4756],â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”[0m 172/203 [2m0:01:06 â€¢ 0:00:12[0m [2;4m2.63it/s[0m  
        [0.5153, 0.4847],
        [0.5173, 0.4827],
        [0.5232, 0.4768],
        [0.5254, 0.4746],
        [0.5277, 0.4723],
        [0.5250, 0.4750],
        [0.5220, 0.4780],
        [0.5191, 0.4809],
[2K        [0.5252, 0.4748]], device='cuda:0', grad_fn=<SoftmaxBackward0>)4mâ•¸[0m[38;5;237mâ”â”â”â”â”â”[0m 172/203 [2m0:01:06 â€¢ 0:00:12[0m [2;4m2.63it/s[0m  
[2KClass label: HighJumpâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”[0m 172/203 [2m0:01:06 â€¢ 0:00:12[0m [2;4m2.63it/s[0m  
[2KAttention weights: tensor([[0.6923, 0.3077]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 172/203 [2m0:01:06 â€¢ 0:00:12[0m [2;4m2.63it/s[0m  
[2KStep 0 - TTA Loss: 1.1725â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”[0m 172/203 [2m0:01:06 â€¢ 0:00:12[0m [2;4m2.63it/s[0m  
[2KAttention weights: tensor([[0.7196, 0.2804]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 172/203 [2m0:01:06 â€¢ 0:00:12[0m [2;4m2.63it/s[0m  
[2KAttention weights: tensor([[0.7462, 0.2538]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 172/203 [2m0:01:06 â€¢ 0:00:12[0m [2;4m2.63it/s[0m  
[2KAttention weights: tensor([[0.7684, 0.2316]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 172/203 [2m0:01:06 â€¢ 0:00:12[0m [2;4m2.63it/s[0m  
[2KAttention weights: tensor([[0.7784, 0.2216]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 172/203 [2m0:01:06 â€¢ 0:00:12[0m [2;4m2.63it/s[0m  
[2KAttention weights: tensor([[0.7820, 0.2180]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 172/203 [2m0:01:06 â€¢ 0:00:12[0m [2;4m2.63it/s[0m  
[2KAttention weights: tensor([[0.7904, 0.2096]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 172/203 [2m0:01:06 â€¢ 0:00:12[0m [2;4m2.63it/s[0m  
[2KAttention weights: tensor([[0.8003, 0.1997]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 172/203 [2m0:01:06 â€¢ 0:00:12[0m [2;4m2.63it/s[0m  
[2KAttention weights: tensor([[0.8049, 0.1951]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 172/203 [2m0:01:06 â€¢ 0:00:12[0m [2;4m2.63it/s[0m  
[2KAttention weights: tensor([[0.8071, 0.1929]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 172/203 [2m0:01:06 â€¢ 0:00:12[0m [2;4m2.63it/s[0m  
[2KAttention weights: tensor([[0.5344, 0.4656]], device='cuda:0')2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”[0m 172/203 [2m0:01:06 â€¢ 0:00:12[0m [2;4m2.63it/s[0m  
[2KAttention weights: tensor([[0.9165, 0.0835],â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”[0m 172/203 [2m0:01:06 â€¢ 0:00:12[0m [2;4m2.63it/s[0m  
        [0.4846, 0.5154],
        [0.5872, 0.4128],
        [0.7492, 0.2508],
        [0.7796, 0.2204],
        [0.8085, 0.1915],
        [0.7623, 0.2377],
        [0.6253, 0.3747],
        [0.6313, 0.3687],
[2K        [0.7922, 0.2078]], device='cuda:0')â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”[0m 172/203 [2m0:01:06 â€¢ 0:00:12[0m [2;4m2.63it/s[0m  
[2KAttention weights: tensor([[0.5245, 0.4755],â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”[0m 173/203 [2m0:01:07 â€¢ 0:00:12[0m [2;4m2.63it/s[0m   
        [0.5154, 0.4846],
        [0.5174, 0.4826],
        [0.5233, 0.4767],
        [0.5255, 0.4745],
        [0.5278, 0.4722],
        [0.5251, 0.4749],
        [0.5220, 0.4780],
        [0.5192, 0.4808],
[2K        [0.5252, 0.4748]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m[38;5;237mâ”â”â”â”â”[0m 173/203 [2m0:01:07 â€¢ 0:00:12[0m [2;4m2.63it/s[0m  
[2KClass label: HammerThrowâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”[0m 173/203 [2m0:01:07 â€¢ 0:00:12[0m [2;4m2.63it/s[0m  
[2KAttention weights: tensor([[0.5808, 0.4192]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 173/203 [2m0:01:07 â€¢ 0:00:12[0m [2;4m2.63it/s[0m  
[2KStep 0 - TTA Loss: 2.6606â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”[0m 173/203 [2m0:01:07 â€¢ 0:00:12[0m [2;4m2.63it/s[0m  
[2KAttention weights: tensor([[0.5808, 0.4192]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 173/203 [2m0:01:07 â€¢ 0:00:12[0m [2;4m2.63it/s[0m  
[2KAttention weights: tensor([[0.5822, 0.4178]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 173/203 [2m0:01:07 â€¢ 0:00:12[0m [2;4m2.63it/s[0m  
[2KAttention weights: tensor([[0.5872, 0.4128]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 173/203 [2m0:01:07 â€¢ 0:00:12[0m [2;4m2.63it/s[0m  
[2KAttention weights: tensor([[0.6003, 0.3997]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 173/203 [2m0:01:07 â€¢ 0:00:12[0m [2;4m2.63it/s[0m  
[2KAttention weights: tensor([[0.6255, 0.3745]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 173/203 [2m0:01:07 â€¢ 0:00:12[0m [2;4m2.63it/s[0m  
[2KAttention weights: tensor([[0.6670, 0.3330]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 173/203 [2m0:01:07 â€¢ 0:00:12[0m [2;4m2.63it/s[0m  
[2KAttention weights: tensor([[0.7152, 0.2848]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 173/203 [2m0:01:07 â€¢ 0:00:12[0m [2;4m2.63it/s[0m  
[2KAttention weights: tensor([[0.7648, 0.2352]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 173/203 [2m0:01:07 â€¢ 0:00:12[0m [2;4m2.63it/s[0m  
[2KAttention weights: tensor([[0.8232, 0.1768]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 173/203 [2m0:01:07 â€¢ 0:00:12[0m [2;4m2.63it/s[0m  
[2KAttention weights: tensor([[0.5370, 0.4630]], device='cuda:0');5;237mâ•º[0m[38;5;237mâ”â”â”â”â”[0m 173/203 [2m0:01:07 â€¢ 0:00:12[0m [2;4m2.63it/s[0m  
[2KAttention weights: tensor([[0.8040, 0.1960],â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”[0m 173/203 [2m0:01:07 â€¢ 0:00:12[0m [2;4m2.63it/s[0m  
        [0.4833, 0.5167],
        [0.5900, 0.4100],
        [0.7540, 0.2460],
        [0.8667, 0.1333],
        [0.8644, 0.1356],
        [0.8165, 0.1835],
        [0.7051, 0.2949],
        [0.6161, 0.3839],
[2K        [0.8348, 0.1652]], device='cuda:0')â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”[0m 173/203 [2m0:01:07 â€¢ 0:00:12[0m [2;4m2.63it/s[0m  
[2KAttention weights: tensor([[0.5246, 0.4754],â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”[0m 174/203 [2m0:01:07 â€¢ 0:00:12[0m [2;4m2.63it/s[0m  
        [0.5154, 0.4846],
        [0.5174, 0.4826],
        [0.5233, 0.4767],
        [0.5256, 0.4744],
        [0.5279, 0.4721],
        [0.5251, 0.4749],
        [0.5221, 0.4779],
        [0.5192, 0.4808],
[2K        [0.5253, 0.4747]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m[38;5;237mâ”â”â”â”â”[0m 174/203 [2m0:01:07 â€¢ 0:00:12[0m [2;4m2.63it/s[0m  
[2KClass label: TennisSwingâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”[0m 174/203 [2m0:01:07 â€¢ 0:00:12[0m [2;4m2.63it/s[0m  
[2KAttention weights: tensor([[0.5189, 0.4811]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 174/203 [2m0:01:07 â€¢ 0:00:12[0m [2;4m2.63it/s[0m  
[2KStep 0 - TTA Loss: 0.9483â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”[0m 174/203 [2m0:01:07 â€¢ 0:00:12[0m [2;4m2.63it/s[0m  
[2KAttention weights: tensor([[0.5382, 0.4618]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 174/203 [2m0:01:07 â€¢ 0:00:12[0m [2;4m2.63it/s[0m  
[2KAttention weights: tensor([[0.5558, 0.4442]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 174/203 [2m0:01:07 â€¢ 0:00:12[0m [2;4m2.63it/s[0m  
[2KAttention weights: tensor([[0.5703, 0.4297]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 174/203 [2m0:01:07 â€¢ 0:00:12[0m [2;4m2.63it/s[0m  
[2KAttention weights: tensor([[0.5829, 0.4171]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 174/203 [2m0:01:07 â€¢ 0:00:12[0m [2;4m2.63it/s[0m  
[2KAttention weights: tensor([[0.5932, 0.4068]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 174/203 [2m0:01:07 â€¢ 0:00:12[0m [2;4m2.63it/s[0m  
[2KAttention weights: tensor([[0.6002, 0.3998]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 174/203 [2m0:01:07 â€¢ 0:00:12[0m [2;4m2.63it/s[0m  
[2KAttention weights: tensor([[0.6042, 0.3958]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 174/203 [2m0:01:07 â€¢ 0:00:12[0m [2;4m2.63it/s[0m  
[2KAttention weights: tensor([[0.6062, 0.3938]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 174/203 [2m0:01:07 â€¢ 0:00:12[0m [2;4m2.63it/s[0m  
[2KAttention weights: tensor([[0.6070, 0.3930]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 174/203 [2m0:01:07 â€¢ 0:00:12[0m [2;4m2.63it/s[0m  
[2KAttention weights: tensor([[0.5225, 0.4775]], device='cuda:0');5;237mâ•º[0m[38;5;237mâ”â”â”â”â”[0m 174/203 [2m0:01:07 â€¢ 0:00:12[0m [2;4m2.63it/s[0m  
[2KAttention weights: tensor([[0.7722, 0.2278],â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”[0m 174/203 [2m0:01:07 â€¢ 0:00:12[0m [2;4m2.63it/s[0m  
        [0.4819, 0.5181],
        [0.5743, 0.4257],
        [0.7353, 0.2647],
        [0.8366, 0.1634],
        [0.8425, 0.1575],
        [0.7937, 0.2063],
        [0.6922, 0.3078],
        [0.6073, 0.3927],
[2K        [0.8053, 0.1947]], device='cuda:0')â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”[0m 174/203 [2m0:01:07 â€¢ 0:00:12[0m [2;4m2.63it/s[0m  
[2KAttention weights: tensor([[0.5246, 0.4754],â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”[0m 175/203 [2m0:01:07 â€¢ 0:00:11[0m [2;4m2.62it/s[0m  
        [0.5155, 0.4845],
        [0.5175, 0.4825],
        [0.5234, 0.4766],
        [0.5257, 0.4743],
        [0.5280, 0.4720],
        [0.5252, 0.4748],
        [0.5221, 0.4779],
        [0.5193, 0.4807],
[2K        [0.5254, 0.4746]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m[38;5;237mâ”â”â”â”â”[0m 175/203 [2m0:01:07 â€¢ 0:00:11[0m [2;4m2.62it/s[0m  
[2KClass label: BaseballPitchâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”[0m 175/203 [2m0:01:07 â€¢ 0:00:11[0m [2;4m2.62it/s[0m  
[2KAttention weights: tensor([[0.6000, 0.4000]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 175/203 [2m0:01:07 â€¢ 0:00:11[0m [2;4m2.62it/s[0m  
[2KStep 0 - TTA Loss: 2.5312â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”[0m 175/203 [2m0:01:07 â€¢ 0:00:11[0m [2;4m2.62it/s[0m  
[2KAttention weights: tensor([[0.6000, 0.4000]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 175/203 [2m0:01:07 â€¢ 0:00:11[0m [2;4m2.62it/s[0m  
[2KAttention weights: tensor([[0.6008, 0.3992]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 175/203 [2m0:01:07 â€¢ 0:00:11[0m [2;4m2.62it/s[0m  
[2KAttention weights: tensor([[0.6044, 0.3956]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 175/203 [2m0:01:07 â€¢ 0:00:11[0m [2;4m2.62it/s[0m  
[2KAttention weights: tensor([[0.6158, 0.3842]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 175/203 [2m0:01:07 â€¢ 0:00:11[0m [2;4m2.62it/s[0m  
[2KAttention weights: tensor([[0.6345, 0.3655]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 175/203 [2m0:01:07 â€¢ 0:00:11[0m [2;4m2.62it/s[0m  
[2KAttention weights: tensor([[0.6659, 0.3341]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 175/203 [2m0:01:07 â€¢ 0:00:11[0m [2;4m2.62it/s[0m  
[2KAttention weights: tensor([[0.7024, 0.2976]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 175/203 [2m0:01:07 â€¢ 0:00:11[0m [2;4m2.62it/s[0m  
[2KAttention weights: tensor([[0.7394, 0.2606]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 175/203 [2m0:01:07 â€¢ 0:00:11[0m [2;4m2.62it/s[0m  
[2KAttention weights: tensor([[0.7801, 0.2199]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 175/203 [2m0:01:07 â€¢ 0:00:11[0m [2;4m2.62it/s[0m  
[2KAttention weights: tensor([[0.5288, 0.4712]], device='cuda:0');5;237mâ•º[0m[38;5;237mâ”â”â”â”â”[0m 175/203 [2m0:01:07 â€¢ 0:00:11[0m [2;4m2.62it/s[0m  
[2KAttention weights: tensor([[0.8126, 0.1874],â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”[0m 175/203 [2m0:01:07 â€¢ 0:00:11[0m [2;4m2.62it/s[0m  
        [0.4707, 0.5293],
        [0.5441, 0.4559],
        [0.6941, 0.3059],
        [0.7265, 0.2735],
        [0.7758, 0.2242],
        [0.7255, 0.2745],
        [0.6329, 0.3671],
        [0.5922, 0.4078],
[2K        [0.7277, 0.2723]], device='cuda:0')â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”[0m 175/203 [2m0:01:07 â€¢ 0:00:11[0m [2;4m2.62it/s[0m  
[2KAttention weights: tensor([[0.5248, 0.4752],â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”[0m 176/203 [2m0:01:08 â€¢ 0:00:11[0m [2;4m2.63it/s[0m  
        [0.5155, 0.4845],
        [0.5176, 0.4824],
        [0.5234, 0.4766],
        [0.5258, 0.4742],
        [0.5280, 0.4720],
        [0.5253, 0.4747],
        [0.5222, 0.4778],
        [0.5193, 0.4807],
[2K        [0.5255, 0.4745]], device='cuda:0', grad_fn=<SoftmaxBackward0>)24mâ•¸[0m[38;5;237mâ”â”â”â”â”[0m 176/203 [2m0:01:08 â€¢ 0:00:11[0m [2;4m2.63it/s[0m  
[2KClass label: BaseballPitchâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”[0m 176/203 [2m0:01:08 â€¢ 0:00:11[0m [2;4m2.63it/s[0m  
[2KAttention weights: tensor([[0.6013, 0.3987]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 176/203 [2m0:01:08 â€¢ 0:00:11[0m [2;4m2.63it/s[0m  
[2KStep 0 - TTA Loss: 1.5989â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”[0m 176/203 [2m0:01:08 â€¢ 0:00:11[0m [2;4m2.63it/s[0m  
[2KAttention weights: tensor([[0.6364, 0.3636]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 176/203 [2m0:01:08 â€¢ 0:00:11[0m [2;4m2.63it/s[0m  
[2KAttention weights: tensor([[0.6609, 0.3391]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 176/203 [2m0:01:08 â€¢ 0:00:11[0m [2;4m2.63it/s[0m  
[2KAttention weights: tensor([[0.6876, 0.3124]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 176/203 [2m0:01:08 â€¢ 0:00:11[0m [2;4m2.63it/s[0m  
[2KAttention weights: tensor([[0.7016, 0.2984]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 176/203 [2m0:01:08 â€¢ 0:00:11[0m [2;4m2.63it/s[0m  
[2KAttention weights: tensor([[0.7087, 0.2913]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 176/203 [2m0:01:08 â€¢ 0:00:11[0m [2;4m2.63it/s[0m  
[2KAttention weights: tensor([[0.7107, 0.2893]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 176/203 [2m0:01:08 â€¢ 0:00:11[0m [2;4m2.63it/s[0m  
[2KAttention weights: tensor([[0.7098, 0.2902]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 176/203 [2m0:01:08 â€¢ 0:00:11[0m [2;4m2.63it/s[0m  
[2KAttention weights: tensor([[0.7092, 0.2908]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 176/203 [2m0:01:08 â€¢ 0:00:11[0m [2;4m2.63it/s[0m  
[2KAttention weights: tensor([[0.7093, 0.2907]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 176/203 [2m0:01:08 â€¢ 0:00:11[0m [2;4m2.63it/s[0m  
[2KAttention weights: tensor([[0.5271, 0.4729]], device='cuda:0');2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”[0m 176/203 [2m0:01:08 â€¢ 0:00:11[0m [2;4m2.63it/s[0m  
[2KAttention weights: tensor([[0.7099, 0.2901],â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”[0m 176/203 [2m0:01:08 â€¢ 0:00:11[0m [2;4m2.63it/s[0m  
        [0.4641, 0.5359],
        [0.5199, 0.4801],
        [0.6542, 0.3458],
        [0.6600, 0.3400],
        [0.7344, 0.2656],
        [0.6844, 0.3156],
        [0.6237, 0.3763],
        [0.5564, 0.4436],
[2K        [0.6615, 0.3385]], device='cuda:0')â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”[0m 176/203 [2m0:01:08 â€¢ 0:00:11[0m [2;4m2.63it/s[0m  
[2KAttention weights: tensor([[0.5248, 0.4752],â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”[0m 177/203 [2m0:01:08 â€¢ 0:00:10[0m [2;4m2.63it/s[0m  
        [0.5155, 0.4845],
        [0.5176, 0.4824],
        [0.5235, 0.4765],
        [0.5259, 0.4741],
        [0.5281, 0.4719],
        [0.5254, 0.4746],
        [0.5222, 0.4778],
        [0.5194, 0.4806],
[2K        [0.5256, 0.4744]], device='cuda:0', grad_fn=<SoftmaxBackward0>)24mâ•¸[0m[38;5;237mâ”â”â”â”â”[0m 177/203 [2m0:01:08 â€¢ 0:00:10[0m [2;4m2.63it/s[0m  
[2KClass label: HighJumpâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”[0m 177/203 [2m0:01:08 â€¢ 0:00:10[0m [2;4m2.63it/s[0m  
[2KAttention weights: tensor([[0.6925, 0.3075]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 177/203 [2m0:01:08 â€¢ 0:00:10[0m [2;4m2.63it/s[0m  
[2KStep 0 - TTA Loss: 1.7554â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”[0m 177/203 [2m0:01:08 â€¢ 0:00:10[0m [2;4m2.63it/s[0m  
[2KAttention weights: tensor([[0.6925, 0.3075]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 177/203 [2m0:01:08 â€¢ 0:00:10[0m [2;4m2.63it/s[0m  
[2KAttention weights: tensor([[0.6924, 0.3076]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 177/203 [2m0:01:08 â€¢ 0:00:10[0m [2;4m2.63it/s[0m  
[2KAttention weights: tensor([[0.6923, 0.3077]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 177/203 [2m0:01:08 â€¢ 0:00:10[0m [2;4m2.63it/s[0m  
[2KAttention weights: tensor([[0.6927, 0.3073]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 177/203 [2m0:01:08 â€¢ 0:00:10[0m [2;4m2.63it/s[0m  
[2KAttention weights: tensor([[0.6954, 0.3046]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 177/203 [2m0:01:08 â€¢ 0:00:10[0m [2;4m2.63it/s[0m  
[2KAttention weights: tensor([[0.7063, 0.2937]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 177/203 [2m0:01:08 â€¢ 0:00:10[0m [2;4m2.63it/s[0m  
[2KAttention weights: tensor([[0.7185, 0.2815]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 177/203 [2m0:01:08 â€¢ 0:00:10[0m [2;4m2.63it/s[0m  
[2KAttention weights: tensor([[0.7398, 0.2602]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 177/203 [2m0:01:08 â€¢ 0:00:10[0m [2;4m2.63it/s[0m  
[2KAttention weights: tensor([[0.7654, 0.2346]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 177/203 [2m0:01:08 â€¢ 0:00:10[0m [2;4m2.63it/s[0m  
[2KAttention weights: tensor([[0.5309, 0.4691]], device='cuda:0');2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”[0m 177/203 [2m0:01:08 â€¢ 0:00:10[0m [2;4m2.63it/s[0m  
[2KAttention weights: tensor([[0.6422, 0.3578],â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”[0m 177/203 [2m0:01:08 â€¢ 0:00:10[0m [2;4m2.63it/s[0m  
        [0.4490, 0.5510],
        [0.5158, 0.4842],
        [0.6333, 0.3667],
        [0.6525, 0.3475],
        [0.7866, 0.2134],
        [0.7205, 0.2795],
        [0.6491, 0.3509],
        [0.5586, 0.4414],
[2K        [0.6604, 0.3396]], device='cuda:0')â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”[0m 177/203 [2m0:01:08 â€¢ 0:00:10[0m [2;4m2.63it/s[0m  
[2KAttention weights: tensor([[0.5248, 0.4752],â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”[0m 178/203 [2m0:01:08 â€¢ 0:00:10[0m [2;4m2.63it/s[0m   
        [0.5156, 0.4844],
        [0.5176, 0.4824],
        [0.5235, 0.4765],
        [0.5259, 0.4741],
        [0.5281, 0.4719],
        [0.5254, 0.4746],
        [0.5222, 0.4778],
        [0.5194, 0.4806],
[2K        [0.5256, 0.4744]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m[38;5;237mâ”â”â”â”[0m 178/203 [2m0:01:08 â€¢ 0:00:10[0m [2;4m2.63it/s[0m  
[2KClass label: HammerThrowâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”[0m 178/203 [2m0:01:08 â€¢ 0:00:10[0m [2;4m2.63it/s[0m  
[2KAttention weights: tensor([[0.5836, 0.4164]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 178/203 [2m0:01:08 â€¢ 0:00:10[0m [2;4m2.63it/s[0m  
[2KStep 0 - TTA Loss: 0.9094â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”[0m 178/203 [2m0:01:08 â€¢ 0:00:10[0m [2;4m2.63it/s[0m  
[2KAttention weights: tensor([[0.6001, 0.3999]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 178/203 [2m0:01:08 â€¢ 0:00:10[0m [2;4m2.63it/s[0m  
[2KAttention weights: tensor([[0.6135, 0.3865]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 178/203 [2m0:01:08 â€¢ 0:00:10[0m [2;4m2.63it/s[0m  
[2KAttention weights: tensor([[0.6172, 0.3828]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 178/203 [2m0:01:08 â€¢ 0:00:10[0m [2;4m2.63it/s[0m  
[2KAttention weights: tensor([[0.6162, 0.3838]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 178/203 [2m0:01:08 â€¢ 0:00:10[0m [2;4m2.63it/s[0m  
[2KAttention weights: tensor([[0.6161, 0.3839]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 178/203 [2m0:01:08 â€¢ 0:00:10[0m [2;4m2.63it/s[0m  
[2KAttention weights: tensor([[0.6161, 0.3839]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 178/203 [2m0:01:08 â€¢ 0:00:10[0m [2;4m2.63it/s[0m  
[2KAttention weights: tensor([[0.6159, 0.3841]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 178/203 [2m0:01:08 â€¢ 0:00:10[0m [2;4m2.63it/s[0m  
[2KAttention weights: tensor([[0.6157, 0.3843]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 178/203 [2m0:01:08 â€¢ 0:00:10[0m [2;4m2.63it/s[0m  
[2KAttention weights: tensor([[0.6156, 0.3844]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 178/203 [2m0:01:08 â€¢ 0:00:10[0m [2;4m2.63it/s[0m  
[2KAttention weights: tensor([[0.5271, 0.4729]], device='cuda:0')8;5;237mâ•º[0m[38;5;237mâ”â”â”â”[0m 178/203 [2m0:01:08 â€¢ 0:00:10[0m [2;4m2.63it/s[0m  
[2KAttention weights: tensor([[0.6285, 0.3715],â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”[0m 178/203 [2m0:01:08 â€¢ 0:00:10[0m [2;4m2.63it/s[0m  
        [0.4544, 0.5456],
        [0.5101, 0.4899],
        [0.6206, 0.3794],
        [0.6158, 0.3842],
        [0.7682, 0.2318],
        [0.7012, 0.2988],
        [0.6383, 0.3617],
        [0.5579, 0.4421],
[2K        [0.6334, 0.3666]], device='cuda:0')â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”[0m 178/203 [2m0:01:08 â€¢ 0:00:10[0m [2;4m2.63it/s[0m  
[2KAttention weights: tensor([[0.5249, 0.4751],â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”[0m 179/203 [2m0:01:09 â€¢ 0:00:10[0m [2;4m2.63it/s[0m  
        [0.5156, 0.4844],
        [0.5176, 0.4824],
        [0.5235, 0.4765],
        [0.5259, 0.4741],
        [0.5281, 0.4719],
        [0.5254, 0.4746],
        [0.5223, 0.4777],
        [0.5194, 0.4806],
[2K        [0.5256, 0.4744]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m[38;5;237mâ”â”â”â”[0m 179/203 [2m0:01:09 â€¢ 0:00:10[0m [2;4m2.63it/s[0m  
[2KClass label: PoleVaultâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”[0m 179/203 [2m0:01:09 â€¢ 0:00:10[0m [2;4m2.63it/s[0m  
[2KAttention weights: tensor([[0.6419, 0.3581]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 179/203 [2m0:01:09 â€¢ 0:00:10[0m [2;4m2.63it/s[0m  
[2KStep 0 - TTA Loss: 1.0844â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”[0m 179/203 [2m0:01:09 â€¢ 0:00:10[0m [2;4m2.63it/s[0m  
[2KAttention weights: tensor([[0.6419, 0.3581]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 179/203 [2m0:01:09 â€¢ 0:00:10[0m [2;4m2.63it/s[0m  
[2KAttention weights: tensor([[0.6423, 0.3577]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 179/203 [2m0:01:09 â€¢ 0:00:10[0m [2;4m2.63it/s[0m  
[2KAttention weights: tensor([[0.6440, 0.3560]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 179/203 [2m0:01:09 â€¢ 0:00:10[0m [2;4m2.63it/s[0m  
[2KAttention weights: tensor([[0.6476, 0.3524]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 179/203 [2m0:01:09 â€¢ 0:00:10[0m [2;4m2.63it/s[0m  
[2KAttention weights: tensor([[0.6592, 0.3408]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 179/203 [2m0:01:09 â€¢ 0:00:10[0m [2;4m2.63it/s[0m  
[2KAttention weights: tensor([[0.6857, 0.3143]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 179/203 [2m0:01:09 â€¢ 0:00:10[0m [2;4m2.63it/s[0m  
[2KAttention weights: tensor([[0.7042, 0.2958]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 179/203 [2m0:01:09 â€¢ 0:00:10[0m [2;4m2.63it/s[0m  
[2KAttention weights: tensor([[0.7497, 0.2503]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 179/203 [2m0:01:09 â€¢ 0:00:10[0m [2;4m2.63it/s[0m  
[2KAttention weights: tensor([[0.7857, 0.2143]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 179/203 [2m0:01:09 â€¢ 0:00:10[0m [2;4m2.63it/s[0m  
[2KAttention weights: tensor([[0.5333, 0.4667]], device='cuda:0')8;5;237mâ•º[0m[38;5;237mâ”â”â”â”[0m 179/203 [2m0:01:09 â€¢ 0:00:10[0m [2;4m2.63it/s[0m  
[2KAttention weights: tensor([[0.6598, 0.3402],â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”[0m 179/203 [2m0:01:09 â€¢ 0:00:10[0m [2;4m2.63it/s[0m  
        [0.4455, 0.5545],
        [0.5381, 0.4619],
        [0.6626, 0.3374],
        [0.6793, 0.3207],
        [0.8119, 0.1881],
        [0.8220, 0.1780],
        [0.6656, 0.3344],
        [0.5520, 0.4480],
[2K        [0.6994, 0.3006]], device='cuda:0')â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”[0m 179/203 [2m0:01:09 â€¢ 0:00:10[0m [2;4m2.63it/s[0m  
[2KAttention weights: tensor([[0.5249, 0.4751],â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”[0m 180/203 [2m0:01:09 â€¢ 0:00:09[0m [2;4m2.62it/s[0m  
        [0.5156, 0.4844],
        [0.5177, 0.4823],
        [0.5235, 0.4765],
        [0.5259, 0.4741],
        [0.5281, 0.4719],
        [0.5254, 0.4746],
        [0.5223, 0.4777],
        [0.5194, 0.4806],
[2K        [0.5256, 0.4744]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m[38;5;237mâ”â”â”â”[0m 180/203 [2m0:01:09 â€¢ 0:00:09[0m [2;4m2.62it/s[0m  
[2KClass label: CleanAndJerkâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”[0m 180/203 [2m0:01:09 â€¢ 0:00:09[0m [2;4m2.62it/s[0m  
[2KAttention weights: tensor([[0.4988, 0.5012]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 180/203 [2m0:01:09 â€¢ 0:00:09[0m [2;4m2.62it/s[0m  
[2KStep 0 - TTA Loss: 0.7446â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”[0m 180/203 [2m0:01:09 â€¢ 0:00:09[0m [2;4m2.62it/s[0m  
[2KAttention weights: tensor([[0.5072, 0.4928]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 180/203 [2m0:01:09 â€¢ 0:00:09[0m [2;4m2.62it/s[0m  
[2KAttention weights: tensor([[0.5147, 0.4853]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 180/203 [2m0:01:09 â€¢ 0:00:09[0m [2;4m2.62it/s[0m  
[2KAttention weights: tensor([[0.5202, 0.4798]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 180/203 [2m0:01:09 â€¢ 0:00:09[0m [2;4m2.62it/s[0m  
[2KAttention weights: tensor([[0.5242, 0.4758]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 180/203 [2m0:01:09 â€¢ 0:00:09[0m [2;4m2.62it/s[0m  
[2KAttention weights: tensor([[0.5271, 0.4729]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 180/203 [2m0:01:09 â€¢ 0:00:09[0m [2;4m2.62it/s[0m  
[2KAttention weights: tensor([[0.5278, 0.4722]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 180/203 [2m0:01:09 â€¢ 0:00:09[0m [2;4m2.62it/s[0m  
[2KAttention weights: tensor([[0.5277, 0.4723]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 180/203 [2m0:01:09 â€¢ 0:00:09[0m [2;4m2.62it/s[0m  
[2KAttention weights: tensor([[0.5276, 0.4724]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 180/203 [2m0:01:09 â€¢ 0:00:09[0m [2;4m2.62it/s[0m  
[2KAttention weights: tensor([[0.5272, 0.4728]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 180/203 [2m0:01:09 â€¢ 0:00:09[0m [2;4m2.62it/s[0m  
[2KAttention weights: tensor([[0.5187, 0.4813]], device='cuda:0')8;5;237mâ•º[0m[38;5;237mâ”â”â”â”[0m 180/203 [2m0:01:09 â€¢ 0:00:09[0m [2;4m2.62it/s[0m  
[2KAttention weights: tensor([[0.6544, 0.3456],â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”[0m 180/203 [2m0:01:09 â€¢ 0:00:09[0m [2;4m2.62it/s[0m  
        [0.4474, 0.5526],
        [0.5270, 0.4730],
        [0.6628, 0.3372],
        [0.6766, 0.3234],
        [0.8050, 0.1950],
        [0.8157, 0.1843],
        [0.6615, 0.3385],
        [0.5491, 0.4509],
[2K        [0.6935, 0.3065]], device='cuda:0')â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”[0m 180/203 [2m0:01:09 â€¢ 0:00:09[0m [2;4m2.62it/s[0m  
[2KAttention weights: tensor([[0.5249, 0.4751],â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”[0m 181/203 [2m0:01:10 â€¢ 0:00:09[0m [2;4m2.62it/s[0m  
        [0.5156, 0.4844],
        [0.5177, 0.4823],
        [0.5235, 0.4765],
        [0.5260, 0.4740],
        [0.5282, 0.4718],
        [0.5255, 0.4745],
        [0.5223, 0.4777],
        [0.5195, 0.4805],
[2K        [0.5256, 0.4744]], device='cuda:0', grad_fn=<SoftmaxBackward0>)224mâ•¸[0m[38;5;237mâ”â”â”â”[0m 181/203 [2m0:01:10 â€¢ 0:00:09[0m [2;4m2.62it/s[0m  
[2KClass label: GolfSwingâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”[0m 181/203 [2m0:01:10 â€¢ 0:00:09[0m [2;4m2.62it/s[0m  
[2KAttention weights: tensor([[0.6027, 0.3973]], device='cuda:0', grad_fn=<SoftmaxBackward0>)mâ”â”â”â”[0m 181/203 [2m0:01:10 â€¢ 0:00:09[0m [2;4m2.62it/s[0m  
[2KStep 0 - TTA Loss: 0.9317â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”[0m 181/203 [2m0:01:10 â€¢ 0:00:09[0m [2;4m2.62it/s[0m  
[2KAttention weights: tensor([[0.6027, 0.3973]], device='cuda:0', grad_fn=<SoftmaxBackward0>)mâ”â”â”â”[0m 181/203 [2m0:01:10 â€¢ 0:00:09[0m [2;4m2.62it/s[0m  
[2KAttention weights: tensor([[0.6027, 0.3973]], device='cuda:0', grad_fn=<SoftmaxBackward0>)mâ”â”â”â”[0m 181/203 [2m0:01:10 â€¢ 0:00:09[0m [2;4m2.62it/s[0m  
[2KAttention weights: tensor([[0.6022, 0.3978]], device='cuda:0', grad_fn=<SoftmaxBackward0>)mâ”â”â”â”[0m 181/203 [2m0:01:10 â€¢ 0:00:09[0m [2;4m2.62it/s[0m  
[2KAttention weights: tensor([[0.6017, 0.3983]], device='cuda:0', grad_fn=<SoftmaxBackward0>)mâ”â”â”â”[0m 181/203 [2m0:01:10 â€¢ 0:00:09[0m [2;4m2.62it/s[0m  
[2KAttention weights: tensor([[0.6003, 0.3997]], device='cuda:0', grad_fn=<SoftmaxBackward0>)mâ”â”â”â”[0m 181/203 [2m0:01:10 â€¢ 0:00:09[0m [2;4m2.62it/s[0m  
[2KAttention weights: tensor([[0.5989, 0.4011]], device='cuda:0', grad_fn=<SoftmaxBackward0>)mâ”â”â”â”[0m 181/203 [2m0:01:10 â€¢ 0:00:09[0m [2;4m2.62it/s[0m  
[2KAttention weights: tensor([[0.5957, 0.4043]], device='cuda:0', grad_fn=<SoftmaxBackward0>)mâ”â”â”â”[0m 181/203 [2m0:01:10 â€¢ 0:00:09[0m [2;4m2.62it/s[0m  
[2KAttention weights: tensor([[0.5938, 0.4062]], device='cuda:0', grad_fn=<SoftmaxBackward0>)mâ”â”â”â”[0m 181/203 [2m0:01:10 â€¢ 0:00:09[0m [2;4m2.62it/s[0m  
[2KAttention weights: tensor([[0.5982, 0.4018]], device='cuda:0', grad_fn=<SoftmaxBackward0>)mâ”â”â”â”[0m 181/203 [2m0:01:10 â€¢ 0:00:09[0m [2;4m2.62it/s[0m  
[2KAttention weights: tensor([[0.5243, 0.4757]], device='cuda:0')8;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”[0m 181/203 [2m0:01:10 â€¢ 0:00:09[0m [2;4m2.62it/s[0m  
[2KAttention weights: tensor([[0.6074, 0.3926],â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”[0m 181/203 [2m0:01:10 â€¢ 0:00:09[0m [2;4m2.62it/s[0m  
        [0.4423, 0.5577],
        [0.4838, 0.5162],
        [0.6037, 0.3963],
        [0.5958, 0.4042],
        [0.7124, 0.2876],
        [0.6771, 0.3229],
        [0.6186, 0.3814],
        [0.5251, 0.4749],
[2K        [0.6022, 0.3978]], device='cuda:0')â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”[0m 181/203 [2m0:01:10 â€¢ 0:00:09[0m [2;4m2.62it/s[0m  
[2KAttention weights: tensor([[0.5249, 0.4751],â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”[0m 182/203 [2m0:01:10 â€¢ 0:00:09[0m [2;4m2.62it/s[0m  
        [0.5156, 0.4844],
        [0.5177, 0.4823],
        [0.5235, 0.4765],
        [0.5260, 0.4740],
        [0.5282, 0.4718],
        [0.5255, 0.4745],
        [0.5223, 0.4777],
        [0.5195, 0.4805],
[2K        [0.5256, 0.4744]], device='cuda:0', grad_fn=<SoftmaxBackward0>)224mâ•¸[0m[38;5;237mâ”â”â”â”[0m 182/203 [2m0:01:10 â€¢ 0:00:09[0m [2;4m2.62it/s[0m  
[2KClass label: CleanAndJerkâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”[0m 182/203 [2m0:01:10 â€¢ 0:00:09[0m [2;4m2.62it/s[0m  
[2KAttention weights: tensor([[0.4954, 0.5046]], device='cuda:0', grad_fn=<SoftmaxBackward0>)mâ”â”â”â”[0m 182/203 [2m0:01:10 â€¢ 0:00:09[0m [2;4m2.62it/s[0m  
[2KStep 0 - TTA Loss: 2.3397â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”[0m 182/203 [2m0:01:10 â€¢ 0:00:09[0m [2;4m2.62it/s[0m  
[2KAttention weights: tensor([[0.5134, 0.4866]], device='cuda:0', grad_fn=<SoftmaxBackward0>)mâ”â”â”â”[0m 182/203 [2m0:01:10 â€¢ 0:00:09[0m [2;4m2.62it/s[0m  
[2KAttention weights: tensor([[0.5324, 0.4676]], device='cuda:0', grad_fn=<SoftmaxBackward0>)mâ”â”â”â”[0m 182/203 [2m0:01:10 â€¢ 0:00:09[0m [2;4m2.62it/s[0m  
[2KAttention weights: tensor([[0.5607, 0.4393]], device='cuda:0', grad_fn=<SoftmaxBackward0>)mâ”â”â”â”[0m 182/203 [2m0:01:10 â€¢ 0:00:09[0m [2;4m2.62it/s[0m  
[2KAttention weights: tensor([[0.5934, 0.4066]], device='cuda:0', grad_fn=<SoftmaxBackward0>)mâ”â”â”â”[0m 182/203 [2m0:01:10 â€¢ 0:00:09[0m [2;4m2.62it/s[0m  
[2KAttention weights: tensor([[0.6256, 0.3744]], device='cuda:0', grad_fn=<SoftmaxBackward0>)mâ”â”â”â”[0m 182/203 [2m0:01:10 â€¢ 0:00:09[0m [2;4m2.62it/s[0m  
[2KAttention weights: tensor([[0.6492, 0.3508]], device='cuda:0', grad_fn=<SoftmaxBackward0>)mâ”â”â”â”[0m 182/203 [2m0:01:10 â€¢ 0:00:09[0m [2;4m2.62it/s[0m  
[2KAttention weights: tensor([[0.6660, 0.3340]], device='cuda:0', grad_fn=<SoftmaxBackward0>)mâ”â”â”â”[0m 182/203 [2m0:01:10 â€¢ 0:00:09[0m [2;4m2.62it/s[0m  
[2KAttention weights: tensor([[0.6761, 0.3239]], device='cuda:0', grad_fn=<SoftmaxBackward0>)mâ”â”â”â”[0m 182/203 [2m0:01:10 â€¢ 0:00:09[0m [2;4m2.62it/s[0m  
[2KAttention weights: tensor([[0.6803, 0.3197]], device='cuda:0', grad_fn=<SoftmaxBackward0>)mâ”â”â”â”[0m 182/203 [2m0:01:10 â€¢ 0:00:09[0m [2;4m2.62it/s[0m  
[2KAttention weights: tensor([[0.5239, 0.4761]], device='cuda:0')8;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”[0m 182/203 [2m0:01:10 â€¢ 0:00:09[0m [2;4m2.62it/s[0m  
[2KAttention weights: tensor([[0.6459, 0.3541],â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”[0m 182/203 [2m0:01:10 â€¢ 0:00:09[0m [2;4m2.62it/s[0m  
        [0.4581, 0.5419],
        [0.6816, 0.3184],
        [0.6572, 0.3428],
        [0.6322, 0.3678],
        [0.7290, 0.2710],
        [0.6993, 0.3007],
        [0.6235, 0.3765],
        [0.5491, 0.4509],
[2K        [0.6472, 0.3528]], device='cuda:0')â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”[0m 182/203 [2m0:01:10 â€¢ 0:00:09[0m [2;4m2.62it/s[0m  
[2KAttention weights: tensor([[0.5249, 0.4751],â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”[0m 183/203 [2m0:01:10 â€¢ 0:00:08[0m [2;4m2.63it/s[0m   
        [0.5156, 0.4844],
        [0.5177, 0.4823],
        [0.5236, 0.4764],
        [0.5260, 0.4740],
        [0.5282, 0.4718],
        [0.5255, 0.4745],
        [0.5223, 0.4777],
        [0.5195, 0.4805],
[2K        [0.5257, 0.4743]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â•º[0m[38;5;237mâ”â”â”[0m 183/203 [2m0:01:10 â€¢ 0:00:08[0m [2;4m2.63it/s[0m  
[2KClass label: BaseballPitchâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”[0m 183/203 [2m0:01:10 â€¢ 0:00:08[0m [2;4m2.63it/s[0m  
[2KAttention weights: tensor([[0.6000, 0.4000]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 183/203 [2m0:01:10 â€¢ 0:00:08[0m [2;4m2.63it/s[0m  
[2KStep 0 - TTA Loss: 1.8633â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”[0m 183/203 [2m0:01:10 â€¢ 0:00:08[0m [2;4m2.63it/s[0m  
[2KAttention weights: tensor([[0.6000, 0.4000]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 183/203 [2m0:01:10 â€¢ 0:00:08[0m [2;4m2.63it/s[0m  
[2KAttention weights: tensor([[0.6005, 0.3995]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 183/203 [2m0:01:10 â€¢ 0:00:08[0m [2;4m2.63it/s[0m  
[2KAttention weights: tensor([[0.6024, 0.3976]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 183/203 [2m0:01:10 â€¢ 0:00:08[0m [2;4m2.63it/s[0m  
[2KAttention weights: tensor([[0.6056, 0.3944]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 183/203 [2m0:01:10 â€¢ 0:00:08[0m [2;4m2.63it/s[0m  
[2KAttention weights: tensor([[0.6083, 0.3917]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 183/203 [2m0:01:10 â€¢ 0:00:08[0m [2;4m2.63it/s[0m  
[2KAttention weights: tensor([[0.6092, 0.3908]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 183/203 [2m0:01:10 â€¢ 0:00:08[0m [2;4m2.63it/s[0m  
[2KAttention weights: tensor([[0.6127, 0.3873]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 183/203 [2m0:01:10 â€¢ 0:00:08[0m [2;4m2.63it/s[0m  
[2KAttention weights: tensor([[0.6146, 0.3854]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 183/203 [2m0:01:10 â€¢ 0:00:08[0m [2;4m2.63it/s[0m  
[2KAttention weights: tensor([[0.6176, 0.3824]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 183/203 [2m0:01:10 â€¢ 0:00:08[0m [2;4m2.63it/s[0m  
[2KAttention weights: tensor([[0.5256, 0.4744]], device='cuda:0')38;5;237mâ•º[0m[38;5;237mâ”â”â”[0m 183/203 [2m0:01:10 â€¢ 0:00:08[0m [2;4m2.63it/s[0m  
[2KAttention weights: tensor([[0.6129, 0.3871],â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”[0m 183/203 [2m0:01:10 â€¢ 0:00:08[0m [2;4m2.63it/s[0m  
        [0.4486, 0.5514],
        [0.5929, 0.4071],
        [0.6256, 0.3744],
        [0.6008, 0.3992],
        [0.7017, 0.2983],
        [0.6624, 0.3376],
        [0.6130, 0.3870],
        [0.5312, 0.4688],
[2K        [0.6087, 0.3913]], device='cuda:0')â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”[0m 183/203 [2m0:01:10 â€¢ 0:00:08[0m [2;4m2.63it/s[0m  
[2KAttention weights: tensor([[0.5250, 0.4750],â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”[0m 184/203 [2m0:01:11 â€¢ 0:00:08[0m [2;4m2.63it/s[0m  
        [0.5157, 0.4843],
        [0.5178, 0.4822],
        [0.5236, 0.4764],
        [0.5260, 0.4740],
        [0.5282, 0.4718],
        [0.5256, 0.4744],
        [0.5223, 0.4777],
        [0.5195, 0.4805],
[2K        [0.5257, 0.4743]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â•º[0m[38;5;237mâ”â”â”[0m 184/203 [2m0:01:11 â€¢ 0:00:08[0m [2;4m2.63it/s[0m  
[2KClass label: SoccerPenaltyâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”[0m 184/203 [2m0:01:11 â€¢ 0:00:08[0m [2;4m2.63it/s[0m  
[2KAttention weights: tensor([[0.6076, 0.3924]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 184/203 [2m0:01:11 â€¢ 0:00:08[0m [2;4m2.63it/s[0m  
[2KStep 0 - TTA Loss: 1.7769â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”[0m 184/203 [2m0:01:11 â€¢ 0:00:08[0m [2;4m2.63it/s[0m  
[2KAttention weights: tensor([[0.6220, 0.3780]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 184/203 [2m0:01:11 â€¢ 0:00:08[0m [2;4m2.63it/s[0m  
[2KAttention weights: tensor([[0.6429, 0.3571]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 184/203 [2m0:01:11 â€¢ 0:00:08[0m [2;4m2.63it/s[0m  
[2KAttention weights: tensor([[0.6674, 0.3326]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 184/203 [2m0:01:11 â€¢ 0:00:08[0m [2;4m2.63it/s[0m  
[2KAttention weights: tensor([[0.6956, 0.3044]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 184/203 [2m0:01:11 â€¢ 0:00:08[0m [2;4m2.63it/s[0m  
[2KAttention weights: tensor([[0.7217, 0.2783]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 184/203 [2m0:01:11 â€¢ 0:00:08[0m [2;4m2.63it/s[0m  
[2KAttention weights: tensor([[0.7426, 0.2574]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 184/203 [2m0:01:11 â€¢ 0:00:08[0m [2;4m2.63it/s[0m  
[2KAttention weights: tensor([[0.7592, 0.2408]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 184/203 [2m0:01:11 â€¢ 0:00:08[0m [2;4m2.63it/s[0m  
[2KAttention weights: tensor([[0.7707, 0.2293]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 184/203 [2m0:01:11 â€¢ 0:00:08[0m [2;4m2.63it/s[0m  
[2KAttention weights: tensor([[0.7764, 0.2236]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 184/203 [2m0:01:11 â€¢ 0:00:08[0m [2;4m2.63it/s[0m  
[2KAttention weights: tensor([[0.5284, 0.4716]], device='cuda:0')38;5;237mâ•º[0m[38;5;237mâ”â”â”[0m 184/203 [2m0:01:11 â€¢ 0:00:08[0m [2;4m2.63it/s[0m  
[2KAttention weights: tensor([[0.5873, 0.4127],â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”[0m 184/203 [2m0:01:11 â€¢ 0:00:08[0m [2;4m2.63it/s[0m  
        [0.4733, 0.5267],
        [0.5679, 0.4321],
        [0.6366, 0.3634],
        [0.6278, 0.3722],
        [0.7392, 0.2608],
        [0.6912, 0.3088],
        [0.7779, 0.2221],
        [0.5538, 0.4462],
[2K        [0.6184, 0.3816]], device='cuda:0')â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”[0m 184/203 [2m0:01:11 â€¢ 0:00:08[0m [2;4m2.63it/s[0m  
[2KAttention weights: tensor([[0.5250, 0.4750],â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”[0m 185/203 [2m0:01:11 â€¢ 0:00:07[0m [2;4m2.63it/s[0m  
        [0.5157, 0.4843],
        [0.5178, 0.4822],
        [0.5236, 0.4764],
        [0.5260, 0.4740],
        [0.5283, 0.4717],
        [0.5256, 0.4744],
        [0.5224, 0.4776],
        [0.5195, 0.4805],
[2K        [0.5257, 0.4743]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â•º[0m[38;5;237mâ”â”â”[0m 185/203 [2m0:01:11 â€¢ 0:00:07[0m [2;4m2.63it/s[0m  
[2KClass label: Billiardsâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”[0m 185/203 [2m0:01:11 â€¢ 0:00:07[0m [2;4m2.63it/s[0m  
[2KAttention weights: tensor([[0.4490, 0.5510]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 185/203 [2m0:01:11 â€¢ 0:00:07[0m [2;4m2.63it/s[0m  
[2KStep 0 - TTA Loss: 1.9040â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”[0m 185/203 [2m0:01:11 â€¢ 0:00:07[0m [2;4m2.63it/s[0m  
[2KAttention weights: tensor([[0.4490, 0.5510]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 185/203 [2m0:01:11 â€¢ 0:00:07[0m [2;4m2.63it/s[0m  
[2KAttention weights: tensor([[0.4495, 0.5505]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 185/203 [2m0:01:11 â€¢ 0:00:07[0m [2;4m2.63it/s[0m  
[2KAttention weights: tensor([[0.4523, 0.5477]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 185/203 [2m0:01:11 â€¢ 0:00:07[0m [2;4m2.63it/s[0m  
[2KAttention weights: tensor([[0.4597, 0.5403]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 185/203 [2m0:01:11 â€¢ 0:00:07[0m [2;4m2.63it/s[0m  
[2KAttention weights: tensor([[0.4735, 0.5265]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 185/203 [2m0:01:11 â€¢ 0:00:07[0m [2;4m2.63it/s[0m  
[2KAttention weights: tensor([[0.4948, 0.5052]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 185/203 [2m0:01:11 â€¢ 0:00:07[0m [2;4m2.63it/s[0m  
[2KAttention weights: tensor([[0.5228, 0.4772]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 185/203 [2m0:01:11 â€¢ 0:00:07[0m [2;4m2.63it/s[0m  
[2KAttention weights: tensor([[0.5560, 0.4440]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 185/203 [2m0:01:11 â€¢ 0:00:07[0m [2;4m2.63it/s[0m  
[2KAttention weights: tensor([[0.5932, 0.4068]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 185/203 [2m0:01:11 â€¢ 0:00:07[0m [2;4m2.63it/s[0m  
[2KAttention weights: tensor([[0.5212, 0.4788]], device='cuda:0')38;5;237mâ•º[0m[38;5;237mâ”â”â”[0m 185/203 [2m0:01:11 â€¢ 0:00:07[0m [2;4m2.63it/s[0m  
[2KAttention weights: tensor([[0.6178, 0.3822],â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”[0m 185/203 [2m0:01:11 â€¢ 0:00:07[0m [2;4m2.63it/s[0m  
        [0.6291, 0.3709],
        [0.5220, 0.4780],
        [0.6538, 0.3462],
        [0.6319, 0.3681],
        [0.7370, 0.2630],
        [0.6816, 0.3184],
        [0.7693, 0.2307],
        [0.5609, 0.4391],
[2K        [0.6206, 0.3794]], device='cuda:0')â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”[0m 185/203 [2m0:01:11 â€¢ 0:00:07[0m [2;4m2.63it/s[0m  
[2KAttention weights: tensor([[0.5250, 0.4750],â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”[0m 186/203 [2m0:01:11 â€¢ 0:00:07[0m [2;4m2.62it/s[0m  
        [0.5157, 0.4843],
        [0.5178, 0.4822],
        [0.5236, 0.4764],
        [0.5261, 0.4739],
        [0.5283, 0.4717],
        [0.5256, 0.4744],
        [0.5224, 0.4776],
        [0.5196, 0.4804],
[2K        [0.5257, 0.4743]], device='cuda:0', grad_fn=<SoftmaxBackward0>);224mâ•¸[0m[38;5;237mâ”â”â”[0m 186/203 [2m0:01:11 â€¢ 0:00:07[0m [2;4m2.62it/s[0m  
[2KClass label: SoccerPenaltyâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”[0m 186/203 [2m0:01:11 â€¢ 0:00:07[0m [2;4m2.62it/s[0m  
[2KAttention weights: tensor([[0.6089, 0.3911]], device='cuda:0', grad_fn=<SoftmaxBackward0>)7mâ”â”â”[0m 186/203 [2m0:01:11 â€¢ 0:00:07[0m [2;4m2.62it/s[0m  
[2KStep 0 - TTA Loss: 1.8059â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”[0m 186/203 [2m0:01:11 â€¢ 0:00:07[0m [2;4m2.62it/s[0m  
[2KAttention weights: tensor([[0.6371, 0.3629]], device='cuda:0', grad_fn=<SoftmaxBackward0>)7mâ”â”â”[0m 186/203 [2m0:01:11 â€¢ 0:00:07[0m [2;4m2.62it/s[0m  
[2KAttention weights: tensor([[0.6655, 0.3345]], device='cuda:0', grad_fn=<SoftmaxBackward0>)7mâ”â”â”[0m 186/203 [2m0:01:11 â€¢ 0:00:07[0m [2;4m2.62it/s[0m  
[2KAttention weights: tensor([[0.6913, 0.3087]], device='cuda:0', grad_fn=<SoftmaxBackward0>)7mâ”â”â”[0m 186/203 [2m0:01:11 â€¢ 0:00:07[0m [2;4m2.62it/s[0m  
[2KAttention weights: tensor([[0.7231, 0.2769]], device='cuda:0', grad_fn=<SoftmaxBackward0>)7mâ”â”â”[0m 186/203 [2m0:01:11 â€¢ 0:00:07[0m [2;4m2.62it/s[0m  
[2KAttention weights: tensor([[0.7456, 0.2544]], device='cuda:0', grad_fn=<SoftmaxBackward0>)7mâ”â”â”[0m 186/203 [2m0:01:11 â€¢ 0:00:07[0m [2;4m2.62it/s[0m  
[2KAttention weights: tensor([[0.7624, 0.2376]], device='cuda:0', grad_fn=<SoftmaxBackward0>)7mâ”â”â”[0m 186/203 [2m0:01:11 â€¢ 0:00:07[0m [2;4m2.62it/s[0m  
[2KAttention weights: tensor([[0.7735, 0.2265]], device='cuda:0', grad_fn=<SoftmaxBackward0>)7mâ”â”â”[0m 186/203 [2m0:01:11 â€¢ 0:00:07[0m [2;4m2.62it/s[0m  
[2KAttention weights: tensor([[0.7792, 0.2208]], device='cuda:0', grad_fn=<SoftmaxBackward0>)7mâ”â”â”[0m 186/203 [2m0:01:11 â€¢ 0:00:07[0m [2;4m2.62it/s[0m  
[2KAttention weights: tensor([[0.7812, 0.2188]], device='cuda:0', grad_fn=<SoftmaxBackward0>)7mâ”â”â”[0m 186/203 [2m0:01:11 â€¢ 0:00:07[0m [2;4m2.62it/s[0m  
[2KAttention weights: tensor([[0.5296, 0.4704]], device='cuda:0')38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”[0m 186/203 [2m0:01:11 â€¢ 0:00:07[0m [2;4m2.62it/s[0m  
[2KAttention weights: tensor([[0.6175, 0.3825],â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”[0m 186/203 [2m0:01:11 â€¢ 0:00:07[0m [2;4m2.62it/s[0m  
        [0.6031, 0.3969],
        [0.5203, 0.4797],
        [0.6533, 0.3467],
        [0.6377, 0.3623],
        [0.7411, 0.2589],
        [0.6850, 0.3150],
        [0.7820, 0.2180],
        [0.5682, 0.4318],
[2K        [0.6241, 0.3759]], device='cuda:0')â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”[0m 186/203 [2m0:01:11 â€¢ 0:00:07[0m [2;4m2.62it/s[0m  
[2KAttention weights: tensor([[0.5251, 0.4749],â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”[0m 187/203 [2m0:01:12 â€¢ 0:00:07[0m [2;4m2.62it/s[0m  
        [0.5158, 0.4842],
        [0.5179, 0.4821],
        [0.5237, 0.4763],
        [0.5261, 0.4739],
        [0.5283, 0.4717],
        [0.5257, 0.4743],
        [0.5225, 0.4775],
        [0.5196, 0.4804],
[2K        [0.5258, 0.4742]], device='cuda:0', grad_fn=<SoftmaxBackward0>);224mâ•¸[0m[38;5;237mâ”â”â”[0m 187/203 [2m0:01:12 â€¢ 0:00:07[0m [2;4m2.62it/s[0m  
[2KClass label: CleanAndJerkâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”[0m 187/203 [2m0:01:12 â€¢ 0:00:07[0m [2;4m2.62it/s[0m  
[2KAttention weights: tensor([[0.4968, 0.5032]], device='cuda:0', grad_fn=<SoftmaxBackward0>)7mâ”â”â”[0m 187/203 [2m0:01:12 â€¢ 0:00:07[0m [2;4m2.62it/s[0m  
[2KStep 0 - TTA Loss: 1.0390â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”[0m 187/203 [2m0:01:12 â€¢ 0:00:07[0m [2;4m2.62it/s[0m  
[2KAttention weights: tensor([[0.4968, 0.5032]], device='cuda:0', grad_fn=<SoftmaxBackward0>)7mâ”â”â”[0m 187/203 [2m0:01:12 â€¢ 0:00:07[0m [2;4m2.62it/s[0m  
[2KAttention weights: tensor([[0.4969, 0.5031]], device='cuda:0', grad_fn=<SoftmaxBackward0>)7mâ”â”â”[0m 187/203 [2m0:01:12 â€¢ 0:00:07[0m [2;4m2.62it/s[0m  
[2KAttention weights: tensor([[0.4970, 0.5030]], device='cuda:0', grad_fn=<SoftmaxBackward0>)7mâ”â”â”[0m 187/203 [2m0:01:12 â€¢ 0:00:07[0m [2;4m2.62it/s[0m  
[2KAttention weights: tensor([[0.4969, 0.5031]], device='cuda:0', grad_fn=<SoftmaxBackward0>)7mâ”â”â”[0m 187/203 [2m0:01:12 â€¢ 0:00:07[0m [2;4m2.62it/s[0m  
[2KAttention weights: tensor([[0.4981, 0.5019]], device='cuda:0', grad_fn=<SoftmaxBackward0>)7mâ”â”â”[0m 187/203 [2m0:01:12 â€¢ 0:00:07[0m [2;4m2.62it/s[0m  
[2KAttention weights: tensor([[0.5003, 0.4997]], device='cuda:0', grad_fn=<SoftmaxBackward0>)7mâ”â”â”[0m 187/203 [2m0:01:12 â€¢ 0:00:07[0m [2;4m2.62it/s[0m  
[2KAttention weights: tensor([[0.5030, 0.4970]], device='cuda:0', grad_fn=<SoftmaxBackward0>)7mâ”â”â”[0m 187/203 [2m0:01:12 â€¢ 0:00:07[0m [2;4m2.62it/s[0m  
[2KAttention weights: tensor([[0.5056, 0.4944]], device='cuda:0', grad_fn=<SoftmaxBackward0>)7mâ”â”â”[0m 187/203 [2m0:01:12 â€¢ 0:00:07[0m [2;4m2.62it/s[0m  
[2KAttention weights: tensor([[0.5072, 0.4928]], device='cuda:0', grad_fn=<SoftmaxBackward0>)7mâ”â”â”[0m 187/203 [2m0:01:12 â€¢ 0:00:07[0m [2;4m2.62it/s[0m  
[2KAttention weights: tensor([[0.5182, 0.4818]], device='cuda:0')38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”[0m 187/203 [2m0:01:12 â€¢ 0:00:07[0m [2;4m2.62it/s[0m  
[2KAttention weights: tensor([[0.6086, 0.3914],â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”[0m 187/203 [2m0:01:12 â€¢ 0:00:07[0m [2;4m2.62it/s[0m  
        [0.4847, 0.5153],
        [0.5080, 0.4920],
        [0.6225, 0.3775],
        [0.6049, 0.3951],
        [0.7146, 0.2854],
        [0.6653, 0.3347],
        [0.6831, 0.3169],
        [0.5383, 0.4617],
[2K        [0.6048, 0.3952]], device='cuda:0')â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”[0m 187/203 [2m0:01:12 â€¢ 0:00:07[0m [2;4m2.62it/s[0m  
[2KAttention weights: tensor([[0.5251, 0.4749],â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”[0m 188/203 [2m0:01:12 â€¢ 0:00:06[0m [2;4m2.62it/s[0m   
        [0.5158, 0.4842],
        [0.5179, 0.4821],
        [0.5237, 0.4763],
        [0.5261, 0.4739],
        [0.5284, 0.4716],
        [0.5257, 0.4743],
        [0.5225, 0.4775],
        [0.5196, 0.4804],
[2K        [0.5258, 0.4742]], device='cuda:0', grad_fn=<SoftmaxBackward0>)mâ•º[0m[38;5;237mâ”â”[0m 188/203 [2m0:01:12 â€¢ 0:00:06[0m [2;4m2.62it/s[0m  
[2KClass label: TennisSwingâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”[0m 188/203 [2m0:01:12 â€¢ 0:00:06[0m [2;4m2.62it/s[0m  
[2KAttention weights: tensor([[0.5192, 0.4808]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 188/203 [2m0:01:12 â€¢ 0:00:06[0m [2;4m2.62it/s[0m  
[2KStep 0 - TTA Loss: 0.9330â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”[0m 188/203 [2m0:01:12 â€¢ 0:00:06[0m [2;4m2.62it/s[0m  
[2KAttention weights: tensor([[0.5223, 0.4777]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 188/203 [2m0:01:12 â€¢ 0:00:06[0m [2;4m2.62it/s[0m  
[2KAttention weights: tensor([[0.5345, 0.4655]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 188/203 [2m0:01:12 â€¢ 0:00:06[0m [2;4m2.62it/s[0m  
[2KAttention weights: tensor([[0.5527, 0.4473]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 188/203 [2m0:01:12 â€¢ 0:00:06[0m [2;4m2.62it/s[0m  
[2KAttention weights: tensor([[0.5662, 0.4338]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 188/203 [2m0:01:12 â€¢ 0:00:06[0m [2;4m2.62it/s[0m  
[2KAttention weights: tensor([[0.5834, 0.4166]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 188/203 [2m0:01:12 â€¢ 0:00:06[0m [2;4m2.62it/s[0m  
[2KAttention weights: tensor([[0.5954, 0.4046]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 188/203 [2m0:01:12 â€¢ 0:00:06[0m [2;4m2.62it/s[0m  
[2KAttention weights: tensor([[0.6068, 0.3932]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 188/203 [2m0:01:12 â€¢ 0:00:06[0m [2;4m2.62it/s[0m  
[2KAttention weights: tensor([[0.6128, 0.3872]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 188/203 [2m0:01:12 â€¢ 0:00:06[0m [2;4m2.62it/s[0m  
[2KAttention weights: tensor([[0.6164, 0.3836]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 188/203 [2m0:01:12 â€¢ 0:00:06[0m [2;4m2.62it/s[0m  
[2KAttention weights: tensor([[0.5231, 0.4769]], device='cuda:0')[38;5;237mâ•º[0m[38;5;237mâ”â”[0m 188/203 [2m0:01:12 â€¢ 0:00:06[0m [2;4m2.62it/s[0m  
[2KAttention weights: tensor([[0.6288, 0.3712],â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”[0m 188/203 [2m0:01:12 â€¢ 0:00:06[0m [2;4m2.62it/s[0m  
        [0.4718, 0.5282],
        [0.5152, 0.4848],
        [0.6281, 0.3719],
        [0.6165, 0.3835],
        [0.7311, 0.2689],
        [0.6668, 0.3332],
        [0.6789, 0.3211],
        [0.6175, 0.3825],
[2K        [0.6281, 0.3719]], device='cuda:0')â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”[0m 188/203 [2m0:01:12 â€¢ 0:00:06[0m [2;4m2.62it/s[0m  
[2KAttention weights: tensor([[0.5251, 0.4749],â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”[0m 189/203 [2m0:01:12 â€¢ 0:00:06[0m [2;4m2.62it/s[0m  
        [0.5158, 0.4842],
        [0.5179, 0.4821],
        [0.5237, 0.4763],
        [0.5262, 0.4738],
        [0.5284, 0.4716],
        [0.5257, 0.4743],
        [0.5226, 0.4774],
        [0.5197, 0.4803],
[2K        [0.5258, 0.4742]], device='cuda:0', grad_fn=<SoftmaxBackward0>)mâ•º[0m[38;5;237mâ”â”[0m 189/203 [2m0:01:12 â€¢ 0:00:06[0m [2;4m2.62it/s[0m  
[2KClass label: GolfSwingâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”[0m 189/203 [2m0:01:12 â€¢ 0:00:06[0m [2;4m2.62it/s[0m  
[2KAttention weights: tensor([[0.6065, 0.3935]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 189/203 [2m0:01:12 â€¢ 0:00:06[0m [2;4m2.62it/s[0m  
[2KStep 0 - TTA Loss: 1.2148â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”[0m 189/203 [2m0:01:12 â€¢ 0:00:06[0m [2;4m2.62it/s[0m  
[2KAttention weights: tensor([[0.6065, 0.3935]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 189/203 [2m0:01:12 â€¢ 0:00:06[0m [2;4m2.62it/s[0m  
[2KAttention weights: tensor([[0.6066, 0.3934]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 189/203 [2m0:01:12 â€¢ 0:00:06[0m [2;4m2.62it/s[0m  
[2KAttention weights: tensor([[0.6073, 0.3927]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 189/203 [2m0:01:12 â€¢ 0:00:06[0m [2;4m2.62it/s[0m  
[2KAttention weights: tensor([[0.6086, 0.3914]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 189/203 [2m0:01:12 â€¢ 0:00:06[0m [2;4m2.62it/s[0m  
[2KAttention weights: tensor([[0.6108, 0.3892]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 189/203 [2m0:01:12 â€¢ 0:00:06[0m [2;4m2.62it/s[0m  
[2KAttention weights: tensor([[0.6144, 0.3856]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 189/203 [2m0:01:12 â€¢ 0:00:06[0m [2;4m2.62it/s[0m  
[2KAttention weights: tensor([[0.6193, 0.3807]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 189/203 [2m0:01:12 â€¢ 0:00:06[0m [2;4m2.62it/s[0m  
[2KAttention weights: tensor([[0.6250, 0.3750]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 189/203 [2m0:01:12 â€¢ 0:00:06[0m [2;4m2.62it/s[0m  
[2KAttention weights: tensor([[0.6322, 0.3678]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 189/203 [2m0:01:12 â€¢ 0:00:06[0m [2;4m2.62it/s[0m  
[2KAttention weights: tensor([[0.5259, 0.4741]], device='cuda:0')[38;5;237mâ•º[0m[38;5;237mâ”â”[0m 189/203 [2m0:01:12 â€¢ 0:00:06[0m [2;4m2.62it/s[0m  
[2KAttention weights: tensor([[0.6334, 0.3666],â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”[0m 189/203 [2m0:01:12 â€¢ 0:00:06[0m [2;4m2.62it/s[0m  
        [0.4601, 0.5399],
        [0.5199, 0.4801],
        [0.6395, 0.3605],
        [0.6111, 0.3889],
        [0.7199, 0.2801],
        [0.6630, 0.3370],
        [0.6378, 0.3622],
        [0.6129, 0.3871],
[2K        [0.6247, 0.3753]], device='cuda:0')â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”[0m 189/203 [2m0:01:12 â€¢ 0:00:06[0m [2;4m2.62it/s[0m  
[2KAttention weights: tensor([[0.5251, 0.4749],â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”[0m 190/203 [2m0:01:13 â€¢ 0:00:05[0m [2;4m2.62it/s[0m  
        [0.5158, 0.4842],
        [0.5179, 0.4821],
        [0.5237, 0.4763],
        [0.5262, 0.4738],
        [0.5284, 0.4716],
        [0.5257, 0.4743],
        [0.5226, 0.4774],
        [0.5197, 0.4803],
[2K        [0.5258, 0.4742]], device='cuda:0', grad_fn=<SoftmaxBackward0>)mâ•º[0m[38;5;237mâ”â”[0m 190/203 [2m0:01:13 â€¢ 0:00:05[0m [2;4m2.62it/s[0m  
[2KClass label: HighJumpâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”[0m 190/203 [2m0:01:13 â€¢ 0:00:05[0m [2;4m2.62it/s[0m  
[2KAttention weights: tensor([[0.6919, 0.3081]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 190/203 [2m0:01:13 â€¢ 0:00:05[0m [2;4m2.62it/s[0m  
[2KStep 0 - TTA Loss: 0.9191â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”[0m 190/203 [2m0:01:13 â€¢ 0:00:05[0m [2;4m2.62it/s[0m  
[2KAttention weights: tensor([[0.6874, 0.3126]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 190/203 [2m0:01:13 â€¢ 0:00:05[0m [2;4m2.62it/s[0m  
[2KAttention weights: tensor([[0.6840, 0.3160]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 190/203 [2m0:01:13 â€¢ 0:00:05[0m [2;4m2.62it/s[0m  
[2KAttention weights: tensor([[0.6846, 0.3154]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 190/203 [2m0:01:13 â€¢ 0:00:05[0m [2;4m2.62it/s[0m  
[2KAttention weights: tensor([[0.6884, 0.3116]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 190/203 [2m0:01:13 â€¢ 0:00:05[0m [2;4m2.62it/s[0m  
[2KAttention weights: tensor([[0.6924, 0.3076]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 190/203 [2m0:01:13 â€¢ 0:00:05[0m [2;4m2.62it/s[0m  
[2KAttention weights: tensor([[0.6942, 0.3058]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 190/203 [2m0:01:13 â€¢ 0:00:05[0m [2;4m2.62it/s[0m  
[2KAttention weights: tensor([[0.6922, 0.3078]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 190/203 [2m0:01:13 â€¢ 0:00:05[0m [2;4m2.62it/s[0m  
[2KAttention weights: tensor([[0.6913, 0.3087]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 190/203 [2m0:01:13 â€¢ 0:00:05[0m [2;4m2.62it/s[0m  
[2KAttention weights: tensor([[0.6909, 0.3091]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 190/203 [2m0:01:13 â€¢ 0:00:05[0m [2;4m2.62it/s[0m  
[2KAttention weights: tensor([[0.5296, 0.4704]], device='cuda:0')[38;5;237mâ•º[0m[38;5;237mâ”â”[0m 190/203 [2m0:01:13 â€¢ 0:00:05[0m [2;4m2.62it/s[0m  
[2KAttention weights: tensor([[0.6145, 0.3855],â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”[0m 190/203 [2m0:01:13 â€¢ 0:00:05[0m [2;4m2.62it/s[0m  
        [0.4573, 0.5427],
        [0.5065, 0.4935],
        [0.6274, 0.3726],
        [0.5913, 0.4087],
        [0.6913, 0.3087],
        [0.6420, 0.3580],
        [0.6211, 0.3789],
        [0.5763, 0.4237],
[2K        [0.6016, 0.3984]], device='cuda:0')â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”[0m 190/203 [2m0:01:13 â€¢ 0:00:05[0m [2;4m2.62it/s[0m  
[2KAttention weights: tensor([[0.5251, 0.4749],â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”[0m 191/203 [2m0:01:13 â€¢ 0:00:05[0m [2;4m2.61it/s[0m  
        [0.5158, 0.4842],
        [0.5179, 0.4821],
        [0.5237, 0.4763],
        [0.5262, 0.4738],
        [0.5284, 0.4716],
        [0.5257, 0.4743],
        [0.5226, 0.4774],
        [0.5197, 0.4803],
[2K        [0.5258, 0.4742]], device='cuda:0', grad_fn=<SoftmaxBackward0>)6;224mâ•¸[0m[38;5;237mâ”â”[0m 191/203 [2m0:01:13 â€¢ 0:00:05[0m [2;4m2.61it/s[0m  
[2KClass label: CleanAndJerkâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”[0m 191/203 [2m0:01:13 â€¢ 0:00:05[0m [2;4m2.61it/s[0m  
[2KAttention weights: tensor([[0.4996, 0.5004]], device='cuda:0', grad_fn=<SoftmaxBackward0>)37mâ”â”[0m 191/203 [2m0:01:13 â€¢ 0:00:05[0m [2;4m2.61it/s[0m  
[2KStep 0 - TTA Loss: 0.9547â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”[0m 191/203 [2m0:01:13 â€¢ 0:00:05[0m [2;4m2.61it/s[0m  
[2KAttention weights: tensor([[0.4996, 0.5004]], device='cuda:0', grad_fn=<SoftmaxBackward0>)37mâ”â”[0m 191/203 [2m0:01:13 â€¢ 0:00:05[0m [2;4m2.61it/s[0m  
[2KAttention weights: tensor([[0.4996, 0.5004]], device='cuda:0', grad_fn=<SoftmaxBackward0>)37mâ”â”[0m 191/203 [2m0:01:13 â€¢ 0:00:05[0m [2;4m2.61it/s[0m  
[2KAttention weights: tensor([[0.5000, 0.5000]], device='cuda:0', grad_fn=<SoftmaxBackward0>)37mâ”â”[0m 191/203 [2m0:01:13 â€¢ 0:00:05[0m [2;4m2.61it/s[0m  
[2KAttention weights: tensor([[0.5012, 0.4988]], device='cuda:0', grad_fn=<SoftmaxBackward0>)37mâ”â”[0m 191/203 [2m0:01:13 â€¢ 0:00:05[0m [2;4m2.61it/s[0m  
[2KAttention weights: tensor([[0.5043, 0.4957]], device='cuda:0', grad_fn=<SoftmaxBackward0>)37mâ”â”[0m 191/203 [2m0:01:13 â€¢ 0:00:05[0m [2;4m2.61it/s[0m  
[2KAttention weights: tensor([[0.5090, 0.4910]], device='cuda:0', grad_fn=<SoftmaxBackward0>)37mâ”â”[0m 191/203 [2m0:01:13 â€¢ 0:00:05[0m [2;4m2.61it/s[0m  
[2KAttention weights: tensor([[0.5148, 0.4852]], device='cuda:0', grad_fn=<SoftmaxBackward0>)37mâ”â”[0m 191/203 [2m0:01:13 â€¢ 0:00:05[0m [2;4m2.61it/s[0m  
[2KAttention weights: tensor([[0.5220, 0.4780]], device='cuda:0', grad_fn=<SoftmaxBackward0>)37mâ”â”[0m 191/203 [2m0:01:13 â€¢ 0:00:05[0m [2;4m2.61it/s[0m  
[2KAttention weights: tensor([[0.5295, 0.4705]], device='cuda:0', grad_fn=<SoftmaxBackward0>)37mâ”â”[0m 191/203 [2m0:01:13 â€¢ 0:00:05[0m [2;4m2.61it/s[0m  
[2KAttention weights: tensor([[0.5193, 0.4807]], device='cuda:0')[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”[0m 191/203 [2m0:01:13 â€¢ 0:00:05[0m [2;4m2.61it/s[0m  
[2KAttention weights: tensor([[0.6097, 0.3903],â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”[0m 191/203 [2m0:01:13 â€¢ 0:00:05[0m [2;4m2.61it/s[0m  
        [0.4535, 0.5465],
        [0.5380, 0.4620],
        [0.6188, 0.3812],
        [0.5802, 0.4198],
        [0.6798, 0.3202],
        [0.6403, 0.3597],
        [0.6080, 0.3920],
        [0.5351, 0.4649],
[2K        [0.5903, 0.4097]], device='cuda:0')â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”[0m 191/203 [2m0:01:13 â€¢ 0:00:05[0m [2;4m2.61it/s[0m  
[2KAttention weights: tensor([[0.5251, 0.4749],â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”[0m 192/203 [2m0:01:14 â€¢ 0:00:05[0m [2;4m2.60it/s[0m  
        [0.5158, 0.4842],
        [0.5179, 0.4821],
        [0.5237, 0.4763],
        [0.5262, 0.4738],
        [0.5284, 0.4716],
        [0.5257, 0.4743],
        [0.5226, 0.4774],
        [0.5197, 0.4803],
[2K        [0.5258, 0.4742]], device='cuda:0', grad_fn=<SoftmaxBackward0>)6;224mâ•¸[0m[38;5;237mâ”â”[0m 192/203 [2m0:01:14 â€¢ 0:00:05[0m [2;4m2.60it/s[0m  
[2KClass label: HighJumpâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”[0m 192/203 [2m0:01:14 â€¢ 0:00:05[0m [2;4m2.60it/s[0m  
[2KAttention weights: tensor([[0.6895, 0.3105]], device='cuda:0', grad_fn=<SoftmaxBackward0>)37mâ”â”[0m 192/203 [2m0:01:14 â€¢ 0:00:05[0m [2;4m2.60it/s[0m  
[2KStep 0 - TTA Loss: 1.4731â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”[0m 192/203 [2m0:01:14 â€¢ 0:00:05[0m [2;4m2.60it/s[0m  
[2KAttention weights: tensor([[0.7033, 0.2967]], device='cuda:0', grad_fn=<SoftmaxBackward0>)37mâ”â”[0m 192/203 [2m0:01:14 â€¢ 0:00:05[0m [2;4m2.60it/s[0m  
[2KAttention weights: tensor([[0.7323, 0.2677]], device='cuda:0', grad_fn=<SoftmaxBackward0>)37mâ”â”[0m 192/203 [2m0:01:14 â€¢ 0:00:05[0m [2;4m2.60it/s[0m  
[2KAttention weights: tensor([[0.7654, 0.2346]], device='cuda:0', grad_fn=<SoftmaxBackward0>)37mâ”â”[0m 192/203 [2m0:01:14 â€¢ 0:00:05[0m [2;4m2.60it/s[0m  
[2KAttention weights: tensor([[0.7935, 0.2065]], device='cuda:0', grad_fn=<SoftmaxBackward0>)37mâ”â”[0m 192/203 [2m0:01:14 â€¢ 0:00:05[0m [2;4m2.60it/s[0m  
[2KAttention weights: tensor([[0.8231, 0.1769]], device='cuda:0', grad_fn=<SoftmaxBackward0>)37mâ”â”[0m 192/203 [2m0:01:14 â€¢ 0:00:05[0m [2;4m2.60it/s[0m  
[2KAttention weights: tensor([[0.8456, 0.1544]], device='cuda:0', grad_fn=<SoftmaxBackward0>)37mâ”â”[0m 192/203 [2m0:01:14 â€¢ 0:00:05[0m [2;4m2.60it/s[0m  
[2KAttention weights: tensor([[0.8598, 0.1402]], device='cuda:0', grad_fn=<SoftmaxBackward0>)37mâ”â”[0m 192/203 [2m0:01:14 â€¢ 0:00:05[0m [2;4m2.60it/s[0m  
[2KAttention weights: tensor([[0.8681, 0.1319]], device='cuda:0', grad_fn=<SoftmaxBackward0>)37mâ”â”[0m 192/203 [2m0:01:14 â€¢ 0:00:05[0m [2;4m2.60it/s[0m  
[2KAttention weights: tensor([[0.8707, 0.1293]], device='cuda:0', grad_fn=<SoftmaxBackward0>)37mâ”â”[0m 192/203 [2m0:01:14 â€¢ 0:00:05[0m [2;4m2.60it/s[0m  
[2KAttention weights: tensor([[0.5382, 0.4618]], device='cuda:0')[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”[0m 192/203 [2m0:01:14 â€¢ 0:00:05[0m [2;4m2.60it/s[0m  
[2KAttention weights: tensor([[0.6853, 0.3147],â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”[0m 192/203 [2m0:01:14 â€¢ 0:00:05[0m [2;4m2.60it/s[0m  
        [0.4599, 0.5401],
        [0.5744, 0.4256],
        [0.6752, 0.3248],
        [0.7260, 0.2740],
        [0.8719, 0.1281],
        [0.7996, 0.2004],
        [0.6974, 0.3026],
        [0.6068, 0.3932],
[2K        [0.7392, 0.2608]], device='cuda:0')â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”[0m 192/203 [2m0:01:14 â€¢ 0:00:05[0m [2;4m2.60it/s[0m  
[2KAttention weights: tensor([[0.5252, 0.4748],â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”[0m 193/203 [2m0:01:14 â€¢ 0:00:04[0m [2;4m2.60it/s[0m   
        [0.5159, 0.4841],
        [0.5180, 0.4820],
        [0.5238, 0.4762],
        [0.5262, 0.4738],
        [0.5285, 0.4715],
        [0.5258, 0.4742],
        [0.5226, 0.4774],
        [0.5197, 0.4803],
[2K        [0.5259, 0.4741]], device='cuda:0', grad_fn=<SoftmaxBackward0>)7mâ•º[0m[38;5;237mâ”[0m 193/203 [2m0:01:14 â€¢ 0:00:04[0m [2;4m2.60it/s[0m  
[2KClass label: BaseballPitchâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”[0m 193/203 [2m0:01:14 â€¢ 0:00:04[0m [2;4m2.60it/s[0m  
[2KAttention weights: tensor([[0.6062, 0.3938]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 193/203 [2m0:01:14 â€¢ 0:00:04[0m [2;4m2.60it/s[0m  
[2KStep 0 - TTA Loss: 1.1440â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”[0m 193/203 [2m0:01:14 â€¢ 0:00:04[0m [2;4m2.60it/s[0m  
[2KAttention weights: tensor([[0.6062, 0.3938]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 193/203 [2m0:01:14 â€¢ 0:00:04[0m [2;4m2.60it/s[0m  
[2KAttention weights: tensor([[0.6067, 0.3933]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 193/203 [2m0:01:14 â€¢ 0:00:04[0m [2;4m2.60it/s[0m  
[2KAttention weights: tensor([[0.6100, 0.3900]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 193/203 [2m0:01:14 â€¢ 0:00:04[0m [2;4m2.60it/s[0m  
[2KAttention weights: tensor([[0.6188, 0.3812]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 193/203 [2m0:01:14 â€¢ 0:00:04[0m [2;4m2.60it/s[0m  
[2KAttention weights: tensor([[0.6378, 0.3622]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 193/203 [2m0:01:14 â€¢ 0:00:04[0m [2;4m2.60it/s[0m  
[2KAttention weights: tensor([[0.6656, 0.3344]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 193/203 [2m0:01:14 â€¢ 0:00:04[0m [2;4m2.60it/s[0m  
[2KAttention weights: tensor([[0.6992, 0.3008]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 193/203 [2m0:01:14 â€¢ 0:00:04[0m [2;4m2.60it/s[0m  
[2KAttention weights: tensor([[0.7429, 0.2571]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 193/203 [2m0:01:14 â€¢ 0:00:04[0m [2;4m2.60it/s[0m  
[2KAttention weights: tensor([[0.7769, 0.2231]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 193/203 [2m0:01:14 â€¢ 0:00:04[0m [2;4m2.60it/s[0m  
[2KAttention weights: tensor([[0.5326, 0.4674]], device='cuda:0')[38;5;237mâ•º[0m[38;5;237mâ”[0m 193/203 [2m0:01:14 â€¢ 0:00:04[0m [2;4m2.60it/s[0m  
[2KAttention weights: tensor([[0.8018, 0.1982],â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”[0m 193/203 [2m0:01:14 â€¢ 0:00:04[0m [2;4m2.60it/s[0m  
        [0.4660, 0.5340],
        [0.5560, 0.4440],
        [0.6894, 0.3106],
        [0.7112, 0.2888],
        [0.7981, 0.2019],
        [0.7405, 0.2595],
        [0.6387, 0.3613],
        [0.5907, 0.4093],
[2K        [0.7235, 0.2765]], device='cuda:0')â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”[0m 193/203 [2m0:01:14 â€¢ 0:00:04[0m [2;4m2.60it/s[0m  
[2KAttention weights: tensor([[0.5252, 0.4748],â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”[0m 194/203 [2m0:01:15 â€¢ 0:00:04[0m [2;4m2.62it/s[0m  
        [0.5159, 0.4841],
        [0.5180, 0.4820],
        [0.5238, 0.4762],
        [0.5262, 0.4738],
        [0.5285, 0.4715],
        [0.5258, 0.4742],
        [0.5227, 0.4773],
        [0.5197, 0.4803],
[2K        [0.5259, 0.4741]], device='cuda:0', grad_fn=<SoftmaxBackward0>)7mâ•º[0m[38;5;237mâ”[0m 194/203 [2m0:01:15 â€¢ 0:00:04[0m [2;4m2.62it/s[0m  
[2KClass label: HighJumpâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”[0m 194/203 [2m0:01:15 â€¢ 0:00:04[0m [2;4m2.62it/s[0m  
[2KAttention weights: tensor([[0.6907, 0.3093]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 194/203 [2m0:01:15 â€¢ 0:00:04[0m [2;4m2.62it/s[0m  
[2KStep 0 - TTA Loss: 0.8537â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”[0m 194/203 [2m0:01:15 â€¢ 0:00:04[0m [2;4m2.62it/s[0m  
[2KAttention weights: tensor([[0.7065, 0.2935]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 194/203 [2m0:01:15 â€¢ 0:00:04[0m [2;4m2.62it/s[0m  
[2KAttention weights: tensor([[0.7101, 0.2899]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 194/203 [2m0:01:15 â€¢ 0:00:04[0m [2;4m2.62it/s[0m  
[2KAttention weights: tensor([[0.7156, 0.2844]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 194/203 [2m0:01:15 â€¢ 0:00:04[0m [2;4m2.62it/s[0m  
[2KAttention weights: tensor([[0.7130, 0.2870]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 194/203 [2m0:01:15 â€¢ 0:00:04[0m [2;4m2.62it/s[0m  
[2KAttention weights: tensor([[0.7118, 0.2882]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 194/203 [2m0:01:15 â€¢ 0:00:04[0m [2;4m2.62it/s[0m  
[2KAttention weights: tensor([[0.7110, 0.2890]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 194/203 [2m0:01:15 â€¢ 0:00:04[0m [2;4m2.62it/s[0m  
[2KAttention weights: tensor([[0.7096, 0.2904]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 194/203 [2m0:01:15 â€¢ 0:00:04[0m [2;4m2.62it/s[0m  
[2KAttention weights: tensor([[0.7079, 0.2921]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 194/203 [2m0:01:15 â€¢ 0:00:04[0m [2;4m2.62it/s[0m  
[2KAttention weights: tensor([[0.7065, 0.2935]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 194/203 [2m0:01:15 â€¢ 0:00:04[0m [2;4m2.62it/s[0m  
[2KAttention weights: tensor([[0.5307, 0.4693]], device='cuda:0')[38;5;237mâ•º[0m[38;5;237mâ”[0m 194/203 [2m0:01:15 â€¢ 0:00:04[0m [2;4m2.62it/s[0m  
[2KAttention weights: tensor([[0.7170, 0.2830],â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”[0m 194/203 [2m0:01:15 â€¢ 0:00:04[0m [2;4m2.62it/s[0m  
        [0.4572, 0.5428],
        [0.5235, 0.4765],
        [0.6417, 0.3583],
        [0.6291, 0.3709],
        [0.7068, 0.2932],
        [0.6655, 0.3345],
        [0.6069, 0.3931],
        [0.5427, 0.4573],
[2K        [0.6361, 0.3639]], device='cuda:0')â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”[0m 194/203 [2m0:01:15 â€¢ 0:00:04[0m [2;4m2.62it/s[0m  
[2KAttention weights: tensor([[0.5252, 0.4748],â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”[0m 195/203 [2m0:01:15 â€¢ 0:00:04[0m [2;4m2.62it/s[0m  
        [0.5159, 0.4841],
        [0.5180, 0.4820],
        [0.5238, 0.4762],
        [0.5263, 0.4737],
        [0.5285, 0.4715],
        [0.5258, 0.4742],
        [0.5227, 0.4773],
        [0.5197, 0.4803],
[2K        [0.5259, 0.4741]], device='cuda:0', grad_fn=<SoftmaxBackward0>)7mâ•º[0m[38;5;237mâ”[0m 195/203 [2m0:01:15 â€¢ 0:00:04[0m [2;4m2.62it/s[0m  
[2KClass label: GolfSwingâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”[0m 195/203 [2m0:01:15 â€¢ 0:00:04[0m [2;4m2.62it/s[0m  
[2KAttention weights: tensor([[0.6101, 0.3899]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 195/203 [2m0:01:15 â€¢ 0:00:04[0m [2;4m2.62it/s[0m  
[2KStep 0 - TTA Loss: 0.8542â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”[0m 195/203 [2m0:01:15 â€¢ 0:00:04[0m [2;4m2.62it/s[0m  
[2KAttention weights: tensor([[0.6101, 0.3899]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 195/203 [2m0:01:15 â€¢ 0:00:04[0m [2;4m2.62it/s[0m  
[2KAttention weights: tensor([[0.6100, 0.3900]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 195/203 [2m0:01:15 â€¢ 0:00:04[0m [2;4m2.62it/s[0m  
[2KAttention weights: tensor([[0.6102, 0.3898]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 195/203 [2m0:01:15 â€¢ 0:00:04[0m [2;4m2.62it/s[0m  
[2KAttention weights: tensor([[0.6110, 0.3890]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 195/203 [2m0:01:15 â€¢ 0:00:04[0m [2;4m2.62it/s[0m  
[2KAttention weights: tensor([[0.6126, 0.3874]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 195/203 [2m0:01:15 â€¢ 0:00:04[0m [2;4m2.62it/s[0m  
[2KAttention weights: tensor([[0.6151, 0.3849]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 195/203 [2m0:01:15 â€¢ 0:00:04[0m [2;4m2.62it/s[0m  
[2KAttention weights: tensor([[0.6192, 0.3808]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 195/203 [2m0:01:15 â€¢ 0:00:04[0m [2;4m2.62it/s[0m  
[2KAttention weights: tensor([[0.6242, 0.3758]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 195/203 [2m0:01:15 â€¢ 0:00:04[0m [2;4m2.62it/s[0m  
[2KAttention weights: tensor([[0.6307, 0.3693]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 195/203 [2m0:01:15 â€¢ 0:00:04[0m [2;4m2.62it/s[0m  
[2KAttention weights: tensor([[0.5257, 0.4743]], device='cuda:0')[38;5;237mâ•º[0m[38;5;237mâ”[0m 195/203 [2m0:01:15 â€¢ 0:00:04[0m [2;4m2.62it/s[0m  
[2KAttention weights: tensor([[0.6244, 0.3756],â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”[0m 195/203 [2m0:01:15 â€¢ 0:00:04[0m [2;4m2.62it/s[0m  
        [0.4597, 0.5403],
        [0.5036, 0.4964],
        [0.6369, 0.3631],
        [0.5819, 0.4181],
        [0.6670, 0.3330],
        [0.6335, 0.3665],
        [0.6020, 0.3980],
        [0.5168, 0.4832],
[2K        [0.5883, 0.4117]], device='cuda:0')â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”[0m 195/203 [2m0:01:15 â€¢ 0:00:04[0m [2;4m2.62it/s[0m  
[2KAttention weights: tensor([[0.5252, 0.4748],â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”[0m 196/203 [2m0:01:15 â€¢ 0:00:03[0m [2;4m2.62it/s[0m  
        [0.5159, 0.4841],
        [0.5180, 0.4820],
        [0.5238, 0.4762],
        [0.5263, 0.4737],
        [0.5285, 0.4715],
        [0.5258, 0.4742],
        [0.5227, 0.4773],
        [0.5197, 0.4803],
[2K        [0.5259, 0.4741]], device='cuda:0', grad_fn=<SoftmaxBackward0>);6;224mâ•¸[0m[38;5;237mâ”[0m 196/203 [2m0:01:15 â€¢ 0:00:03[0m [2;4m2.62it/s[0m  
[2KClass label: HammerThrowâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”[0m 196/203 [2m0:01:15 â€¢ 0:00:03[0m [2;4m2.62it/s[0m  
[2KAttention weights: tensor([[0.5811, 0.4189]], device='cuda:0', grad_fn=<SoftmaxBackward0>)237mâ”[0m 196/203 [2m0:01:15 â€¢ 0:00:03[0m [2;4m2.62it/s[0m  
[2KStep 0 - TTA Loss: 2.3596â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”[0m 196/203 [2m0:01:15 â€¢ 0:00:03[0m [2;4m2.62it/s[0m  
[2KAttention weights: tensor([[0.5858, 0.4142]], device='cuda:0', grad_fn=<SoftmaxBackward0>)237mâ”[0m 196/203 [2m0:01:15 â€¢ 0:00:03[0m [2;4m2.62it/s[0m  
[2KAttention weights: tensor([[0.5764, 0.4236]], device='cuda:0', grad_fn=<SoftmaxBackward0>)237mâ”[0m 196/203 [2m0:01:15 â€¢ 0:00:03[0m [2;4m2.62it/s[0m  
[2KAttention weights: tensor([[0.5576, 0.4424]], device='cuda:0', grad_fn=<SoftmaxBackward0>)237mâ”[0m 196/203 [2m0:01:15 â€¢ 0:00:03[0m [2;4m2.62it/s[0m  
[2KAttention weights: tensor([[0.5386, 0.4614]], device='cuda:0', grad_fn=<SoftmaxBackward0>)237mâ”[0m 196/203 [2m0:01:15 â€¢ 0:00:03[0m [2;4m2.62it/s[0m  
[2KAttention weights: tensor([[0.5207, 0.4793]], device='cuda:0', grad_fn=<SoftmaxBackward0>)237mâ”[0m 196/203 [2m0:01:15 â€¢ 0:00:03[0m [2;4m2.62it/s[0m  
[2KAttention weights: tensor([[0.5090, 0.4910]], device='cuda:0', grad_fn=<SoftmaxBackward0>)237mâ”[0m 196/203 [2m0:01:15 â€¢ 0:00:03[0m [2;4m2.62it/s[0m  
[2KAttention weights: tensor([[0.4976, 0.5024]], device='cuda:0', grad_fn=<SoftmaxBackward0>)237mâ”[0m 196/203 [2m0:01:15 â€¢ 0:00:03[0m [2;4m2.62it/s[0m  
[2KAttention weights: tensor([[0.4922, 0.5078]], device='cuda:0', grad_fn=<SoftmaxBackward0>)237mâ”[0m 196/203 [2m0:01:15 â€¢ 0:00:03[0m [2;4m2.62it/s[0m  
[2KAttention weights: tensor([[0.4897, 0.5103]], device='cuda:0', grad_fn=<SoftmaxBackward0>)237mâ”[0m 196/203 [2m0:01:15 â€¢ 0:00:03[0m [2;4m2.62it/s[0m  
[2KAttention weights: tensor([[0.5242, 0.4758]], device='cuda:0')[38;2;98;6;224mâ•¸[0m[38;5;237mâ”[0m 196/203 [2m0:01:15 â€¢ 0:00:03[0m [2;4m2.62it/s[0m  
[2KAttention weights: tensor([[0.5791, 0.4209],â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”[0m 196/203 [2m0:01:15 â€¢ 0:00:03[0m [2;4m2.62it/s[0m  
        [0.4454, 0.5546],
        [0.4838, 0.5162],
        [0.5929, 0.4071],
        [0.4888, 0.5112],
        [0.6247, 0.3753],
        [0.5923, 0.4077],
        [0.5830, 0.4170],
        [0.5002, 0.4998],
[2K        [0.5184, 0.4816]], device='cuda:0')â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”[0m 196/203 [2m0:01:15 â€¢ 0:00:03[0m [2;4m2.62it/s[0m  
[2KAttention weights: tensor([[0.5253, 0.4747],â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”[0m 197/203 [2m0:01:16 â€¢ 0:00:03[0m [2;4m2.62it/s[0m  
        [0.5159, 0.4841],
        [0.5181, 0.4819],
        [0.5239, 0.4761],
        [0.5264, 0.4736],
        [0.5286, 0.4714],
        [0.5259, 0.4741],
        [0.5227, 0.4773],
        [0.5198, 0.4802],
[2K        [0.5260, 0.4740]], device='cuda:0', grad_fn=<SoftmaxBackward0>);6;224mâ•¸[0m[38;5;237mâ”[0m 197/203 [2m0:01:16 â€¢ 0:00:03[0m [2;4m2.62it/s[0m  
[2KClass label: ThrowDiscusâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”[0m 197/203 [2m0:01:16 â€¢ 0:00:03[0m [2;4m2.62it/s[0m  
[2KAttention weights: tensor([[0.5886, 0.4114]], device='cuda:0', grad_fn=<SoftmaxBackward0>)237mâ”[0m 197/203 [2m0:01:16 â€¢ 0:00:03[0m [2;4m2.62it/s[0m  
[2KStep 0 - TTA Loss: 1.6033â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”[0m 197/203 [2m0:01:16 â€¢ 0:00:03[0m [2;4m2.62it/s[0m  
[2KAttention weights: tensor([[0.5886, 0.4114]], device='cuda:0', grad_fn=<SoftmaxBackward0>)237mâ”[0m 197/203 [2m0:01:16 â€¢ 0:00:03[0m [2;4m2.62it/s[0m  
[2KAttention weights: tensor([[0.5882, 0.4118]], device='cuda:0', grad_fn=<SoftmaxBackward0>)237mâ”[0m 197/203 [2m0:01:16 â€¢ 0:00:03[0m [2;4m2.62it/s[0m  
[2KAttention weights: tensor([[0.5862, 0.4138]], device='cuda:0', grad_fn=<SoftmaxBackward0>)237mâ”[0m 197/203 [2m0:01:16 â€¢ 0:00:03[0m [2;4m2.62it/s[0m  
[2KAttention weights: tensor([[0.5815, 0.4185]], device='cuda:0', grad_fn=<SoftmaxBackward0>)237mâ”[0m 197/203 [2m0:01:16 â€¢ 0:00:03[0m [2;4m2.62it/s[0m  
[2KAttention weights: tensor([[0.5746, 0.4254]], device='cuda:0', grad_fn=<SoftmaxBackward0>)237mâ”[0m 197/203 [2m0:01:16 â€¢ 0:00:03[0m [2;4m2.62it/s[0m  
[2KAttention weights: tensor([[0.5654, 0.4346]], device='cuda:0', grad_fn=<SoftmaxBackward0>)237mâ”[0m 197/203 [2m0:01:16 â€¢ 0:00:03[0m [2;4m2.62it/s[0m  
[2KAttention weights: tensor([[0.5458, 0.4542]], device='cuda:0', grad_fn=<SoftmaxBackward0>)237mâ”[0m 197/203 [2m0:01:16 â€¢ 0:00:03[0m [2;4m2.62it/s[0m  
[2KAttention weights: tensor([[0.5269, 0.4731]], device='cuda:0', grad_fn=<SoftmaxBackward0>)237mâ”[0m 197/203 [2m0:01:16 â€¢ 0:00:03[0m [2;4m2.62it/s[0m  
[2KAttention weights: tensor([[0.5081, 0.4919]], device='cuda:0', grad_fn=<SoftmaxBackward0>)237mâ”[0m 197/203 [2m0:01:16 â€¢ 0:00:03[0m [2;4m2.62it/s[0m  
[2KAttention weights: tensor([[0.5235, 0.4765]], device='cuda:0')[38;2;98;6;224mâ•¸[0m[38;5;237mâ”[0m 197/203 [2m0:01:16 â€¢ 0:00:03[0m [2;4m2.62it/s[0m  
[2KAttention weights: tensor([[0.5555, 0.4445],â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”[0m 197/203 [2m0:01:16 â€¢ 0:00:03[0m [2;4m2.62it/s[0m  
        [0.4355, 0.5645],
        [0.4733, 0.5267],
        [0.5622, 0.4378],
        [0.4794, 0.5206],
        [0.6279, 0.3721],
        [0.5853, 0.4147],
        [0.5788, 0.4212],
        [0.4886, 0.5114],
[2K        [0.4914, 0.5086]], device='cuda:0')â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”[0m 197/203 [2m0:01:16 â€¢ 0:00:03[0m [2;4m2.62it/s[0m  
[2KAttention weights: tensor([[0.5253, 0.4747],â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m 198/203 [2m0:01:16 â€¢ 0:00:02[0m [2;4m2.62it/s[0m  4m2.62it/s[0m  
        [0.5160, 0.4840],
        [0.5181, 0.4819],
        [0.5239, 0.4761],
        [0.5265, 0.4735],
        [0.5286, 0.4714],
        [0.5259, 0.4741],
        [0.5227, 0.4773],
        [0.5198, 0.4802],
[2K        [0.5261, 0.4739]], device='cuda:0', grad_fn=<SoftmaxBackward0>)37mâ•º[0m 198/203 [2m0:01:16 â€¢ 0:00:02[0m [2;4m2.62it/s[0m  
[2KClass label: SoccerPenaltyâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m 198/203 [2m0:01:16 â€¢ 0:00:02[0m [2;4m2.62it/s[0m  
[2KAttention weights: tensor([[0.6091, 0.3909]], device='cuda:0', grad_fn=<SoftmaxBackward0>)2m0:01:16 â€¢ 0:00:02[0m [2;4m2.62it/s[0m  
[2KStep 0 - TTA Loss: 1.5378â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m 198/203 [2m0:01:16 â€¢ 0:00:02[0m [2;4m2.62it/s[0m  
[2KAttention weights: tensor([[0.6194, 0.3806]], device='cuda:0', grad_fn=<SoftmaxBackward0>)2m0:01:16 â€¢ 0:00:02[0m [2;4m2.62it/s[0m  
[2KAttention weights: tensor([[0.6377, 0.3623]], device='cuda:0', grad_fn=<SoftmaxBackward0>)2m0:01:16 â€¢ 0:00:02[0m [2;4m2.62it/s[0m  
[2KAttention weights: tensor([[0.6465, 0.3535]], device='cuda:0', grad_fn=<SoftmaxBackward0>)2m0:01:16 â€¢ 0:00:02[0m [2;4m2.62it/s[0m  
[2KAttention weights: tensor([[0.6559, 0.3441]], device='cuda:0', grad_fn=<SoftmaxBackward0>)2m0:01:16 â€¢ 0:00:02[0m [2;4m2.62it/s[0m  
[2KAttention weights: tensor([[0.6693, 0.3307]], device='cuda:0', grad_fn=<SoftmaxBackward0>)2m0:01:16 â€¢ 0:00:02[0m [2;4m2.62it/s[0m  
[2KAttention weights: tensor([[0.6825, 0.3175]], device='cuda:0', grad_fn=<SoftmaxBackward0>)2m0:01:16 â€¢ 0:00:02[0m [2;4m2.62it/s[0m  
[2KAttention weights: tensor([[0.6931, 0.3069]], device='cuda:0', grad_fn=<SoftmaxBackward0>)2m0:01:16 â€¢ 0:00:02[0m [2;4m2.62it/s[0m  
[2KAttention weights: tensor([[0.6992, 0.3008]], device='cuda:0', grad_fn=<SoftmaxBackward0>)2m0:01:16 â€¢ 0:00:02[0m [2;4m2.62it/s[0m  
[2KAttention weights: tensor([[0.7022, 0.2978]], device='cuda:0', grad_fn=<SoftmaxBackward0>)2m0:01:16 â€¢ 0:00:02[0m [2;4m2.62it/s[0m  
[2KAttention weights: tensor([[0.5262, 0.4738]], device='cuda:0')m[38;5;237mâ•º[0m 198/203 [2m0:01:16 â€¢ 0:00:02[0m [2;4m2.62it/s[0m  
[2KAttention weights: tensor([[0.5769, 0.4231],â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m 198/203 [2m0:01:16 â€¢ 0:00:02[0m [2;4m2.62it/s[0m  
        [0.4613, 0.5387],
        [0.4834, 0.5166],
        [0.5938, 0.4062],
        [0.5426, 0.4574],
        [0.6801, 0.3199],
        [0.6325, 0.3675],
        [0.7032, 0.2968],
        [0.5182, 0.4818],
[2K        [0.5412, 0.4588]], device='cuda:0')â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m 198/203 [2m0:01:16 â€¢ 0:00:02[0m [2;4m2.62it/s[0m  
[2KAttention weights: tensor([[0.5254, 0.4746],â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m 199/203 [2m0:01:16 â€¢ 0:00:02[0m [2;4m2.62it/s[0m  
        [0.5160, 0.4840],
        [0.5182, 0.4818],
        [0.5239, 0.4761],
        [0.5265, 0.4735],
        [0.5287, 0.4713],
        [0.5260, 0.4740],
        [0.5228, 0.4772],
        [0.5199, 0.4801],
[2K        [0.5261, 0.4739]], device='cuda:0', grad_fn=<SoftmaxBackward0>)37mâ•º[0m 199/203 [2m0:01:16 â€¢ 0:00:02[0m [2;4m2.62it/s[0m  
[2KClass label: PoleVaultâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m 199/203 [2m0:01:16 â€¢ 0:00:02[0m [2;4m2.62it/s[0m  
[2KAttention weights: tensor([[0.6430, 0.3570]], device='cuda:0', grad_fn=<SoftmaxBackward0>)2m0:01:16 â€¢ 0:00:02[0m [2;4m2.62it/s[0m  
[2KStep 0 - TTA Loss: 1.2510â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m 199/203 [2m0:01:16 â€¢ 0:00:02[0m [2;4m2.62it/s[0m  
[2KAttention weights: tensor([[0.6430, 0.3570]], device='cuda:0', grad_fn=<SoftmaxBackward0>)2m0:01:16 â€¢ 0:00:02[0m [2;4m2.62it/s[0m  
[2KAttention weights: tensor([[0.6431, 0.3569]], device='cuda:0', grad_fn=<SoftmaxBackward0>)2m0:01:16 â€¢ 0:00:02[0m [2;4m2.62it/s[0m  
[2KAttention weights: tensor([[0.6433, 0.3567]], device='cuda:0', grad_fn=<SoftmaxBackward0>)2m0:01:16 â€¢ 0:00:02[0m [2;4m2.62it/s[0m  
[2KAttention weights: tensor([[0.6446, 0.3554]], device='cuda:0', grad_fn=<SoftmaxBackward0>)2m0:01:16 â€¢ 0:00:02[0m [2;4m2.62it/s[0m  
[2KAttention weights: tensor([[0.6472, 0.3528]], device='cuda:0', grad_fn=<SoftmaxBackward0>)2m0:01:16 â€¢ 0:00:02[0m [2;4m2.62it/s[0m  
[2KAttention weights: tensor([[0.6517, 0.3483]], device='cuda:0', grad_fn=<SoftmaxBackward0>)2m0:01:16 â€¢ 0:00:02[0m [2;4m2.62it/s[0m  
[2KAttention weights: tensor([[0.6600, 0.3400]], device='cuda:0', grad_fn=<SoftmaxBackward0>)2m0:01:16 â€¢ 0:00:02[0m [2;4m2.62it/s[0m  
[2KAttention weights: tensor([[0.6713, 0.3287]], device='cuda:0', grad_fn=<SoftmaxBackward0>)2m0:01:16 â€¢ 0:00:02[0m [2;4m2.62it/s[0m  
[2KAttention weights: tensor([[0.6795, 0.3205]], device='cuda:0', grad_fn=<SoftmaxBackward0>)2m0:01:16 â€¢ 0:00:02[0m [2;4m2.62it/s[0m  
[2KAttention weights: tensor([[0.5281, 0.4719]], device='cuda:0')m[38;5;237mâ•º[0m 199/203 [2m0:01:16 â€¢ 0:00:02[0m [2;4m2.62it/s[0m  
[2KAttention weights: tensor([[0.6085, 0.3915],â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m 199/203 [2m0:01:16 â€¢ 0:00:02[0m [2;4m2.62it/s[0m  
        [0.4542, 0.5458],
        [0.5031, 0.4969],
        [0.6228, 0.3772],
        [0.6070, 0.3930],
        [0.7240, 0.2760],
        [0.6851, 0.3149],
        [0.6951, 0.3049],
        [0.5382, 0.4618],
[2K        [0.6066, 0.3934]], device='cuda:0')â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m 199/203 [2m0:01:16 â€¢ 0:00:02[0m [2;4m2.62it/s[0m  
[2KAttention weights: tensor([[0.5254, 0.4746],â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m 200/203 [2m0:01:17 â€¢ 0:00:02[0m [2;4m2.62it/s[0m  
        [0.5160, 0.4840],
        [0.5182, 0.4818],
        [0.5239, 0.4761],
        [0.5265, 0.4735],
        [0.5287, 0.4713],
        [0.5260, 0.4740],
        [0.5228, 0.4772],
        [0.5199, 0.4801],
[2K        [0.5261, 0.4739]], device='cuda:0', grad_fn=<SoftmaxBackward0>)37mâ•º[0m 200/203 [2m0:01:17 â€¢ 0:00:02[0m [2;4m2.62it/s[0m  
[2KClass label: CleanAndJerkâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m 200/203 [2m0:01:17 â€¢ 0:00:02[0m [2;4m2.62it/s[0m  
[2KAttention weights: tensor([[0.4914, 0.5086]], device='cuda:0', grad_fn=<SoftmaxBackward0>)2m0:01:17 â€¢ 0:00:02[0m [2;4m2.62it/s[0m  
[2KStep 0 - TTA Loss: 0.8311â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m 200/203 [2m0:01:17 â€¢ 0:00:02[0m [2;4m2.62it/s[0m  
[2KAttention weights: tensor([[0.4922, 0.5078]], device='cuda:0', grad_fn=<SoftmaxBackward0>)2m0:01:17 â€¢ 0:00:02[0m [2;4m2.62it/s[0m  
[2KAttention weights: tensor([[0.4936, 0.5064]], device='cuda:0', grad_fn=<SoftmaxBackward0>)2m0:01:17 â€¢ 0:00:02[0m [2;4m2.62it/s[0m  
[2KAttention weights: tensor([[0.4937, 0.5063]], device='cuda:0', grad_fn=<SoftmaxBackward0>)2m0:01:17 â€¢ 0:00:02[0m [2;4m2.62it/s[0m  
[2KAttention weights: tensor([[0.4944, 0.5056]], device='cuda:0', grad_fn=<SoftmaxBackward0>)2m0:01:17 â€¢ 0:00:02[0m [2;4m2.62it/s[0m  
[2KAttention weights: tensor([[0.4946, 0.5054]], device='cuda:0', grad_fn=<SoftmaxBackward0>)2m0:01:17 â€¢ 0:00:02[0m [2;4m2.62it/s[0m  
[2KAttention weights: tensor([[0.4944, 0.5056]], device='cuda:0', grad_fn=<SoftmaxBackward0>)2m0:01:17 â€¢ 0:00:02[0m [2;4m2.62it/s[0m  
[2KAttention weights: tensor([[0.4945, 0.5055]], device='cuda:0', grad_fn=<SoftmaxBackward0>)2m0:01:17 â€¢ 0:00:02[0m [2;4m2.62it/s[0m  
[2KAttention weights: tensor([[0.4948, 0.5052]], device='cuda:0', grad_fn=<SoftmaxBackward0>)2m0:01:17 â€¢ 0:00:02[0m [2;4m2.62it/s[0m  
[2KAttention weights: tensor([[0.4947, 0.5053]], device='cuda:0', grad_fn=<SoftmaxBackward0>)2m0:01:17 â€¢ 0:00:02[0m [2;4m2.62it/s[0m  
[2KAttention weights: tensor([[0.5179, 0.4821]], device='cuda:0')m[38;5;237mâ•º[0m 200/203 [2m0:01:17 â€¢ 0:00:02[0m [2;4m2.62it/s[0m  
[2KAttention weights: tensor([[0.6052, 0.3948],â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m 200/203 [2m0:01:17 â€¢ 0:00:02[0m [2;4m2.62it/s[0m  
        [0.4525, 0.5475],
        [0.4947, 0.5053],
        [0.6076, 0.3924],
        [0.5922, 0.4078],
        [0.7068, 0.2932],
        [0.6641, 0.3359],
        [0.6649, 0.3351],
        [0.5290, 0.4710],
[2K        [0.5953, 0.4047]], device='cuda:0')â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m 200/203 [2m0:01:17 â€¢ 0:00:02[0m [2;4m2.62it/s[0m  
[2KAttention weights: tensor([[0.5254, 0.4746],â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m 201/203 [2m0:01:17 â€¢ 0:00:01[0m [2;4m2.62it/s[0m  
        [0.5160, 0.4840],
        [0.5182, 0.4818],
        [0.5239, 0.4761],
        [0.5265, 0.4735],
        [0.5287, 0.4713],
        [0.5260, 0.4740],
        [0.5229, 0.4771],
        [0.5199, 0.4801],
[2K        [0.5261, 0.4739]], device='cuda:0', grad_fn=<SoftmaxBackward0>)8;6;224mâ•¸[0m 201/203 [2m0:01:17 â€¢ 0:00:01[0m [2;4m2.62it/s[0m  
[2KClass label: CleanAndJerkâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m 201/203 [2m0:01:17 â€¢ 0:00:01[0m [2;4m2.62it/s[0m  
[2KAttention weights: tensor([[0.5015, 0.4985]], device='cuda:0', grad_fn=<SoftmaxBackward0>)03 [2m0:01:17 â€¢ 0:00:01[0m [2;4m2.62it/s[0m  
[2KStep 0 - TTA Loss: 0.8026â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m 201/203 [2m0:01:17 â€¢ 0:00:01[0m [2;4m2.62it/s[0m  
[2KAttention weights: tensor([[0.5015, 0.4985]], device='cuda:0', grad_fn=<SoftmaxBackward0>)03 [2m0:01:17 â€¢ 0:00:01[0m [2;4m2.62it/s[0m  
[2KAttention weights: tensor([[0.5015, 0.4985]], device='cuda:0', grad_fn=<SoftmaxBackward0>)03 [2m0:01:17 â€¢ 0:00:01[0m [2;4m2.62it/s[0m  
[2KAttention weights: tensor([[0.5015, 0.4985]], device='cuda:0', grad_fn=<SoftmaxBackward0>)03 [2m0:01:17 â€¢ 0:00:01[0m [2;4m2.62it/s[0m  
[2KAttention weights: tensor([[0.5015, 0.4985]], device='cuda:0', grad_fn=<SoftmaxBackward0>)03 [2m0:01:17 â€¢ 0:00:01[0m [2;4m2.62it/s[0m  
[2KAttention weights: tensor([[0.5014, 0.4986]], device='cuda:0', grad_fn=<SoftmaxBackward0>)03 [2m0:01:17 â€¢ 0:00:01[0m [2;4m2.62it/s[0m  
[2KAttention weights: tensor([[0.5014, 0.4986]], device='cuda:0', grad_fn=<SoftmaxBackward0>)03 [2m0:01:17 â€¢ 0:00:01[0m [2;4m2.62it/s[0m  
[2KAttention weights: tensor([[0.5015, 0.4985]], device='cuda:0', grad_fn=<SoftmaxBackward0>)03 [2m0:01:17 â€¢ 0:00:01[0m [2;4m2.62it/s[0m  
[2KAttention weights: tensor([[0.5016, 0.4984]], device='cuda:0', grad_fn=<SoftmaxBackward0>)03 [2m0:01:17 â€¢ 0:00:01[0m [2;4m2.62it/s[0m  
[2KAttention weights: tensor([[0.5016, 0.4984]], device='cuda:0', grad_fn=<SoftmaxBackward0>)03 [2m0:01:17 â€¢ 0:00:01[0m [2;4m2.62it/s[0m  
[2KAttention weights: tensor([[0.5182, 0.4818]], device='cuda:0')m[38;2;98;6;224mâ•¸[0m 201/203 [2m0:01:17 â€¢ 0:00:01[0m [2;4m2.62it/s[0m  
[2KAttention weights: tensor([[0.6088, 0.3912],â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m 201/203 [2m0:01:17 â€¢ 0:00:01[0m [2;4m2.62it/s[0m  
        [0.4481, 0.5519],
        [0.5011, 0.4989],
        [0.6099, 0.3901],
        [0.5870, 0.4130],
        [0.6946, 0.3054],
        [0.6515, 0.3485],
        [0.6219, 0.3781],
        [0.5206, 0.4794],
[2K        [0.5917, 0.4083]], device='cuda:0')â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m 201/203 [2m0:01:17 â€¢ 0:00:01[0m [2;4m2.62it/s[0m  
[2KAttention weights: tensor([[0.5254, 0.4746],â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m 202/203 [2m0:01:18 â€¢ 0:00:01[0m [2;4m2.61it/s[0m  
        [0.5160, 0.4840],
        [0.5182, 0.4818],
        [0.5239, 0.4761],
        [0.5265, 0.4735],
        [0.5287, 0.4713],
        [0.5260, 0.4740],
        [0.5229, 0.4771],
        [0.5199, 0.4801],
[2K        [0.5261, 0.4739]], device='cuda:0', grad_fn=<SoftmaxBackward0>)8;6;224mâ•¸[0m 202/203 [2m0:01:18 â€¢ 0:00:01[0m [2;4m2.61it/s[0m  
[2KClass label: HammerThrowâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m 202/203 [2m0:01:18 â€¢ 0:00:01[0m [2;4m2.61it/s[0m  
[2KAttention weights: tensor([[0.5792, 0.4208]], device='cuda:0', grad_fn=<SoftmaxBackward0>)03 [2m0:01:18 â€¢ 0:00:01[0m [2;4m2.61it/s[0m  
[2KStep 0 - TTA Loss: 1.5684â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m 202/203 [2m0:01:18 â€¢ 0:00:01[0m [2;4m2.61it/s[0m  
[2KAttention weights: tensor([[0.5772, 0.4228]], device='cuda:0', grad_fn=<SoftmaxBackward0>)03 [2m0:01:18 â€¢ 0:00:01[0m [2;4m2.61it/s[0m  
[2KAttention weights: tensor([[0.5757, 0.4243]], device='cuda:0', grad_fn=<SoftmaxBackward0>)03 [2m0:01:18 â€¢ 0:00:01[0m [2;4m2.61it/s[0m  
[2KAttention weights: tensor([[0.5780, 0.4220]], device='cuda:0', grad_fn=<SoftmaxBackward0>)03 [2m0:01:18 â€¢ 0:00:01[0m [2;4m2.61it/s[0m  
[2KAttention weights: tensor([[0.5806, 0.4194]], device='cuda:0', grad_fn=<SoftmaxBackward0>)03 [2m0:01:18 â€¢ 0:00:01[0m [2;4m2.61it/s[0m  
[2KAttention weights: tensor([[0.5845, 0.4155]], device='cuda:0', grad_fn=<SoftmaxBackward0>)03 [2m0:01:18 â€¢ 0:00:01[0m [2;4m2.61it/s[0m  
[2KAttention weights: tensor([[0.5877, 0.4123]], device='cuda:0', grad_fn=<SoftmaxBackward0>)03 [2m0:01:18 â€¢ 0:00:01[0m [2;4m2.61it/s[0m  
[2KAttention weights: tensor([[0.5926, 0.4074]], device='cuda:0', grad_fn=<SoftmaxBackward0>)03 [2m0:01:18 â€¢ 0:00:01[0m [2;4m2.61it/s[0m  
[2KAttention weights: tensor([[0.5970, 0.4030]], device='cuda:0', grad_fn=<SoftmaxBackward0>)03 [2m0:01:18 â€¢ 0:00:01[0m [2;4m2.61it/s[0m  
[2KAttention weights: tensor([[0.5983, 0.4017]], device='cuda:0', grad_fn=<SoftmaxBackward0>)03 [2m0:01:18 â€¢ 0:00:01[0m [2;4m2.61it/s[0m  
[2KAttention weights: tensor([[0.5274, 0.4726]], device='cuda:0')m[38;2;98;6;224mâ•¸[0m 202/203 [2m0:01:18 â€¢ 0:00:01[0m [2;4m2.61it/s[0m  
[2KAttention weights: tensor([[0.6108, 0.3892],â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m 202/203 [2m0:01:18 â€¢ 0:00:01[0m [2;4m2.61it/s[0m  
        [0.4473, 0.5527],
        [0.4986, 0.5014],
        [0.6143, 0.3857],
        [0.5989, 0.4011],
        [0.7053, 0.2947],
        [0.6594, 0.3406],
        [0.6231, 0.3769],
        [0.5270, 0.4730],
[2K        [0.6021, 0.3979]], device='cuda:0')â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m 202/203 [2m0:01:18 â€¢ 0:00:01[0m [2;4m2.61it/s[0m  
[2K                   video-id  t-start  t-end     labelâ”â”â”â”â”â”â”â”â”â”â”[0m 203/203 [2m0:01:18 â€¢ 0:00:00[0m [2;4m2.61it/s[0m  4m2.61it/s[0m  
0  video_validation_0000365     18.1   24.3  HighJump
1  video_validation_0000365     29.6   33.3  HighJump
2  video_validation_0000365     69.7   77.3  HighJump
3  video_validation_0000365     80.8   84.3  HighJump
[2K4  video_validation_0000365    110.4  116.2  HighJumpâ”â”â”â”â”â”â”[0m 203/203 [2m0:01:18 â€¢ 0:00:00[0m [2;4m2.61it/s[0m  
[2K                   video-id    t-start      t-end      score     label03 [2m0:01:18 â€¢ 0:00:00[0m [2;4m2.61it/s[0m  
0  video_validation_0000365   1.666667   4.700000  1.4500381  HighJump
1  video_validation_0000365   6.666667   9.166667   1.298864  HighJump
2  video_validation_0000365  11.133333  12.966667  1.0950488  HighJump
3  video_validation_0000365  13.933333  17.400000  1.3384109  HighJump
[2K4  video_validation_0000365  18.966667  24.433333  1.2516369  HighJump03 [2m0:01:18 â€¢ 0:00:00[0m [2;4m2.61it/s[0m  
[2KGround truth labels:  ['HighJump' 'PoleVault' 'TennisSwing' 'GolfSwing' 'HammerThrow'â€¢ 0:00:00[0m [2;4m2.61it/s[0m  
[2K 'Billiards' 'BaseballPitch' 'CleanAndJerk' 'ThrowDiscus' 'SoccerPenalty'][2m0:01:18 â€¢ 0:00:00[0m [2;4m2.61it/s[0m  
[2KPredicted labels:  ['HighJump' 'TennisSwing' 'GolfSwing' 'HammerThrow' 'Billiards'18 â€¢ 0:00:00[0m [2;4m2.61it/s[0m  
[2K 'BaseballPitch' 'CleanAndJerk' 'ThrowDiscus' 'SoccerPenalty' 'PoleVault'][2m0:01:18 â€¢ 0:00:00[0m [2;4m2.61it/s[0m  
[2King [38;2;98;6;224mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 203/203 [2m0:01:18 â€¢ 0:00:00[0m [2;4m2.61it/s[0m  
[2King [38;2;98;6;224mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 203/203 [2m0:01:18 â€¢ 0:00:00[0m [2;4m2.61it/s[0m  
[2KBaseballPitch [1.7, 0.1, 0.1, 0.1, 0.0]â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 203/203 [2m0:01:18 â€¢ 0:00:00[0m [2;4m2.61it/s[0m  
[2King [38;2;98;6;224mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 203/203 [2m0:01:18 â€¢ 0:00:00[0m [2;4m2.61it/s[0m  
[2King [38;2;98;6;224mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 203/203 [2m0:01:18 â€¢ 0:00:00[0m [2;4m2.61it/s[0m  
[2KBilliards [0.2, 0.2, 0.1, 0.0, 0.0]â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 203/203 [2m0:01:18 â€¢ 0:00:00[0m [2;4m2.61it/s[0m  
[2King [38;2;98;6;224mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 203/203 [2m0:01:18 â€¢ 0:00:00[0m [2;4m2.61it/s[0m  
[2King [38;2;98;6;224mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 203/203 [2m0:01:18 â€¢ 0:00:00[0m [2;4m2.61it/s[0m  
[2KCleanAndJerk [3.5, 2.3, 1.8, 1.0, 0.1]â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 203/203 [2m0:01:18 â€¢ 0:00:00[0m [2;4m2.61it/s[0m  
[2King [38;2;98;6;224mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 203/203 [2m0:01:18 â€¢ 0:00:00[0m [2;4m2.61it/s[0m  
[2King [38;2;98;6;224mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 203/203 [2m0:01:18 â€¢ 0:00:00[0m [2;4m2.61it/s[0m  
[2KGolfSwing [0.2, 0.1, 0.1, 0.1, 0.0]â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 203/203 [2m0:01:18 â€¢ 0:00:00[0m [2;4m2.61it/s[0m  
[2King [38;2;98;6;224mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 203/203 [2m0:01:18 â€¢ 0:00:00[0m [2;4m2.61it/s[0m  
[2King [38;2;98;6;224mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 203/203 [2m0:01:18 â€¢ 0:00:00[0m [2;4m2.61it/s[0m  
[2KHammerThrow [0.2, 0.1, 0.0, 0.0, 0.0]â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 203/203 [2m0:01:18 â€¢ 0:00:00[0m [2;4m2.61it/s[0m  
[2King [38;2;98;6;224mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 203/203 [2m0:01:18 â€¢ 0:00:00[0m [2;4m2.61it/s[0m  
[2King [38;2;98;6;224mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 203/203 [2m0:01:18 â€¢ 0:00:00[0m [2;4m2.61it/s[0m  
[2KHighJump [0.3, 0.0, 0.0, 0.0, 0.0]â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 203/203 [2m0:01:18 â€¢ 0:00:00[0m [2;4m2.61it/s[0m  
[2King [38;2;98;6;224mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 203/203 [2m0:01:18 â€¢ 0:00:00[0m [2;4m2.61it/s[0m  
[2King [38;2;98;6;224mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 203/203 [2m0:01:18 â€¢ 0:00:00[0m [2;4m2.61it/s[0m  
[2KPoleVault [0.6, 0.2, 0.2, 0.2, 0.2]â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 203/203 [2m0:01:18 â€¢ 0:00:00[0m [2;4m2.61it/s[0m  
[2King [38;2;98;6;224mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 203/203 [2m0:01:18 â€¢ 0:00:00[0m [2;4m2.61it/s[0m  
[2King [38;2;98;6;224mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 203/203 [2m0:01:18 â€¢ 0:00:00[0m [2;4m2.61it/s[0m  
[2KSoccerPenalty [0.6, 0.0, 0.0, 0.0, 0.0]â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 203/203 [2m0:01:18 â€¢ 0:00:00[0m [2;4m2.61it/s[0m  
[2King [38;2;98;6;224mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 203/203 [2m0:01:18 â€¢ 0:00:00[0m [2;4m2.61it/s[0m  
[2King [38;2;98;6;224mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 203/203 [2m0:01:18 â€¢ 0:00:00[0m [2;4m2.61it/s[0m  
[2KTennisSwing [0.2, 0.1, 0.0, 0.0, 0.0]â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 203/203 [2m0:01:18 â€¢ 0:00:00[0m [2;4m2.61it/s[0m  
[2King [38;2;98;6;224mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 203/203 [2m0:01:18 â€¢ 0:00:00[0m [2;4m2.61it/s[0m  
[2King [38;2;98;6;224mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 203/203 [2m0:01:18 â€¢ 0:00:00[0m [2;4m2.61it/s[0m  
[2KThrowDiscus [0.0, 0.0, 0.0, 0.0, 0.0]â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 203/203 [2m0:01:18 â€¢ 0:00:00[0m [2;4m2.61it/s[0m  
[2King [38;2;98;6;224mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 203/203 [2m0:01:18 â€¢ 0:00:00[0m [2;4m2.61it/s[0m  
[2King [38;2;98;6;224mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 203/203 [2m0:01:18 â€¢ 0:00:00[0m [2;4m2.61it/s[0m  
[2K\begin{tabular}{lrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrr}
\hline
 Class         &   AP@0% &    AP@0% &   AP@0% &   AP@0% &   AP@0% \\
\hline
 BaseballPitch &     1.7 & 0.1      &     0.1 &     0.1 &     0   \\
 Billiards     &     0.2 & 0.2      &     0.1 &     0   &     0   \\
 CleanAndJerk  &     3.5 & 2.3      &     1.8 &     1   &     0.1 \\
 GolfSwing     &     0.2 & 0.1      &     0.1 &     0.1 &     0   \\
 HammerThrow   &     0.2 & 0.1      &     0   &     0   &     0   \\
 HighJump      &     0.3 & 0        &     0   &     0   &     0   \\
 PoleVault     &     0.6 & 0.2      &     0.2 &     0.2 &     0.2 \\
 SoccerPenalty &     0.6 & 0        &     0   &     0   &     0   \\
 TennisSwing   &     0.2 & 0.1      &     0   &     0   &     0   \\
 ThrowDiscus   &     0   & 0        &     0   &     0   &     0   \\
 IoU           &     0   & 0.307359 &     0   &     0   &     0   \\
\hline
[2K\end{tabular};6;224mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 203/203 [2m0:01:18 â€¢ 0:00:00[0m [2;4m2.61it/s[0m  
[2K[0.75 0.31 0.23 0.14 0.03]â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 203/203 [2m0:01:18 â€¢ 0:00:00[0m [2;4m2.61it/s[0m  
[2KAverage TIOU:  0.0032915687315475993â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 203/203 [2m0:01:18 â€¢ 0:00:00[0m [2;4m2.61it/s[0m  
[2Kpreds_tensor: torch.Size([203, 10])â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 203/203 [2m0:01:18 â€¢ 0:00:00[0m [2;4m2.61it/s[0m  
[2KTop-1 accuracy: 0.8029556650246306â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 203/203 [2m0:01:18 â€¢ 0:00:00[0m [2;4m2.61it/s[0m  
[2Kpreds_tensor: torch.Size([203, 10])â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 203/203 [2m0:01:18 â€¢ 0:00:00[0m [2;4m2.61it/s[0m  
[2KTop-3 accuracy: 0.9507389162561576â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 203/203 [2m0:01:18 â€¢ 0:00:00[0m [2;4m2.61it/s[0m  
[2Kpreds_tensor: torch.Size([203, 10])â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 203/203 [2m0:01:18 â€¢ 0:00:00[0m [2;4m2.61it/s[0m  
[2KTop-5 accuracy: 1.0mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 203/203 [2m0:01:18 â€¢ 0:00:00[0m [2;4m2.61it/s[0m  
[2Kâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“â”â”â”[0m 203/203 [2m0:01:18 â€¢ 0:00:00[0m [2;4m2.61it/s[0m  
â”ƒ[1m [0m[1m       Test metric       [0m[1m [0mâ”ƒ[1m [0m[1m      DataLoader 0       [0m[1m [0mâ”ƒ
â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©
â”‚[36m [0m[36m          AP_0           [0m[36m [0mâ”‚[35m [0m[35m          0.75           [0m[35m [0mâ”‚
â”‚[36m [0m[36m         avg_AP          [0m[36m [0mâ”‚[35m [0m[35m   0.2919999957084656    [0m[35m [0mâ”‚
â”‚[36m [0m[36m  label top-1 accuracy   [0m[36m [0mâ”‚[35m [0m[35m    0.802955687046051    [0m[35m [0mâ”‚
â”‚[36m [0m[36m  label top-3 accuracy   [0m[36m [0mâ”‚[35m [0m[35m   0.9507389068603516    [0m[35m [0mâ”‚
â”‚[36m [0m[36m  label top-5 accuracy   [0m[36m [0mâ”‚[35m [0m[35m           1.0           [0m[35m [0mâ”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
[2KTesting [38;2;98;6;224mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 203/203 [2m0:01:18 â€¢ 0:00:00[0m [2;4m2.61it/s[0m
[?25h[[36m2025-02-14 11:00:08,936[0m][[34m__main__[0m][[32mINFO[0m] - Best ckpt path: None[0m
[[36m2025-02-14 11:00:08,937[0m][[34msrc.utils.utils[0m][[32mINFO[0m] - Output dir: /home/def/fewshot/logs/train/runs/2025-02-14_10-58-37[0m
[[36m2025-02-14 11:00:08,937[0m][[34msrc.utils.utils[0m][[32mINFO[0m] - Closing wandb![0m
