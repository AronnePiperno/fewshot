[[36m2025-02-14 01:09:22,469[0m][[34m__main__[0m][[32mINFO[0m] - Starting training![0m
You are using a CUDA device ('NVIDIA GeForce RTX 4070 SUPER') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision
No of videos in train is 214
Loading train Video Information ...
No of class 10
No of videos in validation is 203
Loading validation Video Information ...
No of class 10
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”“
â”ƒ[1;35m [0m[1;35m   [0m[1;35m [0mâ”ƒ[1;35m [0m[1;35mName                                                   [0m[1;35m [0mâ”ƒ[1;35m [0m[1;35mType                           [0m[1;35m [0mâ”ƒ[1;35m [0m[1;35mParams[0m[1;35m [0mâ”ƒ[1;35m [0m[1;35mMode [0m[1;35m [0mâ”ƒ
â”¡â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”©
â”‚[2m [0m[2m0  [0m[2m [0mâ”‚ net                                                     â”‚ T3ALNet                         â”‚  639 M â”‚ train â”‚
â”‚[2m [0m[2m1  [0m[2m [0mâ”‚ net.model                                               â”‚ CoCa                            â”‚  638 M â”‚ train â”‚
â”‚[2m [0m[2m2  [0m[2m [0mâ”‚ net.model.text                                          â”‚ TextTransformer                 â”‚  123 M â”‚ train â”‚
â”‚[2m [0m[2m3  [0m[2m [0mâ”‚ net.model.text.token_embedding                          â”‚ Embedding                       â”‚ 37.9 M â”‚ train â”‚
â”‚[2m [0m[2m4  [0m[2m [0mâ”‚ net.model.text.transformer                              â”‚ Transformer                     â”‚ 85.1 M â”‚ train â”‚
â”‚[2m [0m[2m5  [0m[2m [0mâ”‚ net.model.text.transformer.resblocks                    â”‚ ModuleList                      â”‚ 85.1 M â”‚ train â”‚
â”‚[2m [0m[2m6  [0m[2m [0mâ”‚ net.model.text.transformer.resblocks.0                  â”‚ ResidualAttentionBlock          â”‚  7.1 M â”‚ train â”‚
â”‚[2m [0m[2m7  [0m[2m [0mâ”‚ net.model.text.transformer.resblocks.0.ln_1             â”‚ LayerNorm                       â”‚  1.5 K â”‚ train â”‚
â”‚[2m [0m[2m8  [0m[2m [0mâ”‚ net.model.text.transformer.resblocks.0.attn             â”‚ MultiheadAttention              â”‚  2.4 M â”‚ train â”‚
â”‚[2m [0m[2m9  [0m[2m [0mâ”‚ net.model.text.transformer.resblocks.0.attn.out_proj    â”‚ NonDynamicallyQuantizableLinear â”‚  590 K â”‚ train â”‚
â”‚[2m [0m[2m10 [0m[2m [0mâ”‚ net.model.text.transformer.resblocks.0.ls_1             â”‚ Identity                        â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m11 [0m[2m [0mâ”‚ net.model.text.transformer.resblocks.0.ln_2             â”‚ LayerNorm                       â”‚  1.5 K â”‚ train â”‚
â”‚[2m [0m[2m12 [0m[2m [0mâ”‚ net.model.text.transformer.resblocks.0.mlp              â”‚ Sequential                      â”‚  4.7 M â”‚ train â”‚
â”‚[2m [0m[2m13 [0m[2m [0mâ”‚ net.model.text.transformer.resblocks.0.mlp.c_fc         â”‚ Linear                          â”‚  2.4 M â”‚ train â”‚
â”‚[2m [0m[2m14 [0m[2m [0mâ”‚ net.model.text.transformer.resblocks.0.mlp.gelu         â”‚ GELU                            â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m15 [0m[2m [0mâ”‚ net.model.text.transformer.resblocks.0.mlp.c_proj       â”‚ Linear                          â”‚  2.4 M â”‚ train â”‚
â”‚[2m [0m[2m16 [0m[2m [0mâ”‚ net.model.text.transformer.resblocks.0.ls_2             â”‚ Identity                        â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m17 [0m[2m [0mâ”‚ net.model.text.transformer.resblocks.1                  â”‚ ResidualAttentionBlock          â”‚  7.1 M â”‚ train â”‚
â”‚[2m [0m[2m18 [0m[2m [0mâ”‚ net.model.text.transformer.resblocks.1.ln_1             â”‚ LayerNorm                       â”‚  1.5 K â”‚ train â”‚
â”‚[2m [0m[2m19 [0m[2m [0mâ”‚ net.model.text.transformer.resblocks.1.attn             â”‚ MultiheadAttention              â”‚  2.4 M â”‚ train â”‚
â”‚[2m [0m[2m20 [0m[2m [0mâ”‚ net.model.text.transformer.resblocks.1.attn.out_proj    â”‚ NonDynamicallyQuantizableLinear â”‚  590 K â”‚ train â”‚
â”‚[2m [0m[2m21 [0m[2m [0mâ”‚ net.model.text.transformer.resblocks.1.ls_1             â”‚ Identity                        â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m22 [0m[2m [0mâ”‚ net.model.text.transformer.resblocks.1.ln_2             â”‚ LayerNorm                       â”‚  1.5 K â”‚ train â”‚
â”‚[2m [0m[2m23 [0m[2m [0mâ”‚ net.model.text.transformer.resblocks.1.mlp              â”‚ Sequential                      â”‚  4.7 M â”‚ train â”‚
â”‚[2m [0m[2m24 [0m[2m [0mâ”‚ net.model.text.transformer.resblocks.1.mlp.c_fc         â”‚ Linear                          â”‚  2.4 M â”‚ train â”‚
â”‚[2m [0m[2m25 [0m[2m [0mâ”‚ net.model.text.transformer.resblocks.1.mlp.gelu         â”‚ GELU                            â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m26 [0m[2m [0mâ”‚ net.model.text.transformer.resblocks.1.mlp.c_proj       â”‚ Linear                          â”‚  2.4 M â”‚ train â”‚
â”‚[2m [0m[2m27 [0m[2m [0mâ”‚ net.model.text.transformer.resblocks.1.ls_2             â”‚ Identity                        â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m28 [0m[2m [0mâ”‚ net.model.text.transformer.resblocks.2                  â”‚ ResidualAttentionBlock          â”‚  7.1 M â”‚ train â”‚
â”‚[2m [0m[2m29 [0m[2m [0mâ”‚ net.model.text.transformer.resblocks.2.ln_1             â”‚ LayerNorm                       â”‚  1.5 K â”‚ train â”‚
â”‚[2m [0m[2m30 [0m[2m [0mâ”‚ net.model.text.transformer.resblocks.2.attn             â”‚ MultiheadAttention              â”‚  2.4 M â”‚ train â”‚
â”‚[2m [0m[2m31 [0m[2m [0mâ”‚ net.model.text.transformer.resblocks.2.attn.out_proj    â”‚ NonDynamicallyQuantizableLinear â”‚  590 K â”‚ train â”‚
â”‚[2m [0m[2m32 [0m[2m [0mâ”‚ net.model.text.transformer.resblocks.2.ls_1             â”‚ Identity                        â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m33 [0m[2m [0mâ”‚ net.model.text.transformer.resblocks.2.ln_2             â”‚ LayerNorm                       â”‚  1.5 K â”‚ train â”‚
â”‚[2m [0m[2m34 [0m[2m [0mâ”‚ net.model.text.transformer.resblocks.2.mlp              â”‚ Sequential                      â”‚  4.7 M â”‚ train â”‚
â”‚[2m [0m[2m35 [0m[2m [0mâ”‚ net.model.text.transformer.resblocks.2.mlp.c_fc         â”‚ Linear                          â”‚  2.4 M â”‚ train â”‚
â”‚[2m [0m[2m36 [0m[2m [0mâ”‚ net.model.text.transformer.resblocks.2.mlp.gelu         â”‚ GELU                            â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m37 [0m[2m [0mâ”‚ net.model.text.transformer.resblocks.2.mlp.c_proj       â”‚ Linear                          â”‚  2.4 M â”‚ train â”‚
â”‚[2m [0m[2m38 [0m[2m [0mâ”‚ net.model.text.transformer.resblocks.2.ls_2             â”‚ Identity                        â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m39 [0m[2m [0mâ”‚ net.model.text.transformer.resblocks.3                  â”‚ ResidualAttentionBlock          â”‚  7.1 M â”‚ train â”‚
â”‚[2m [0m[2m40 [0m[2m [0mâ”‚ net.model.text.transformer.resblocks.3.ln_1             â”‚ LayerNorm                       â”‚  1.5 K â”‚ train â”‚
â”‚[2m [0m[2m41 [0m[2m [0mâ”‚ net.model.text.transformer.resblocks.3.attn             â”‚ MultiheadAttention              â”‚  2.4 M â”‚ train â”‚
â”‚[2m [0m[2m42 [0m[2m [0mâ”‚ net.model.text.transformer.resblocks.3.attn.out_proj    â”‚ NonDynamicallyQuantizableLinear â”‚  590 K â”‚ train â”‚
â”‚[2m [0m[2m43 [0m[2m [0mâ”‚ net.model.text.transformer.resblocks.3.ls_1             â”‚ Identity                        â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m44 [0m[2m [0mâ”‚ net.model.text.transformer.resblocks.3.ln_2             â”‚ LayerNorm                       â”‚  1.5 K â”‚ train â”‚
â”‚[2m [0m[2m45 [0m[2m [0mâ”‚ net.model.text.transformer.resblocks.3.mlp              â”‚ Sequential                      â”‚  4.7 M â”‚ train â”‚
â”‚[2m [0m[2m46 [0m[2m [0mâ”‚ net.model.text.transformer.resblocks.3.mlp.c_fc         â”‚ Linear                          â”‚  2.4 M â”‚ train â”‚
â”‚[2m [0m[2m47 [0m[2m [0mâ”‚ net.model.text.transformer.resblocks.3.mlp.gelu         â”‚ GELU                            â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m48 [0m[2m [0mâ”‚ net.model.text.transformer.resblocks.3.mlp.c_proj       â”‚ Linear                          â”‚  2.4 M â”‚ train â”‚
â”‚[2m [0m[2m49 [0m[2m [0mâ”‚ net.model.text.transformer.resblocks.3.ls_2             â”‚ Identity                        â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m50 [0m[2m [0mâ”‚ net.model.text.transformer.resblocks.4                  â”‚ ResidualAttentionBlock          â”‚  7.1 M â”‚ train â”‚
â”‚[2m [0m[2m51 [0m[2m [0mâ”‚ net.model.text.transformer.resblocks.4.ln_1             â”‚ LayerNorm                       â”‚  1.5 K â”‚ train â”‚
â”‚[2m [0m[2m52 [0m[2m [0mâ”‚ net.model.text.transformer.resblocks.4.attn             â”‚ MultiheadAttention              â”‚  2.4 M â”‚ train â”‚
â”‚[2m [0m[2m53 [0m[2m [0mâ”‚ net.model.text.transformer.resblocks.4.attn.out_proj    â”‚ NonDynamicallyQuantizableLinear â”‚  590 K â”‚ train â”‚
â”‚[2m [0m[2m54 [0m[2m [0mâ”‚ net.model.text.transformer.resblocks.4.ls_1             â”‚ Identity                        â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m55 [0m[2m [0mâ”‚ net.model.text.transformer.resblocks.4.ln_2             â”‚ LayerNorm                       â”‚  1.5 K â”‚ train â”‚
â”‚[2m [0m[2m56 [0m[2m [0mâ”‚ net.model.text.transformer.resblocks.4.mlp              â”‚ Sequential                      â”‚  4.7 M â”‚ train â”‚
â”‚[2m [0m[2m57 [0m[2m [0mâ”‚ net.model.text.transformer.resblocks.4.mlp.c_fc         â”‚ Linear                          â”‚  2.4 M â”‚ train â”‚
â”‚[2m [0m[2m58 [0m[2m [0mâ”‚ net.model.text.transformer.resblocks.4.mlp.gelu         â”‚ GELU                            â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m59 [0m[2m [0mâ”‚ net.model.text.transformer.resblocks.4.mlp.c_proj       â”‚ Linear                          â”‚  2.4 M â”‚ train â”‚
â”‚[2m [0m[2m60 [0m[2m [0mâ”‚ net.model.text.transformer.resblocks.4.ls_2             â”‚ Identity                        â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m61 [0m[2m [0mâ”‚ net.model.text.transformer.resblocks.5                  â”‚ ResidualAttentionBlock          â”‚  7.1 M â”‚ train â”‚
â”‚[2m [0m[2m62 [0m[2m [0mâ”‚ net.model.text.transformer.resblocks.5.ln_1             â”‚ LayerNorm                       â”‚  1.5 K â”‚ train â”‚
â”‚[2m [0m[2m63 [0m[2m [0mâ”‚ net.model.text.transformer.resblocks.5.attn             â”‚ MultiheadAttention              â”‚  2.4 M â”‚ train â”‚
â”‚[2m [0m[2m64 [0m[2m [0mâ”‚ net.model.text.transformer.resblocks.5.attn.out_proj    â”‚ NonDynamicallyQuantizableLinear â”‚  590 K â”‚ train â”‚
â”‚[2m [0m[2m65 [0m[2m [0mâ”‚ net.model.text.transformer.resblocks.5.ls_1             â”‚ Identity                        â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m66 [0m[2m [0mâ”‚ net.model.text.transformer.resblocks.5.ln_2             â”‚ LayerNorm                       â”‚  1.5 K â”‚ train â”‚
â”‚[2m [0m[2m67 [0m[2m [0mâ”‚ net.model.text.transformer.resblocks.5.mlp              â”‚ Sequential                      â”‚  4.7 M â”‚ train â”‚
â”‚[2m [0m[2m68 [0m[2m [0mâ”‚ net.model.text.transformer.resblocks.5.mlp.c_fc         â”‚ Linear                          â”‚  2.4 M â”‚ train â”‚
â”‚[2m [0m[2m69 [0m[2m [0mâ”‚ net.model.text.transformer.resblocks.5.mlp.gelu         â”‚ GELU                            â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m70 [0m[2m [0mâ”‚ net.model.text.transformer.resblocks.5.mlp.c_proj       â”‚ Linear                          â”‚  2.4 M â”‚ train â”‚
â”‚[2m [0m[2m71 [0m[2m [0mâ”‚ net.model.text.transformer.resblocks.5.ls_2             â”‚ Identity                        â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m72 [0m[2m [0mâ”‚ net.model.text.transformer.resblocks.6                  â”‚ ResidualAttentionBlock          â”‚  7.1 M â”‚ train â”‚
â”‚[2m [0m[2m73 [0m[2m [0mâ”‚ net.model.text.transformer.resblocks.6.ln_1             â”‚ LayerNorm                       â”‚  1.5 K â”‚ train â”‚
â”‚[2m [0m[2m74 [0m[2m [0mâ”‚ net.model.text.transformer.resblocks.6.attn             â”‚ MultiheadAttention              â”‚  2.4 M â”‚ train â”‚
â”‚[2m [0m[2m75 [0m[2m [0mâ”‚ net.model.text.transformer.resblocks.6.attn.out_proj    â”‚ NonDynamicallyQuantizableLinear â”‚  590 K â”‚ train â”‚
â”‚[2m [0m[2m76 [0m[2m [0mâ”‚ net.model.text.transformer.resblocks.6.ls_1             â”‚ Identity                        â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m77 [0m[2m [0mâ”‚ net.model.text.transformer.resblocks.6.ln_2             â”‚ LayerNorm                       â”‚  1.5 K â”‚ train â”‚
â”‚[2m [0m[2m78 [0m[2m [0mâ”‚ net.model.text.transformer.resblocks.6.mlp              â”‚ Sequential                      â”‚  4.7 M â”‚ train â”‚
â”‚[2m [0m[2m79 [0m[2m [0mâ”‚ net.model.text.transformer.resblocks.6.mlp.c_fc         â”‚ Linear                          â”‚  2.4 M â”‚ train â”‚
â”‚[2m [0m[2m80 [0m[2m [0mâ”‚ net.model.text.transformer.resblocks.6.mlp.gelu         â”‚ GELU                            â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m81 [0m[2m [0mâ”‚ net.model.text.transformer.resblocks.6.mlp.c_proj       â”‚ Linear                          â”‚  2.4 M â”‚ train â”‚
â”‚[2m [0m[2m82 [0m[2m [0mâ”‚ net.model.text.transformer.resblocks.6.ls_2             â”‚ Identity                        â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m83 [0m[2m [0mâ”‚ net.model.text.transformer.resblocks.7                  â”‚ ResidualAttentionBlock          â”‚  7.1 M â”‚ train â”‚
â”‚[2m [0m[2m84 [0m[2m [0mâ”‚ net.model.text.transformer.resblocks.7.ln_1             â”‚ LayerNorm                       â”‚  1.5 K â”‚ train â”‚
â”‚[2m [0m[2m85 [0m[2m [0mâ”‚ net.model.text.transformer.resblocks.7.attn             â”‚ MultiheadAttention              â”‚  2.4 M â”‚ train â”‚
â”‚[2m [0m[2m86 [0m[2m [0mâ”‚ net.model.text.transformer.resblocks.7.attn.out_proj    â”‚ NonDynamicallyQuantizableLinear â”‚  590 K â”‚ train â”‚
â”‚[2m [0m[2m87 [0m[2m [0mâ”‚ net.model.text.transformer.resblocks.7.ls_1             â”‚ Identity                        â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m88 [0m[2m [0mâ”‚ net.model.text.transformer.resblocks.7.ln_2             â”‚ LayerNorm                       â”‚  1.5 K â”‚ train â”‚
â”‚[2m [0m[2m89 [0m[2m [0mâ”‚ net.model.text.transformer.resblocks.7.mlp              â”‚ Sequential                      â”‚  4.7 M â”‚ train â”‚
â”‚[2m [0m[2m90 [0m[2m [0mâ”‚ net.model.text.transformer.resblocks.7.mlp.c_fc         â”‚ Linear                          â”‚  2.4 M â”‚ train â”‚
â”‚[2m [0m[2m91 [0m[2m [0mâ”‚ net.model.text.transformer.resblocks.7.mlp.gelu         â”‚ GELU                            â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m92 [0m[2m [0mâ”‚ net.model.text.transformer.resblocks.7.mlp.c_proj       â”‚ Linear                          â”‚  2.4 M â”‚ train â”‚
â”‚[2m [0m[2m93 [0m[2m [0mâ”‚ net.model.text.transformer.resblocks.7.ls_2             â”‚ Identity                        â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m94 [0m[2m [0mâ”‚ net.model.text.transformer.resblocks.8                  â”‚ ResidualAttentionBlock          â”‚  7.1 M â”‚ train â”‚
â”‚[2m [0m[2m95 [0m[2m [0mâ”‚ net.model.text.transformer.resblocks.8.ln_1             â”‚ LayerNorm                       â”‚  1.5 K â”‚ train â”‚
â”‚[2m [0m[2m96 [0m[2m [0mâ”‚ net.model.text.transformer.resblocks.8.attn             â”‚ MultiheadAttention              â”‚  2.4 M â”‚ train â”‚
â”‚[2m [0m[2m97 [0m[2m [0mâ”‚ net.model.text.transformer.resblocks.8.attn.out_proj    â”‚ NonDynamicallyQuantizableLinear â”‚  590 K â”‚ train â”‚
â”‚[2m [0m[2m98 [0m[2m [0mâ”‚ net.model.text.transformer.resblocks.8.ls_1             â”‚ Identity                        â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m99 [0m[2m [0mâ”‚ net.model.text.transformer.resblocks.8.ln_2             â”‚ LayerNorm                       â”‚  1.5 K â”‚ train â”‚
â”‚[2m [0m[2m100[0m[2m [0mâ”‚ net.model.text.transformer.resblocks.8.mlp              â”‚ Sequential                      â”‚  4.7 M â”‚ train â”‚
â”‚[2m [0m[2m101[0m[2m [0mâ”‚ net.model.text.transformer.resblocks.8.mlp.c_fc         â”‚ Linear                          â”‚  2.4 M â”‚ train â”‚
â”‚[2m [0m[2m102[0m[2m [0mâ”‚ net.model.text.transformer.resblocks.8.mlp.gelu         â”‚ GELU                            â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m103[0m[2m [0mâ”‚ net.model.text.transformer.resblocks.8.mlp.c_proj       â”‚ Linear                          â”‚  2.4 M â”‚ train â”‚
â”‚[2m [0m[2m104[0m[2m [0mâ”‚ net.model.text.transformer.resblocks.8.ls_2             â”‚ Identity                        â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m105[0m[2m [0mâ”‚ net.model.text.transformer.resblocks.9                  â”‚ ResidualAttentionBlock          â”‚  7.1 M â”‚ train â”‚
â”‚[2m [0m[2m106[0m[2m [0mâ”‚ net.model.text.transformer.resblocks.9.ln_1             â”‚ LayerNorm                       â”‚  1.5 K â”‚ train â”‚
â”‚[2m [0m[2m107[0m[2m [0mâ”‚ net.model.text.transformer.resblocks.9.attn             â”‚ MultiheadAttention              â”‚  2.4 M â”‚ train â”‚
â”‚[2m [0m[2m108[0m[2m [0mâ”‚ net.model.text.transformer.resblocks.9.attn.out_proj    â”‚ NonDynamicallyQuantizableLinear â”‚  590 K â”‚ train â”‚
â”‚[2m [0m[2m109[0m[2m [0mâ”‚ net.model.text.transformer.resblocks.9.ls_1             â”‚ Identity                        â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m110[0m[2m [0mâ”‚ net.model.text.transformer.resblocks.9.ln_2             â”‚ LayerNorm                       â”‚  1.5 K â”‚ train â”‚
â”‚[2m [0m[2m111[0m[2m [0mâ”‚ net.model.text.transformer.resblocks.9.mlp              â”‚ Sequential                      â”‚  4.7 M â”‚ train â”‚
â”‚[2m [0m[2m112[0m[2m [0mâ”‚ net.model.text.transformer.resblocks.9.mlp.c_fc         â”‚ Linear                          â”‚  2.4 M â”‚ train â”‚
â”‚[2m [0m[2m113[0m[2m [0mâ”‚ net.model.text.transformer.resblocks.9.mlp.gelu         â”‚ GELU                            â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m114[0m[2m [0mâ”‚ net.model.text.transformer.resblocks.9.mlp.c_proj       â”‚ Linear                          â”‚  2.4 M â”‚ train â”‚
â”‚[2m [0m[2m115[0m[2m [0mâ”‚ net.model.text.transformer.resblocks.9.ls_2             â”‚ Identity                        â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m116[0m[2m [0mâ”‚ net.model.text.transformer.resblocks.10                 â”‚ ResidualAttentionBlock          â”‚  7.1 M â”‚ train â”‚
â”‚[2m [0m[2m117[0m[2m [0mâ”‚ net.model.text.transformer.resblocks.10.ln_1            â”‚ LayerNorm                       â”‚  1.5 K â”‚ train â”‚
â”‚[2m [0m[2m118[0m[2m [0mâ”‚ net.model.text.transformer.resblocks.10.attn            â”‚ MultiheadAttention              â”‚  2.4 M â”‚ train â”‚
â”‚[2m [0m[2m119[0m[2m [0mâ”‚ net.model.text.transformer.resblocks.10.attn.out_proj   â”‚ NonDynamicallyQuantizableLinear â”‚  590 K â”‚ train â”‚
â”‚[2m [0m[2m120[0m[2m [0mâ”‚ net.model.text.transformer.resblocks.10.ls_1            â”‚ Identity                        â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m121[0m[2m [0mâ”‚ net.model.text.transformer.resblocks.10.ln_2            â”‚ LayerNorm                       â”‚  1.5 K â”‚ train â”‚
â”‚[2m [0m[2m122[0m[2m [0mâ”‚ net.model.text.transformer.resblocks.10.mlp             â”‚ Sequential                      â”‚  4.7 M â”‚ train â”‚
â”‚[2m [0m[2m123[0m[2m [0mâ”‚ net.model.text.transformer.resblocks.10.mlp.c_fc        â”‚ Linear                          â”‚  2.4 M â”‚ train â”‚
â”‚[2m [0m[2m124[0m[2m [0mâ”‚ net.model.text.transformer.resblocks.10.mlp.gelu        â”‚ GELU                            â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m125[0m[2m [0mâ”‚ net.model.text.transformer.resblocks.10.mlp.c_proj      â”‚ Linear                          â”‚  2.4 M â”‚ train â”‚
â”‚[2m [0m[2m126[0m[2m [0mâ”‚ net.model.text.transformer.resblocks.10.ls_2            â”‚ Identity                        â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m127[0m[2m [0mâ”‚ net.model.text.transformer.resblocks.11                 â”‚ ResidualAttentionBlock          â”‚  7.1 M â”‚ train â”‚
â”‚[2m [0m[2m128[0m[2m [0mâ”‚ net.model.text.transformer.resblocks.11.ln_1            â”‚ LayerNorm                       â”‚  1.5 K â”‚ train â”‚
â”‚[2m [0m[2m129[0m[2m [0mâ”‚ net.model.text.transformer.resblocks.11.attn            â”‚ MultiheadAttention              â”‚  2.4 M â”‚ train â”‚
â”‚[2m [0m[2m130[0m[2m [0mâ”‚ net.model.text.transformer.resblocks.11.attn.out_proj   â”‚ NonDynamicallyQuantizableLinear â”‚  590 K â”‚ train â”‚
â”‚[2m [0m[2m131[0m[2m [0mâ”‚ net.model.text.transformer.resblocks.11.ls_1            â”‚ Identity                        â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m132[0m[2m [0mâ”‚ net.model.text.transformer.resblocks.11.ln_2            â”‚ LayerNorm                       â”‚  1.5 K â”‚ train â”‚
â”‚[2m [0m[2m133[0m[2m [0mâ”‚ net.model.text.transformer.resblocks.11.mlp             â”‚ Sequential                      â”‚  4.7 M â”‚ train â”‚
â”‚[2m [0m[2m134[0m[2m [0mâ”‚ net.model.text.transformer.resblocks.11.mlp.c_fc        â”‚ Linear                          â”‚  2.4 M â”‚ train â”‚
â”‚[2m [0m[2m135[0m[2m [0mâ”‚ net.model.text.transformer.resblocks.11.mlp.gelu        â”‚ GELU                            â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m136[0m[2m [0mâ”‚ net.model.text.transformer.resblocks.11.mlp.c_proj      â”‚ Linear                          â”‚  2.4 M â”‚ train â”‚
â”‚[2m [0m[2m137[0m[2m [0mâ”‚ net.model.text.transformer.resblocks.11.ls_2            â”‚ Identity                        â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m138[0m[2m [0mâ”‚ net.model.text.ln_final                                 â”‚ LayerNorm                       â”‚  1.5 K â”‚ train â”‚
â”‚[2m [0m[2m139[0m[2m [0mâ”‚ net.model.visual                                        â”‚ VisionTransformer               â”‚  306 M â”‚ train â”‚
â”‚[2m [0m[2m140[0m[2m [0mâ”‚ net.model.visual.conv1                                  â”‚ Conv2d                          â”‚  602 K â”‚ train â”‚
â”‚[2m [0m[2m141[0m[2m [0mâ”‚ net.model.visual.patch_dropout                          â”‚ Identity                        â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m142[0m[2m [0mâ”‚ net.model.visual.ln_pre                                 â”‚ LayerNorm                       â”‚  2.0 K â”‚ train â”‚
â”‚[2m [0m[2m143[0m[2m [0mâ”‚ net.model.visual.transformer                            â”‚ Transformer                     â”‚  302 M â”‚ train â”‚
â”‚[2m [0m[2m144[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks                  â”‚ ModuleList                      â”‚  302 M â”‚ train â”‚
â”‚[2m [0m[2m145[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.0                â”‚ ResidualAttentionBlock          â”‚ 12.6 M â”‚ train â”‚
â”‚[2m [0m[2m146[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.0.ln_1           â”‚ LayerNorm                       â”‚  2.0 K â”‚ train â”‚
â”‚[2m [0m[2m147[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.0.attn           â”‚ MultiheadAttention              â”‚  4.2 M â”‚ train â”‚
â”‚[2m [0m[2m148[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.0.attn.out_proj  â”‚ NonDynamicallyQuantizableLinear â”‚  1.0 M â”‚ train â”‚
â”‚[2m [0m[2m149[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.0.ls_1           â”‚ Identity                        â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m150[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.0.ln_2           â”‚ LayerNorm                       â”‚  2.0 K â”‚ train â”‚
â”‚[2m [0m[2m151[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.0.mlp            â”‚ Sequential                      â”‚  8.4 M â”‚ train â”‚
â”‚[2m [0m[2m152[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.0.mlp.c_fc       â”‚ Linear                          â”‚  4.2 M â”‚ train â”‚
â”‚[2m [0m[2m153[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.0.mlp.gelu       â”‚ GELU                            â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m154[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.0.mlp.c_proj     â”‚ Linear                          â”‚  4.2 M â”‚ train â”‚
â”‚[2m [0m[2m155[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.0.ls_2           â”‚ Identity                        â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m156[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.1                â”‚ ResidualAttentionBlock          â”‚ 12.6 M â”‚ train â”‚
â”‚[2m [0m[2m157[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.1.ln_1           â”‚ LayerNorm                       â”‚  2.0 K â”‚ train â”‚
â”‚[2m [0m[2m158[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.1.attn           â”‚ MultiheadAttention              â”‚  4.2 M â”‚ train â”‚
â”‚[2m [0m[2m159[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.1.attn.out_proj  â”‚ NonDynamicallyQuantizableLinear â”‚  1.0 M â”‚ train â”‚
â”‚[2m [0m[2m160[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.1.ls_1           â”‚ Identity                        â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m161[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.1.ln_2           â”‚ LayerNorm                       â”‚  2.0 K â”‚ train â”‚
â”‚[2m [0m[2m162[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.1.mlp            â”‚ Sequential                      â”‚  8.4 M â”‚ train â”‚
â”‚[2m [0m[2m163[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.1.mlp.c_fc       â”‚ Linear                          â”‚  4.2 M â”‚ train â”‚
â”‚[2m [0m[2m164[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.1.mlp.gelu       â”‚ GELU                            â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m165[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.1.mlp.c_proj     â”‚ Linear                          â”‚  4.2 M â”‚ train â”‚
â”‚[2m [0m[2m166[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.1.ls_2           â”‚ Identity                        â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m167[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.2                â”‚ ResidualAttentionBlock          â”‚ 12.6 M â”‚ train â”‚
â”‚[2m [0m[2m168[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.2.ln_1           â”‚ LayerNorm                       â”‚  2.0 K â”‚ train â”‚
â”‚[2m [0m[2m169[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.2.attn           â”‚ MultiheadAttention              â”‚  4.2 M â”‚ train â”‚
â”‚[2m [0m[2m170[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.2.attn.out_proj  â”‚ NonDynamicallyQuantizableLinear â”‚  1.0 M â”‚ train â”‚
â”‚[2m [0m[2m171[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.2.ls_1           â”‚ Identity                        â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m172[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.2.ln_2           â”‚ LayerNorm                       â”‚  2.0 K â”‚ train â”‚
â”‚[2m [0m[2m173[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.2.mlp            â”‚ Sequential                      â”‚  8.4 M â”‚ train â”‚
â”‚[2m [0m[2m174[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.2.mlp.c_fc       â”‚ Linear                          â”‚  4.2 M â”‚ train â”‚
â”‚[2m [0m[2m175[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.2.mlp.gelu       â”‚ GELU                            â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m176[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.2.mlp.c_proj     â”‚ Linear                          â”‚  4.2 M â”‚ train â”‚
â”‚[2m [0m[2m177[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.2.ls_2           â”‚ Identity                        â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m178[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.3                â”‚ ResidualAttentionBlock          â”‚ 12.6 M â”‚ train â”‚
â”‚[2m [0m[2m179[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.3.ln_1           â”‚ LayerNorm                       â”‚  2.0 K â”‚ train â”‚
â”‚[2m [0m[2m180[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.3.attn           â”‚ MultiheadAttention              â”‚  4.2 M â”‚ train â”‚
â”‚[2m [0m[2m181[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.3.attn.out_proj  â”‚ NonDynamicallyQuantizableLinear â”‚  1.0 M â”‚ train â”‚
â”‚[2m [0m[2m182[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.3.ls_1           â”‚ Identity                        â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m183[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.3.ln_2           â”‚ LayerNorm                       â”‚  2.0 K â”‚ train â”‚
â”‚[2m [0m[2m184[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.3.mlp            â”‚ Sequential                      â”‚  8.4 M â”‚ train â”‚
â”‚[2m [0m[2m185[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.3.mlp.c_fc       â”‚ Linear                          â”‚  4.2 M â”‚ train â”‚
â”‚[2m [0m[2m186[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.3.mlp.gelu       â”‚ GELU                            â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m187[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.3.mlp.c_proj     â”‚ Linear                          â”‚  4.2 M â”‚ train â”‚
â”‚[2m [0m[2m188[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.3.ls_2           â”‚ Identity                        â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m189[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.4                â”‚ ResidualAttentionBlock          â”‚ 12.6 M â”‚ train â”‚
â”‚[2m [0m[2m190[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.4.ln_1           â”‚ LayerNorm                       â”‚  2.0 K â”‚ train â”‚
â”‚[2m [0m[2m191[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.4.attn           â”‚ MultiheadAttention              â”‚  4.2 M â”‚ train â”‚
â”‚[2m [0m[2m192[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.4.attn.out_proj  â”‚ NonDynamicallyQuantizableLinear â”‚  1.0 M â”‚ train â”‚
â”‚[2m [0m[2m193[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.4.ls_1           â”‚ Identity                        â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m194[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.4.ln_2           â”‚ LayerNorm                       â”‚  2.0 K â”‚ train â”‚
â”‚[2m [0m[2m195[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.4.mlp            â”‚ Sequential                      â”‚  8.4 M â”‚ train â”‚
â”‚[2m [0m[2m196[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.4.mlp.c_fc       â”‚ Linear                          â”‚  4.2 M â”‚ train â”‚
â”‚[2m [0m[2m197[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.4.mlp.gelu       â”‚ GELU                            â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m198[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.4.mlp.c_proj     â”‚ Linear                          â”‚  4.2 M â”‚ train â”‚
â”‚[2m [0m[2m199[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.4.ls_2           â”‚ Identity                        â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m200[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.5                â”‚ ResidualAttentionBlock          â”‚ 12.6 M â”‚ train â”‚
â”‚[2m [0m[2m201[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.5.ln_1           â”‚ LayerNorm                       â”‚  2.0 K â”‚ train â”‚
â”‚[2m [0m[2m202[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.5.attn           â”‚ MultiheadAttention              â”‚  4.2 M â”‚ train â”‚
â”‚[2m [0m[2m203[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.5.attn.out_proj  â”‚ NonDynamicallyQuantizableLinear â”‚  1.0 M â”‚ train â”‚
â”‚[2m [0m[2m204[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.5.ls_1           â”‚ Identity                        â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m205[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.5.ln_2           â”‚ LayerNorm                       â”‚  2.0 K â”‚ train â”‚
â”‚[2m [0m[2m206[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.5.mlp            â”‚ Sequential                      â”‚  8.4 M â”‚ train â”‚
â”‚[2m [0m[2m207[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.5.mlp.c_fc       â”‚ Linear                          â”‚  4.2 M â”‚ train â”‚
â”‚[2m [0m[2m208[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.5.mlp.gelu       â”‚ GELU                            â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m209[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.5.mlp.c_proj     â”‚ Linear                          â”‚  4.2 M â”‚ train â”‚
â”‚[2m [0m[2m210[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.5.ls_2           â”‚ Identity                        â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m211[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.6                â”‚ ResidualAttentionBlock          â”‚ 12.6 M â”‚ train â”‚
â”‚[2m [0m[2m212[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.6.ln_1           â”‚ LayerNorm                       â”‚  2.0 K â”‚ train â”‚
â”‚[2m [0m[2m213[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.6.attn           â”‚ MultiheadAttention              â”‚  4.2 M â”‚ train â”‚
â”‚[2m [0m[2m214[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.6.attn.out_proj  â”‚ NonDynamicallyQuantizableLinear â”‚  1.0 M â”‚ train â”‚
â”‚[2m [0m[2m215[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.6.ls_1           â”‚ Identity                        â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m216[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.6.ln_2           â”‚ LayerNorm                       â”‚  2.0 K â”‚ train â”‚
â”‚[2m [0m[2m217[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.6.mlp            â”‚ Sequential                      â”‚  8.4 M â”‚ train â”‚
â”‚[2m [0m[2m218[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.6.mlp.c_fc       â”‚ Linear                          â”‚  4.2 M â”‚ train â”‚
â”‚[2m [0m[2m219[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.6.mlp.gelu       â”‚ GELU                            â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m220[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.6.mlp.c_proj     â”‚ Linear                          â”‚  4.2 M â”‚ train â”‚
â”‚[2m [0m[2m221[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.6.ls_2           â”‚ Identity                        â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m222[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.7                â”‚ ResidualAttentionBlock          â”‚ 12.6 M â”‚ train â”‚
â”‚[2m [0m[2m223[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.7.ln_1           â”‚ LayerNorm                       â”‚  2.0 K â”‚ train â”‚
â”‚[2m [0m[2m224[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.7.attn           â”‚ MultiheadAttention              â”‚  4.2 M â”‚ train â”‚
â”‚[2m [0m[2m225[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.7.attn.out_proj  â”‚ NonDynamicallyQuantizableLinear â”‚  1.0 M â”‚ train â”‚
â”‚[2m [0m[2m226[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.7.ls_1           â”‚ Identity                        â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m227[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.7.ln_2           â”‚ LayerNorm                       â”‚  2.0 K â”‚ train â”‚
â”‚[2m [0m[2m228[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.7.mlp            â”‚ Sequential                      â”‚  8.4 M â”‚ train â”‚
â”‚[2m [0m[2m229[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.7.mlp.c_fc       â”‚ Linear                          â”‚  4.2 M â”‚ train â”‚
â”‚[2m [0m[2m230[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.7.mlp.gelu       â”‚ GELU                            â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m231[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.7.mlp.c_proj     â”‚ Linear                          â”‚  4.2 M â”‚ train â”‚
â”‚[2m [0m[2m232[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.7.ls_2           â”‚ Identity                        â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m233[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.8                â”‚ ResidualAttentionBlock          â”‚ 12.6 M â”‚ train â”‚
â”‚[2m [0m[2m234[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.8.ln_1           â”‚ LayerNorm                       â”‚  2.0 K â”‚ train â”‚
â”‚[2m [0m[2m235[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.8.attn           â”‚ MultiheadAttention              â”‚  4.2 M â”‚ train â”‚
â”‚[2m [0m[2m236[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.8.attn.out_proj  â”‚ NonDynamicallyQuantizableLinear â”‚  1.0 M â”‚ train â”‚
â”‚[2m [0m[2m237[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.8.ls_1           â”‚ Identity                        â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m238[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.8.ln_2           â”‚ LayerNorm                       â”‚  2.0 K â”‚ train â”‚
â”‚[2m [0m[2m239[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.8.mlp            â”‚ Sequential                      â”‚  8.4 M â”‚ train â”‚
â”‚[2m [0m[2m240[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.8.mlp.c_fc       â”‚ Linear                          â”‚  4.2 M â”‚ train â”‚
â”‚[2m [0m[2m241[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.8.mlp.gelu       â”‚ GELU                            â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m242[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.8.mlp.c_proj     â”‚ Linear                          â”‚  4.2 M â”‚ train â”‚
â”‚[2m [0m[2m243[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.8.ls_2           â”‚ Identity                        â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m244[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.9                â”‚ ResidualAttentionBlock          â”‚ 12.6 M â”‚ train â”‚
â”‚[2m [0m[2m245[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.9.ln_1           â”‚ LayerNorm                       â”‚  2.0 K â”‚ train â”‚
â”‚[2m [0m[2m246[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.9.attn           â”‚ MultiheadAttention              â”‚  4.2 M â”‚ train â”‚
â”‚[2m [0m[2m247[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.9.attn.out_proj  â”‚ NonDynamicallyQuantizableLinear â”‚  1.0 M â”‚ train â”‚
â”‚[2m [0m[2m248[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.9.ls_1           â”‚ Identity                        â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m249[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.9.ln_2           â”‚ LayerNorm                       â”‚  2.0 K â”‚ train â”‚
â”‚[2m [0m[2m250[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.9.mlp            â”‚ Sequential                      â”‚  8.4 M â”‚ train â”‚
â”‚[2m [0m[2m251[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.9.mlp.c_fc       â”‚ Linear                          â”‚  4.2 M â”‚ train â”‚
â”‚[2m [0m[2m252[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.9.mlp.gelu       â”‚ GELU                            â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m253[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.9.mlp.c_proj     â”‚ Linear                          â”‚  4.2 M â”‚ train â”‚
â”‚[2m [0m[2m254[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.9.ls_2           â”‚ Identity                        â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m255[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.10               â”‚ ResidualAttentionBlock          â”‚ 12.6 M â”‚ train â”‚
â”‚[2m [0m[2m256[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.10.ln_1          â”‚ LayerNorm                       â”‚  2.0 K â”‚ train â”‚
â”‚[2m [0m[2m257[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.10.attn          â”‚ MultiheadAttention              â”‚  4.2 M â”‚ train â”‚
â”‚[2m [0m[2m258[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.10.attn.out_proj â”‚ NonDynamicallyQuantizableLinear â”‚  1.0 M â”‚ train â”‚
â”‚[2m [0m[2m259[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.10.ls_1          â”‚ Identity                        â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m260[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.10.ln_2          â”‚ LayerNorm                       â”‚  2.0 K â”‚ train â”‚
â”‚[2m [0m[2m261[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.10.mlp           â”‚ Sequential                      â”‚  8.4 M â”‚ train â”‚
â”‚[2m [0m[2m262[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.10.mlp.c_fc      â”‚ Linear                          â”‚  4.2 M â”‚ train â”‚
â”‚[2m [0m[2m263[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.10.mlp.gelu      â”‚ GELU                            â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m264[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.10.mlp.c_proj    â”‚ Linear                          â”‚  4.2 M â”‚ train â”‚
â”‚[2m [0m[2m265[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.10.ls_2          â”‚ Identity                        â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m266[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.11               â”‚ ResidualAttentionBlock          â”‚ 12.6 M â”‚ train â”‚
â”‚[2m [0m[2m267[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.11.ln_1          â”‚ LayerNorm                       â”‚  2.0 K â”‚ train â”‚
â”‚[2m [0m[2m268[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.11.attn          â”‚ MultiheadAttention              â”‚  4.2 M â”‚ train â”‚
â”‚[2m [0m[2m269[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.11.attn.out_proj â”‚ NonDynamicallyQuantizableLinear â”‚  1.0 M â”‚ train â”‚
â”‚[2m [0m[2m270[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.11.ls_1          â”‚ Identity                        â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m271[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.11.ln_2          â”‚ LayerNorm                       â”‚  2.0 K â”‚ train â”‚
â”‚[2m [0m[2m272[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.11.mlp           â”‚ Sequential                      â”‚  8.4 M â”‚ train â”‚
â”‚[2m [0m[2m273[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.11.mlp.c_fc      â”‚ Linear                          â”‚  4.2 M â”‚ train â”‚
â”‚[2m [0m[2m274[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.11.mlp.gelu      â”‚ GELU                            â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m275[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.11.mlp.c_proj    â”‚ Linear                          â”‚  4.2 M â”‚ train â”‚
â”‚[2m [0m[2m276[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.11.ls_2          â”‚ Identity                        â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m277[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.12               â”‚ ResidualAttentionBlock          â”‚ 12.6 M â”‚ train â”‚
â”‚[2m [0m[2m278[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.12.ln_1          â”‚ LayerNorm                       â”‚  2.0 K â”‚ train â”‚
â”‚[2m [0m[2m279[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.12.attn          â”‚ MultiheadAttention              â”‚  4.2 M â”‚ train â”‚
â”‚[2m [0m[2m280[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.12.attn.out_proj â”‚ NonDynamicallyQuantizableLinear â”‚  1.0 M â”‚ train â”‚
â”‚[2m [0m[2m281[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.12.ls_1          â”‚ Identity                        â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m282[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.12.ln_2          â”‚ LayerNorm                       â”‚  2.0 K â”‚ train â”‚
â”‚[2m [0m[2m283[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.12.mlp           â”‚ Sequential                      â”‚  8.4 M â”‚ train â”‚
â”‚[2m [0m[2m284[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.12.mlp.c_fc      â”‚ Linear                          â”‚  4.2 M â”‚ train â”‚
â”‚[2m [0m[2m285[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.12.mlp.gelu      â”‚ GELU                            â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m286[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.12.mlp.c_proj    â”‚ Linear                          â”‚  4.2 M â”‚ train â”‚
â”‚[2m [0m[2m287[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.12.ls_2          â”‚ Identity                        â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m288[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.13               â”‚ ResidualAttentionBlock          â”‚ 12.6 M â”‚ train â”‚
â”‚[2m [0m[2m289[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.13.ln_1          â”‚ LayerNorm                       â”‚  2.0 K â”‚ train â”‚
â”‚[2m [0m[2m290[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.13.attn          â”‚ MultiheadAttention              â”‚  4.2 M â”‚ train â”‚
â”‚[2m [0m[2m291[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.13.attn.out_proj â”‚ NonDynamicallyQuantizableLinear â”‚  1.0 M â”‚ train â”‚
â”‚[2m [0m[2m292[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.13.ls_1          â”‚ Identity                        â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m293[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.13.ln_2          â”‚ LayerNorm                       â”‚  2.0 K â”‚ train â”‚
â”‚[2m [0m[2m294[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.13.mlp           â”‚ Sequential                      â”‚  8.4 M â”‚ train â”‚
â”‚[2m [0m[2m295[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.13.mlp.c_fc      â”‚ Linear                          â”‚  4.2 M â”‚ train â”‚
â”‚[2m [0m[2m296[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.13.mlp.gelu      â”‚ GELU                            â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m297[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.13.mlp.c_proj    â”‚ Linear                          â”‚  4.2 M â”‚ train â”‚
â”‚[2m [0m[2m298[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.13.ls_2          â”‚ Identity                        â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m299[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.14               â”‚ ResidualAttentionBlock          â”‚ 12.6 M â”‚ train â”‚
â”‚[2m [0m[2m300[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.14.ln_1          â”‚ LayerNorm                       â”‚  2.0 K â”‚ train â”‚
â”‚[2m [0m[2m301[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.14.attn          â”‚ MultiheadAttention              â”‚  4.2 M â”‚ train â”‚
â”‚[2m [0m[2m302[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.14.attn.out_proj â”‚ NonDynamicallyQuantizableLinear â”‚  1.0 M â”‚ train â”‚
â”‚[2m [0m[2m303[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.14.ls_1          â”‚ Identity                        â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m304[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.14.ln_2          â”‚ LayerNorm                       â”‚  2.0 K â”‚ train â”‚
â”‚[2m [0m[2m305[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.14.mlp           â”‚ Sequential                      â”‚  8.4 M â”‚ train â”‚
â”‚[2m [0m[2m306[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.14.mlp.c_fc      â”‚ Linear                          â”‚  4.2 M â”‚ train â”‚
â”‚[2m [0m[2m307[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.14.mlp.gelu      â”‚ GELU                            â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m308[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.14.mlp.c_proj    â”‚ Linear                          â”‚  4.2 M â”‚ train â”‚
â”‚[2m [0m[2m309[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.14.ls_2          â”‚ Identity                        â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m310[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.15               â”‚ ResidualAttentionBlock          â”‚ 12.6 M â”‚ train â”‚
â”‚[2m [0m[2m311[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.15.ln_1          â”‚ LayerNorm                       â”‚  2.0 K â”‚ train â”‚
â”‚[2m [0m[2m312[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.15.attn          â”‚ MultiheadAttention              â”‚  4.2 M â”‚ train â”‚
â”‚[2m [0m[2m313[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.15.attn.out_proj â”‚ NonDynamicallyQuantizableLinear â”‚  1.0 M â”‚ train â”‚
â”‚[2m [0m[2m314[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.15.ls_1          â”‚ Identity                        â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m315[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.15.ln_2          â”‚ LayerNorm                       â”‚  2.0 K â”‚ train â”‚
â”‚[2m [0m[2m316[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.15.mlp           â”‚ Sequential                      â”‚  8.4 M â”‚ train â”‚
â”‚[2m [0m[2m317[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.15.mlp.c_fc      â”‚ Linear                          â”‚  4.2 M â”‚ train â”‚
â”‚[2m [0m[2m318[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.15.mlp.gelu      â”‚ GELU                            â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m319[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.15.mlp.c_proj    â”‚ Linear                          â”‚  4.2 M â”‚ train â”‚
â”‚[2m [0m[2m320[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.15.ls_2          â”‚ Identity                        â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m321[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.16               â”‚ ResidualAttentionBlock          â”‚ 12.6 M â”‚ train â”‚
â”‚[2m [0m[2m322[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.16.ln_1          â”‚ LayerNorm                       â”‚  2.0 K â”‚ train â”‚
â”‚[2m [0m[2m323[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.16.attn          â”‚ MultiheadAttention              â”‚  4.2 M â”‚ train â”‚
â”‚[2m [0m[2m324[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.16.attn.out_proj â”‚ NonDynamicallyQuantizableLinear â”‚  1.0 M â”‚ train â”‚
â”‚[2m [0m[2m325[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.16.ls_1          â”‚ Identity                        â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m326[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.16.ln_2          â”‚ LayerNorm                       â”‚  2.0 K â”‚ train â”‚
â”‚[2m [0m[2m327[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.16.mlp           â”‚ Sequential                      â”‚  8.4 M â”‚ train â”‚
â”‚[2m [0m[2m328[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.16.mlp.c_fc      â”‚ Linear                          â”‚  4.2 M â”‚ train â”‚
â”‚[2m [0m[2m329[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.16.mlp.gelu      â”‚ GELU                            â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m330[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.16.mlp.c_proj    â”‚ Linear                          â”‚  4.2 M â”‚ train â”‚
â”‚[2m [0m[2m331[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.16.ls_2          â”‚ Identity                        â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m332[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.17               â”‚ ResidualAttentionBlock          â”‚ 12.6 M â”‚ train â”‚
â”‚[2m [0m[2m333[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.17.ln_1          â”‚ LayerNorm                       â”‚  2.0 K â”‚ train â”‚
â”‚[2m [0m[2m334[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.17.attn          â”‚ MultiheadAttention              â”‚  4.2 M â”‚ train â”‚
â”‚[2m [0m[2m335[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.17.attn.out_proj â”‚ NonDynamicallyQuantizableLinear â”‚  1.0 M â”‚ train â”‚
â”‚[2m [0m[2m336[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.17.ls_1          â”‚ Identity                        â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m337[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.17.ln_2          â”‚ LayerNorm                       â”‚  2.0 K â”‚ train â”‚
â”‚[2m [0m[2m338[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.17.mlp           â”‚ Sequential                      â”‚  8.4 M â”‚ train â”‚
â”‚[2m [0m[2m339[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.17.mlp.c_fc      â”‚ Linear                          â”‚  4.2 M â”‚ train â”‚
â”‚[2m [0m[2m340[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.17.mlp.gelu      â”‚ GELU                            â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m341[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.17.mlp.c_proj    â”‚ Linear                          â”‚  4.2 M â”‚ train â”‚
â”‚[2m [0m[2m342[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.17.ls_2          â”‚ Identity                        â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m343[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.18               â”‚ ResidualAttentionBlock          â”‚ 12.6 M â”‚ train â”‚
â”‚[2m [0m[2m344[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.18.ln_1          â”‚ LayerNorm                       â”‚  2.0 K â”‚ train â”‚
â”‚[2m [0m[2m345[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.18.attn          â”‚ MultiheadAttention              â”‚  4.2 M â”‚ train â”‚
â”‚[2m [0m[2m346[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.18.attn.out_proj â”‚ NonDynamicallyQuantizableLinear â”‚  1.0 M â”‚ train â”‚
â”‚[2m [0m[2m347[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.18.ls_1          â”‚ Identity                        â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m348[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.18.ln_2          â”‚ LayerNorm                       â”‚  2.0 K â”‚ train â”‚
â”‚[2m [0m[2m349[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.18.mlp           â”‚ Sequential                      â”‚  8.4 M â”‚ train â”‚
â”‚[2m [0m[2m350[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.18.mlp.c_fc      â”‚ Linear                          â”‚  4.2 M â”‚ train â”‚
â”‚[2m [0m[2m351[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.18.mlp.gelu      â”‚ GELU                            â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m352[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.18.mlp.c_proj    â”‚ Linear                          â”‚  4.2 M â”‚ train â”‚
â”‚[2m [0m[2m353[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.18.ls_2          â”‚ Identity                        â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m354[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.19               â”‚ ResidualAttentionBlock          â”‚ 12.6 M â”‚ train â”‚
â”‚[2m [0m[2m355[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.19.ln_1          â”‚ LayerNorm                       â”‚  2.0 K â”‚ train â”‚
â”‚[2m [0m[2m356[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.19.attn          â”‚ MultiheadAttention              â”‚  4.2 M â”‚ train â”‚
â”‚[2m [0m[2m357[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.19.attn.out_proj â”‚ NonDynamicallyQuantizableLinear â”‚  1.0 M â”‚ train â”‚
â”‚[2m [0m[2m358[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.19.ls_1          â”‚ Identity                        â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m359[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.19.ln_2          â”‚ LayerNorm                       â”‚  2.0 K â”‚ train â”‚
â”‚[2m [0m[2m360[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.19.mlp           â”‚ Sequential                      â”‚  8.4 M â”‚ train â”‚
â”‚[2m [0m[2m361[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.19.mlp.c_fc      â”‚ Linear                          â”‚  4.2 M â”‚ train â”‚
â”‚[2m [0m[2m362[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.19.mlp.gelu      â”‚ GELU                            â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m363[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.19.mlp.c_proj    â”‚ Linear                          â”‚  4.2 M â”‚ train â”‚
â”‚[2m [0m[2m364[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.19.ls_2          â”‚ Identity                        â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m365[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.20               â”‚ ResidualAttentionBlock          â”‚ 12.6 M â”‚ train â”‚
â”‚[2m [0m[2m366[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.20.ln_1          â”‚ LayerNorm                       â”‚  2.0 K â”‚ train â”‚
â”‚[2m [0m[2m367[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.20.attn          â”‚ MultiheadAttention              â”‚  4.2 M â”‚ train â”‚
â”‚[2m [0m[2m368[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.20.attn.out_proj â”‚ NonDynamicallyQuantizableLinear â”‚  1.0 M â”‚ train â”‚
â”‚[2m [0m[2m369[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.20.ls_1          â”‚ Identity                        â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m370[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.20.ln_2          â”‚ LayerNorm                       â”‚  2.0 K â”‚ train â”‚
â”‚[2m [0m[2m371[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.20.mlp           â”‚ Sequential                      â”‚  8.4 M â”‚ train â”‚
â”‚[2m [0m[2m372[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.20.mlp.c_fc      â”‚ Linear                          â”‚  4.2 M â”‚ train â”‚
â”‚[2m [0m[2m373[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.20.mlp.gelu      â”‚ GELU                            â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m374[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.20.mlp.c_proj    â”‚ Linear                          â”‚  4.2 M â”‚ train â”‚
â”‚[2m [0m[2m375[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.20.ls_2          â”‚ Identity                        â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m376[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.21               â”‚ ResidualAttentionBlock          â”‚ 12.6 M â”‚ train â”‚
â”‚[2m [0m[2m377[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.21.ln_1          â”‚ LayerNorm                       â”‚  2.0 K â”‚ train â”‚
â”‚[2m [0m[2m378[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.21.attn          â”‚ MultiheadAttention              â”‚  4.2 M â”‚ train â”‚
â”‚[2m [0m[2m379[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.21.attn.out_proj â”‚ NonDynamicallyQuantizableLinear â”‚  1.0 M â”‚ train â”‚
â”‚[2m [0m[2m380[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.21.ls_1          â”‚ Identity                        â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m381[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.21.ln_2          â”‚ LayerNorm                       â”‚  2.0 K â”‚ train â”‚
â”‚[2m [0m[2m382[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.21.mlp           â”‚ Sequential                      â”‚  8.4 M â”‚ train â”‚
â”‚[2m [0m[2m383[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.21.mlp.c_fc      â”‚ Linear                          â”‚  4.2 M â”‚ train â”‚
â”‚[2m [0m[2m384[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.21.mlp.gelu      â”‚ GELU                            â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m385[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.21.mlp.c_proj    â”‚ Linear                          â”‚  4.2 M â”‚ train â”‚
â”‚[2m [0m[2m386[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.21.ls_2          â”‚ Identity                        â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m387[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.22               â”‚ ResidualAttentionBlock          â”‚ 12.6 M â”‚ train â”‚
â”‚[2m [0m[2m388[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.22.ln_1          â”‚ LayerNorm                       â”‚  2.0 K â”‚ train â”‚
â”‚[2m [0m[2m389[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.22.attn          â”‚ MultiheadAttention              â”‚  4.2 M â”‚ train â”‚
â”‚[2m [0m[2m390[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.22.attn.out_proj â”‚ NonDynamicallyQuantizableLinear â”‚  1.0 M â”‚ train â”‚
â”‚[2m [0m[2m391[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.22.ls_1          â”‚ Identity                        â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m392[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.22.ln_2          â”‚ LayerNorm                       â”‚  2.0 K â”‚ train â”‚
â”‚[2m [0m[2m393[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.22.mlp           â”‚ Sequential                      â”‚  8.4 M â”‚ train â”‚
â”‚[2m [0m[2m394[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.22.mlp.c_fc      â”‚ Linear                          â”‚  4.2 M â”‚ train â”‚
â”‚[2m [0m[2m395[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.22.mlp.gelu      â”‚ GELU                            â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m396[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.22.mlp.c_proj    â”‚ Linear                          â”‚  4.2 M â”‚ train â”‚
â”‚[2m [0m[2m397[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.22.ls_2          â”‚ Identity                        â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m398[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.23               â”‚ ResidualAttentionBlock          â”‚ 12.6 M â”‚ train â”‚
â”‚[2m [0m[2m399[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.23.ln_1          â”‚ LayerNorm                       â”‚  2.0 K â”‚ train â”‚
â”‚[2m [0m[2m400[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.23.attn          â”‚ MultiheadAttention              â”‚  4.2 M â”‚ train â”‚
â”‚[2m [0m[2m401[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.23.attn.out_proj â”‚ NonDynamicallyQuantizableLinear â”‚  1.0 M â”‚ train â”‚
â”‚[2m [0m[2m402[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.23.ls_1          â”‚ Identity                        â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m403[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.23.ln_2          â”‚ LayerNorm                       â”‚  2.0 K â”‚ train â”‚
â”‚[2m [0m[2m404[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.23.mlp           â”‚ Sequential                      â”‚  8.4 M â”‚ train â”‚
â”‚[2m [0m[2m405[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.23.mlp.c_fc      â”‚ Linear                          â”‚  4.2 M â”‚ train â”‚
â”‚[2m [0m[2m406[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.23.mlp.gelu      â”‚ GELU                            â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m407[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.23.mlp.c_proj    â”‚ Linear                          â”‚  4.2 M â”‚ train â”‚
â”‚[2m [0m[2m408[0m[2m [0mâ”‚ net.model.visual.transformer.resblocks.23.ls_2          â”‚ Identity                        â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m409[0m[2m [0mâ”‚ net.model.visual.attn_pool                              â”‚ AttentionalPooler               â”‚  3.0 M â”‚ train â”‚
â”‚[2m [0m[2m410[0m[2m [0mâ”‚ net.model.visual.attn_pool.attn                         â”‚ MultiheadAttention              â”‚  2.8 M â”‚ train â”‚
â”‚[2m [0m[2m411[0m[2m [0mâ”‚ net.model.visual.attn_pool.attn.out_proj                â”‚ NonDynamicallyQuantizableLinear â”‚  590 K â”‚ train â”‚
â”‚[2m [0m[2m412[0m[2m [0mâ”‚ net.model.visual.attn_pool.ln_q                         â”‚ LayerNorm                       â”‚  1.5 K â”‚ train â”‚
â”‚[2m [0m[2m413[0m[2m [0mâ”‚ net.model.visual.attn_pool.ln_k                         â”‚ LayerNorm                       â”‚  2.0 K â”‚ train â”‚
â”‚[2m [0m[2m414[0m[2m [0mâ”‚ net.model.visual.ln_post                                â”‚ LayerNorm                       â”‚  1.5 K â”‚ train â”‚
â”‚[2m [0m[2m415[0m[2m [0mâ”‚ net.model.text_decoder                                  â”‚ MultimodalTransformer           â”‚  208 M â”‚ train â”‚
â”‚[2m [0m[2m416[0m[2m [0mâ”‚ net.model.text_decoder.resblocks                        â”‚ ModuleList                      â”‚ 85.1 M â”‚ train â”‚
â”‚[2m [0m[2m417[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.0                      â”‚ ResidualAttentionBlock          â”‚  7.1 M â”‚ train â”‚
â”‚[2m [0m[2m418[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.0.ln_1                 â”‚ LayerNorm                       â”‚  1.5 K â”‚ train â”‚
â”‚[2m [0m[2m419[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.0.attn                 â”‚ MultiheadAttention              â”‚  2.4 M â”‚ train â”‚
â”‚[2m [0m[2m420[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.0.attn.out_proj        â”‚ NonDynamicallyQuantizableLinear â”‚  590 K â”‚ train â”‚
â”‚[2m [0m[2m421[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.0.ls_1                 â”‚ Identity                        â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m422[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.0.ln_2                 â”‚ LayerNorm                       â”‚  1.5 K â”‚ train â”‚
â”‚[2m [0m[2m423[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.0.mlp                  â”‚ Sequential                      â”‚  4.7 M â”‚ train â”‚
â”‚[2m [0m[2m424[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.0.mlp.c_fc             â”‚ Linear                          â”‚  2.4 M â”‚ train â”‚
â”‚[2m [0m[2m425[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.0.mlp.gelu             â”‚ GELU                            â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m426[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.0.mlp.c_proj           â”‚ Linear                          â”‚  2.4 M â”‚ train â”‚
â”‚[2m [0m[2m427[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.0.ls_2                 â”‚ Identity                        â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m428[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.1                      â”‚ ResidualAttentionBlock          â”‚  7.1 M â”‚ train â”‚
â”‚[2m [0m[2m429[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.1.ln_1                 â”‚ LayerNorm                       â”‚  1.5 K â”‚ train â”‚
â”‚[2m [0m[2m430[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.1.attn                 â”‚ MultiheadAttention              â”‚  2.4 M â”‚ train â”‚
â”‚[2m [0m[2m431[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.1.attn.out_proj        â”‚ NonDynamicallyQuantizableLinear â”‚  590 K â”‚ train â”‚
â”‚[2m [0m[2m432[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.1.ls_1                 â”‚ Identity                        â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m433[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.1.ln_2                 â”‚ LayerNorm                       â”‚  1.5 K â”‚ train â”‚
â”‚[2m [0m[2m434[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.1.mlp                  â”‚ Sequential                      â”‚  4.7 M â”‚ train â”‚
â”‚[2m [0m[2m435[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.1.mlp.c_fc             â”‚ Linear                          â”‚  2.4 M â”‚ train â”‚
â”‚[2m [0m[2m436[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.1.mlp.gelu             â”‚ GELU                            â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m437[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.1.mlp.c_proj           â”‚ Linear                          â”‚  2.4 M â”‚ train â”‚
â”‚[2m [0m[2m438[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.1.ls_2                 â”‚ Identity                        â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m439[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.2                      â”‚ ResidualAttentionBlock          â”‚  7.1 M â”‚ train â”‚
â”‚[2m [0m[2m440[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.2.ln_1                 â”‚ LayerNorm                       â”‚  1.5 K â”‚ train â”‚
â”‚[2m [0m[2m441[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.2.attn                 â”‚ MultiheadAttention              â”‚  2.4 M â”‚ train â”‚
â”‚[2m [0m[2m442[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.2.attn.out_proj        â”‚ NonDynamicallyQuantizableLinear â”‚  590 K â”‚ train â”‚
â”‚[2m [0m[2m443[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.2.ls_1                 â”‚ Identity                        â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m444[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.2.ln_2                 â”‚ LayerNorm                       â”‚  1.5 K â”‚ train â”‚
â”‚[2m [0m[2m445[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.2.mlp                  â”‚ Sequential                      â”‚  4.7 M â”‚ train â”‚
â”‚[2m [0m[2m446[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.2.mlp.c_fc             â”‚ Linear                          â”‚  2.4 M â”‚ train â”‚
â”‚[2m [0m[2m447[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.2.mlp.gelu             â”‚ GELU                            â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m448[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.2.mlp.c_proj           â”‚ Linear                          â”‚  2.4 M â”‚ train â”‚
â”‚[2m [0m[2m449[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.2.ls_2                 â”‚ Identity                        â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m450[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.3                      â”‚ ResidualAttentionBlock          â”‚  7.1 M â”‚ train â”‚
â”‚[2m [0m[2m451[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.3.ln_1                 â”‚ LayerNorm                       â”‚  1.5 K â”‚ train â”‚
â”‚[2m [0m[2m452[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.3.attn                 â”‚ MultiheadAttention              â”‚  2.4 M â”‚ train â”‚
â”‚[2m [0m[2m453[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.3.attn.out_proj        â”‚ NonDynamicallyQuantizableLinear â”‚  590 K â”‚ train â”‚
â”‚[2m [0m[2m454[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.3.ls_1                 â”‚ Identity                        â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m455[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.3.ln_2                 â”‚ LayerNorm                       â”‚  1.5 K â”‚ train â”‚
â”‚[2m [0m[2m456[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.3.mlp                  â”‚ Sequential                      â”‚  4.7 M â”‚ train â”‚
â”‚[2m [0m[2m457[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.3.mlp.c_fc             â”‚ Linear                          â”‚  2.4 M â”‚ train â”‚
â”‚[2m [0m[2m458[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.3.mlp.gelu             â”‚ GELU                            â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m459[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.3.mlp.c_proj           â”‚ Linear                          â”‚  2.4 M â”‚ train â”‚
â”‚[2m [0m[2m460[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.3.ls_2                 â”‚ Identity                        â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m461[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.4                      â”‚ ResidualAttentionBlock          â”‚  7.1 M â”‚ train â”‚
â”‚[2m [0m[2m462[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.4.ln_1                 â”‚ LayerNorm                       â”‚  1.5 K â”‚ train â”‚
â”‚[2m [0m[2m463[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.4.attn                 â”‚ MultiheadAttention              â”‚  2.4 M â”‚ train â”‚
â”‚[2m [0m[2m464[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.4.attn.out_proj        â”‚ NonDynamicallyQuantizableLinear â”‚  590 K â”‚ train â”‚
â”‚[2m [0m[2m465[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.4.ls_1                 â”‚ Identity                        â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m466[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.4.ln_2                 â”‚ LayerNorm                       â”‚  1.5 K â”‚ train â”‚
â”‚[2m [0m[2m467[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.4.mlp                  â”‚ Sequential                      â”‚  4.7 M â”‚ train â”‚
â”‚[2m [0m[2m468[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.4.mlp.c_fc             â”‚ Linear                          â”‚  2.4 M â”‚ train â”‚
â”‚[2m [0m[2m469[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.4.mlp.gelu             â”‚ GELU                            â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m470[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.4.mlp.c_proj           â”‚ Linear                          â”‚  2.4 M â”‚ train â”‚
â”‚[2m [0m[2m471[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.4.ls_2                 â”‚ Identity                        â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m472[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.5                      â”‚ ResidualAttentionBlock          â”‚  7.1 M â”‚ train â”‚
â”‚[2m [0m[2m473[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.5.ln_1                 â”‚ LayerNorm                       â”‚  1.5 K â”‚ train â”‚
â”‚[2m [0m[2m474[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.5.attn                 â”‚ MultiheadAttention              â”‚  2.4 M â”‚ train â”‚
â”‚[2m [0m[2m475[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.5.attn.out_proj        â”‚ NonDynamicallyQuantizableLinear â”‚  590 K â”‚ train â”‚
â”‚[2m [0m[2m476[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.5.ls_1                 â”‚ Identity                        â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m477[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.5.ln_2                 â”‚ LayerNorm                       â”‚  1.5 K â”‚ train â”‚
â”‚[2m [0m[2m478[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.5.mlp                  â”‚ Sequential                      â”‚  4.7 M â”‚ train â”‚
â”‚[2m [0m[2m479[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.5.mlp.c_fc             â”‚ Linear                          â”‚  2.4 M â”‚ train â”‚
â”‚[2m [0m[2m480[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.5.mlp.gelu             â”‚ GELU                            â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m481[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.5.mlp.c_proj           â”‚ Linear                          â”‚  2.4 M â”‚ train â”‚
â”‚[2m [0m[2m482[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.5.ls_2                 â”‚ Identity                        â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m483[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.6                      â”‚ ResidualAttentionBlock          â”‚  7.1 M â”‚ train â”‚
â”‚[2m [0m[2m484[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.6.ln_1                 â”‚ LayerNorm                       â”‚  1.5 K â”‚ train â”‚
â”‚[2m [0m[2m485[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.6.attn                 â”‚ MultiheadAttention              â”‚  2.4 M â”‚ train â”‚
â”‚[2m [0m[2m486[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.6.attn.out_proj        â”‚ NonDynamicallyQuantizableLinear â”‚  590 K â”‚ train â”‚
â”‚[2m [0m[2m487[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.6.ls_1                 â”‚ Identity                        â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m488[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.6.ln_2                 â”‚ LayerNorm                       â”‚  1.5 K â”‚ train â”‚
â”‚[2m [0m[2m489[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.6.mlp                  â”‚ Sequential                      â”‚  4.7 M â”‚ train â”‚
â”‚[2m [0m[2m490[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.6.mlp.c_fc             â”‚ Linear                          â”‚  2.4 M â”‚ train â”‚
â”‚[2m [0m[2m491[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.6.mlp.gelu             â”‚ GELU                            â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m492[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.6.mlp.c_proj           â”‚ Linear                          â”‚  2.4 M â”‚ train â”‚
â”‚[2m [0m[2m493[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.6.ls_2                 â”‚ Identity                        â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m494[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.7                      â”‚ ResidualAttentionBlock          â”‚  7.1 M â”‚ train â”‚
â”‚[2m [0m[2m495[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.7.ln_1                 â”‚ LayerNorm                       â”‚  1.5 K â”‚ train â”‚
â”‚[2m [0m[2m496[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.7.attn                 â”‚ MultiheadAttention              â”‚  2.4 M â”‚ train â”‚
â”‚[2m [0m[2m497[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.7.attn.out_proj        â”‚ NonDynamicallyQuantizableLinear â”‚  590 K â”‚ train â”‚
â”‚[2m [0m[2m498[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.7.ls_1                 â”‚ Identity                        â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m499[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.7.ln_2                 â”‚ LayerNorm                       â”‚  1.5 K â”‚ train â”‚
â”‚[2m [0m[2m500[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.7.mlp                  â”‚ Sequential                      â”‚  4.7 M â”‚ train â”‚
â”‚[2m [0m[2m501[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.7.mlp.c_fc             â”‚ Linear                          â”‚  2.4 M â”‚ train â”‚
â”‚[2m [0m[2m502[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.7.mlp.gelu             â”‚ GELU                            â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m503[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.7.mlp.c_proj           â”‚ Linear                          â”‚  2.4 M â”‚ train â”‚
â”‚[2m [0m[2m504[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.7.ls_2                 â”‚ Identity                        â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m505[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.8                      â”‚ ResidualAttentionBlock          â”‚  7.1 M â”‚ train â”‚
â”‚[2m [0m[2m506[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.8.ln_1                 â”‚ LayerNorm                       â”‚  1.5 K â”‚ train â”‚
â”‚[2m [0m[2m507[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.8.attn                 â”‚ MultiheadAttention              â”‚  2.4 M â”‚ train â”‚
â”‚[2m [0m[2m508[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.8.attn.out_proj        â”‚ NonDynamicallyQuantizableLinear â”‚  590 K â”‚ train â”‚
â”‚[2m [0m[2m509[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.8.ls_1                 â”‚ Identity                        â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m510[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.8.ln_2                 â”‚ LayerNorm                       â”‚  1.5 K â”‚ train â”‚
â”‚[2m [0m[2m511[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.8.mlp                  â”‚ Sequential                      â”‚  4.7 M â”‚ train â”‚
â”‚[2m [0m[2m512[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.8.mlp.c_fc             â”‚ Linear                          â”‚  2.4 M â”‚ train â”‚
â”‚[2m [0m[2m513[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.8.mlp.gelu             â”‚ GELU                            â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m514[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.8.mlp.c_proj           â”‚ Linear                          â”‚  2.4 M â”‚ train â”‚
â”‚[2m [0m[2m515[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.8.ls_2                 â”‚ Identity                        â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m516[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.9                      â”‚ ResidualAttentionBlock          â”‚  7.1 M â”‚ train â”‚
â”‚[2m [0m[2m517[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.9.ln_1                 â”‚ LayerNorm                       â”‚  1.5 K â”‚ train â”‚
â”‚[2m [0m[2m518[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.9.attn                 â”‚ MultiheadAttention              â”‚  2.4 M â”‚ train â”‚
â”‚[2m [0m[2m519[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.9.attn.out_proj        â”‚ NonDynamicallyQuantizableLinear â”‚  590 K â”‚ train â”‚
â”‚[2m [0m[2m520[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.9.ls_1                 â”‚ Identity                        â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m521[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.9.ln_2                 â”‚ LayerNorm                       â”‚  1.5 K â”‚ train â”‚
â”‚[2m [0m[2m522[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.9.mlp                  â”‚ Sequential                      â”‚  4.7 M â”‚ train â”‚
â”‚[2m [0m[2m523[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.9.mlp.c_fc             â”‚ Linear                          â”‚  2.4 M â”‚ train â”‚
â”‚[2m [0m[2m524[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.9.mlp.gelu             â”‚ GELU                            â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m525[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.9.mlp.c_proj           â”‚ Linear                          â”‚  2.4 M â”‚ train â”‚
â”‚[2m [0m[2m526[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.9.ls_2                 â”‚ Identity                        â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m527[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.10                     â”‚ ResidualAttentionBlock          â”‚  7.1 M â”‚ train â”‚
â”‚[2m [0m[2m528[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.10.ln_1                â”‚ LayerNorm                       â”‚  1.5 K â”‚ train â”‚
â”‚[2m [0m[2m529[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.10.attn                â”‚ MultiheadAttention              â”‚  2.4 M â”‚ train â”‚
â”‚[2m [0m[2m530[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.10.attn.out_proj       â”‚ NonDynamicallyQuantizableLinear â”‚  590 K â”‚ train â”‚
â”‚[2m [0m[2m531[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.10.ls_1                â”‚ Identity                        â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m532[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.10.ln_2                â”‚ LayerNorm                       â”‚  1.5 K â”‚ train â”‚
â”‚[2m [0m[2m533[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.10.mlp                 â”‚ Sequential                      â”‚  4.7 M â”‚ train â”‚
â”‚[2m [0m[2m534[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.10.mlp.c_fc            â”‚ Linear                          â”‚  2.4 M â”‚ train â”‚
â”‚[2m [0m[2m535[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.10.mlp.gelu            â”‚ GELU                            â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m536[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.10.mlp.c_proj          â”‚ Linear                          â”‚  2.4 M â”‚ train â”‚
â”‚[2m [0m[2m537[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.10.ls_2                â”‚ Identity                        â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m538[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.11                     â”‚ ResidualAttentionBlock          â”‚  7.1 M â”‚ train â”‚
â”‚[2m [0m[2m539[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.11.ln_1                â”‚ LayerNorm                       â”‚  1.5 K â”‚ train â”‚
â”‚[2m [0m[2m540[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.11.attn                â”‚ MultiheadAttention              â”‚  2.4 M â”‚ train â”‚
â”‚[2m [0m[2m541[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.11.attn.out_proj       â”‚ NonDynamicallyQuantizableLinear â”‚  590 K â”‚ train â”‚
â”‚[2m [0m[2m542[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.11.ls_1                â”‚ Identity                        â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m543[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.11.ln_2                â”‚ LayerNorm                       â”‚  1.5 K â”‚ train â”‚
â”‚[2m [0m[2m544[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.11.mlp                 â”‚ Sequential                      â”‚  4.7 M â”‚ train â”‚
â”‚[2m [0m[2m545[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.11.mlp.c_fc            â”‚ Linear                          â”‚  2.4 M â”‚ train â”‚
â”‚[2m [0m[2m546[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.11.mlp.gelu            â”‚ GELU                            â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m547[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.11.mlp.c_proj          â”‚ Linear                          â”‚  2.4 M â”‚ train â”‚
â”‚[2m [0m[2m548[0m[2m [0mâ”‚ net.model.text_decoder.resblocks.11.ls_2                â”‚ Identity                        â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m549[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn                       â”‚ ModuleList                      â”‚ 85.1 M â”‚ train â”‚
â”‚[2m [0m[2m550[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.0                     â”‚ ResidualAttentionBlock          â”‚  7.1 M â”‚ train â”‚
â”‚[2m [0m[2m551[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.0.ln_1                â”‚ LayerNorm                       â”‚  1.5 K â”‚ train â”‚
â”‚[2m [0m[2m552[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.0.attn                â”‚ MultiheadAttention              â”‚  2.4 M â”‚ train â”‚
â”‚[2m [0m[2m553[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.0.attn.out_proj       â”‚ NonDynamicallyQuantizableLinear â”‚  590 K â”‚ train â”‚
â”‚[2m [0m[2m554[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.0.ls_1                â”‚ Identity                        â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m555[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.0.ln_1_kv             â”‚ LayerNorm                       â”‚  1.5 K â”‚ train â”‚
â”‚[2m [0m[2m556[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.0.ln_2                â”‚ LayerNorm                       â”‚  1.5 K â”‚ train â”‚
â”‚[2m [0m[2m557[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.0.mlp                 â”‚ Sequential                      â”‚  4.7 M â”‚ train â”‚
â”‚[2m [0m[2m558[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.0.mlp.c_fc            â”‚ Linear                          â”‚  2.4 M â”‚ train â”‚
â”‚[2m [0m[2m559[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.0.mlp.gelu            â”‚ GELU                            â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m560[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.0.mlp.c_proj          â”‚ Linear                          â”‚  2.4 M â”‚ train â”‚
â”‚[2m [0m[2m561[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.0.ls_2                â”‚ Identity                        â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m562[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.1                     â”‚ ResidualAttentionBlock          â”‚  7.1 M â”‚ train â”‚
â”‚[2m [0m[2m563[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.1.ln_1                â”‚ LayerNorm                       â”‚  1.5 K â”‚ train â”‚
â”‚[2m [0m[2m564[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.1.attn                â”‚ MultiheadAttention              â”‚  2.4 M â”‚ train â”‚
â”‚[2m [0m[2m565[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.1.attn.out_proj       â”‚ NonDynamicallyQuantizableLinear â”‚  590 K â”‚ train â”‚
â”‚[2m [0m[2m566[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.1.ls_1                â”‚ Identity                        â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m567[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.1.ln_1_kv             â”‚ LayerNorm                       â”‚  1.5 K â”‚ train â”‚
â”‚[2m [0m[2m568[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.1.ln_2                â”‚ LayerNorm                       â”‚  1.5 K â”‚ train â”‚
â”‚[2m [0m[2m569[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.1.mlp                 â”‚ Sequential                      â”‚  4.7 M â”‚ train â”‚
â”‚[2m [0m[2m570[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.1.mlp.c_fc            â”‚ Linear                          â”‚  2.4 M â”‚ train â”‚
â”‚[2m [0m[2m571[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.1.mlp.gelu            â”‚ GELU                            â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m572[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.1.mlp.c_proj          â”‚ Linear                          â”‚  2.4 M â”‚ train â”‚
â”‚[2m [0m[2m573[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.1.ls_2                â”‚ Identity                        â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m574[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.2                     â”‚ ResidualAttentionBlock          â”‚  7.1 M â”‚ train â”‚
â”‚[2m [0m[2m575[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.2.ln_1                â”‚ LayerNorm                       â”‚  1.5 K â”‚ train â”‚
â”‚[2m [0m[2m576[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.2.attn                â”‚ MultiheadAttention              â”‚  2.4 M â”‚ train â”‚
â”‚[2m [0m[2m577[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.2.attn.out_proj       â”‚ NonDynamicallyQuantizableLinear â”‚  590 K â”‚ train â”‚
â”‚[2m [0m[2m578[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.2.ls_1                â”‚ Identity                        â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m579[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.2.ln_1_kv             â”‚ LayerNorm                       â”‚  1.5 K â”‚ train â”‚
â”‚[2m [0m[2m580[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.2.ln_2                â”‚ LayerNorm                       â”‚  1.5 K â”‚ train â”‚
â”‚[2m [0m[2m581[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.2.mlp                 â”‚ Sequential                      â”‚  4.7 M â”‚ train â”‚
â”‚[2m [0m[2m582[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.2.mlp.c_fc            â”‚ Linear                          â”‚  2.4 M â”‚ train â”‚
â”‚[2m [0m[2m583[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.2.mlp.gelu            â”‚ GELU                            â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m584[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.2.mlp.c_proj          â”‚ Linear                          â”‚  2.4 M â”‚ train â”‚
â”‚[2m [0m[2m585[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.2.ls_2                â”‚ Identity                        â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m586[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.3                     â”‚ ResidualAttentionBlock          â”‚  7.1 M â”‚ train â”‚
â”‚[2m [0m[2m587[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.3.ln_1                â”‚ LayerNorm                       â”‚  1.5 K â”‚ train â”‚
â”‚[2m [0m[2m588[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.3.attn                â”‚ MultiheadAttention              â”‚  2.4 M â”‚ train â”‚
â”‚[2m [0m[2m589[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.3.attn.out_proj       â”‚ NonDynamicallyQuantizableLinear â”‚  590 K â”‚ train â”‚
â”‚[2m [0m[2m590[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.3.ls_1                â”‚ Identity                        â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m591[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.3.ln_1_kv             â”‚ LayerNorm                       â”‚  1.5 K â”‚ train â”‚
â”‚[2m [0m[2m592[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.3.ln_2                â”‚ LayerNorm                       â”‚  1.5 K â”‚ train â”‚
â”‚[2m [0m[2m593[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.3.mlp                 â”‚ Sequential                      â”‚  4.7 M â”‚ train â”‚
â”‚[2m [0m[2m594[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.3.mlp.c_fc            â”‚ Linear                          â”‚  2.4 M â”‚ train â”‚
â”‚[2m [0m[2m595[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.3.mlp.gelu            â”‚ GELU                            â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m596[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.3.mlp.c_proj          â”‚ Linear                          â”‚  2.4 M â”‚ train â”‚
â”‚[2m [0m[2m597[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.3.ls_2                â”‚ Identity                        â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m598[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.4                     â”‚ ResidualAttentionBlock          â”‚  7.1 M â”‚ train â”‚
â”‚[2m [0m[2m599[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.4.ln_1                â”‚ LayerNorm                       â”‚  1.5 K â”‚ train â”‚
â”‚[2m [0m[2m600[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.4.attn                â”‚ MultiheadAttention              â”‚  2.4 M â”‚ train â”‚
â”‚[2m [0m[2m601[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.4.attn.out_proj       â”‚ NonDynamicallyQuantizableLinear â”‚  590 K â”‚ train â”‚
â”‚[2m [0m[2m602[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.4.ls_1                â”‚ Identity                        â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m603[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.4.ln_1_kv             â”‚ LayerNorm                       â”‚  1.5 K â”‚ train â”‚
â”‚[2m [0m[2m604[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.4.ln_2                â”‚ LayerNorm                       â”‚  1.5 K â”‚ train â”‚
â”‚[2m [0m[2m605[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.4.mlp                 â”‚ Sequential                      â”‚  4.7 M â”‚ train â”‚
â”‚[2m [0m[2m606[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.4.mlp.c_fc            â”‚ Linear                          â”‚  2.4 M â”‚ train â”‚
â”‚[2m [0m[2m607[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.4.mlp.gelu            â”‚ GELU                            â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m608[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.4.mlp.c_proj          â”‚ Linear                          â”‚  2.4 M â”‚ train â”‚
â”‚[2m [0m[2m609[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.4.ls_2                â”‚ Identity                        â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m610[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.5                     â”‚ ResidualAttentionBlock          â”‚  7.1 M â”‚ train â”‚
â”‚[2m [0m[2m611[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.5.ln_1                â”‚ LayerNorm                       â”‚  1.5 K â”‚ train â”‚
â”‚[2m [0m[2m612[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.5.attn                â”‚ MultiheadAttention              â”‚  2.4 M â”‚ train â”‚
â”‚[2m [0m[2m613[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.5.attn.out_proj       â”‚ NonDynamicallyQuantizableLinear â”‚  590 K â”‚ train â”‚
â”‚[2m [0m[2m614[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.5.ls_1                â”‚ Identity                        â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m615[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.5.ln_1_kv             â”‚ LayerNorm                       â”‚  1.5 K â”‚ train â”‚
â”‚[2m [0m[2m616[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.5.ln_2                â”‚ LayerNorm                       â”‚  1.5 K â”‚ train â”‚
â”‚[2m [0m[2m617[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.5.mlp                 â”‚ Sequential                      â”‚  4.7 M â”‚ train â”‚
â”‚[2m [0m[2m618[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.5.mlp.c_fc            â”‚ Linear                          â”‚  2.4 M â”‚ train â”‚
â”‚[2m [0m[2m619[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.5.mlp.gelu            â”‚ GELU                            â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m620[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.5.mlp.c_proj          â”‚ Linear                          â”‚  2.4 M â”‚ train â”‚
â”‚[2m [0m[2m621[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.5.ls_2                â”‚ Identity                        â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m622[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.6                     â”‚ ResidualAttentionBlock          â”‚  7.1 M â”‚ train â”‚
â”‚[2m [0m[2m623[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.6.ln_1                â”‚ LayerNorm                       â”‚  1.5 K â”‚ train â”‚
â”‚[2m [0m[2m624[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.6.attn                â”‚ MultiheadAttention              â”‚  2.4 M â”‚ train â”‚
â”‚[2m [0m[2m625[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.6.attn.out_proj       â”‚ NonDynamicallyQuantizableLinear â”‚  590 K â”‚ train â”‚
â”‚[2m [0m[2m626[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.6.ls_1                â”‚ Identity                        â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m627[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.6.ln_1_kv             â”‚ LayerNorm                       â”‚  1.5 K â”‚ train â”‚
â”‚[2m [0m[2m628[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.6.ln_2                â”‚ LayerNorm                       â”‚  1.5 K â”‚ train â”‚
â”‚[2m [0m[2m629[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.6.mlp                 â”‚ Sequential                      â”‚  4.7 M â”‚ train â”‚
â”‚[2m [0m[2m630[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.6.mlp.c_fc            â”‚ Linear                          â”‚  2.4 M â”‚ train â”‚
â”‚[2m [0m[2m631[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.6.mlp.gelu            â”‚ GELU                            â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m632[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.6.mlp.c_proj          â”‚ Linear                          â”‚  2.4 M â”‚ train â”‚
â”‚[2m [0m[2m633[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.6.ls_2                â”‚ Identity                        â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m634[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.7                     â”‚ ResidualAttentionBlock          â”‚  7.1 M â”‚ train â”‚
â”‚[2m [0m[2m635[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.7.ln_1                â”‚ LayerNorm                       â”‚  1.5 K â”‚ train â”‚
â”‚[2m [0m[2m636[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.7.attn                â”‚ MultiheadAttention              â”‚  2.4 M â”‚ train â”‚
â”‚[2m [0m[2m637[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.7.attn.out_proj       â”‚ NonDynamicallyQuantizableLinear â”‚  590 K â”‚ train â”‚
â”‚[2m [0m[2m638[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.7.ls_1                â”‚ Identity                        â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m639[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.7.ln_1_kv             â”‚ LayerNorm                       â”‚  1.5 K â”‚ train â”‚
â”‚[2m [0m[2m640[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.7.ln_2                â”‚ LayerNorm                       â”‚  1.5 K â”‚ train â”‚
â”‚[2m [0m[2m641[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.7.mlp                 â”‚ Sequential                      â”‚  4.7 M â”‚ train â”‚
â”‚[2m [0m[2m642[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.7.mlp.c_fc            â”‚ Linear                          â”‚  2.4 M â”‚ train â”‚
â”‚[2m [0m[2m643[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.7.mlp.gelu            â”‚ GELU                            â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m644[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.7.mlp.c_proj          â”‚ Linear                          â”‚  2.4 M â”‚ train â”‚
â”‚[2m [0m[2m645[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.7.ls_2                â”‚ Identity                        â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m646[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.8                     â”‚ ResidualAttentionBlock          â”‚  7.1 M â”‚ train â”‚
â”‚[2m [0m[2m647[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.8.ln_1                â”‚ LayerNorm                       â”‚  1.5 K â”‚ train â”‚
â”‚[2m [0m[2m648[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.8.attn                â”‚ MultiheadAttention              â”‚  2.4 M â”‚ train â”‚
â”‚[2m [0m[2m649[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.8.attn.out_proj       â”‚ NonDynamicallyQuantizableLinear â”‚  590 K â”‚ train â”‚
â”‚[2m [0m[2m650[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.8.ls_1                â”‚ Identity                        â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m651[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.8.ln_1_kv             â”‚ LayerNorm                       â”‚  1.5 K â”‚ train â”‚
â”‚[2m [0m[2m652[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.8.ln_2                â”‚ LayerNorm                       â”‚  1.5 K â”‚ train â”‚
â”‚[2m [0m[2m653[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.8.mlp                 â”‚ Sequential                      â”‚  4.7 M â”‚ train â”‚
â”‚[2m [0m[2m654[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.8.mlp.c_fc            â”‚ Linear                          â”‚  2.4 M â”‚ train â”‚
â”‚[2m [0m[2m655[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.8.mlp.gelu            â”‚ GELU                            â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m656[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.8.mlp.c_proj          â”‚ Linear                          â”‚  2.4 M â”‚ train â”‚
â”‚[2m [0m[2m657[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.8.ls_2                â”‚ Identity                        â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m658[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.9                     â”‚ ResidualAttentionBlock          â”‚  7.1 M â”‚ train â”‚
â”‚[2m [0m[2m659[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.9.ln_1                â”‚ LayerNorm                       â”‚  1.5 K â”‚ train â”‚
â”‚[2m [0m[2m660[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.9.attn                â”‚ MultiheadAttention              â”‚  2.4 M â”‚ train â”‚
â”‚[2m [0m[2m661[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.9.attn.out_proj       â”‚ NonDynamicallyQuantizableLinear â”‚  590 K â”‚ train â”‚
â”‚[2m [0m[2m662[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.9.ls_1                â”‚ Identity                        â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m663[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.9.ln_1_kv             â”‚ LayerNorm                       â”‚  1.5 K â”‚ train â”‚
â”‚[2m [0m[2m664[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.9.ln_2                â”‚ LayerNorm                       â”‚  1.5 K â”‚ train â”‚
â”‚[2m [0m[2m665[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.9.mlp                 â”‚ Sequential                      â”‚  4.7 M â”‚ train â”‚
â”‚[2m [0m[2m666[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.9.mlp.c_fc            â”‚ Linear                          â”‚  2.4 M â”‚ train â”‚
â”‚[2m [0m[2m667[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.9.mlp.gelu            â”‚ GELU                            â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m668[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.9.mlp.c_proj          â”‚ Linear                          â”‚  2.4 M â”‚ train â”‚
â”‚[2m [0m[2m669[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.9.ls_2                â”‚ Identity                        â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m670[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.10                    â”‚ ResidualAttentionBlock          â”‚  7.1 M â”‚ train â”‚
â”‚[2m [0m[2m671[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.10.ln_1               â”‚ LayerNorm                       â”‚  1.5 K â”‚ train â”‚
â”‚[2m [0m[2m672[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.10.attn               â”‚ MultiheadAttention              â”‚  2.4 M â”‚ train â”‚
â”‚[2m [0m[2m673[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.10.attn.out_proj      â”‚ NonDynamicallyQuantizableLinear â”‚  590 K â”‚ train â”‚
â”‚[2m [0m[2m674[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.10.ls_1               â”‚ Identity                        â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m675[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.10.ln_1_kv            â”‚ LayerNorm                       â”‚  1.5 K â”‚ train â”‚
â”‚[2m [0m[2m676[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.10.ln_2               â”‚ LayerNorm                       â”‚  1.5 K â”‚ train â”‚
â”‚[2m [0m[2m677[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.10.mlp                â”‚ Sequential                      â”‚  4.7 M â”‚ train â”‚
â”‚[2m [0m[2m678[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.10.mlp.c_fc           â”‚ Linear                          â”‚  2.4 M â”‚ train â”‚
â”‚[2m [0m[2m679[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.10.mlp.gelu           â”‚ GELU                            â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m680[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.10.mlp.c_proj         â”‚ Linear                          â”‚  2.4 M â”‚ train â”‚
â”‚[2m [0m[2m681[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.10.ls_2               â”‚ Identity                        â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m682[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.11                    â”‚ ResidualAttentionBlock          â”‚  7.1 M â”‚ train â”‚
â”‚[2m [0m[2m683[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.11.ln_1               â”‚ LayerNorm                       â”‚  1.5 K â”‚ train â”‚
â”‚[2m [0m[2m684[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.11.attn               â”‚ MultiheadAttention              â”‚  2.4 M â”‚ train â”‚
â”‚[2m [0m[2m685[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.11.attn.out_proj      â”‚ NonDynamicallyQuantizableLinear â”‚  590 K â”‚ train â”‚
â”‚[2m [0m[2m686[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.11.ls_1               â”‚ Identity                        â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m687[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.11.ln_1_kv            â”‚ LayerNorm                       â”‚  1.5 K â”‚ train â”‚
â”‚[2m [0m[2m688[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.11.ln_2               â”‚ LayerNorm                       â”‚  1.5 K â”‚ train â”‚
â”‚[2m [0m[2m689[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.11.mlp                â”‚ Sequential                      â”‚  4.7 M â”‚ train â”‚
â”‚[2m [0m[2m690[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.11.mlp.c_fc           â”‚ Linear                          â”‚  2.4 M â”‚ train â”‚
â”‚[2m [0m[2m691[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.11.mlp.gelu           â”‚ GELU                            â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m692[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.11.mlp.c_proj         â”‚ Linear                          â”‚  2.4 M â”‚ train â”‚
â”‚[2m [0m[2m693[0m[2m [0mâ”‚ net.model.text_decoder.cross_attn.11.ls_2               â”‚ Identity                        â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m694[0m[2m [0mâ”‚ net.model.text_decoder.ln_final                         â”‚ LayerNorm                       â”‚  1.5 K â”‚ train â”‚
â”‚[2m [0m[2m695[0m[2m [0mâ”‚ net.tta_loss                                            â”‚ ByolLoss                        â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m696[0m[2m [0mâ”‚ net.video_proj                                          â”‚ VideoProjector                  â”‚  591 K â”‚ train â”‚
â”‚[2m [0m[2m697[0m[2m [0mâ”‚ net.video_proj.transform                                â”‚ Sequential                      â”‚  1.5 K â”‚ train â”‚
â”‚[2m [0m[2m698[0m[2m [0mâ”‚ net.video_proj.transform.0                              â”‚ LayerNorm                       â”‚  1.5 K â”‚ train â”‚
â”‚[2m [0m[2m699[0m[2m [0mâ”‚ net.video_proj.transform.1                              â”‚ Dropout                         â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m700[0m[2m [0mâ”‚ net.fusion                                              â”‚ Fusion                          â”‚  6.2 K â”‚ train â”‚
â”‚[2m [0m[2m701[0m[2m [0mâ”‚ net.fusion.attn                                         â”‚ Sequential                      â”‚  6.2 K â”‚ train â”‚
â”‚[2m [0m[2m702[0m[2m [0mâ”‚ net.fusion.attn.0                                       â”‚ Linear                          â”‚  6.1 K â”‚ train â”‚
â”‚[2m [0m[2m703[0m[2m [0mâ”‚ net.fusion.attn.1                                       â”‚ Linear                          â”‚     10 â”‚ train â”‚
â”‚[2m [0m[2m704[0m[2m [0mâ”‚ net.fusion.attn.2                                       â”‚ Softmax                         â”‚      0 â”‚ train â”‚
â”‚[2m [0m[2m705[0m[2m [0mâ”‚ binary_acc                                              â”‚ BinaryAccuracy                  â”‚      0 â”‚ train â”‚
â””â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”˜
[1mTrainable params[0m: 1.2 M
[1mNon-trainable params[0m: 637 M
[1mTotal params[0m: 639 M
[1mTotal estimated model params size (MB)[0m: 2.6 K
[1mModules in train mode[0m: 706
[1mModules in eval mode[0m: 0
/home/def/miniforge3/envs/fewshot/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:425: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.
`Trainer.fit` stopped: `max_epochs=0` reached.
[[36m2025-02-14 01:09:24,283[0m][[34m__main__[0m][[32mINFO[0m] - Starting testing![0m
[[36m2025-02-14 01:09:24,284[0m][[34m__main__[0m][[33mWARNING[0m] - Best ckpt not found! Using current weights for testing...[0m
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
/home/def/miniforge3/envs/fewshot/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:425: The 'test_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.
[2KStart testing...
[2KAttention weights: tensor([[0.5582, 0.4418],â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 0/203 [2m0:00:00 â€¢ -:--:--[0m [2;4m0.00it/s[0m  
        [0.5540, 0.4460],
        [0.5547, 0.4453],
        [0.5570, 0.4430],
        [0.5559, 0.4441],
        [0.5534, 0.4466],
        [0.5526, 0.4474],
        [0.5577, 0.4423],
        [0.5582, 0.4418],
[2K        [0.5555, 0.4445]], device='cuda:0', grad_fn=<SoftmaxBackward0>):00:00 â€¢ -:--:--[0m [2;4m0.00it/s[0m  
[2K/home/def/fewshot/src/models/components/tt_method.py:317: UserWarning: The use of `x.T` on tensors of dimension other than 2
to reverse their shape is deprecated and it will throw an error in a future release. Consider `x.mT` to transpose batches of
matrices or `x.permute(*torch.arange(x.ndim - 1, -1, -1))` to reverse the dimensions of a tensor. (Triggered internally at
../aten/src/ATen/native/TensorShape.cpp:3683.)
  dot_product = (x @ y.T)
[2KClass label: HighJumpâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 0/203 [2m0:00:00 â€¢ -:--:--[0m [2;4m0.00it/s[0m  
[2KAttention weights: tensor([[0.5939, 0.4061]], device='cuda:0', grad_fn=<SoftmaxBackward0>)m [2;4m0.00it/s[0m  
[2KStep 0 - TTA Loss: 0.6590â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 0/203 [2m0:00:00 â€¢ -:--:--[0m [2;4m0.00it/s[0m  
[2KAttention weights: tensor([[0.6231, 0.3769]], device='cuda:0', grad_fn=<SoftmaxBackward0>)m [2;4m0.00it/s[0m  
[2KAttention weights: tensor([[0.5936, 0.4064]], device='cuda:0', grad_fn=<SoftmaxBackward0>)m [2;4m0.00it/s[0m  
[2KAttention weights: tensor([[0.5362, 0.4638]], device='cuda:0', grad_fn=<SoftmaxBackward0>)m [2;4m0.00it/s[0m  
[2KAttention weights: tensor([[0.5000, 0.5000]], device='cuda:0', grad_fn=<SoftmaxBackward0>)m [2;4m0.00it/s[0m  
[2KAttention weights: tensor([[0.5214, 0.4786]], device='cuda:0', grad_fn=<SoftmaxBackward0>)m [2;4m0.00it/s[0m  
[2KAttention weights: tensor([[0.5520, 0.4480]], device='cuda:0', grad_fn=<SoftmaxBackward0>)m [2;4m0.00it/s[0m  
[2KAttention weights: tensor([[0.5777, 0.4223]], device='cuda:0', grad_fn=<SoftmaxBackward0>)m [2;4m0.00it/s[0m  
[2KAttention weights: tensor([[0.5946, 0.4054]], device='cuda:0', grad_fn=<SoftmaxBackward0>)m [2;4m0.00it/s[0m  
[2KAttention weights: tensor([[0.6024, 0.3976]], device='cuda:0', grad_fn=<SoftmaxBackward0>)m [2;4m0.00it/s[0m  
[2KAttention weights: tensor([[0.5531, 0.4469]], device='cuda:0')203 [2m0:00:00 â€¢ -:--:--[0m [2;4m0.00it/s[0m  
[2KAttention weights: tensor([[0.6229, 0.3771],â”â”â”â”â”â”â”â”â”â”â”[0m 0/203 [2m0:00:00 â€¢ -:--:--[0m [2;4m0.00it/s[0m  
        [0.5882, 0.4118],
        [0.5712, 0.4288],
        [0.6349, 0.3651],
        [0.5929, 0.4071],
        [0.6045, 0.3955],
        [0.5564, 0.4436],
        [0.6437, 0.3563],
        [0.6527, 0.3473],
[2K        [0.6427, 0.3573]], device='cuda:0')â”â”â”â”â”â”â”â”â”â”â”â”[0m 0/203 [2m0:00:00 â€¢ -:--:--[0m [2;4m0.00it/s[0m  
[2KAttention weights: tensor([[0.5582, 0.4418],â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 1/203 [2m0:00:02 â€¢ -:--:--[0m [2;4m0.00it/s[0m  
        [0.5540, 0.4460],
        [0.5547, 0.4453],
        [0.5570, 0.4430],
        [0.5559, 0.4441],
        [0.5534, 0.4466],
        [0.5526, 0.4474],
        [0.5577, 0.4423],
        [0.5582, 0.4418],
[2K        [0.5555, 0.4445]], device='cuda:0', grad_fn=<SoftmaxBackward0>):00:02 â€¢ -:--:--[0m [2;4m0.00it/s[0m  
[2KClass label: HighJumpâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 1/203 [2m0:00:02 â€¢ -:--:--[0m [2;4m0.00it/s[0m  
[2KAttention weights: tensor([[0.5913, 0.4087]], device='cuda:0', grad_fn=<SoftmaxBackward0>)m [2;4m0.00it/s[0m  
[2KStep 0 - TTA Loss: 0.8538â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 1/203 [2m0:00:02 â€¢ -:--:--[0m [2;4m0.00it/s[0m  
[2KAttention weights: tensor([[0.5913, 0.4087]], device='cuda:0', grad_fn=<SoftmaxBackward0>)m [2;4m0.00it/s[0m  
[2KAttention weights: tensor([[0.5932, 0.4068]], device='cuda:0', grad_fn=<SoftmaxBackward0>)m [2;4m0.00it/s[0m  
[2KAttention weights: tensor([[0.6000, 0.4000]], device='cuda:0', grad_fn=<SoftmaxBackward0>)m [2;4m0.00it/s[0m  
[2KAttention weights: tensor([[0.6138, 0.3862]], device='cuda:0', grad_fn=<SoftmaxBackward0>)m [2;4m0.00it/s[0m  
[2KAttention weights: tensor([[0.6347, 0.3653]], device='cuda:0', grad_fn=<SoftmaxBackward0>)m [2;4m0.00it/s[0m  
[2KAttention weights: tensor([[0.6627, 0.3373]], device='cuda:0', grad_fn=<SoftmaxBackward0>)m [2;4m0.00it/s[0m  
[2KAttention weights: tensor([[0.6903, 0.3097]], device='cuda:0', grad_fn=<SoftmaxBackward0>)m [2;4m0.00it/s[0m  
[2KAttention weights: tensor([[0.7105, 0.2895]], device='cuda:0', grad_fn=<SoftmaxBackward0>)m [2;4m0.00it/s[0m  
[2KAttention weights: tensor([[0.7179, 0.2821]], device='cuda:0', grad_fn=<SoftmaxBackward0>)m [2;4m0.00it/s[0m  
[2KAttention weights: tensor([[0.5555, 0.4445]], device='cuda:0')203 [2m0:00:02 â€¢ -:--:--[0m [2;4m0.00it/s[0m  
[2KAttention weights: tensor([[0.7009, 0.2991],â”â”â”â”â”â”â”â”â”â”â”[0m 1/203 [2m0:00:02 â€¢ -:--:--[0m [2;4m0.00it/s[0m  
        [0.6387, 0.3613],
        [0.6445, 0.3555],
        [0.7022, 0.2978],
        [0.6850, 0.3150],
        [0.7123, 0.2877],
        [0.6557, 0.3443],
        [0.7177, 0.2823],
        [0.7203, 0.2797],
[2K        [0.7263, 0.2737]], device='cuda:0')â”â”â”â”â”â”â”â”â”â”â”â”[0m 1/203 [2m0:00:02 â€¢ -:--:--[0m [2;4m0.00it/s[0m  
[2KAttention weights: tensor([[0.5582, 0.4418],â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 2/203 [2m0:00:04 â€¢ 0:05:27[0m [2;4m0.61it/s[0m  
        [0.5540, 0.4460],
        [0.5547, 0.4453],
        [0.5570, 0.4430],
        [0.5559, 0.4441],
        [0.5533, 0.4467],
        [0.5526, 0.4474],
        [0.5577, 0.4423],
        [0.5582, 0.4418],
[2K        [0.5555, 0.4445]], device='cuda:0', grad_fn=<SoftmaxBackward0>):00:04 â€¢ 0:05:27[0m [2;4m0.61it/s[0m  
[2KClass label: TennisSwingâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 2/203 [2m0:00:04 â€¢ 0:05:27[0m [2;4m0.61it/s[0m  
[2KAttention weights: tensor([[0.6455, 0.3545]], device='cuda:0', grad_fn=<SoftmaxBackward0>)m [2;4m0.61it/s[0m  
[2KStep 0 - TTA Loss: 0.5517â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 2/203 [2m0:00:04 â€¢ 0:05:27[0m [2;4m0.61it/s[0m  
[2KAttention weights: tensor([[0.6361, 0.3639]], device='cuda:0', grad_fn=<SoftmaxBackward0>)m [2;4m0.61it/s[0m  
[2KAttention weights: tensor([[0.6188, 0.3812]], device='cuda:0', grad_fn=<SoftmaxBackward0>)m [2;4m0.61it/s[0m  
[2KAttention weights: tensor([[0.5962, 0.4038]], device='cuda:0', grad_fn=<SoftmaxBackward0>)m [2;4m0.61it/s[0m  
[2KAttention weights: tensor([[0.5711, 0.4289]], device='cuda:0', grad_fn=<SoftmaxBackward0>)m [2;4m0.61it/s[0m  
[2KAttention weights: tensor([[0.5478, 0.4522]], device='cuda:0', grad_fn=<SoftmaxBackward0>)m [2;4m0.61it/s[0m  
[2KAttention weights: tensor([[0.5311, 0.4689]], device='cuda:0', grad_fn=<SoftmaxBackward0>)m [2;4m0.61it/s[0m  
[2KAttention weights: tensor([[0.5212, 0.4788]], device='cuda:0', grad_fn=<SoftmaxBackward0>)m [2;4m0.61it/s[0m  
[2KAttention weights: tensor([[0.5181, 0.4819]], device='cuda:0', grad_fn=<SoftmaxBackward0>)m [2;4m0.61it/s[0m  
[2KAttention weights: tensor([[0.5172, 0.4828]], device='cuda:0', grad_fn=<SoftmaxBackward0>)m [2;4m0.61it/s[0m  
[2KAttention weights: tensor([[0.5538, 0.4462]], device='cuda:0')203 [2m0:00:04 â€¢ 0:05:27[0m [2;4m0.61it/s[0m  
[2KAttention weights: tensor([[0.5226, 0.4774],â”â”â”â”â”â”â”â”â”â”â”[0m 2/203 [2m0:00:04 â€¢ 0:05:27[0m [2;4m0.61it/s[0m  
        [0.5097, 0.4903],
        [0.5026, 0.4974],
        [0.5394, 0.4606],
        [0.5021, 0.4979],
        [0.5099, 0.4901],
        [0.4852, 0.5148],
        [0.5709, 0.4291],
        [0.5171, 0.4829],
[2K        [0.5479, 0.4521]], device='cuda:0')â”â”â”â”â”â”â”â”â”â”â”â”[0m 2/203 [2m0:00:04 â€¢ 0:05:27[0m [2;4m0.61it/s[0m  
[2KAttention weights: tensor([[0.5580, 0.4420],â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 3/203 [2m0:00:05 â€¢ 0:04:34[0m [2;4m0.73it/s[0m  
        [0.5538, 0.4462],
        [0.5546, 0.4454],
        [0.5568, 0.4432],
        [0.5557, 0.4443],
        [0.5532, 0.4468],
        [0.5524, 0.4476],
        [0.5576, 0.4424],
        [0.5580, 0.4420],
[2K        [0.5553, 0.4447]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”[0m 3/203 [2m0:00:05 â€¢ 0:04:34[0m [2;4m0.73it/s[0m  
[2KClass label: HighJump[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 3/203 [2m0:00:05 â€¢ 0:04:34[0m [2;4m0.73it/s[0m  
[2KAttention weights: tensor([[0.5927, 0.4073]], device='cuda:0', grad_fn=<SoftmaxBackward0>)0:00:05 â€¢ 0:04:34[0m [2;4m0.73it/s[0m  
[2KStep 0 - TTA Loss: 0.5501[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 3/203 [2m0:00:05 â€¢ 0:04:34[0m [2;4m0.73it/s[0m  
[2KAttention weights: tensor([[0.5927, 0.4073]], device='cuda:0', grad_fn=<SoftmaxBackward0>)0:00:05 â€¢ 0:04:34[0m [2;4m0.73it/s[0m  
[2KAttention weights: tensor([[0.5934, 0.4066]], device='cuda:0', grad_fn=<SoftmaxBackward0>)0:00:05 â€¢ 0:04:34[0m [2;4m0.73it/s[0m  
[2KAttention weights: tensor([[0.5971, 0.4029]], device='cuda:0', grad_fn=<SoftmaxBackward0>)0:00:05 â€¢ 0:04:34[0m [2;4m0.73it/s[0m  
[2KAttention weights: tensor([[0.6063, 0.3937]], device='cuda:0', grad_fn=<SoftmaxBackward0>)0:00:05 â€¢ 0:04:34[0m [2;4m0.73it/s[0m  
[2KAttention weights: tensor([[0.6238, 0.3762]], device='cuda:0', grad_fn=<SoftmaxBackward0>)0:00:05 â€¢ 0:04:34[0m [2;4m0.73it/s[0m  
[2KAttention weights: tensor([[0.6510, 0.3490]], device='cuda:0', grad_fn=<SoftmaxBackward0>)0:00:05 â€¢ 0:04:34[0m [2;4m0.73it/s[0m  
[2KAttention weights: tensor([[0.6846, 0.3154]], device='cuda:0', grad_fn=<SoftmaxBackward0>)0:00:05 â€¢ 0:04:34[0m [2;4m0.73it/s[0m  
[2KAttention weights: tensor([[0.7177, 0.2823]], device='cuda:0', grad_fn=<SoftmaxBackward0>)0:00:05 â€¢ 0:04:34[0m [2;4m0.73it/s[0m  
[2KAttention weights: tensor([[0.7438, 0.2562]], device='cuda:0', grad_fn=<SoftmaxBackward0>)0:00:05 â€¢ 0:04:34[0m [2;4m0.73it/s[0m  
[2KAttention weights: tensor([[0.5576, 0.4424]], device='cuda:0')â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 3/203 [2m0:00:05 â€¢ 0:04:34[0m [2;4m0.73it/s[0m  
[2KAttention weights: tensor([[0.7445, 0.2555],â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 3/203 [2m0:00:05 â€¢ 0:04:34[0m [2;4m0.73it/s[0m  
        [0.6728, 0.3272],
        [0.6907, 0.3093],
        [0.7388, 0.2612],
        [0.7393, 0.2607],
        [0.7735, 0.2265],
        [0.7179, 0.2821],
        [0.7625, 0.2375],
        [0.7530, 0.2470],
[2K        [0.7742, 0.2258]], device='cuda:0')â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 3/203 [2m0:00:05 â€¢ 0:04:34[0m [2;4m0.73it/s[0m  
[2KAttention weights: tensor([[0.5580, 0.4420],â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 4/203 [2m0:00:13 â€¢ 0:12:12[0m [2;4m0.27it/s[0m  
        [0.5538, 0.4462],
        [0.5546, 0.4454],
        [0.5568, 0.4432],
        [0.5557, 0.4443],
        [0.5532, 0.4468],
        [0.5524, 0.4476],
        [0.5576, 0.4424],
        [0.5580, 0.4420],
[2K        [0.5553, 0.4447]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”[0m 4/203 [2m0:00:13 â€¢ 0:12:12[0m [2;4m0.27it/s[0m  
[2KClass label: GolfSwing[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 4/203 [2m0:00:13 â€¢ 0:12:12[0m [2;4m0.27it/s[0m  
[2KAttention weights: tensor([[0.6322, 0.3678]], device='cuda:0', grad_fn=<SoftmaxBackward0>)0:00:13 â€¢ 0:12:12[0m [2;4m0.27it/s[0m  
[2KStep 0 - TTA Loss: 0.8831[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 4/203 [2m0:00:13 â€¢ 0:12:12[0m [2;4m0.27it/s[0m  
[2KAttention weights: tensor([[0.6642, 0.3358]], device='cuda:0', grad_fn=<SoftmaxBackward0>)0:00:13 â€¢ 0:12:12[0m [2;4m0.27it/s[0m  
[2KAttention weights: tensor([[0.7011, 0.2989]], device='cuda:0', grad_fn=<SoftmaxBackward0>)0:00:13 â€¢ 0:12:12[0m [2;4m0.27it/s[0m  
[2KAttention weights: tensor([[0.7377, 0.2623]], device='cuda:0', grad_fn=<SoftmaxBackward0>)0:00:13 â€¢ 0:12:12[0m [2;4m0.27it/s[0m  
[2KAttention weights: tensor([[0.7652, 0.2348]], device='cuda:0', grad_fn=<SoftmaxBackward0>)0:00:13 â€¢ 0:12:12[0m [2;4m0.27it/s[0m  
[2KAttention weights: tensor([[0.7830, 0.2170]], device='cuda:0', grad_fn=<SoftmaxBackward0>)0:00:13 â€¢ 0:12:12[0m [2;4m0.27it/s[0m  
[2KAttention weights: tensor([[0.7924, 0.2076]], device='cuda:0', grad_fn=<SoftmaxBackward0>)0:00:13 â€¢ 0:12:12[0m [2;4m0.27it/s[0m  
[2KAttention weights: tensor([[0.7951, 0.2049]], device='cuda:0', grad_fn=<SoftmaxBackward0>)0:00:13 â€¢ 0:12:12[0m [2;4m0.27it/s[0m  
[2KAttention weights: tensor([[0.7938, 0.2062]], device='cuda:0', grad_fn=<SoftmaxBackward0>)0:00:13 â€¢ 0:12:12[0m [2;4m0.27it/s[0m  
[2KAttention weights: tensor([[0.7921, 0.2079]], device='cuda:0', grad_fn=<SoftmaxBackward0>)0:00:13 â€¢ 0:12:12[0m [2;4m0.27it/s[0m  
[2KAttention weights: tensor([[0.5620, 0.4380]], device='cuda:0')â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 4/203 [2m0:00:13 â€¢ 0:12:12[0m [2;4m0.27it/s[0m  
[2KAttention weights: tensor([[0.7797, 0.2203],â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 4/203 [2m0:00:13 â€¢ 0:12:12[0m [2;4m0.27it/s[0m  
        [0.6889, 0.3111],
        [0.7065, 0.2935],
        [0.7915, 0.2085],
        [0.7611, 0.2389],
        [0.7757, 0.2243],
        [0.7249, 0.2751],
        [0.7682, 0.2318],
        [0.7796, 0.2204],
[2K        [0.7965, 0.2035]], device='cuda:0')â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 4/203 [2m0:00:13 â€¢ 0:12:12[0m [2;4m0.27it/s[0m  
[2KAttention weights: tensor([[0.5580, 0.4420],â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 5/203 [2m0:00:14 â€¢ 0:09:38[0m [2;4m0.34it/s[0m  
        [0.5538, 0.4462],
        [0.5546, 0.4454],
        [0.5568, 0.4432],
        [0.5557, 0.4443],
        [0.5532, 0.4468],
        [0.5524, 0.4476],
        [0.5576, 0.4424],
        [0.5580, 0.4420],
[2K        [0.5553, 0.4447]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”[0m 5/203 [2m0:00:14 â€¢ 0:09:38[0m [2;4m0.34it/s[0m  
[2KClass label: HammerThrowm[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 5/203 [2m0:00:14 â€¢ 0:09:38[0m [2;4m0.34it/s[0m  
[2KAttention weights: tensor([[0.5864, 0.4136]], device='cuda:0', grad_fn=<SoftmaxBackward0>)0:00:14 â€¢ 0:09:38[0m [2;4m0.34it/s[0m  
[2KStep 0 - TTA Loss: 0.6650[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 5/203 [2m0:00:14 â€¢ 0:09:38[0m [2;4m0.34it/s[0m  
[2KAttention weights: tensor([[0.5864, 0.4136]], device='cuda:0', grad_fn=<SoftmaxBackward0>)0:00:14 â€¢ 0:09:38[0m [2;4m0.34it/s[0m  
[2KAttention weights: tensor([[0.5859, 0.4141]], device='cuda:0', grad_fn=<SoftmaxBackward0>)0:00:14 â€¢ 0:09:38[0m [2;4m0.34it/s[0m  
[2KAttention weights: tensor([[0.5837, 0.4163]], device='cuda:0', grad_fn=<SoftmaxBackward0>)0:00:14 â€¢ 0:09:38[0m [2;4m0.34it/s[0m  
[2KAttention weights: tensor([[0.5792, 0.4208]], device='cuda:0', grad_fn=<SoftmaxBackward0>)0:00:14 â€¢ 0:09:38[0m [2;4m0.34it/s[0m  
[2KAttention weights: tensor([[0.5711, 0.4289]], device='cuda:0', grad_fn=<SoftmaxBackward0>)0:00:14 â€¢ 0:09:38[0m [2;4m0.34it/s[0m  
[2KAttention weights: tensor([[0.5564, 0.4436]], device='cuda:0', grad_fn=<SoftmaxBackward0>)0:00:14 â€¢ 0:09:38[0m [2;4m0.34it/s[0m  
[2KAttention weights: tensor([[0.5316, 0.4684]], device='cuda:0', grad_fn=<SoftmaxBackward0>)0:00:14 â€¢ 0:09:38[0m [2;4m0.34it/s[0m  
[2KAttention weights: tensor([[0.4947, 0.5053]], device='cuda:0', grad_fn=<SoftmaxBackward0>)0:00:14 â€¢ 0:09:38[0m [2;4m0.34it/s[0m  
[2KAttention weights: tensor([[0.4470, 0.5530]], device='cuda:0', grad_fn=<SoftmaxBackward0>)0:00:14 â€¢ 0:09:38[0m [2;4m0.34it/s[0m  
[2KAttention weights: tensor([[0.5517, 0.4483]], device='cuda:0')â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 5/203 [2m0:00:14 â€¢ 0:09:38[0m [2;4m0.34it/s[0m  
[2KAttention weights: tensor([[0.4483, 0.5517],â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 5/203 [2m0:00:14 â€¢ 0:09:38[0m [2;4m0.34it/s[0m  
        [0.5001, 0.4999],
        [0.4461, 0.5539],
        [0.4506, 0.5494],
        [0.4032, 0.5968],
        [0.4765, 0.5235],
        [0.4316, 0.5684],
        [0.5296, 0.4704],
        [0.5191, 0.4809],
[2K        [0.4729, 0.5271]], device='cuda:0')â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 5/203 [2m0:00:14 â€¢ 0:09:38[0m [2;4m0.34it/s[0m  
[2KAttention weights: tensor([[0.5580, 0.4420],m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 6/203 [2m0:00:16 â€¢ 0:08:52[0m [2;4m0.37it/s[0m  
        [0.5538, 0.4462],
        [0.5546, 0.4454],
        [0.5568, 0.4432],
        [0.5558, 0.4442],
        [0.5532, 0.4468],
        [0.5524, 0.4476],
        [0.5576, 0.4424],
        [0.5580, 0.4420],
[2K        [0.5554, 0.4446]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 6/203 [2m0:00:16 â€¢ 0:08:52[0m [2;4m0.37it/s[0m  
[2KClass label: HammerThrowm[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 6/203 [2m0:00:16 â€¢ 0:08:52[0m [2;4m0.37it/s[0m  
[2KAttention weights: tensor([[0.5763, 0.4237]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 6/203 [2m0:00:16 â€¢ 0:08:52[0m [2;4m0.37it/s[0m  
[2KStep 0 - TTA Loss: 0.5819[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 6/203 [2m0:00:16 â€¢ 0:08:52[0m [2;4m0.37it/s[0m  
[2KAttention weights: tensor([[0.5395, 0.4605]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 6/203 [2m0:00:16 â€¢ 0:08:52[0m [2;4m0.37it/s[0m  
[2KAttention weights: tensor([[0.5070, 0.4930]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 6/203 [2m0:00:16 â€¢ 0:08:52[0m [2;4m0.37it/s[0m  
[2KAttention weights: tensor([[0.4780, 0.5220]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 6/203 [2m0:00:16 â€¢ 0:08:52[0m [2;4m0.37it/s[0m  
[2KAttention weights: tensor([[0.4515, 0.5485]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 6/203 [2m0:00:16 â€¢ 0:08:52[0m [2;4m0.37it/s[0m  
[2KAttention weights: tensor([[0.4287, 0.5713]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 6/203 [2m0:00:16 â€¢ 0:08:52[0m [2;4m0.37it/s[0m  
[2KAttention weights: tensor([[0.4142, 0.5858]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 6/203 [2m0:00:16 â€¢ 0:08:52[0m [2;4m0.37it/s[0m  
[2KAttention weights: tensor([[0.4076, 0.5924]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 6/203 [2m0:00:16 â€¢ 0:08:52[0m [2;4m0.37it/s[0m  
[2KAttention weights: tensor([[0.4041, 0.5959]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 6/203 [2m0:00:16 â€¢ 0:08:52[0m [2;4m0.37it/s[0m  
[2KAttention weights: tensor([[0.4034, 0.5966]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 6/203 [2m0:00:16 â€¢ 0:08:52[0m [2;4m0.37it/s[0m  
[2KAttention weights: tensor([[0.5518, 0.4482]], device='cuda:0')â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 6/203 [2m0:00:16 â€¢ 0:08:52[0m [2;4m0.37it/s[0m  
[2KAttention weights: tensor([[0.4571, 0.5429],8;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 6/203 [2m0:00:16 â€¢ 0:08:52[0m [2;4m0.37it/s[0m  
        [0.4978, 0.5022],
        [0.4456, 0.5544],
        [0.4685, 0.5315],
        [0.4033, 0.5967],
        [0.4699, 0.5301],
        [0.4278, 0.5722],
        [0.5242, 0.4758],
        [0.5226, 0.4774],
[2K        [0.4755, 0.5245]], device='cuda:0')38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 6/203 [2m0:00:16 â€¢ 0:08:52[0m [2;4m0.37it/s[0m  
[2KAttention weights: tensor([[0.5580, 0.4420],m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 7/203 [2m0:00:24 â€¢ 0:12:01[0m [2;4m0.27it/s[0m  
        [0.5538, 0.4462],
        [0.5546, 0.4454],
        [0.5568, 0.4432],
        [0.5558, 0.4442],
        [0.5532, 0.4468],
        [0.5524, 0.4476],
        [0.5576, 0.4424],
        [0.5580, 0.4420],
[2K        [0.5554, 0.4446]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 7/203 [2m0:00:24 â€¢ 0:12:01[0m [2;4m0.27it/s[0m  
[2KClass label: Billiards[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 7/203 [2m0:00:24 â€¢ 0:12:01[0m [2;4m0.27it/s[0m  
[2KAttention weights: tensor([[0.5795, 0.4205]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 7/203 [2m0:00:24 â€¢ 0:12:01[0m [2;4m0.27it/s[0m  
[2KStep 0 - TTA Loss: 0.4485[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 7/203 [2m0:00:24 â€¢ 0:12:01[0m [2;4m0.27it/s[0m  
[2KAttention weights: tensor([[0.5795, 0.4205]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 7/203 [2m0:00:24 â€¢ 0:12:01[0m [2;4m0.27it/s[0m  
[2KAttention weights: tensor([[0.5788, 0.4212]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 7/203 [2m0:00:24 â€¢ 0:12:01[0m [2;4m0.27it/s[0m  
[2KAttention weights: tensor([[0.5754, 0.4246]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 7/203 [2m0:00:24 â€¢ 0:12:01[0m [2;4m0.27it/s[0m  
[2KAttention weights: tensor([[0.5659, 0.4341]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 7/203 [2m0:00:24 â€¢ 0:12:01[0m [2;4m0.27it/s[0m  
[2KAttention weights: tensor([[0.5463, 0.4537]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 7/203 [2m0:00:24 â€¢ 0:12:01[0m [2;4m0.27it/s[0m  
[2KAttention weights: tensor([[0.5118, 0.4882]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 7/203 [2m0:00:24 â€¢ 0:12:01[0m [2;4m0.27it/s[0m  
[2KAttention weights: tensor([[0.4608, 0.5392]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 7/203 [2m0:00:24 â€¢ 0:12:01[0m [2;4m0.27it/s[0m  
[2KAttention weights: tensor([[0.4044, 0.5956]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 7/203 [2m0:00:24 â€¢ 0:12:01[0m [2;4m0.27it/s[0m  
[2KAttention weights: tensor([[0.3659, 0.6341]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 7/203 [2m0:00:24 â€¢ 0:12:01[0m [2;4m0.27it/s[0m  
[2KAttention weights: tensor([[0.5488, 0.4512]], device='cuda:0')â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 7/203 [2m0:00:24 â€¢ 0:12:01[0m [2;4m0.27it/s[0m  
[2KAttention weights: tensor([[0.5320, 0.4680],8;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 7/203 [2m0:00:24 â€¢ 0:12:01[0m [2;4m0.27it/s[0m  
        [0.3542, 0.6458],
        [0.4927, 0.5073],
        [0.5470, 0.4530],
        [0.5070, 0.4930],
        [0.5114, 0.4886],
        [0.4695, 0.5305],
        [0.5459, 0.4541],
        [0.5491, 0.4509],
[2K        [0.5547, 0.4453]], device='cuda:0')38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 7/203 [2m0:00:24 â€¢ 0:12:01[0m [2;4m0.27it/s[0m  
[2KAttention weights: tensor([[0.5580, 0.4420],mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 8/203 [2m0:00:26 â€¢ 0:11:11[0m [2;4m0.29it/s[0m  
        [0.5538, 0.4462],
        [0.5546, 0.4454],
        [0.5568, 0.4432],
        [0.5558, 0.4442],
        [0.5532, 0.4468],
        [0.5524, 0.4476],
        [0.5576, 0.4424],
        [0.5579, 0.4421],
[2K        [0.5554, 0.4446]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 8/203 [2m0:00:26 â€¢ 0:11:11[0m [2;4m0.29it/s[0m  
[2KClass label: BaseballPitch[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 8/203 [2m0:00:26 â€¢ 0:11:11[0m [2;4m0.29it/s[0m  
[2KAttention weights: tensor([[0.6111, 0.3889]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 8/203 [2m0:00:26 â€¢ 0:11:11[0m [2;4m0.29it/s[0m  
[2KStep 0 - TTA Loss: 0.7228[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 8/203 [2m0:00:26 â€¢ 0:11:11[0m [2;4m0.29it/s[0m  
[2KAttention weights: tensor([[0.6201, 0.3799]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 8/203 [2m0:00:26 â€¢ 0:11:11[0m [2;4m0.29it/s[0m  
[2KAttention weights: tensor([[0.6370, 0.3630]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 8/203 [2m0:00:26 â€¢ 0:11:11[0m [2;4m0.29it/s[0m  
[2KAttention weights: tensor([[0.6601, 0.3399]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 8/203 [2m0:00:26 â€¢ 0:11:11[0m [2;4m0.29it/s[0m  
[2KAttention weights: tensor([[0.6799, 0.3201]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 8/203 [2m0:00:26 â€¢ 0:11:11[0m [2;4m0.29it/s[0m  
[2KAttention weights: tensor([[0.6910, 0.3090]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 8/203 [2m0:00:26 â€¢ 0:11:11[0m [2;4m0.29it/s[0m  
[2KAttention weights: tensor([[0.6934, 0.3066]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 8/203 [2m0:00:26 â€¢ 0:11:11[0m [2;4m0.29it/s[0m  
[2KAttention weights: tensor([[0.6902, 0.3098]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 8/203 [2m0:00:26 â€¢ 0:11:11[0m [2;4m0.29it/s[0m  
[2KAttention weights: tensor([[0.6854, 0.3146]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 8/203 [2m0:00:26 â€¢ 0:11:11[0m [2;4m0.29it/s[0m  
[2KAttention weights: tensor([[0.6819, 0.3181]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 8/203 [2m0:00:26 â€¢ 0:11:11[0m [2;4m0.29it/s[0m  
[2KAttention weights: tensor([[0.5592, 0.4408]], device='cuda:0')â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 8/203 [2m0:00:26 â€¢ 0:11:11[0m [2;4m0.29it/s[0m  
[2KAttention weights: tensor([[0.6809, 0.3191],0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 8/203 [2m0:00:26 â€¢ 0:11:11[0m [2;4m0.29it/s[0m  
        [0.5572, 0.4428],
        [0.5786, 0.4214],
        [0.6648, 0.3352],
        [0.6215, 0.3785],
        [0.6201, 0.3799],
        [0.5709, 0.4291],
        [0.6608, 0.3392],
        [0.6709, 0.3291],
[2K        [0.6711, 0.3289]], device='cuda:0')[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 8/203 [2m0:00:26 â€¢ 0:11:11[0m [2;4m0.29it/s[0m  
[2KAttention weights: tensor([[0.5580, 0.4420],mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 9/203 [2m0:00:28 â€¢ 0:10:21[0m [2;4m0.31it/s[0m  
        [0.5537, 0.4463],
        [0.5546, 0.4454],
        [0.5568, 0.4432],
        [0.5558, 0.4442],
        [0.5532, 0.4468],
        [0.5524, 0.4476],
        [0.5576, 0.4424],
        [0.5579, 0.4421],
[2K        [0.5554, 0.4446]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 9/203 [2m0:00:28 â€¢ 0:10:21[0m [2;4m0.31it/s[0m  
[2KClass label: BaseballPitch[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 9/203 [2m0:00:28 â€¢ 0:10:21[0m [2;4m0.31it/s[0m  
[2KAttention weights: tensor([[0.6136, 0.3864]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 9/203 [2m0:00:28 â€¢ 0:10:21[0m [2;4m0.31it/s[0m  
[2KStep 0 - TTA Loss: 0.6530[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 9/203 [2m0:00:28 â€¢ 0:10:21[0m [2;4m0.31it/s[0m  
[2KAttention weights: tensor([[0.6136, 0.3864]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 9/203 [2m0:00:28 â€¢ 0:10:21[0m [2;4m0.31it/s[0m  
[2KAttention weights: tensor([[0.6132, 0.3868]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 9/203 [2m0:00:28 â€¢ 0:10:21[0m [2;4m0.31it/s[0m  
[2KAttention weights: tensor([[0.6128, 0.3872]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 9/203 [2m0:00:28 â€¢ 0:10:21[0m [2;4m0.31it/s[0m  
[2KAttention weights: tensor([[0.6134, 0.3866]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 9/203 [2m0:00:28 â€¢ 0:10:21[0m [2;4m0.31it/s[0m  
[2KAttention weights: tensor([[0.6165, 0.3835]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 9/203 [2m0:00:28 â€¢ 0:10:21[0m [2;4m0.31it/s[0m  
[2KAttention weights: tensor([[0.6198, 0.3802]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 9/203 [2m0:00:28 â€¢ 0:10:21[0m [2;4m0.31it/s[0m  
[2KAttention weights: tensor([[0.6186, 0.3814]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 9/203 [2m0:00:28 â€¢ 0:10:21[0m [2;4m0.31it/s[0m  
[2KAttention weights: tensor([[0.6098, 0.3902]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 9/203 [2m0:00:28 â€¢ 0:10:21[0m [2;4m0.31it/s[0m  
[2KAttention weights: tensor([[0.5940, 0.4060]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 9/203 [2m0:00:28 â€¢ 0:10:21[0m [2;4m0.31it/s[0m  
[2KAttention weights: tensor([[0.5565, 0.4435]], device='cuda:0')â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 9/203 [2m0:00:28 â€¢ 0:10:21[0m [2;4m0.31it/s[0m  
[2KAttention weights: tensor([[0.5844, 0.4156],0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 9/203 [2m0:00:28 â€¢ 0:10:21[0m [2;4m0.31it/s[0m  
        [0.5576, 0.4424],
        [0.5559, 0.4441],
        [0.6122, 0.3878],
        [0.5666, 0.4334],
        [0.5753, 0.4247],
        [0.5307, 0.4693],
        [0.6212, 0.3788],
        [0.6270, 0.3730],
[2K        [0.6142, 0.3858]], device='cuda:0')[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 9/203 [2m0:00:28 â€¢ 0:10:21[0m [2;4m0.31it/s[0m  
[2KAttention weights: tensor([[0.5579, 0.4421],mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 10/203 [2m0:00:29 â€¢ 0:09:27[0m [2;4m0.34it/s[0m  
        [0.5537, 0.4463],
        [0.5546, 0.4454],
        [0.5567, 0.4433],
        [0.5557, 0.4443],
        [0.5531, 0.4469],
        [0.5524, 0.4476],
        [0.5575, 0.4425],
        [0.5579, 0.4421],
[2K        [0.5553, 0.4447]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 10/203 [2m0:00:29 â€¢ 0:09:27[0m [2;4m0.34it/s[0m  
[2KClass label: TennisSwingm[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 10/203 [2m0:00:29 â€¢ 0:09:27[0m [2;4m0.34it/s[0m  
[2KAttention weights: tensor([[0.6446, 0.3554]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 10/203 [2m0:00:29 â€¢ 0:09:27[0m [2;4m0.34it/s[0m  
[2KStep 0 - TTA Loss: 0.4943[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 10/203 [2m0:00:29 â€¢ 0:09:27[0m [2;4m0.34it/s[0m  
[2KAttention weights: tensor([[0.6371, 0.3629]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 10/203 [2m0:00:29 â€¢ 0:09:27[0m [2;4m0.34it/s[0m  
[2KAttention weights: tensor([[0.6105, 0.3895]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 10/203 [2m0:00:29 â€¢ 0:09:27[0m [2;4m0.34it/s[0m  
[2KAttention weights: tensor([[0.5740, 0.4260]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 10/203 [2m0:00:29 â€¢ 0:09:27[0m [2;4m0.34it/s[0m  
[2KAttention weights: tensor([[0.5363, 0.4637]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 10/203 [2m0:00:29 â€¢ 0:09:27[0m [2;4m0.34it/s[0m  
[2KAttention weights: tensor([[0.5038, 0.4962]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 10/203 [2m0:00:29 â€¢ 0:09:27[0m [2;4m0.34it/s[0m  
[2KAttention weights: tensor([[0.4809, 0.5191]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 10/203 [2m0:00:29 â€¢ 0:09:27[0m [2;4m0.34it/s[0m  
[2KAttention weights: tensor([[0.4708, 0.5292]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 10/203 [2m0:00:29 â€¢ 0:09:27[0m [2;4m0.34it/s[0m  
[2KAttention weights: tensor([[0.4667, 0.5333]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 10/203 [2m0:00:29 â€¢ 0:09:27[0m [2;4m0.34it/s[0m  
[2KAttention weights: tensor([[0.4654, 0.5346]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 10/203 [2m0:00:29 â€¢ 0:09:27[0m [2;4m0.34it/s[0m  
[2KAttention weights: tensor([[0.5523, 0.4477]], device='cuda:0')â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 10/203 [2m0:00:29 â€¢ 0:09:27[0m [2;4m0.34it/s[0m  
[2KAttention weights: tensor([[0.4827, 0.5173],0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 10/203 [2m0:00:29 â€¢ 0:09:27[0m [2;4m0.34it/s[0m  
        [0.4894, 0.5106],
        [0.4846, 0.5154],
        [0.5054, 0.4946],
        [0.4805, 0.5195],
        [0.4872, 0.5128],
        [0.4736, 0.5264],
        [0.5504, 0.4496],
        [0.4652, 0.5348],
[2K        [0.5179, 0.4821]], device='cuda:0')[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 10/203 [2m0:00:29 â€¢ 0:09:27[0m [2;4m0.34it/s[0m  
[2KAttention weights: tensor([[0.5578, 0.4422],0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 11/203 [2m0:00:30 â€¢ 0:08:45[0m [2;4m0.37it/s[0m   
        [0.5536, 0.4464],
        [0.5545, 0.4455],
        [0.5566, 0.4434],
        [0.5557, 0.4443],
        [0.5531, 0.4469],
        [0.5523, 0.4477],
        [0.5574, 0.4426],
        [0.5578, 0.4422],
[2K        [0.5552, 0.4448]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 11/203 [2m0:00:30 â€¢ 0:08:45[0m [2;4m0.37it/s[0m  
[2KClass label: HammerThrow0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 11/203 [2m0:00:30 â€¢ 0:08:45[0m [2;4m0.37it/s[0m  
[2KAttention weights: tensor([[0.5813, 0.4187]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 11/203 [2m0:00:30 â€¢ 0:08:45[0m [2;4m0.37it/s[0m  
[2KStep 0 - TTA Loss: 0.6308m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 11/203 [2m0:00:30 â€¢ 0:08:45[0m [2;4m0.37it/s[0m  
[2KAttention weights: tensor([[0.5813, 0.4187]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 11/203 [2m0:00:30 â€¢ 0:08:45[0m [2;4m0.37it/s[0m  
[2KAttention weights: tensor([[0.5817, 0.4183]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 11/203 [2m0:00:30 â€¢ 0:08:45[0m [2;4m0.37it/s[0m  
[2KAttention weights: tensor([[0.5842, 0.4158]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 11/203 [2m0:00:30 â€¢ 0:08:45[0m [2;4m0.37it/s[0m  
[2KAttention weights: tensor([[0.5906, 0.4094]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 11/203 [2m0:00:30 â€¢ 0:08:45[0m [2;4m0.37it/s[0m  
[2KAttention weights: tensor([[0.6026, 0.3974]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 11/203 [2m0:00:30 â€¢ 0:08:45[0m [2;4m0.37it/s[0m  
[2KAttention weights: tensor([[0.6198, 0.3802]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 11/203 [2m0:00:30 â€¢ 0:08:45[0m [2;4m0.37it/s[0m  
[2KAttention weights: tensor([[0.6389, 0.3611]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 11/203 [2m0:00:30 â€¢ 0:08:45[0m [2;4m0.37it/s[0m  
[2KAttention weights: tensor([[0.6534, 0.3466]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 11/203 [2m0:00:30 â€¢ 0:08:45[0m [2;4m0.37it/s[0m  
[2KAttention weights: tensor([[0.6565, 0.3435]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 11/203 [2m0:00:30 â€¢ 0:08:45[0m [2;4m0.37it/s[0m  
[2KAttention weights: tensor([[0.5569, 0.4431]], device='cuda:0')â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 11/203 [2m0:00:30 â€¢ 0:08:45[0m [2;4m0.37it/s[0m  
[2KAttention weights: tensor([[0.6486, 0.3514],38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 11/203 [2m0:00:30 â€¢ 0:08:45[0m [2;4m0.37it/s[0m  
        [0.6005, 0.3995],
        [0.6111, 0.3889],
        [0.6632, 0.3368],
        [0.6491, 0.3509],
        [0.6407, 0.3593],
        [0.5944, 0.4056],
        [0.6724, 0.3276],
        [0.6695, 0.3305],
[2K        [0.6825, 0.3175]], device='cuda:0')[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 11/203 [2m0:00:30 â€¢ 0:08:45[0m [2;4m0.37it/s[0m  
[2KAttention weights: tensor([[0.5577, 0.4423],0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 12/203 [2m0:00:31 â€¢ 0:08:17[0m [2;4m0.38it/s[0m  
        [0.5536, 0.4464],
        [0.5545, 0.4455],
        [0.5566, 0.4434],
        [0.5557, 0.4443],
        [0.5531, 0.4469],
        [0.5523, 0.4477],
        [0.5575, 0.4425],
        [0.5578, 0.4422],
[2K        [0.5553, 0.4447]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 12/203 [2m0:00:31 â€¢ 0:08:17[0m [2;4m0.38it/s[0m  
[2KClass label: CleanAndJerkm[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 12/203 [2m0:00:31 â€¢ 0:08:17[0m [2;4m0.38it/s[0m  
[2KAttention weights: tensor([[0.5713, 0.4287]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 12/203 [2m0:00:31 â€¢ 0:08:17[0m [2;4m0.38it/s[0m  
[2KStep 0 - TTA Loss: 0.6335m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 12/203 [2m0:00:31 â€¢ 0:08:17[0m [2;4m0.38it/s[0m  
[2KAttention weights: tensor([[0.5841, 0.4159]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 12/203 [2m0:00:31 â€¢ 0:08:17[0m [2;4m0.38it/s[0m  
[2KAttention weights: tensor([[0.6017, 0.3983]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 12/203 [2m0:00:31 â€¢ 0:08:17[0m [2;4m0.38it/s[0m  
[2KAttention weights: tensor([[0.6148, 0.3852]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 12/203 [2m0:00:31 â€¢ 0:08:17[0m [2;4m0.38it/s[0m  
[2KAttention weights: tensor([[0.6168, 0.3832]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 12/203 [2m0:00:31 â€¢ 0:08:17[0m [2;4m0.38it/s[0m  
[2KAttention weights: tensor([[0.6135, 0.3865]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 12/203 [2m0:00:31 â€¢ 0:08:17[0m [2;4m0.38it/s[0m  
[2KAttention weights: tensor([[0.6130, 0.3870]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 12/203 [2m0:00:31 â€¢ 0:08:17[0m [2;4m0.38it/s[0m  
[2KAttention weights: tensor([[0.6177, 0.3823]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 12/203 [2m0:00:31 â€¢ 0:08:17[0m [2;4m0.38it/s[0m  
[2KAttention weights: tensor([[0.6249, 0.3751]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 12/203 [2m0:00:31 â€¢ 0:08:17[0m [2;4m0.38it/s[0m  
[2KAttention weights: tensor([[0.6301, 0.3699]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 12/203 [2m0:00:31 â€¢ 0:08:17[0m [2;4m0.38it/s[0m  
[2KAttention weights: tensor([[0.5557, 0.4443]], device='cuda:0')â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 12/203 [2m0:00:31 â€¢ 0:08:17[0m [2;4m0.38it/s[0m  
[2KAttention weights: tensor([[0.6116, 0.3884],38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 12/203 [2m0:00:31 â€¢ 0:08:17[0m [2;4m0.38it/s[0m  
        [0.5902, 0.4098],
        [0.6324, 0.3676],
        [0.6357, 0.3643],
        [0.5959, 0.4041],
        [0.6098, 0.3902],
        [0.5627, 0.4374],
        [0.6402, 0.3598],
        [0.6511, 0.3489],
[2K        [0.6453, 0.3547]], device='cuda:0')[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 12/203 [2m0:00:31 â€¢ 0:08:17[0m [2;4m0.38it/s[0m  
[2KAttention weights: tensor([[0.5577, 0.4423],4mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 13/203 [2m0:00:31 â€¢ 0:07:40[0m [2;4m0.41it/s[0m  
        [0.5536, 0.4464],
        [0.5545, 0.4455],
        [0.5566, 0.4434],
        [0.5557, 0.4443],
        [0.5531, 0.4469],
        [0.5523, 0.4477],
        [0.5574, 0.4426],
        [0.5578, 0.4422],
[2K        [0.5552, 0.4448]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 13/203 [2m0:00:31 â€¢ 0:07:40[0m [2;4m0.41it/s[0m  
[2KClass label: BaseballPitch[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 13/203 [2m0:00:31 â€¢ 0:07:40[0m [2;4m0.41it/s[0m  
[2KAttention weights: tensor([[0.6126, 0.3874]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 13/203 [2m0:00:31 â€¢ 0:07:40[0m [2;4m0.41it/s[0m  
[2KStep 0 - TTA Loss: 0.7545m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 13/203 [2m0:00:31 â€¢ 0:07:40[0m [2;4m0.41it/s[0m  
[2KAttention weights: tensor([[0.6126, 0.3874]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 13/203 [2m0:00:31 â€¢ 0:07:40[0m [2;4m0.41it/s[0m  
[2KAttention weights: tensor([[0.6150, 0.3850]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 13/203 [2m0:00:31 â€¢ 0:07:40[0m [2;4m0.41it/s[0m  
[2KAttention weights: tensor([[0.6267, 0.3733]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 13/203 [2m0:00:31 â€¢ 0:07:40[0m [2;4m0.41it/s[0m  
[2KAttention weights: tensor([[0.6561, 0.3439]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 13/203 [2m0:00:31 â€¢ 0:07:40[0m [2;4m0.41it/s[0m  
[2KAttention weights: tensor([[0.7068, 0.2932]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 13/203 [2m0:00:31 â€¢ 0:07:40[0m [2;4m0.41it/s[0m  
[2KAttention weights: tensor([[0.7736, 0.2264]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 13/203 [2m0:00:31 â€¢ 0:07:40[0m [2;4m0.41it/s[0m  
[2KAttention weights: tensor([[0.8390, 0.1610]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 13/203 [2m0:00:31 â€¢ 0:07:40[0m [2;4m0.41it/s[0m  
[2KAttention weights: tensor([[0.8919, 0.1081]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 13/203 [2m0:00:31 â€¢ 0:07:40[0m [2;4m0.41it/s[0m  
[2KAttention weights: tensor([[0.9400, 0.0600]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 13/203 [2m0:00:31 â€¢ 0:07:40[0m [2;4m0.41it/s[0m  
[2KAttention weights: tensor([[0.5736, 0.4264]], device='cuda:0')â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 13/203 [2m0:00:31 â€¢ 0:07:40[0m [2;4m0.41it/s[0m  
[2KAttention weights: tensor([[0.9823, 0.0177],[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 13/203 [2m0:00:31 â€¢ 0:07:40[0m [2;4m0.41it/s[0m  
        [0.8515, 0.1485],
        [0.9084, 0.0916],
        [0.9557, 0.0443],
        [0.9446, 0.0554],
        [0.9305, 0.0695],
        [0.8991, 0.1009],
        [0.9233, 0.0767],
        [0.9415, 0.0585],
[2K        [0.9596, 0.0404]], device='cuda:0')[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 13/203 [2m0:00:31 â€¢ 0:07:40[0m [2;4m0.41it/s[0m  
[2KAttention weights: tensor([[0.5579, 0.4421],4mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 14/203 [2m0:00:33 â€¢ 0:07:32[0m [2;4m0.42it/s[0m  
        [0.5537, 0.4463],
        [0.5546, 0.4454],
        [0.5567, 0.4433],
        [0.5558, 0.4442],
        [0.5532, 0.4468],
        [0.5524, 0.4476],
        [0.5575, 0.4425],
        [0.5579, 0.4421],
[2K        [0.5553, 0.4447]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 14/203 [2m0:00:33 â€¢ 0:07:32[0m [2;4m0.42it/s[0m  
[2KClass label: GolfSwing[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 14/203 [2m0:00:33 â€¢ 0:07:32[0m [2;4m0.42it/s[0m  
[2KAttention weights: tensor([[0.6270, 0.3730]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 14/203 [2m0:00:33 â€¢ 0:07:32[0m [2;4m0.42it/s[0m  
[2KStep 0 - TTA Loss: 0.8628m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 14/203 [2m0:00:33 â€¢ 0:07:32[0m [2;4m0.42it/s[0m  
[2KAttention weights: tensor([[0.7895, 0.2105]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 14/203 [2m0:00:33 â€¢ 0:07:32[0m [2;4m0.42it/s[0m  
[2KAttention weights: tensor([[0.8841, 0.1159]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 14/203 [2m0:00:33 â€¢ 0:07:32[0m [2;4m0.42it/s[0m  
[2KAttention weights: tensor([[0.9328, 0.0672]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 14/203 [2m0:00:33 â€¢ 0:07:32[0m [2;4m0.42it/s[0m  
[2KAttention weights: tensor([[0.9564, 0.0436]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 14/203 [2m0:00:33 â€¢ 0:07:32[0m [2;4m0.42it/s[0m  
[2KAttention weights: tensor([[0.9679, 0.0321]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 14/203 [2m0:00:33 â€¢ 0:07:32[0m [2;4m0.42it/s[0m  
[2KAttention weights: tensor([[0.9735, 0.0265]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 14/203 [2m0:00:33 â€¢ 0:07:32[0m [2;4m0.42it/s[0m  
[2KAttention weights: tensor([[0.9759, 0.0241]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 14/203 [2m0:00:33 â€¢ 0:07:32[0m [2;4m0.42it/s[0m  
[2KAttention weights: tensor([[0.9767, 0.0233]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 14/203 [2m0:00:33 â€¢ 0:07:32[0m [2;4m0.42it/s[0m  
[2KAttention weights: tensor([[0.9768, 0.0232]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 14/203 [2m0:00:33 â€¢ 0:07:32[0m [2;4m0.42it/s[0m  
[2KAttention weights: tensor([[0.5782, 0.4218]], device='cuda:0')â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 14/203 [2m0:00:33 â€¢ 0:07:32[0m [2;4m0.42it/s[0m  
[2KAttention weights: tensor([[0.9950, 0.0050],[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 14/203 [2m0:00:33 â€¢ 0:07:32[0m [2;4m0.42it/s[0m  
        [0.8917, 0.1083],
        [0.9204, 0.0796],
        [0.9769, 0.0231],
        [0.9713, 0.0287],
        [0.9600, 0.0400],
        [0.9373, 0.0627],
        [0.9572, 0.0428],
        [0.9672, 0.0328],
[2K        [0.9802, 0.0198]], device='cuda:0')[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 14/203 [2m0:00:33 â€¢ 0:07:32[0m [2;4m0.42it/s[0m  
[2KAttention weights: tensor([[0.5582, 0.4418],4mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 15/203 [2m0:00:33 â€¢ 0:07:07[0m [2;4m0.44it/s[0m  
        [0.5539, 0.4461],
        [0.5548, 0.4452],
        [0.5569, 0.4431],
        [0.5560, 0.4440],
        [0.5533, 0.4467],
        [0.5526, 0.4474],
        [0.5577, 0.4423],
        [0.5581, 0.4419],
[2K        [0.5555, 0.4445]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 15/203 [2m0:00:33 â€¢ 0:07:07[0m [2;4m0.44it/s[0m  
[2KClass label: HighJumpâ”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 15/203 [2m0:00:33 â€¢ 0:07:07[0m [2;4m0.44it/s[0m  
[2KAttention weights: tensor([[0.5938, 0.4062]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 15/203 [2m0:00:33 â€¢ 0:07:07[0m [2;4m0.44it/s[0m  
[2KStep 0 - TTA Loss: 1.1139m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 15/203 [2m0:00:33 â€¢ 0:07:07[0m [2;4m0.44it/s[0m  
[2KAttention weights: tensor([[0.5938, 0.4062]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 15/203 [2m0:00:33 â€¢ 0:07:07[0m [2;4m0.44it/s[0m  
[2KAttention weights: tensor([[0.5942, 0.4058]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 15/203 [2m0:00:33 â€¢ 0:07:07[0m [2;4m0.44it/s[0m  
[2KAttention weights: tensor([[0.5962, 0.4038]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 15/203 [2m0:00:33 â€¢ 0:07:07[0m [2;4m0.44it/s[0m  
[2KAttention weights: tensor([[0.6010, 0.3990]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 15/203 [2m0:00:33 â€¢ 0:07:07[0m [2;4m0.44it/s[0m  
[2KAttention weights: tensor([[0.6077, 0.3923]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 15/203 [2m0:00:33 â€¢ 0:07:07[0m [2;4m0.44it/s[0m  
[2KAttention weights: tensor([[0.6140, 0.3860]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 15/203 [2m0:00:33 â€¢ 0:07:07[0m [2;4m0.44it/s[0m  
[2KAttention weights: tensor([[0.6176, 0.3824]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 15/203 [2m0:00:33 â€¢ 0:07:07[0m [2;4m0.44it/s[0m  
[2KAttention weights: tensor([[0.6188, 0.3812]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 15/203 [2m0:00:33 â€¢ 0:07:07[0m [2;4m0.44it/s[0m  
[2KAttention weights: tensor([[0.6147, 0.3853]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 15/203 [2m0:00:33 â€¢ 0:07:07[0m [2;4m0.44it/s[0m  
[2KAttention weights: tensor([[0.5532, 0.4468]], device='cuda:0')â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 15/203 [2m0:00:33 â€¢ 0:07:07[0m [2;4m0.44it/s[0m  
[2KAttention weights: tensor([[0.6858, 0.3142],[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 15/203 [2m0:00:33 â€¢ 0:07:07[0m [2;4m0.44it/s[0m  
        [0.5869, 0.4131],
        [0.5713, 0.4287],
        [0.5935, 0.4065],
        [0.6045, 0.3955],
        [0.6093, 0.3907],
        [0.5568, 0.4432],
        [0.6583, 0.3417],
        [0.6410, 0.3590],
[2K        [0.6519, 0.3481]], device='cuda:0')[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 15/203 [2m0:00:33 â€¢ 0:07:07[0m [2;4m0.44it/s[0m  
[2KAttention weights: tensor([[0.5582, 0.4418],[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 16/203 [2m0:00:34 â€¢ 0:06:57[0m [2;4m0.45it/s[0m   
        [0.5539, 0.4461],
        [0.5548, 0.4452],
        [0.5570, 0.4430],
        [0.5560, 0.4440],
        [0.5533, 0.4467],
        [0.5526, 0.4474],
        [0.5578, 0.4422],
        [0.5581, 0.4419],
[2K        [0.5556, 0.4444]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 16/203 [2m0:00:34 â€¢ 0:06:57[0m [2;4m0.45it/s[0m  
[2KClass label: HighJumpâ”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 16/203 [2m0:00:34 â€¢ 0:06:57[0m [2;4m0.45it/s[0m  
[2KAttention weights: tensor([[0.5891, 0.4109]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 16/203 [2m0:00:34 â€¢ 0:06:57[0m [2;4m0.45it/s[0m  
[2KStep 0 - TTA Loss: 0.75790m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 16/203 [2m0:00:34 â€¢ 0:06:57[0m [2;4m0.45it/s[0m  
[2KAttention weights: tensor([[0.5881, 0.4119]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 16/203 [2m0:00:34 â€¢ 0:06:57[0m [2;4m0.45it/s[0m  
[2KAttention weights: tensor([[0.5871, 0.4129]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 16/203 [2m0:00:34 â€¢ 0:06:57[0m [2;4m0.45it/s[0m  
[2KAttention weights: tensor([[0.5845, 0.4155]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 16/203 [2m0:00:34 â€¢ 0:06:57[0m [2;4m0.45it/s[0m  
[2KAttention weights: tensor([[0.5805, 0.4195]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 16/203 [2m0:00:34 â€¢ 0:06:57[0m [2;4m0.45it/s[0m  
[2KAttention weights: tensor([[0.5740, 0.4260]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 16/203 [2m0:00:34 â€¢ 0:06:57[0m [2;4m0.45it/s[0m  
[2KAttention weights: tensor([[0.5649, 0.4351]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 16/203 [2m0:00:34 â€¢ 0:06:57[0m [2;4m0.45it/s[0m  
[2KAttention weights: tensor([[0.5564, 0.4436]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 16/203 [2m0:00:34 â€¢ 0:06:57[0m [2;4m0.45it/s[0m  
[2KAttention weights: tensor([[0.5497, 0.4503]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 16/203 [2m0:00:34 â€¢ 0:06:57[0m [2;4m0.45it/s[0m  
[2KAttention weights: tensor([[0.5460, 0.4540]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 16/203 [2m0:00:34 â€¢ 0:06:57[0m [2;4m0.45it/s[0m  
[2KAttention weights: tensor([[0.5517, 0.4483]], device='cuda:0')â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 16/203 [2m0:00:34 â€¢ 0:06:57[0m [2;4m0.45it/s[0m  
[2KAttention weights: tensor([[0.6241, 0.3759],[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 16/203 [2m0:00:34 â€¢ 0:06:57[0m [2;4m0.45it/s[0m  
        [0.5564, 0.4436],
        [0.5319, 0.4681],
        [0.5695, 0.4305],
        [0.5510, 0.4490],
        [0.5448, 0.4552],
        [0.5045, 0.4955],
        [0.6144, 0.3856],
        [0.6045, 0.3955],
[2K        [0.6016, 0.3984]], device='cuda:0')[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 16/203 [2m0:00:34 â€¢ 0:06:57[0m [2;4m0.45it/s[0m  
[2KAttention weights: tensor([[0.5582, 0.4418],[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 17/203 [2m0:00:35 â€¢ 0:05:16[0m [2;4m0.59it/s[0m  
        [0.5539, 0.4461],
        [0.5548, 0.4452],
        [0.5570, 0.4430],
        [0.5560, 0.4440],
        [0.5532, 0.4468],
        [0.5525, 0.4475],
        [0.5578, 0.4422],
        [0.5581, 0.4419],
[2K        [0.5555, 0.4445]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 17/203 [2m0:00:35 â€¢ 0:05:16[0m [2;4m0.59it/s[0m  
[2KClass label: GolfSwingâ”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 17/203 [2m0:00:35 â€¢ 0:05:16[0m [2;4m0.59it/s[0m  
[2KAttention weights: tensor([[0.6246, 0.3754]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 17/203 [2m0:00:35 â€¢ 0:05:16[0m [2;4m0.59it/s[0m  
[2KStep 0 - TTA Loss: 0.68790m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 17/203 [2m0:00:35 â€¢ 0:05:16[0m [2;4m0.59it/s[0m  
[2KAttention weights: tensor([[0.6246, 0.3754]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 17/203 [2m0:00:35 â€¢ 0:05:16[0m [2;4m0.59it/s[0m  
[2KAttention weights: tensor([[0.6239, 0.3761]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 17/203 [2m0:00:35 â€¢ 0:05:16[0m [2;4m0.59it/s[0m  
[2KAttention weights: tensor([[0.6215, 0.3785]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 17/203 [2m0:00:35 â€¢ 0:05:16[0m [2;4m0.59it/s[0m  
[2KAttention weights: tensor([[0.6162, 0.3838]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 17/203 [2m0:00:35 â€¢ 0:05:16[0m [2;4m0.59it/s[0m  
[2KAttention weights: tensor([[0.6075, 0.3925]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 17/203 [2m0:00:35 â€¢ 0:05:16[0m [2;4m0.59it/s[0m  
[2KAttention weights: tensor([[0.5940, 0.4060]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 17/203 [2m0:00:35 â€¢ 0:05:16[0m [2;4m0.59it/s[0m  
[2KAttention weights: tensor([[0.5748, 0.4252]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 17/203 [2m0:00:35 â€¢ 0:05:16[0m [2;4m0.59it/s[0m  
[2KAttention weights: tensor([[0.5490, 0.4510]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 17/203 [2m0:00:35 â€¢ 0:05:16[0m [2;4m0.59it/s[0m  
[2KAttention weights: tensor([[0.5191, 0.4809]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 17/203 [2m0:00:35 â€¢ 0:05:16[0m [2;4m0.59it/s[0m  
[2KAttention weights: tensor([[0.5527, 0.4473]], device='cuda:0')â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 17/203 [2m0:00:35 â€¢ 0:05:16[0m [2;4m0.59it/s[0m  
[2KAttention weights: tensor([[0.5026, 0.4974],[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 17/203 [2m0:00:35 â€¢ 0:05:16[0m [2;4m0.59it/s[0m  
        [0.5012, 0.4988],
        [0.4655, 0.5345],
        [0.4901, 0.5099],
        [0.4583, 0.5417],
        [0.4539, 0.5461],
        [0.4233, 0.5767],
        [0.5379, 0.4621],
        [0.5324, 0.4676],
[2K        [0.5092, 0.4908]], device='cuda:0')[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 17/203 [2m0:00:35 â€¢ 0:05:16[0m [2;4m0.59it/s[0m  
[2KAttention weights: tensor([[0.5582, 0.4418],24mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 18/203 [2m0:00:37 â€¢ 0:05:10[0m [2;4m0.60it/s[0m  
        [0.5539, 0.4461],
        [0.5547, 0.4453],
        [0.5569, 0.4431],
        [0.5559, 0.4441],
        [0.5532, 0.4468],
        [0.5524, 0.4476],
        [0.5577, 0.4423],
        [0.5581, 0.4419],
[2K        [0.5555, 0.4445]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 18/203 [2m0:00:37 â€¢ 0:05:10[0m [2;4m0.60it/s[0m  
[2KClass label: ThrowDiscus[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 18/203 [2m0:00:37 â€¢ 0:05:10[0m [2;4m0.60it/s[0m  
[2KAttention weights: tensor([[0.6350, 0.3650]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 18/203 [2m0:00:37 â€¢ 0:05:10[0m [2;4m0.60it/s[0m  
[2KStep 0 - TTA Loss: 0.47760m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 18/203 [2m0:00:37 â€¢ 0:05:10[0m [2;4m0.60it/s[0m  
[2KAttention weights: tensor([[0.5908, 0.4092]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 18/203 [2m0:00:37 â€¢ 0:05:10[0m [2;4m0.60it/s[0m  
[2KAttention weights: tensor([[0.5294, 0.4706]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 18/203 [2m0:00:37 â€¢ 0:05:10[0m [2;4m0.60it/s[0m  
[2KAttention weights: tensor([[0.4617, 0.5383]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 18/203 [2m0:00:37 â€¢ 0:05:10[0m [2;4m0.60it/s[0m  
[2KAttention weights: tensor([[0.4004, 0.5996]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 18/203 [2m0:00:37 â€¢ 0:05:10[0m [2;4m0.60it/s[0m  
[2KAttention weights: tensor([[0.3531, 0.6469]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 18/203 [2m0:00:37 â€¢ 0:05:10[0m [2;4m0.60it/s[0m  
[2KAttention weights: tensor([[0.3222, 0.6778]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 18/203 [2m0:00:37 â€¢ 0:05:10[0m [2;4m0.60it/s[0m  
[2KAttention weights: tensor([[0.3047, 0.6953]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 18/203 [2m0:00:37 â€¢ 0:05:10[0m [2;4m0.60it/s[0m  
[2KAttention weights: tensor([[0.2963, 0.7037]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 18/203 [2m0:00:37 â€¢ 0:05:10[0m [2;4m0.60it/s[0m  
[2KAttention weights: tensor([[0.2928, 0.7072]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 18/203 [2m0:00:37 â€¢ 0:05:10[0m [2;4m0.60it/s[0m  
[2KAttention weights: tensor([[0.5456, 0.4544]], device='cuda:0')â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 18/203 [2m0:00:37 â€¢ 0:05:10[0m [2;4m0.60it/s[0m  
[2KAttention weights: tensor([[0.3195, 0.6805],[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 18/203 [2m0:00:37 â€¢ 0:05:10[0m [2;4m0.60it/s[0m  
        [0.4081, 0.5919],
        [0.3310, 0.6690],
        [0.3289, 0.6711],
        [0.2747, 0.7253],
        [0.3022, 0.6978],
        [0.2857, 0.7143],
        [0.4168, 0.5832],
        [0.3720, 0.6280],
[2K        [0.2918, 0.7082]], device='cuda:0')â•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 18/203 [2m0:00:37 â€¢ 0:05:10[0m [2;4m0.60it/s[0m  
[2KAttention weights: tensor([[0.5581, 0.4419],24mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 19/203 [2m0:00:38 â€¢ 0:05:02[0m [2;4m0.61it/s[0m  
        [0.5538, 0.4462],
        [0.5546, 0.4454],
        [0.5568, 0.4432],
        [0.5558, 0.4442],
        [0.5530, 0.4470],
        [0.5523, 0.4477],
        [0.5576, 0.4424],
        [0.5580, 0.4420],
[2K        [0.5553, 0.4447]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 19/203 [2m0:00:38 â€¢ 0:05:02[0m [2;4m0.61it/s[0m  
[2KClass label: SoccerPenaltym[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 19/203 [2m0:00:38 â€¢ 0:05:02[0m [2;4m0.61it/s[0m  
[2KAttention weights: tensor([[0.6402, 0.3598]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 19/203 [2m0:00:38 â€¢ 0:05:02[0m [2;4m0.61it/s[0m  
[2KStep 0 - TTA Loss: 0.46860m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 19/203 [2m0:00:38 â€¢ 0:05:02[0m [2;4m0.61it/s[0m  
[2KAttention weights: tensor([[0.6402, 0.3598]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 19/203 [2m0:00:38 â€¢ 0:05:02[0m [2;4m0.61it/s[0m  
[2KAttention weights: tensor([[0.6401, 0.3599]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 19/203 [2m0:00:38 â€¢ 0:05:02[0m [2;4m0.61it/s[0m  
[2KAttention weights: tensor([[0.6403, 0.3597]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 19/203 [2m0:00:38 â€¢ 0:05:02[0m [2;4m0.61it/s[0m  
[2KAttention weights: tensor([[0.6414, 0.3586]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 19/203 [2m0:00:38 â€¢ 0:05:02[0m [2;4m0.61it/s[0m  
[2KAttention weights: tensor([[0.6430, 0.3570]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 19/203 [2m0:00:38 â€¢ 0:05:02[0m [2;4m0.61it/s[0m  
[2KAttention weights: tensor([[0.6429, 0.3571]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 19/203 [2m0:00:38 â€¢ 0:05:02[0m [2;4m0.61it/s[0m  
[2KAttention weights: tensor([[0.6399, 0.3601]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 19/203 [2m0:00:38 â€¢ 0:05:02[0m [2;4m0.61it/s[0m  
[2KAttention weights: tensor([[0.6333, 0.3667]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 19/203 [2m0:00:38 â€¢ 0:05:02[0m [2;4m0.61it/s[0m  
[2KAttention weights: tensor([[0.6320, 0.3680]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 19/203 [2m0:00:38 â€¢ 0:05:02[0m [2;4m0.61it/s[0m  
[2KAttention weights: tensor([[0.5566, 0.4434]], device='cuda:0')â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 19/203 [2m0:00:38 â€¢ 0:05:02[0m [2;4m0.61it/s[0m  
[2KAttention weights: tensor([[0.5795, 0.4205],[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 19/203 [2m0:00:38 â€¢ 0:05:02[0m [2;4m0.61it/s[0m  
        [0.5668, 0.4332],
        [0.5329, 0.4671],
        [0.5897, 0.4103],
        [0.5456, 0.4544],
        [0.5603, 0.4397],
        [0.5177, 0.4823],
        [0.6473, 0.3527],
        [0.6164, 0.3836],
[2K        [0.5899, 0.4101]], device='cuda:0')â•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 19/203 [2m0:00:38 â€¢ 0:05:02[0m [2;4m0.61it/s[0m  
[2KAttention weights: tensor([[0.5580, 0.4420],24mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 20/203 [2m0:00:38 â€¢ 0:04:46[0m [2;4m0.64it/s[0m  
        [0.5537, 0.4463],
        [0.5546, 0.4454],
        [0.5568, 0.4432],
        [0.5557, 0.4443],
        [0.5530, 0.4470],
        [0.5523, 0.4477],
        [0.5576, 0.4424],
        [0.5579, 0.4421],
[2K        [0.5553, 0.4447]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 20/203 [2m0:00:38 â€¢ 0:04:46[0m [2;4m0.64it/s[0m  
[2KClass label: HighJumpâ”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 20/203 [2m0:00:38 â€¢ 0:04:46[0m [2;4m0.64it/s[0m  
[2KAttention weights: tensor([[0.5918, 0.4082]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 20/203 [2m0:00:38 â€¢ 0:04:46[0m [2;4m0.64it/s[0m  
[2KStep 0 - TTA Loss: 0.66840m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 20/203 [2m0:00:38 â€¢ 0:04:46[0m [2;4m0.64it/s[0m  
[2KAttention weights: tensor([[0.6049, 0.3951]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 20/203 [2m0:00:38 â€¢ 0:04:46[0m [2;4m0.64it/s[0m  
[2KAttention weights: tensor([[0.6262, 0.3738]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 20/203 [2m0:00:38 â€¢ 0:04:46[0m [2;4m0.64it/s[0m  
[2KAttention weights: tensor([[0.6483, 0.3517]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 20/203 [2m0:00:38 â€¢ 0:04:46[0m [2;4m0.64it/s[0m  
[2KAttention weights: tensor([[0.6658, 0.3342]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 20/203 [2m0:00:38 â€¢ 0:04:46[0m [2;4m0.64it/s[0m  
[2KAttention weights: tensor([[0.6766, 0.3234]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 20/203 [2m0:00:38 â€¢ 0:04:46[0m [2;4m0.64it/s[0m  
[2KAttention weights: tensor([[0.6814, 0.3186]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 20/203 [2m0:00:38 â€¢ 0:04:46[0m [2;4m0.64it/s[0m  
[2KAttention weights: tensor([[0.6826, 0.3174]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 20/203 [2m0:00:38 â€¢ 0:04:46[0m [2;4m0.64it/s[0m  
[2KAttention weights: tensor([[0.6824, 0.3176]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 20/203 [2m0:00:38 â€¢ 0:04:46[0m [2;4m0.64it/s[0m  
[2KAttention weights: tensor([[0.6821, 0.3179]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 20/203 [2m0:00:38 â€¢ 0:04:46[0m [2;4m0.64it/s[0m  
[2KAttention weights: tensor([[0.5550, 0.4450]], device='cuda:0')â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 20/203 [2m0:00:38 â€¢ 0:04:46[0m [2;4m0.64it/s[0m  
[2KAttention weights: tensor([[0.6705, 0.3295],[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 20/203 [2m0:00:38 â€¢ 0:04:46[0m [2;4m0.64it/s[0m  
        [0.6354, 0.3646],
        [0.6129, 0.3871],
        [0.6697, 0.3303],
        [0.6504, 0.3496],
        [0.6821, 0.3179],
        [0.6274, 0.3726],
        [0.7449, 0.2551],
        [0.6966, 0.3034],
[2K        [0.6887, 0.3113]], device='cuda:0')â•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 20/203 [2m0:00:38 â€¢ 0:04:46[0m [2;4m0.64it/s[0m  
[2KAttention weights: tensor([[0.5580, 0.4420],[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 21/203 [2m0:00:44 â€¢ 0:05:42[0m [2;4m0.53it/s[0m   
        [0.5537, 0.4463],
        [0.5546, 0.4454],
        [0.5568, 0.4432],
        [0.5557, 0.4443],
        [0.5530, 0.4470],
        [0.5523, 0.4477],
        [0.5575, 0.4425],
        [0.5579, 0.4421],
[2K        [0.5553, 0.4447]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 21/203 [2m0:00:44 â€¢ 0:05:42[0m [2;4m0.53it/s[0m  
[2KClass label: BaseballPitch0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 21/203 [2m0:00:44 â€¢ 0:05:42[0m [2;4m0.53it/s[0m  
[2KAttention weights: tensor([[0.6142, 0.3858]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 21/203 [2m0:00:44 â€¢ 0:05:42[0m [2;4m0.53it/s[0m  
[2KStep 0 - TTA Loss: 0.5408[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 21/203 [2m0:00:44 â€¢ 0:05:42[0m [2;4m0.53it/s[0m  
[2KAttention weights: tensor([[0.6142, 0.3858]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 21/203 [2m0:00:44 â€¢ 0:05:42[0m [2;4m0.53it/s[0m  
[2KAttention weights: tensor([[0.6137, 0.3863]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 21/203 [2m0:00:44 â€¢ 0:05:42[0m [2;4m0.53it/s[0m  
[2KAttention weights: tensor([[0.6107, 0.3893]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 21/203 [2m0:00:44 â€¢ 0:05:42[0m [2;4m0.53it/s[0m  
[2KAttention weights: tensor([[0.6048, 0.3952]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 21/203 [2m0:00:44 â€¢ 0:05:42[0m [2;4m0.53it/s[0m  
[2KAttention weights: tensor([[0.5963, 0.4037]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 21/203 [2m0:00:44 â€¢ 0:05:42[0m [2;4m0.53it/s[0m  
[2KAttention weights: tensor([[0.5848, 0.4152]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 21/203 [2m0:00:44 â€¢ 0:05:42[0m [2;4m0.53it/s[0m  
[2KAttention weights: tensor([[0.5586, 0.4414]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 21/203 [2m0:00:44 â€¢ 0:05:42[0m [2;4m0.53it/s[0m  
[2KAttention weights: tensor([[0.5276, 0.4724]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 21/203 [2m0:00:44 â€¢ 0:05:42[0m [2;4m0.53it/s[0m  
[2KAttention weights: tensor([[0.5030, 0.4970]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 21/203 [2m0:00:44 â€¢ 0:05:42[0m [2;4m0.53it/s[0m  
[2KAttention weights: tensor([[0.5547, 0.4453]], device='cuda:0')â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 21/203 [2m0:00:44 â€¢ 0:05:42[0m [2;4m0.53it/s[0m  
[2KAttention weights: tensor([[0.4937, 0.5063],[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 21/203 [2m0:00:44 â€¢ 0:05:42[0m [2;4m0.53it/s[0m  
        [0.5340, 0.4660],
        [0.5123, 0.4877],
        [0.5457, 0.4543],
        [0.4974, 0.5026],
        [0.5151, 0.4849],
        [0.4768, 0.5232],
        [0.5835, 0.4165],
        [0.5748, 0.4252],
[2K        [0.5462, 0.4538]], device='cuda:0')m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 21/203 [2m0:00:44 â€¢ 0:05:42[0m [2;4m0.53it/s[0m  
[2KAttention weights: tensor([[0.5580, 0.4420],[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 22/203 [2m0:00:45 â€¢ 0:05:35[0m [2;4m0.54it/s[0m  
        [0.5537, 0.4463],
        [0.5546, 0.4454],
        [0.5568, 0.4432],
        [0.5557, 0.4443],
        [0.5530, 0.4470],
        [0.5523, 0.4477],
        [0.5575, 0.4425],
        [0.5579, 0.4421],
[2K        [0.5553, 0.4447]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 22/203 [2m0:00:45 â€¢ 0:05:35[0m [2;4m0.54it/s[0m  
[2KClass label: CleanAndJerk[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 22/203 [2m0:00:45 â€¢ 0:05:35[0m [2;4m0.54it/s[0m  
[2KAttention weights: tensor([[0.5645, 0.4355]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 22/203 [2m0:00:45 â€¢ 0:05:35[0m [2;4m0.54it/s[0m  
[2KStep 0 - TTA Loss: 0.8476[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 22/203 [2m0:00:45 â€¢ 0:05:35[0m [2;4m0.54it/s[0m  
[2KAttention weights: tensor([[0.5628, 0.4372]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 22/203 [2m0:00:45 â€¢ 0:05:35[0m [2;4m0.54it/s[0m  
[2KAttention weights: tensor([[0.5641, 0.4359]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 22/203 [2m0:00:45 â€¢ 0:05:35[0m [2;4m0.54it/s[0m  
[2KAttention weights: tensor([[0.5668, 0.4332]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 22/203 [2m0:00:45 â€¢ 0:05:35[0m [2;4m0.54it/s[0m  
[2KAttention weights: tensor([[0.5674, 0.4326]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 22/203 [2m0:00:45 â€¢ 0:05:35[0m [2;4m0.54it/s[0m  
[2KAttention weights: tensor([[0.5654, 0.4346]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 22/203 [2m0:00:45 â€¢ 0:05:35[0m [2;4m0.54it/s[0m  
[2KAttention weights: tensor([[0.5605, 0.4395]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 22/203 [2m0:00:45 â€¢ 0:05:35[0m [2;4m0.54it/s[0m  
[2KAttention weights: tensor([[0.5550, 0.4450]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 22/203 [2m0:00:45 â€¢ 0:05:35[0m [2;4m0.54it/s[0m  
[2KAttention weights: tensor([[0.5499, 0.4501]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 22/203 [2m0:00:45 â€¢ 0:05:35[0m [2;4m0.54it/s[0m  
[2KAttention weights: tensor([[0.5466, 0.4534]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 22/203 [2m0:00:45 â€¢ 0:05:35[0m [2;4m0.54it/s[0m  
[2KAttention weights: tensor([[0.5538, 0.4462]], device='cuda:0')â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 22/203 [2m0:00:45 â€¢ 0:05:35[0m [2;4m0.54it/s[0m  
[2KAttention weights: tensor([[0.5778, 0.4222],[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 22/203 [2m0:00:45 â€¢ 0:05:35[0m [2;4m0.54it/s[0m  
        [0.5647, 0.4353],
        [0.5454, 0.4546],
        [0.6021, 0.3979],
        [0.5566, 0.4434],
        [0.5651, 0.4349],
        [0.5209, 0.4791],
        [0.6222, 0.3778],
        [0.6224, 0.3776],
[2K        [0.6045, 0.3955]], device='cuda:0')m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 22/203 [2m0:00:45 â€¢ 0:05:35[0m [2;4m0.54it/s[0m  
[2KAttention weights: tensor([[0.5580, 0.4420],224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 23/203 [2m0:00:46 â€¢ 0:04:05[0m [2;4m0.74it/s[0m  
        [0.5537, 0.4463],
        [0.5545, 0.4455],
        [0.5567, 0.4433],
        [0.5557, 0.4443],
        [0.5530, 0.4470],
        [0.5523, 0.4477],
        [0.5575, 0.4425],
        [0.5579, 0.4421],
[2K        [0.5552, 0.4448]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 23/203 [2m0:00:46 â€¢ 0:04:05[0m [2;4m0.74it/s[0m  
[2KClass label: TennisSwing[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 23/203 [2m0:00:46 â€¢ 0:04:05[0m [2;4m0.74it/s[0m  
[2KAttention weights: tensor([[0.6425, 0.3575]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 23/203 [2m0:00:46 â€¢ 0:04:05[0m [2;4m0.74it/s[0m  
[2KStep 0 - TTA Loss: 0.6708[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 23/203 [2m0:00:46 â€¢ 0:04:05[0m [2;4m0.74it/s[0m  
[2KAttention weights: tensor([[0.6425, 0.3575]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 23/203 [2m0:00:46 â€¢ 0:04:05[0m [2;4m0.74it/s[0m  
[2KAttention weights: tensor([[0.6413, 0.3587]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 23/203 [2m0:00:46 â€¢ 0:04:05[0m [2;4m0.74it/s[0m  
[2KAttention weights: tensor([[0.6356, 0.3644]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 23/203 [2m0:00:46 â€¢ 0:04:05[0m [2;4m0.74it/s[0m  
[2KAttention weights: tensor([[0.6208, 0.3792]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 23/203 [2m0:00:46 â€¢ 0:04:05[0m [2;4m0.74it/s[0m  
[2KAttention weights: tensor([[0.5916, 0.4084]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 23/203 [2m0:00:46 â€¢ 0:04:05[0m [2;4m0.74it/s[0m  
[2KAttention weights: tensor([[0.5512, 0.4488]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 23/203 [2m0:00:46 â€¢ 0:04:05[0m [2;4m0.74it/s[0m  
[2KAttention weights: tensor([[0.4899, 0.5101]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 23/203 [2m0:00:46 â€¢ 0:04:05[0m [2;4m0.74it/s[0m  
[2KAttention weights: tensor([[0.4152, 0.5848]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 23/203 [2m0:00:46 â€¢ 0:04:05[0m [2;4m0.74it/s[0m  
[2KAttention weights: tensor([[0.3479, 0.6521]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 23/203 [2m0:00:46 â€¢ 0:04:05[0m [2;4m0.74it/s[0m  
[2KAttention weights: tensor([[0.5492, 0.4508]], device='cuda:0')â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 23/203 [2m0:00:46 â€¢ 0:04:05[0m [2;4m0.74it/s[0m  
[2KAttention weights: tensor([[0.3987, 0.6013],â•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 23/203 [2m0:00:46 â€¢ 0:04:05[0m [2;4m0.74it/s[0m  
        [0.4039, 0.5961],
        [0.3433, 0.6567],
        [0.3924, 0.6076],
        [0.3709, 0.6291],
        [0.3731, 0.6269],
        [0.3850, 0.6150],
        [0.4780, 0.5220],
        [0.3129, 0.6871],
[2K        [0.4020, 0.5980]], device='cuda:0')mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 23/203 [2m0:00:46 â€¢ 0:04:05[0m [2;4m0.74it/s[0m  
[2KAttention weights: tensor([[0.5579, 0.4421],224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 24/203 [2m0:00:48 â€¢ 0:04:04[0m [2;4m0.73it/s[0m  
        [0.5536, 0.4464],
        [0.5544, 0.4456],
        [0.5566, 0.4434],
        [0.5556, 0.4444],
        [0.5529, 0.4471],
        [0.5522, 0.4478],
        [0.5574, 0.4426],
        [0.5577, 0.4423],
[2K        [0.5551, 0.4449]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 24/203 [2m0:00:48 â€¢ 0:04:04[0m [2;4m0.73it/s[0m  
[2KClass label: Billiardsâ”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 24/203 [2m0:00:48 â€¢ 0:04:04[0m [2;4m0.73it/s[0m  
[2KAttention weights: tensor([[0.5779, 0.4221]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 24/203 [2m0:00:48 â€¢ 0:04:04[0m [2;4m0.73it/s[0m  
[2KStep 0 - TTA Loss: 0.9228[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 24/203 [2m0:00:48 â€¢ 0:04:04[0m [2;4m0.73it/s[0m  
[2KAttention weights: tensor([[0.5593, 0.4407]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 24/203 [2m0:00:48 â€¢ 0:04:04[0m [2;4m0.73it/s[0m  
[2KAttention weights: tensor([[0.5428, 0.4572]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 24/203 [2m0:00:48 â€¢ 0:04:04[0m [2;4m0.73it/s[0m  
[2KAttention weights: tensor([[0.5283, 0.4717]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 24/203 [2m0:00:48 â€¢ 0:04:04[0m [2;4m0.73it/s[0m  
[2KAttention weights: tensor([[0.5157, 0.4843]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 24/203 [2m0:00:48 â€¢ 0:04:04[0m [2;4m0.73it/s[0m  
[2KAttention weights: tensor([[0.5053, 0.4947]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 24/203 [2m0:00:48 â€¢ 0:04:04[0m [2;4m0.73it/s[0m  
[2KAttention weights: tensor([[0.4980, 0.5020]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 24/203 [2m0:00:48 â€¢ 0:04:04[0m [2;4m0.73it/s[0m  
[2KAttention weights: tensor([[0.4923, 0.5077]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 24/203 [2m0:00:48 â€¢ 0:04:04[0m [2;4m0.73it/s[0m  
[2KAttention weights: tensor([[0.4887, 0.5113]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 24/203 [2m0:00:48 â€¢ 0:04:04[0m [2;4m0.73it/s[0m  
[2KAttention weights: tensor([[0.4869, 0.5131]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 24/203 [2m0:00:48 â€¢ 0:04:04[0m [2;4m0.73it/s[0m  
[2KAttention weights: tensor([[0.5507, 0.4493]], device='cuda:0')â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 24/203 [2m0:00:48 â€¢ 0:04:04[0m [2;4m0.73it/s[0m  
[2KAttention weights: tensor([[0.5118, 0.4882],â•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 24/203 [2m0:00:48 â€¢ 0:04:04[0m [2;4m0.73it/s[0m  
        [0.4864, 0.5136],
        [0.4454, 0.5546],
        [0.5146, 0.4854],
        [0.4751, 0.5249],
        [0.4843, 0.5157],
        [0.4624, 0.5376],
        [0.5595, 0.4405],
        [0.4883, 0.5117],
[2K        [0.5223, 0.4777]], device='cuda:0')mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 24/203 [2m0:00:48 â€¢ 0:04:04[0m [2;4m0.73it/s[0m  
[2KAttention weights: tensor([[0.5578, 0.4422],224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 25/203 [2m0:00:50 â€¢ 0:04:10[0m [2;4m0.71it/s[0m  
        [0.5535, 0.4465],
        [0.5543, 0.4457],
        [0.5566, 0.4434],
        [0.5555, 0.4445],
        [0.5528, 0.4472],
        [0.5521, 0.4479],
        [0.5573, 0.4427],
        [0.5576, 0.4424],
[2K        [0.5550, 0.4450]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 25/203 [2m0:00:50 â€¢ 0:04:10[0m [2;4m0.71it/s[0m  
[2KClass label: GolfSwingâ”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 25/203 [2m0:00:50 â€¢ 0:04:10[0m [2;4m0.71it/s[0m  
[2KAttention weights: tensor([[0.6212, 0.3788]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 25/203 [2m0:00:50 â€¢ 0:04:10[0m [2;4m0.71it/s[0m  
[2KStep 0 - TTA Loss: 0.6597[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 25/203 [2m0:00:50 â€¢ 0:04:10[0m [2;4m0.71it/s[0m  
[2KAttention weights: tensor([[0.6212, 0.3788]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 25/203 [2m0:00:50 â€¢ 0:04:10[0m [2;4m0.71it/s[0m  
[2KAttention weights: tensor([[0.6213, 0.3787]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 25/203 [2m0:00:50 â€¢ 0:04:10[0m [2;4m0.71it/s[0m  
[2KAttention weights: tensor([[0.6223, 0.3777]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 25/203 [2m0:00:50 â€¢ 0:04:10[0m [2;4m0.71it/s[0m  
[2KAttention weights: tensor([[0.6250, 0.3750]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 25/203 [2m0:00:50 â€¢ 0:04:10[0m [2;4m0.71it/s[0m  
[2KAttention weights: tensor([[0.6292, 0.3708]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 25/203 [2m0:00:50 â€¢ 0:04:10[0m [2;4m0.71it/s[0m  
[2KAttention weights: tensor([[0.6344, 0.3656]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 25/203 [2m0:00:50 â€¢ 0:04:10[0m [2;4m0.71it/s[0m  
[2KAttention weights: tensor([[0.6369, 0.3631]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 25/203 [2m0:00:50 â€¢ 0:04:10[0m [2;4m0.71it/s[0m  
[2KAttention weights: tensor([[0.6319, 0.3681]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 25/203 [2m0:00:50 â€¢ 0:04:10[0m [2;4m0.71it/s[0m  
[2KAttention weights: tensor([[0.6136, 0.3864]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 25/203 [2m0:00:50 â€¢ 0:04:10[0m [2;4m0.71it/s[0m  
[2KAttention weights: tensor([[0.5547, 0.4453]], device='cuda:0')â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 25/203 [2m0:00:50 â€¢ 0:04:10[0m [2;4m0.71it/s[0m  
[2KAttention weights: tensor([[0.5670, 0.4330],â•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 25/203 [2m0:00:50 â€¢ 0:04:10[0m [2;4m0.71it/s[0m  
        [0.5289, 0.4711],
        [0.5253, 0.4747],
        [0.5767, 0.4233],
        [0.5412, 0.4588],
        [0.5534, 0.4466],
        [0.5132, 0.4868],
        [0.6037, 0.3963],
        [0.5900, 0.4100],
[2K        [0.5909, 0.4091]], device='cuda:0')mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 25/203 [2m0:00:50 â€¢ 0:04:10[0m [2;4m0.71it/s[0m  
[2KAttention weights: tensor([[0.5578, 0.4422],â•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 26/203 [2m0:00:51 â€¢ 0:04:07[0m [2;4m0.72it/s[0m   
        [0.5535, 0.4465],
        [0.5543, 0.4457],
        [0.5566, 0.4434],
        [0.5555, 0.4445],
        [0.5528, 0.4472],
        [0.5521, 0.4479],
        [0.5573, 0.4427],
        [0.5576, 0.4424],
[2K        [0.5550, 0.4450]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 26/203 [2m0:00:51 â€¢ 0:04:07[0m [2;4m0.72it/s[0m  
[2KClass label: HighJumpâ”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 26/203 [2m0:00:51 â€¢ 0:04:07[0m [2;4m0.72it/s[0m  
[2KAttention weights: tensor([[0.5913, 0.4087]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 26/203 [2m0:00:51 â€¢ 0:04:07[0m [2;4m0.72it/s[0m  
[2KStep 0 - TTA Loss: 0.5728[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 26/203 [2m0:00:51 â€¢ 0:04:07[0m [2;4m0.72it/s[0m  
[2KAttention weights: tensor([[0.5816, 0.4184]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 26/203 [2m0:00:51 â€¢ 0:04:07[0m [2;4m0.72it/s[0m  
[2KAttention weights: tensor([[0.5784, 0.4216]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 26/203 [2m0:00:51 â€¢ 0:04:07[0m [2;4m0.72it/s[0m  
[2KAttention weights: tensor([[0.5747, 0.4253]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 26/203 [2m0:00:51 â€¢ 0:04:07[0m [2;4m0.72it/s[0m  
[2KAttention weights: tensor([[0.5739, 0.4261]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 26/203 [2m0:00:51 â€¢ 0:04:07[0m [2;4m0.72it/s[0m  
[2KAttention weights: tensor([[0.5893, 0.4107]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 26/203 [2m0:00:51 â€¢ 0:04:07[0m [2;4m0.72it/s[0m  
[2KAttention weights: tensor([[0.6096, 0.3904]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 26/203 [2m0:00:51 â€¢ 0:04:07[0m [2;4m0.72it/s[0m  
[2KAttention weights: tensor([[0.6292, 0.3708]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 26/203 [2m0:00:51 â€¢ 0:04:07[0m [2;4m0.72it/s[0m  
[2KAttention weights: tensor([[0.6414, 0.3586]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 26/203 [2m0:00:51 â€¢ 0:04:07[0m [2;4m0.72it/s[0m  
[2KAttention weights: tensor([[0.6469, 0.3531]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 26/203 [2m0:00:51 â€¢ 0:04:07[0m [2;4m0.72it/s[0m  
[2KAttention weights: tensor([[0.5544, 0.4456]], device='cuda:0')â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 26/203 [2m0:00:51 â€¢ 0:04:07[0m [2;4m0.72it/s[0m  
[2KAttention weights: tensor([[0.5894, 0.4106],m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 26/203 [2m0:00:51 â€¢ 0:04:07[0m [2;4m0.72it/s[0m  
        [0.5703, 0.4297],
        [0.5756, 0.4244],
        [0.5660, 0.4340],
        [0.5965, 0.4035],
        [0.6484, 0.3516],
        [0.5880, 0.4120],
        [0.6569, 0.3431],
        [0.6219, 0.3781],
[2K        [0.6365, 0.3635]], device='cuda:0')0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 26/203 [2m0:00:51 â€¢ 0:04:07[0m [2;4m0.72it/s[0m  
[2KAttention weights: tensor([[0.5578, 0.4422],â•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 27/203 [2m0:00:56 â€¢ 0:04:40[0m [2;4m0.63it/s[0m  
        [0.5535, 0.4465],
        [0.5543, 0.4457],
        [0.5566, 0.4434],
        [0.5555, 0.4445],
        [0.5528, 0.4472],
        [0.5521, 0.4479],
        [0.5573, 0.4427],
        [0.5576, 0.4424],
[2K        [0.5550, 0.4450]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 27/203 [2m0:00:56 â€¢ 0:04:40[0m [2;4m0.63it/s[0m  
[2KClass label: GolfSwingâ”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 27/203 [2m0:00:56 â€¢ 0:04:40[0m [2;4m0.63it/s[0m  
[2KAttention weights: tensor([[0.6273, 0.3727]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 27/203 [2m0:00:56 â€¢ 0:04:40[0m [2;4m0.63it/s[0m  
[2KStep 0 - TTA Loss: 0.6958[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 27/203 [2m0:00:56 â€¢ 0:04:40[0m [2;4m0.63it/s[0m  
[2KAttention weights: tensor([[0.6273, 0.3727]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 27/203 [2m0:00:56 â€¢ 0:04:40[0m [2;4m0.63it/s[0m  
[2KAttention weights: tensor([[0.6277, 0.3723]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 27/203 [2m0:00:56 â€¢ 0:04:40[0m [2;4m0.63it/s[0m  
[2KAttention weights: tensor([[0.6289, 0.3711]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 27/203 [2m0:00:56 â€¢ 0:04:40[0m [2;4m0.63it/s[0m  
[2KAttention weights: tensor([[0.6310, 0.3690]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 27/203 [2m0:00:56 â€¢ 0:04:40[0m [2;4m0.63it/s[0m  
[2KAttention weights: tensor([[0.6336, 0.3664]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 27/203 [2m0:00:56 â€¢ 0:04:40[0m [2;4m0.63it/s[0m  
[2KAttention weights: tensor([[0.6346, 0.3654]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 27/203 [2m0:00:56 â€¢ 0:04:40[0m [2;4m0.63it/s[0m  
[2KAttention weights: tensor([[0.6318, 0.3682]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 27/203 [2m0:00:56 â€¢ 0:04:40[0m [2;4m0.63it/s[0m  
[2KAttention weights: tensor([[0.6223, 0.3777]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 27/203 [2m0:00:56 â€¢ 0:04:40[0m [2;4m0.63it/s[0m  
[2KAttention weights: tensor([[0.6030, 0.3970]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 27/203 [2m0:00:56 â€¢ 0:04:40[0m [2;4m0.63it/s[0m  
[2KAttention weights: tensor([[0.5546, 0.4454]], device='cuda:0')â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 27/203 [2m0:00:56 â€¢ 0:04:40[0m [2;4m0.63it/s[0m  
[2KAttention weights: tensor([[0.5995, 0.4005],m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 27/203 [2m0:00:56 â€¢ 0:04:40[0m [2;4m0.63it/s[0m  
        [0.5885, 0.4115],
        [0.5866, 0.4134],
        [0.5776, 0.4224],
        [0.6025, 0.3975],
        [0.6534, 0.3466],
        [0.5951, 0.4049],
        [0.6632, 0.3368],
        [0.6365, 0.3635],
[2K        [0.6437, 0.3563]], device='cuda:0')0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 27/203 [2m0:00:56 â€¢ 0:04:40[0m [2;4m0.63it/s[0m  
[2KAttention weights: tensor([[0.5578, 0.4422],;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 28/203 [2m0:00:58 â€¢ 0:04:49[0m [2;4m0.61it/s[0m  
        [0.5535, 0.4465],
        [0.5543, 0.4457],
        [0.5566, 0.4434],
        [0.5555, 0.4445],
        [0.5528, 0.4472],
        [0.5521, 0.4479],
        [0.5573, 0.4427],
        [0.5576, 0.4424],
[2K        [0.5551, 0.4449]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 28/203 [2m0:00:58 â€¢ 0:04:49[0m [2;4m0.61it/s[0m  
[2KClass label: HighJumpâ”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 28/203 [2m0:00:58 â€¢ 0:04:49[0m [2;4m0.61it/s[0m  
[2KAttention weights: tensor([[0.5902, 0.4098]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 28/203 [2m0:00:58 â€¢ 0:04:49[0m [2;4m0.61it/s[0m  
[2KStep 0 - TTA Loss: 0.9293[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 28/203 [2m0:00:58 â€¢ 0:04:49[0m [2;4m0.61it/s[0m  
[2KAttention weights: tensor([[0.6055, 0.3945]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 28/203 [2m0:00:58 â€¢ 0:04:49[0m [2;4m0.61it/s[0m  
[2KAttention weights: tensor([[0.6286, 0.3714]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 28/203 [2m0:00:58 â€¢ 0:04:49[0m [2;4m0.61it/s[0m  
[2KAttention weights: tensor([[0.6522, 0.3478]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 28/203 [2m0:00:58 â€¢ 0:04:49[0m [2;4m0.61it/s[0m  
[2KAttention weights: tensor([[0.6726, 0.3274]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 28/203 [2m0:00:58 â€¢ 0:04:49[0m [2;4m0.61it/s[0m  
[2KAttention weights: tensor([[0.6830, 0.3170]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 28/203 [2m0:00:58 â€¢ 0:04:49[0m [2;4m0.61it/s[0m  
[2KAttention weights: tensor([[0.6850, 0.3150]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 28/203 [2m0:00:58 â€¢ 0:04:49[0m [2;4m0.61it/s[0m  
[2KAttention weights: tensor([[0.6828, 0.3172]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 28/203 [2m0:00:58 â€¢ 0:04:49[0m [2;4m0.61it/s[0m  
[2KAttention weights: tensor([[0.6793, 0.3207]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 28/203 [2m0:00:58 â€¢ 0:04:49[0m [2;4m0.61it/s[0m  
[2KAttention weights: tensor([[0.6773, 0.3227]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 28/203 [2m0:00:58 â€¢ 0:04:49[0m [2;4m0.61it/s[0m  
[2KAttention weights: tensor([[0.5547, 0.4453]], device='cuda:0')â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 28/203 [2m0:00:58 â€¢ 0:04:49[0m [2;4m0.61it/s[0m  
[2KAttention weights: tensor([[0.6044, 0.3956],mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 28/203 [2m0:00:58 â€¢ 0:04:49[0m [2;4m0.61it/s[0m  
        [0.6014, 0.3986],
        [0.5991, 0.4009],
        [0.5743, 0.4257],
        [0.6163, 0.3837],
        [0.6767, 0.3233],
        [0.6134, 0.3866],
        [0.6763, 0.3237],
        [0.6407, 0.3593],
[2K        [0.6557, 0.3443]], device='cuda:0')4mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 28/203 [2m0:00:58 â€¢ 0:04:49[0m [2;4m0.61it/s[0m  
[2KAttention weights: tensor([[0.5578, 0.4422],;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 29/203 [2m0:00:59 â€¢ 0:04:48[0m [2;4m0.61it/s[0m  
        [0.5535, 0.4465],
        [0.5543, 0.4457],
        [0.5565, 0.4435],
        [0.5555, 0.4445],
        [0.5529, 0.4471],
        [0.5521, 0.4479],
        [0.5573, 0.4427],
        [0.5576, 0.4424],
[2K        [0.5551, 0.4449]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 29/203 [2m0:00:59 â€¢ 0:04:48[0m [2;4m0.61it/s[0m  
[2KClass label: Billiardsâ”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 29/203 [2m0:00:59 â€¢ 0:04:48[0m [2;4m0.61it/s[0m  
[2KAttention weights: tensor([[0.5785, 0.4215]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 29/203 [2m0:00:59 â€¢ 0:04:48[0m [2;4m0.61it/s[0m  
[2KStep 0 - TTA Loss: 0.5381[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 29/203 [2m0:00:59 â€¢ 0:04:48[0m [2;4m0.61it/s[0m  
[2KAttention weights: tensor([[0.5785, 0.4215]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 29/203 [2m0:00:59 â€¢ 0:04:48[0m [2;4m0.61it/s[0m  
[2KAttention weights: tensor([[0.5783, 0.4217]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 29/203 [2m0:00:59 â€¢ 0:04:48[0m [2;4m0.61it/s[0m  
[2KAttention weights: tensor([[0.5777, 0.4223]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 29/203 [2m0:00:59 â€¢ 0:04:48[0m [2;4m0.61it/s[0m  
[2KAttention weights: tensor([[0.5767, 0.4233]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 29/203 [2m0:00:59 â€¢ 0:04:48[0m [2;4m0.61it/s[0m  
[2KAttention weights: tensor([[0.5738, 0.4262]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 29/203 [2m0:00:59 â€¢ 0:04:48[0m [2;4m0.61it/s[0m  
[2KAttention weights: tensor([[0.5668, 0.4332]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 29/203 [2m0:00:59 â€¢ 0:04:48[0m [2;4m0.61it/s[0m  
[2KAttention weights: tensor([[0.5567, 0.4433]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 29/203 [2m0:00:59 â€¢ 0:04:48[0m [2;4m0.61it/s[0m  
[2KAttention weights: tensor([[0.5618, 0.4382]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 29/203 [2m0:00:59 â€¢ 0:04:48[0m [2;4m0.61it/s[0m  
[2KAttention weights: tensor([[0.6051, 0.3949]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 29/203 [2m0:00:59 â€¢ 0:04:48[0m [2;4m0.61it/s[0m  
[2KAttention weights: tensor([[0.5555, 0.4445]], device='cuda:0')â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 29/203 [2m0:00:59 â€¢ 0:04:48[0m [2;4m0.61it/s[0m  
[2KAttention weights: tensor([[0.5965, 0.4035],mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 29/203 [2m0:00:59 â€¢ 0:04:48[0m [2;4m0.61it/s[0m  
        [0.6892, 0.3108],
        [0.5588, 0.4412],
        [0.6082, 0.3918],
        [0.5629, 0.4371],
        [0.5701, 0.4299],
        [0.5316, 0.4684],
        [0.6431, 0.3569],
        [0.6412, 0.3588],
[2K        [0.6136, 0.3864]], device='cuda:0')4mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 29/203 [2m0:00:59 â€¢ 0:04:48[0m [2;4m0.61it/s[0m  
[2KAttention weights: tensor([[0.5578, 0.4422],;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 30/203 [2m0:01:01 â€¢ 0:04:47[0m [2;4m0.60it/s[0m  
        [0.5535, 0.4465],
        [0.5543, 0.4457],
        [0.5565, 0.4435],
        [0.5555, 0.4445],
        [0.5528, 0.4472],
        [0.5521, 0.4479],
        [0.5573, 0.4427],
        [0.5576, 0.4424],
[2K        [0.5550, 0.4450]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 30/203 [2m0:01:01 â€¢ 0:04:47[0m [2;4m0.60it/s[0m  
[2KClass label: CleanAndJerk[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 30/203 [2m0:01:01 â€¢ 0:04:47[0m [2;4m0.60it/s[0m  
[2KAttention weights: tensor([[0.5662, 0.4338]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 30/203 [2m0:01:01 â€¢ 0:04:47[0m [2;4m0.60it/s[0m  
[2KStep 0 - TTA Loss: 0.5649[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 30/203 [2m0:01:01 â€¢ 0:04:47[0m [2;4m0.60it/s[0m  
[2KAttention weights: tensor([[0.5778, 0.4222]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 30/203 [2m0:01:01 â€¢ 0:04:47[0m [2;4m0.60it/s[0m  
[2KAttention weights: tensor([[0.5799, 0.4201]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 30/203 [2m0:01:01 â€¢ 0:04:47[0m [2;4m0.60it/s[0m  
[2KAttention weights: tensor([[0.5712, 0.4288]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 30/203 [2m0:01:01 â€¢ 0:04:47[0m [2;4m0.60it/s[0m  
[2KAttention weights: tensor([[0.5531, 0.4469]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 30/203 [2m0:01:01 â€¢ 0:04:47[0m [2;4m0.60it/s[0m  
[2KAttention weights: tensor([[0.5333, 0.4667]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 30/203 [2m0:01:01 â€¢ 0:04:47[0m [2;4m0.60it/s[0m  
[2KAttention weights: tensor([[0.5162, 0.4838]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 30/203 [2m0:01:01 â€¢ 0:04:47[0m [2;4m0.60it/s[0m  
[2KAttention weights: tensor([[0.5052, 0.4948]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 30/203 [2m0:01:01 â€¢ 0:04:47[0m [2;4m0.60it/s[0m  
[2KAttention weights: tensor([[0.4994, 0.5006]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 30/203 [2m0:01:01 â€¢ 0:04:47[0m [2;4m0.60it/s[0m  
[2KAttention weights: tensor([[0.4971, 0.5029]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 30/203 [2m0:01:01 â€¢ 0:04:47[0m [2;4m0.60it/s[0m  
[2KAttention weights: tensor([[0.5523, 0.4477]], device='cuda:0')â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 30/203 [2m0:01:01 â€¢ 0:04:47[0m [2;4m0.60it/s[0m  
[2KAttention weights: tensor([[0.6336, 0.3664],mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 30/203 [2m0:01:01 â€¢ 0:04:47[0m [2;4m0.60it/s[0m  
        [0.8318, 0.1682],
        [0.4965, 0.5035],
        [0.6362, 0.3638],
        [0.5788, 0.4212],
        [0.6003, 0.3997],
        [0.5585, 0.4415],
        [0.6946, 0.3054],
        [0.6853, 0.3147],
[2K        [0.6355, 0.3645]], device='cuda:0')4mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 30/203 [2m0:01:01 â€¢ 0:04:47[0m [2;4m0.60it/s[0m  
[2KAttention weights: tensor([[0.5578, 0.4422],mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 31/203 [2m0:01:02 â€¢ 0:05:02[0m [2;4m0.57it/s[0m   
        [0.5535, 0.4465],
        [0.5542, 0.4458],
        [0.5565, 0.4435],
        [0.5554, 0.4446],
        [0.5528, 0.4472],
        [0.5521, 0.4479],
        [0.5573, 0.4427],
        [0.5576, 0.4424],
[2K        [0.5550, 0.4450]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 31/203 [2m0:01:02 â€¢ 0:05:02[0m [2;4m0.57it/s[0m  
[2KClass label: CleanAndJerkâ”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 31/203 [2m0:01:02 â€¢ 0:05:02[0m [2;4m0.57it/s[0m  
[2KAttention weights: tensor([[0.5639, 0.4361]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 31/203 [2m0:01:02 â€¢ 0:05:02[0m [2;4m0.57it/s[0m  
[2KStep 0 - TTA Loss: 0.5358â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 31/203 [2m0:01:02 â€¢ 0:05:02[0m [2;4m0.57it/s[0m  
[2KAttention weights: tensor([[0.5639, 0.4361]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 31/203 [2m0:01:02 â€¢ 0:05:02[0m [2;4m0.57it/s[0m  
[2KAttention weights: tensor([[0.5639, 0.4361]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 31/203 [2m0:01:02 â€¢ 0:05:02[0m [2;4m0.57it/s[0m  
[2KAttention weights: tensor([[0.5644, 0.4356]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 31/203 [2m0:01:02 â€¢ 0:05:02[0m [2;4m0.57it/s[0m  
[2KAttention weights: tensor([[0.5662, 0.4338]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 31/203 [2m0:01:02 â€¢ 0:05:02[0m [2;4m0.57it/s[0m  
[2KAttention weights: tensor([[0.5704, 0.4296]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 31/203 [2m0:01:02 â€¢ 0:05:02[0m [2;4m0.57it/s[0m  
[2KAttention weights: tensor([[0.5782, 0.4218]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 31/203 [2m0:01:02 â€¢ 0:05:02[0m [2;4m0.57it/s[0m  
[2KAttention weights: tensor([[0.5863, 0.4137]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 31/203 [2m0:01:02 â€¢ 0:05:02[0m [2;4m0.57it/s[0m  
[2KAttention weights: tensor([[0.5904, 0.4096]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 31/203 [2m0:01:02 â€¢ 0:05:02[0m [2;4m0.57it/s[0m  
[2KAttention weights: tensor([[0.5877, 0.4123]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 31/203 [2m0:01:02 â€¢ 0:05:02[0m [2;4m0.57it/s[0m  
[2KAttention weights: tensor([[0.5543, 0.4457]], device='cuda:0')â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 31/203 [2m0:01:02 â€¢ 0:05:02[0m [2;4m0.57it/s[0m  
[2KAttention weights: tensor([[0.6259, 0.3741],0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 31/203 [2m0:01:02 â€¢ 0:05:02[0m [2;4m0.57it/s[0m  
        [0.6465, 0.3535],
        [0.5844, 0.4156],
        [0.6407, 0.3593],
        [0.5959, 0.4041],
        [0.6080, 0.3920],
        [0.5640, 0.4360],
        [0.6583, 0.3417],
        [0.6618, 0.3382],
[2K        [0.6466, 0.3534]], device='cuda:0')[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 31/203 [2m0:01:02 â€¢ 0:05:02[0m [2;4m0.57it/s[0m  
[2KAttention weights: tensor([[0.5578, 0.4422],mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 32/203 [2m0:01:05 â€¢ 0:05:35[0m [2;4m0.51it/s[0m  
        [0.5536, 0.4464],
        [0.5542, 0.4458],
        [0.5565, 0.4435],
        [0.5554, 0.4446],
        [0.5528, 0.4472],
        [0.5521, 0.4479],
        [0.5573, 0.4427],
        [0.5576, 0.4424],
[2K        [0.5550, 0.4450]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 32/203 [2m0:01:05 â€¢ 0:05:35[0m [2;4m0.51it/s[0m  
[2KClass label: TennisSwingâ”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 32/203 [2m0:01:05 â€¢ 0:05:35[0m [2;4m0.51it/s[0m  
[2KAttention weights: tensor([[0.6451, 0.3549]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 32/203 [2m0:01:05 â€¢ 0:05:35[0m [2;4m0.51it/s[0m  
[2KStep 0 - TTA Loss: 0.6254â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 32/203 [2m0:01:05 â€¢ 0:05:35[0m [2;4m0.51it/s[0m  
[2KAttention weights: tensor([[0.6256, 0.3744]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 32/203 [2m0:01:05 â€¢ 0:05:35[0m [2;4m0.51it/s[0m  
[2KAttention weights: tensor([[0.5856, 0.4144]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 32/203 [2m0:01:05 â€¢ 0:05:35[0m [2;4m0.51it/s[0m  
[2KAttention weights: tensor([[0.5266, 0.4734]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 32/203 [2m0:01:05 â€¢ 0:05:35[0m [2;4m0.51it/s[0m  
[2KAttention weights: tensor([[0.4561, 0.5439]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 32/203 [2m0:01:05 â€¢ 0:05:35[0m [2;4m0.51it/s[0m  
[2KAttention weights: tensor([[0.3897, 0.6103]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 32/203 [2m0:01:05 â€¢ 0:05:35[0m [2;4m0.51it/s[0m  
[2KAttention weights: tensor([[0.3411, 0.6589]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 32/203 [2m0:01:05 â€¢ 0:05:35[0m [2;4m0.51it/s[0m  
[2KAttention weights: tensor([[0.3138, 0.6862]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 32/203 [2m0:01:05 â€¢ 0:05:35[0m [2;4m0.51it/s[0m  
[2KAttention weights: tensor([[0.3027, 0.6973]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 32/203 [2m0:01:05 â€¢ 0:05:35[0m [2;4m0.51it/s[0m  
[2KAttention weights: tensor([[0.2998, 0.7002]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 32/203 [2m0:01:05 â€¢ 0:05:35[0m [2;4m0.51it/s[0m  
[2KAttention weights: tensor([[0.5476, 0.4524]], device='cuda:0')â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 32/203 [2m0:01:05 â€¢ 0:05:35[0m [2;4m0.51it/s[0m  
[2KAttention weights: tensor([[0.4048, 0.5952],0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 32/203 [2m0:01:05 â€¢ 0:05:35[0m [2;4m0.51it/s[0m  
        [0.4577, 0.5423],
        [0.4000, 0.6000],
        [0.3989, 0.6011],
        [0.3894, 0.6106],
        [0.3883, 0.6117],
        [0.4059, 0.5941],
        [0.4863, 0.5137],
        [0.2996, 0.7004],
[2K        [0.4132, 0.5868]], device='cuda:0')[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 32/203 [2m0:01:05 â€¢ 0:05:35[0m [2;4m0.51it/s[0m  
[2KAttention weights: tensor([[0.5577, 0.4423],6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 33/203 [2m0:01:16 â€¢ 0:08:25[0m [2;4m0.34it/s[0m  
        [0.5535, 0.4465],
        [0.5542, 0.4458],
        [0.5564, 0.4436],
        [0.5554, 0.4446],
        [0.5527, 0.4473],
        [0.5520, 0.4480],
        [0.5572, 0.4428],
        [0.5574, 0.4426],
[2K        [0.5549, 0.4451]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 33/203 [2m0:01:16 â€¢ 0:08:25[0m [2;4m0.34it/s[0m  
[2KClass label: CleanAndJerkâ”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 33/203 [2m0:01:16 â€¢ 0:08:25[0m [2;4m0.34it/s[0m  
[2KAttention weights: tensor([[0.5657, 0.4343]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 33/203 [2m0:01:16 â€¢ 0:08:25[0m [2;4m0.34it/s[0m  
[2KStep 0 - TTA Loss: 0.4997â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 33/203 [2m0:01:16 â€¢ 0:08:25[0m [2;4m0.34it/s[0m  
[2KAttention weights: tensor([[0.5657, 0.4343]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 33/203 [2m0:01:16 â€¢ 0:08:25[0m [2;4m0.34it/s[0m  
[2KAttention weights: tensor([[0.5663, 0.4337]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 33/203 [2m0:01:16 â€¢ 0:08:25[0m [2;4m0.34it/s[0m  
[2KAttention weights: tensor([[0.5696, 0.4304]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 33/203 [2m0:01:16 â€¢ 0:08:25[0m [2;4m0.34it/s[0m  
[2KAttention weights: tensor([[0.5793, 0.4207]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 33/203 [2m0:01:16 â€¢ 0:08:25[0m [2;4m0.34it/s[0m  
[2KAttention weights: tensor([[0.5981, 0.4019]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 33/203 [2m0:01:16 â€¢ 0:08:25[0m [2;4m0.34it/s[0m  
[2KAttention weights: tensor([[0.6251, 0.3749]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 33/203 [2m0:01:16 â€¢ 0:08:25[0m [2;4m0.34it/s[0m  
[2KAttention weights: tensor([[0.6573, 0.3427]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 33/203 [2m0:01:16 â€¢ 0:08:25[0m [2;4m0.34it/s[0m  
[2KAttention weights: tensor([[0.6865, 0.3135]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 33/203 [2m0:01:16 â€¢ 0:08:25[0m [2;4m0.34it/s[0m  
[2KAttention weights: tensor([[0.7018, 0.2982]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 33/203 [2m0:01:16 â€¢ 0:08:25[0m [2;4m0.34it/s[0m  
[2KAttention weights: tensor([[0.5569, 0.4431]], device='cuda:0')â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 33/203 [2m0:01:16 â€¢ 0:08:25[0m [2;4m0.34it/s[0m  
[2KAttention weights: tensor([[0.6540, 0.3460],4mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 33/203 [2m0:01:16 â€¢ 0:08:25[0m [2;4m0.34it/s[0m  
        [0.6230, 0.3770],
        [0.7013, 0.2987],
        [0.6736, 0.3264],
        [0.6535, 0.3465],
        [0.6561, 0.3439],
        [0.6120, 0.3880],
        [0.6702, 0.3298],
        [0.6835, 0.3165],
[2K        [0.6932, 0.3068]], device='cuda:0')24mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 33/203 [2m0:01:16 â€¢ 0:08:25[0m [2;4m0.34it/s[0m  
[2KAttention weights: tensor([[0.5577, 0.4423],6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 34/203 [2m0:01:20 â€¢ 0:10:24[0m [2;4m0.27it/s[0m  
        [0.5535, 0.4465],
        [0.5542, 0.4458],
        [0.5564, 0.4436],
        [0.5554, 0.4446],
        [0.5527, 0.4473],
        [0.5520, 0.4480],
        [0.5572, 0.4428],
        [0.5574, 0.4426],
[2K        [0.5549, 0.4451]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 34/203 [2m0:01:20 â€¢ 0:10:24[0m [2;4m0.27it/s[0m  
[2KClass label: HammerThrowâ”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 34/203 [2m0:01:20 â€¢ 0:10:24[0m [2;4m0.27it/s[0m  
[2KAttention weights: tensor([[0.5860, 0.4140]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 34/203 [2m0:01:20 â€¢ 0:10:24[0m [2;4m0.27it/s[0m  
[2KStep 0 - TTA Loss: 0.5855â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 34/203 [2m0:01:20 â€¢ 0:10:24[0m [2;4m0.27it/s[0m  
[2KAttention weights: tensor([[0.5814, 0.4186]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 34/203 [2m0:01:20 â€¢ 0:10:24[0m [2;4m0.27it/s[0m  
[2KAttention weights: tensor([[0.5718, 0.4282]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 34/203 [2m0:01:20 â€¢ 0:10:24[0m [2;4m0.27it/s[0m  
[2KAttention weights: tensor([[0.5553, 0.4447]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 34/203 [2m0:01:20 â€¢ 0:10:24[0m [2;4m0.27it/s[0m  
[2KAttention weights: tensor([[0.5329, 0.4671]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 34/203 [2m0:01:20 â€¢ 0:10:24[0m [2;4m0.27it/s[0m  
[2KAttention weights: tensor([[0.5107, 0.4893]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 34/203 [2m0:01:20 â€¢ 0:10:24[0m [2;4m0.27it/s[0m  
[2KAttention weights: tensor([[0.4946, 0.5054]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 34/203 [2m0:01:20 â€¢ 0:10:24[0m [2;4m0.27it/s[0m  
[2KAttention weights: tensor([[0.4868, 0.5132]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 34/203 [2m0:01:20 â€¢ 0:10:24[0m [2;4m0.27it/s[0m  
[2KAttention weights: tensor([[0.4850, 0.5150]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 34/203 [2m0:01:20 â€¢ 0:10:24[0m [2;4m0.27it/s[0m  
[2KAttention weights: tensor([[0.4854, 0.5146]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 34/203 [2m0:01:20 â€¢ 0:10:24[0m [2;4m0.27it/s[0m  
[2KAttention weights: tensor([[0.5527, 0.4473]], device='cuda:0')â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 34/203 [2m0:01:20 â€¢ 0:10:24[0m [2;4m0.27it/s[0m  
[2KAttention weights: tensor([[0.5415, 0.4585],4mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 34/203 [2m0:01:20 â€¢ 0:10:24[0m [2;4m0.27it/s[0m  
        [0.5430, 0.4570],
        [0.5032, 0.4968],
        [0.5657, 0.4343],
        [0.4858, 0.5142],
        [0.5191, 0.4809],
        [0.4781, 0.5219],
        [0.5801, 0.4199],
        [0.5877, 0.4123],
[2K        [0.5534, 0.4466]], device='cuda:0')24mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 34/203 [2m0:01:20 â€¢ 0:10:24[0m [2;4m0.27it/s[0m  
[2KAttention weights: tensor([[0.5576, 0.4424],6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 35/203 [2m0:01:23 â€¢ 0:09:21[0m [2;4m0.30it/s[0m  
        [0.5535, 0.4465],
        [0.5541, 0.4459],
        [0.5564, 0.4436],
        [0.5553, 0.4447],
        [0.5527, 0.4473],
        [0.5520, 0.4480],
        [0.5572, 0.4428],
        [0.5574, 0.4426],
[2K        [0.5549, 0.4451]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 35/203 [2m0:01:23 â€¢ 0:09:21[0m [2;4m0.30it/s[0m  
[2KClass label: GolfSwingâ”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 35/203 [2m0:01:23 â€¢ 0:09:21[0m [2;4m0.30it/s[0m  
[2KAttention weights: tensor([[0.6281, 0.3719]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 35/203 [2m0:01:23 â€¢ 0:09:21[0m [2;4m0.30it/s[0m  
[2KStep 0 - TTA Loss: 1.0455â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 35/203 [2m0:01:23 â€¢ 0:09:21[0m [2;4m0.30it/s[0m  
[2KAttention weights: tensor([[0.6281, 0.3719]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 35/203 [2m0:01:23 â€¢ 0:09:21[0m [2;4m0.30it/s[0m  
[2KAttention weights: tensor([[0.6286, 0.3714]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 35/203 [2m0:01:23 â€¢ 0:09:21[0m [2;4m0.30it/s[0m  
[2KAttention weights: tensor([[0.6314, 0.3686]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 35/203 [2m0:01:23 â€¢ 0:09:21[0m [2;4m0.30it/s[0m  
[2KAttention weights: tensor([[0.6399, 0.3601]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 35/203 [2m0:01:23 â€¢ 0:09:21[0m [2;4m0.30it/s[0m  
[2KAttention weights: tensor([[0.6564, 0.3436]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 35/203 [2m0:01:23 â€¢ 0:09:21[0m [2;4m0.30it/s[0m  
[2KAttention weights: tensor([[0.6810, 0.3190]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 35/203 [2m0:01:23 â€¢ 0:09:21[0m [2;4m0.30it/s[0m  
[2KAttention weights: tensor([[0.6977, 0.3023]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 35/203 [2m0:01:23 â€¢ 0:09:21[0m [2;4m0.30it/s[0m  
[2KAttention weights: tensor([[0.6964, 0.3036]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 35/203 [2m0:01:23 â€¢ 0:09:21[0m [2;4m0.30it/s[0m  
[2KAttention weights: tensor([[0.6653, 0.3347]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 35/203 [2m0:01:23 â€¢ 0:09:21[0m [2;4m0.30it/s[0m  
[2KAttention weights: tensor([[0.5554, 0.4446]], device='cuda:0')â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 35/203 [2m0:01:23 â€¢ 0:09:21[0m [2;4m0.30it/s[0m  
[2KAttention weights: tensor([[0.6147, 0.3853],4mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 35/203 [2m0:01:23 â€¢ 0:09:21[0m [2;4m0.30it/s[0m  
        [0.5845, 0.4155],
        [0.5771, 0.4229],
        [0.6239, 0.3761],
        [0.5966, 0.4034],
        [0.6018, 0.3982],
        [0.5533, 0.4467],
        [0.6411, 0.3589],
        [0.6448, 0.3552],
[2K        [0.6395, 0.3605]], device='cuda:0')24mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 35/203 [2m0:01:23 â€¢ 0:09:21[0m [2;4m0.30it/s[0m  
[2KAttention weights: tensor([[0.5576, 0.4424],7mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 36/203 [2m0:01:24 â€¢ 0:08:26[0m [2;4m0.33it/s[0m   
        [0.5534, 0.4466],
        [0.5541, 0.4459],
        [0.5564, 0.4436],
        [0.5553, 0.4447],
        [0.5527, 0.4473],
        [0.5519, 0.4481],
        [0.5572, 0.4428],
        [0.5574, 0.4426],
[2K        [0.5549, 0.4451]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 36/203 [2m0:01:24 â€¢ 0:08:26[0m [2;4m0.33it/s[0m  
[2KClass label: TennisSwingâ”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 36/203 [2m0:01:24 â€¢ 0:08:26[0m [2;4m0.33it/s[0m  
[2KAttention weights: tensor([[0.6457, 0.3543]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 36/203 [2m0:01:24 â€¢ 0:08:26[0m [2;4m0.33it/s[0m  
[2KStep 0 - TTA Loss: 0.7063â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 36/203 [2m0:01:24 â€¢ 0:08:26[0m [2;4m0.33it/s[0m  
[2KAttention weights: tensor([[0.6072, 0.3928]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 36/203 [2m0:01:24 â€¢ 0:08:26[0m [2;4m0.33it/s[0m  
[2KAttention weights: tensor([[0.5713, 0.4287]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 36/203 [2m0:01:24 â€¢ 0:08:26[0m [2;4m0.33it/s[0m  
[2KAttention weights: tensor([[0.5390, 0.4610]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 36/203 [2m0:01:24 â€¢ 0:08:26[0m [2;4m0.33it/s[0m  
[2KAttention weights: tensor([[0.5192, 0.4808]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 36/203 [2m0:01:24 â€¢ 0:08:26[0m [2;4m0.33it/s[0m  
[2KAttention weights: tensor([[0.4971, 0.5029]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 36/203 [2m0:01:24 â€¢ 0:08:26[0m [2;4m0.33it/s[0m  
[2KAttention weights: tensor([[0.4727, 0.5273]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 36/203 [2m0:01:24 â€¢ 0:08:26[0m [2;4m0.33it/s[0m  
[2KAttention weights: tensor([[0.4512, 0.5488]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 36/203 [2m0:01:24 â€¢ 0:08:26[0m [2;4m0.33it/s[0m  
[2KAttention weights: tensor([[0.4377, 0.5623]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 36/203 [2m0:01:24 â€¢ 0:08:26[0m [2;4m0.33it/s[0m  
[2KAttention weights: tensor([[0.4312, 0.5688]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 36/203 [2m0:01:24 â€¢ 0:08:26[0m [2;4m0.33it/s[0m  
[2KAttention weights: tensor([[0.5510, 0.4490]], device='cuda:0')â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 36/203 [2m0:01:24 â€¢ 0:08:26[0m [2;4m0.33it/s[0m  
[2KAttention weights: tensor([[0.4235, 0.5765],[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 36/203 [2m0:01:24 â€¢ 0:08:26[0m [2;4m0.33it/s[0m  
        [0.4669, 0.5331],
        [0.4418, 0.5582],
        [0.3930, 0.6070],
        [0.4222, 0.5778],
        [0.4422, 0.5578],
        [0.4178, 0.5822],
        [0.5150, 0.4850],
        [0.4293, 0.5707],
[2K        [0.4549, 0.5451]], device='cuda:0')[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 36/203 [2m0:01:24 â€¢ 0:08:26[0m [2;4m0.33it/s[0m  
[2KAttention weights: tensor([[0.5576, 0.4424],7mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 37/203 [2m0:01:25 â€¢ 0:07:56[0m [2;4m0.35it/s[0m  
        [0.5534, 0.4466],
        [0.5540, 0.4460],
        [0.5563, 0.4437],
        [0.5552, 0.4448],
        [0.5526, 0.4474],
        [0.5519, 0.4481],
        [0.5571, 0.4429],
        [0.5573, 0.4427],
[2K        [0.5548, 0.4452]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 37/203 [2m0:01:25 â€¢ 0:07:56[0m [2;4m0.35it/s[0m  
[2KClass label: SoccerPenaltyâ”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 37/203 [2m0:01:25 â€¢ 0:07:56[0m [2;4m0.35it/s[0m  
[2KAttention weights: tensor([[0.6367, 0.3633]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 37/203 [2m0:01:25 â€¢ 0:07:56[0m [2;4m0.35it/s[0m  
[2KStep 0 - TTA Loss: 0.9578â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 37/203 [2m0:01:25 â€¢ 0:07:56[0m [2;4m0.35it/s[0m  
[2KAttention weights: tensor([[0.6367, 0.3633]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 37/203 [2m0:01:25 â€¢ 0:07:56[0m [2;4m0.35it/s[0m  
[2KAttention weights: tensor([[0.6374, 0.3626]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 37/203 [2m0:01:25 â€¢ 0:07:56[0m [2;4m0.35it/s[0m  
[2KAttention weights: tensor([[0.6423, 0.3577]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 37/203 [2m0:01:25 â€¢ 0:07:56[0m [2;4m0.35it/s[0m  
[2KAttention weights: tensor([[0.6563, 0.3437]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 37/203 [2m0:01:25 â€¢ 0:07:56[0m [2;4m0.35it/s[0m  
[2KAttention weights: tensor([[0.6852, 0.3148]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 37/203 [2m0:01:25 â€¢ 0:07:56[0m [2;4m0.35it/s[0m  
[2KAttention weights: tensor([[0.7276, 0.2724]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 37/203 [2m0:01:25 â€¢ 0:07:56[0m [2;4m0.35it/s[0m  
[2KAttention weights: tensor([[0.7762, 0.2238]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 37/203 [2m0:01:25 â€¢ 0:07:56[0m [2;4m0.35it/s[0m  
[2KAttention weights: tensor([[0.8149, 0.1851]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 37/203 [2m0:01:25 â€¢ 0:07:56[0m [2;4m0.35it/s[0m  
[2KAttention weights: tensor([[0.8194, 0.1806]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 37/203 [2m0:01:25 â€¢ 0:07:56[0m [2;4m0.35it/s[0m  
[2KAttention weights: tensor([[0.5608, 0.4392]], device='cuda:0')â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 37/203 [2m0:01:25 â€¢ 0:07:56[0m [2;4m0.35it/s[0m  
[2KAttention weights: tensor([[0.6499, 0.3501],[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 37/203 [2m0:01:25 â€¢ 0:07:56[0m [2;4m0.35it/s[0m  
        [0.6248, 0.3752],
        [0.5773, 0.4227],
        [0.6203, 0.3797],
        [0.6398, 0.3602],
        [0.6500, 0.3500],
        [0.6248, 0.3752],
        [0.8338, 0.1662],
        [0.6021, 0.3979],
[2K        [0.6592, 0.3408]], device='cuda:0')[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 37/203 [2m0:01:25 â€¢ 0:07:56[0m [2;4m0.35it/s[0m  
[2KAttention weights: tensor([[0.5576, 0.4424],7mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 38/203 [2m0:01:28 â€¢ 0:08:09[0m [2;4m0.34it/s[0m  
        [0.5534, 0.4466],
        [0.5540, 0.4460],
        [0.5563, 0.4437],
        [0.5553, 0.4447],
        [0.5526, 0.4474],
        [0.5519, 0.4481],
        [0.5572, 0.4428],
        [0.5573, 0.4427],
[2K        [0.5548, 0.4452]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 38/203 [2m0:01:28 â€¢ 0:08:09[0m [2;4m0.34it/s[0m  
[2KClass label: ThrowDiscusâ”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 38/203 [2m0:01:28 â€¢ 0:08:09[0m [2;4m0.34it/s[0m  
[2KAttention weights: tensor([[0.6360, 0.3640]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 38/203 [2m0:01:28 â€¢ 0:08:09[0m [2;4m0.34it/s[0m  
[2KStep 0 - TTA Loss: 0.8673â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 38/203 [2m0:01:28 â€¢ 0:08:09[0m [2;4m0.34it/s[0m  
[2KAttention weights: tensor([[0.6467, 0.3533]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 38/203 [2m0:01:28 â€¢ 0:08:09[0m [2;4m0.34it/s[0m  
[2KAttention weights: tensor([[0.6669, 0.3331]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 38/203 [2m0:01:28 â€¢ 0:08:09[0m [2;4m0.34it/s[0m  
[2KAttention weights: tensor([[0.6899, 0.3101]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 38/203 [2m0:01:28 â€¢ 0:08:09[0m [2;4m0.34it/s[0m  
[2KAttention weights: tensor([[0.7044, 0.2956]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 38/203 [2m0:01:28 â€¢ 0:08:09[0m [2;4m0.34it/s[0m  
[2KAttention weights: tensor([[0.7090, 0.2910]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 38/203 [2m0:01:28 â€¢ 0:08:09[0m [2;4m0.34it/s[0m  
[2KAttention weights: tensor([[0.7151, 0.2849]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 38/203 [2m0:01:28 â€¢ 0:08:09[0m [2;4m0.34it/s[0m  
[2KAttention weights: tensor([[0.7259, 0.2741]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 38/203 [2m0:01:28 â€¢ 0:08:09[0m [2;4m0.34it/s[0m  
[2KAttention weights: tensor([[0.7388, 0.2612]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 38/203 [2m0:01:28 â€¢ 0:08:09[0m [2;4m0.34it/s[0m  
[2KAttention weights: tensor([[0.7474, 0.2526]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 38/203 [2m0:01:28 â€¢ 0:08:09[0m [2;4m0.34it/s[0m  
[2KAttention weights: tensor([[0.5578, 0.4422]], device='cuda:0')â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 38/203 [2m0:01:28 â€¢ 0:08:09[0m [2;4m0.34it/s[0m  
[2KAttention weights: tensor([[0.7195, 0.2805],[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 38/203 [2m0:01:28 â€¢ 0:08:09[0m [2;4m0.34it/s[0m  
        [0.6467, 0.3533],
        [0.6450, 0.3550],
        [0.7040, 0.2960],
        [0.7113, 0.2887],
        [0.7041, 0.2959],
        [0.6693, 0.3307],
        [0.7856, 0.2144],
        [0.6892, 0.3108],
[2K        [0.7503, 0.2497]], device='cuda:0')[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 38/203 [2m0:01:28 â€¢ 0:08:09[0m [2;4m0.34it/s[0m  
[2KAttention weights: tensor([[0.5576, 0.4424],;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 39/203 [2m0:01:37 â€¢ 0:09:50[0m [2;4m0.28it/s[0m  
        [0.5534, 0.4466],
        [0.5541, 0.4459],
        [0.5563, 0.4437],
        [0.5553, 0.4447],
        [0.5527, 0.4473],
        [0.5520, 0.4480],
        [0.5573, 0.4427],
        [0.5573, 0.4427],
[2K        [0.5549, 0.4451]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 39/203 [2m0:01:37 â€¢ 0:09:50[0m [2;4m0.28it/s[0m  
[2KClass label: GolfSwingâ”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 39/203 [2m0:01:37 â€¢ 0:09:50[0m [2;4m0.28it/s[0m  
[2KAttention weights: tensor([[0.6247, 0.3753]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 39/203 [2m0:01:37 â€¢ 0:09:50[0m [2;4m0.28it/s[0m  
[2KStep 0 - TTA Loss: 0.6339â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 39/203 [2m0:01:37 â€¢ 0:09:50[0m [2;4m0.28it/s[0m  
[2KAttention weights: tensor([[0.6247, 0.3753]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 39/203 [2m0:01:37 â€¢ 0:09:50[0m [2;4m0.28it/s[0m  
[2KAttention weights: tensor([[0.6266, 0.3734]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 39/203 [2m0:01:37 â€¢ 0:09:50[0m [2;4m0.28it/s[0m  
[2KAttention weights: tensor([[0.6330, 0.3670]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 39/203 [2m0:01:37 â€¢ 0:09:50[0m [2;4m0.28it/s[0m  
[2KAttention weights: tensor([[0.6432, 0.3568]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 39/203 [2m0:01:37 â€¢ 0:09:50[0m [2;4m0.28it/s[0m  
[2KAttention weights: tensor([[0.6572, 0.3428]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 39/203 [2m0:01:37 â€¢ 0:09:50[0m [2;4m0.28it/s[0m  
[2KAttention weights: tensor([[0.6734, 0.3266]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 39/203 [2m0:01:37 â€¢ 0:09:50[0m [2;4m0.28it/s[0m  
[2KAttention weights: tensor([[0.6886, 0.3114]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 39/203 [2m0:01:37 â€¢ 0:09:50[0m [2;4m0.28it/s[0m  
[2KAttention weights: tensor([[0.6976, 0.3024]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 39/203 [2m0:01:37 â€¢ 0:09:50[0m [2;4m0.28it/s[0m  
[2KAttention weights: tensor([[0.6943, 0.3057]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 39/203 [2m0:01:37 â€¢ 0:09:50[0m [2;4m0.28it/s[0m  
[2KAttention weights: tensor([[0.5576, 0.4424]], device='cuda:0')mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 39/203 [2m0:01:37 â€¢ 0:09:50[0m [2;4m0.28it/s[0m  
[2KAttention weights: tensor([[0.7233, 0.2767],24mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 39/203 [2m0:01:37 â€¢ 0:09:50[0m [2;4m0.28it/s[0m  
        [0.6433, 0.3567],
        [0.6696, 0.3304],
        [0.6806, 0.3194],
        [0.7330, 0.2670],
        [0.7261, 0.2739],
        [0.6786, 0.3214],
        [0.7375, 0.2625],
        [0.7223, 0.2777],
[2K        [0.7835, 0.2165]], device='cuda:0')224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 39/203 [2m0:01:37 â€¢ 0:09:50[0m [2;4m0.28it/s[0m  
[2KAttention weights: tensor([[0.5576, 0.4424],;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 40/203 [2m0:01:41 â€¢ 0:09:43[0m [2;4m0.28it/s[0m  
        [0.5534, 0.4466],
        [0.5541, 0.4459],
        [0.5563, 0.4437],
        [0.5554, 0.4446],
        [0.5527, 0.4473],
        [0.5520, 0.4480],
        [0.5573, 0.4427],
        [0.5573, 0.4427],
[2K        [0.5549, 0.4451]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 40/203 [2m0:01:41 â€¢ 0:09:43[0m [2;4m0.28it/s[0m  
[2KClass label: PoleVaultâ”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 40/203 [2m0:01:41 â€¢ 0:09:43[0m [2;4m0.28it/s[0m  
[2KAttention weights: tensor([[0.5477, 0.4523]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 40/203 [2m0:01:41 â€¢ 0:09:43[0m [2;4m0.28it/s[0m  
[2KStep 0 - TTA Loss: 0.7390â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 40/203 [2m0:01:41 â€¢ 0:09:43[0m [2;4m0.28it/s[0m  
[2KAttention weights: tensor([[0.5491, 0.4509]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 40/203 [2m0:01:41 â€¢ 0:09:43[0m [2;4m0.28it/s[0m  
[2KAttention weights: tensor([[0.5446, 0.4554]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 40/203 [2m0:01:41 â€¢ 0:09:43[0m [2;4m0.28it/s[0m  
[2KAttention weights: tensor([[0.5329, 0.4671]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 40/203 [2m0:01:41 â€¢ 0:09:43[0m [2;4m0.28it/s[0m  
[2KAttention weights: tensor([[0.5128, 0.4872]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 40/203 [2m0:01:41 â€¢ 0:09:43[0m [2;4m0.28it/s[0m  
[2KAttention weights: tensor([[0.4872, 0.5128]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 40/203 [2m0:01:41 â€¢ 0:09:43[0m [2;4m0.28it/s[0m  
[2KAttention weights: tensor([[0.4628, 0.5372]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 40/203 [2m0:01:41 â€¢ 0:09:43[0m [2;4m0.28it/s[0m  
[2KAttention weights: tensor([[0.4462, 0.5538]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 40/203 [2m0:01:41 â€¢ 0:09:43[0m [2;4m0.28it/s[0m  
[2KAttention weights: tensor([[0.4377, 0.5623]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 40/203 [2m0:01:41 â€¢ 0:09:43[0m [2;4m0.28it/s[0m  
[2KAttention weights: tensor([[0.4346, 0.5654]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 40/203 [2m0:01:41 â€¢ 0:09:43[0m [2;4m0.28it/s[0m  
[2KAttention weights: tensor([[0.5490, 0.4510]], device='cuda:0')mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 40/203 [2m0:01:41 â€¢ 0:09:43[0m [2;4m0.28it/s[0m  
[2KAttention weights: tensor([[0.5413, 0.4587],24mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 40/203 [2m0:01:41 â€¢ 0:09:43[0m [2;4m0.28it/s[0m  
        [0.5242, 0.4758],
        [0.5123, 0.4877],
        [0.4956, 0.5044],
        [0.5273, 0.4727],
        [0.5217, 0.4783],
        [0.4338, 0.5662],
        [0.5819, 0.4181],
        [0.5801, 0.4199],
[2K        [0.5893, 0.4107]], device='cuda:0')224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 40/203 [2m0:01:41 â€¢ 0:09:43[0m [2;4m0.28it/s[0m  
[2KAttention weights: tensor([[0.5576, 0.4424],37mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 41/203 [2m0:01:51 â€¢ 0:12:32[0m [2;4m0.22it/s[0m   
        [0.5534, 0.4466],
        [0.5541, 0.4459],
        [0.5562, 0.4438],
        [0.5553, 0.4447],
        [0.5526, 0.4474],
        [0.5519, 0.4481],
        [0.5572, 0.4428],
        [0.5572, 0.4428],
[2K        [0.5549, 0.4451]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 41/203 [2m0:01:51 â€¢ 0:12:32[0m [2;4m0.22it/s[0m  
[2KClass label: HammerThrowâ”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 41/203 [2m0:01:51 â€¢ 0:12:32[0m [2;4m0.22it/s[0m  
[2KAttention weights: tensor([[0.5811, 0.4189]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 41/203 [2m0:01:51 â€¢ 0:12:32[0m [2;4m0.22it/s[0m  
[2KStep 0 - TTA Loss: 0.5311â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 41/203 [2m0:01:51 â€¢ 0:12:32[0m [2;4m0.22it/s[0m  
[2KAttention weights: tensor([[0.5811, 0.4189]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 41/203 [2m0:01:51 â€¢ 0:12:32[0m [2;4m0.22it/s[0m  
[2KAttention weights: tensor([[0.5811, 0.4189]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 41/203 [2m0:01:51 â€¢ 0:12:32[0m [2;4m0.22it/s[0m  
[2KAttention weights: tensor([[0.5819, 0.4181]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 41/203 [2m0:01:51 â€¢ 0:12:32[0m [2;4m0.22it/s[0m  
[2KAttention weights: tensor([[0.5848, 0.4152]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 41/203 [2m0:01:51 â€¢ 0:12:32[0m [2;4m0.22it/s[0m  
[2KAttention weights: tensor([[0.5892, 0.4108]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 41/203 [2m0:01:51 â€¢ 0:12:32[0m [2;4m0.22it/s[0m  
[2KAttention weights: tensor([[0.5944, 0.4056]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 41/203 [2m0:01:51 â€¢ 0:12:32[0m [2;4m0.22it/s[0m  
[2KAttention weights: tensor([[0.5983, 0.4017]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 41/203 [2m0:01:51 â€¢ 0:12:32[0m [2;4m0.22it/s[0m  
[2KAttention weights: tensor([[0.5979, 0.4021]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 41/203 [2m0:01:51 â€¢ 0:12:32[0m [2;4m0.22it/s[0m  
[2KAttention weights: tensor([[0.5912, 0.4088]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 41/203 [2m0:01:51 â€¢ 0:12:32[0m [2;4m0.22it/s[0m  
[2KAttention weights: tensor([[0.5550, 0.4450]], device='cuda:0')â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 41/203 [2m0:01:51 â€¢ 0:12:32[0m [2;4m0.22it/s[0m  
[2KAttention weights: tensor([[0.6023, 0.3977],[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 41/203 [2m0:01:51 â€¢ 0:12:32[0m [2;4m0.22it/s[0m  
        [0.5681, 0.4319],
        [0.5601, 0.4399],
        [0.6068, 0.3932],
        [0.5846, 0.4154],
        [0.5810, 0.4190],
        [0.5170, 0.4830],
        [0.6271, 0.3729],
        [0.6371, 0.3629],
[2K        [0.6306, 0.3694]], device='cuda:0')â•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 41/203 [2m0:01:51 â€¢ 0:12:32[0m [2;4m0.22it/s[0m  
[2KAttention weights: tensor([[0.5575, 0.4425],37mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 42/203 [2m0:01:56 â€¢ 0:18:37[0m [2;4m0.14it/s[0m  
        [0.5534, 0.4466],
        [0.5540, 0.4460],
        [0.5562, 0.4438],
        [0.5553, 0.4447],
        [0.5526, 0.4474],
        [0.5518, 0.4482],
        [0.5572, 0.4428],
        [0.5572, 0.4428],
[2K        [0.5549, 0.4451]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 42/203 [2m0:01:56 â€¢ 0:18:37[0m [2;4m0.14it/s[0m  
[2KClass label: ThrowDiscusâ”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 42/203 [2m0:01:56 â€¢ 0:18:37[0m [2;4m0.14it/s[0m  
[2KAttention weights: tensor([[0.6285, 0.3715]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 42/203 [2m0:01:56 â€¢ 0:18:37[0m [2;4m0.14it/s[0m  
[2KStep 0 - TTA Loss: 0.8634â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 42/203 [2m0:01:56 â€¢ 0:18:37[0m [2;4m0.14it/s[0m  
[2KAttention weights: tensor([[0.6273, 0.3727]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 42/203 [2m0:01:56 â€¢ 0:18:37[0m [2;4m0.14it/s[0m  
[2KAttention weights: tensor([[0.6297, 0.3703]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 42/203 [2m0:01:56 â€¢ 0:18:37[0m [2;4m0.14it/s[0m  
[2KAttention weights: tensor([[0.6331, 0.3669]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 42/203 [2m0:01:56 â€¢ 0:18:37[0m [2;4m0.14it/s[0m  
[2KAttention weights: tensor([[0.6363, 0.3637]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 42/203 [2m0:01:56 â€¢ 0:18:37[0m [2;4m0.14it/s[0m  
[2KAttention weights: tensor([[0.6388, 0.3612]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 42/203 [2m0:01:56 â€¢ 0:18:37[0m [2;4m0.14it/s[0m  
[2KAttention weights: tensor([[0.6405, 0.3595]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 42/203 [2m0:01:56 â€¢ 0:18:37[0m [2;4m0.14it/s[0m  
[2KAttention weights: tensor([[0.6411, 0.3589]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 42/203 [2m0:01:56 â€¢ 0:18:37[0m [2;4m0.14it/s[0m  
[2KAttention weights: tensor([[0.6413, 0.3587]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 42/203 [2m0:01:56 â€¢ 0:18:37[0m [2;4m0.14it/s[0m  
[2KAttention weights: tensor([[0.6412, 0.3588]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 42/203 [2m0:01:56 â€¢ 0:18:37[0m [2;4m0.14it/s[0m  
[2KAttention weights: tensor([[0.5547, 0.4453]], device='cuda:0')â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 42/203 [2m0:01:56 â€¢ 0:18:37[0m [2;4m0.14it/s[0m  
[2KAttention weights: tensor([[0.6125, 0.3875],[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 42/203 [2m0:01:56 â€¢ 0:18:37[0m [2;4m0.14it/s[0m  
        [0.5775, 0.4225],
        [0.5644, 0.4356],
        [0.6205, 0.3795],
        [0.5856, 0.4144],
        [0.5914, 0.4086],
        [0.5327, 0.4673],
        [0.6345, 0.3655],
        [0.6467, 0.3533],
[2K        [0.6412, 0.3588]], device='cuda:0')â•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 42/203 [2m0:01:56 â€¢ 0:18:37[0m [2;4m0.14it/s[0m  
[2KAttention weights: tensor([[0.5575, 0.4425],37mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 43/203 [2m0:01:57 â€¢ 0:15:24[0m [2;4m0.17it/s[0m  
        [0.5533, 0.4467],
        [0.5540, 0.4460],
        [0.5562, 0.4438],
        [0.5552, 0.4448],
        [0.5525, 0.4475],
        [0.5518, 0.4482],
        [0.5572, 0.4428],
        [0.5572, 0.4428],
[2K        [0.5549, 0.4451]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 43/203 [2m0:01:57 â€¢ 0:15:24[0m [2;4m0.17it/s[0m  
[2KClass label: ThrowDiscusâ”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 43/203 [2m0:01:57 â€¢ 0:15:24[0m [2;4m0.17it/s[0m  
[2KAttention weights: tensor([[0.6295, 0.3705]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 43/203 [2m0:01:57 â€¢ 0:15:24[0m [2;4m0.17it/s[0m  
[2KStep 0 - TTA Loss: 0.7323â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 43/203 [2m0:01:57 â€¢ 0:15:24[0m [2;4m0.17it/s[0m  
[2KAttention weights: tensor([[0.6295, 0.3705]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 43/203 [2m0:01:57 â€¢ 0:15:24[0m [2;4m0.17it/s[0m  
[2KAttention weights: tensor([[0.6299, 0.3701]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 43/203 [2m0:01:57 â€¢ 0:15:24[0m [2;4m0.17it/s[0m  
[2KAttention weights: tensor([[0.6317, 0.3683]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 43/203 [2m0:01:57 â€¢ 0:15:24[0m [2;4m0.17it/s[0m  
[2KAttention weights: tensor([[0.6368, 0.3632]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 43/203 [2m0:01:57 â€¢ 0:15:24[0m [2;4m0.17it/s[0m  
[2KAttention weights: tensor([[0.6457, 0.3543]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 43/203 [2m0:01:57 â€¢ 0:15:24[0m [2;4m0.17it/s[0m  
[2KAttention weights: tensor([[0.6581, 0.3419]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 43/203 [2m0:01:57 â€¢ 0:15:24[0m [2;4m0.17it/s[0m  
[2KAttention weights: tensor([[0.6736, 0.3264]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 43/203 [2m0:01:57 â€¢ 0:15:24[0m [2;4m0.17it/s[0m  
[2KAttention weights: tensor([[0.6917, 0.3083]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 43/203 [2m0:01:57 â€¢ 0:15:24[0m [2;4m0.17it/s[0m  
[2KAttention weights: tensor([[0.7073, 0.2927]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 43/203 [2m0:01:57 â€¢ 0:15:24[0m [2;4m0.17it/s[0m  
[2KAttention weights: tensor([[0.5566, 0.4434]], device='cuda:0')â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 43/203 [2m0:01:57 â€¢ 0:15:24[0m [2;4m0.17it/s[0m  
[2KAttention weights: tensor([[0.6826, 0.3174],[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 43/203 [2m0:01:57 â€¢ 0:15:24[0m [2;4m0.17it/s[0m  
        [0.6166, 0.3834],
        [0.6226, 0.3774],
        [0.6892, 0.3108],
        [0.6616, 0.3384],
        [0.6615, 0.3385],
        [0.6099, 0.3901],
        [0.6827, 0.3173],
        [0.7018, 0.2982],
[2K        [0.7143, 0.2857]], device='cuda:0')â•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 43/203 [2m0:01:57 â€¢ 0:15:24[0m [2;4m0.17it/s[0m  
[2KAttention weights: tensor([[0.5576, 0.4424],8;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 44/203 [2m0:02:02 â€¢ 0:12:55[0m [2;4m0.21it/s[0m  
        [0.5534, 0.4466],
        [0.5541, 0.4459],
        [0.5562, 0.4438],
        [0.5553, 0.4447],
        [0.5526, 0.4474],
        [0.5518, 0.4482],
        [0.5572, 0.4428],
        [0.5572, 0.4428],
[2K        [0.5550, 0.4450]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 44/203 [2m0:02:02 â€¢ 0:12:55[0m [2;4m0.21it/s[0m  
[2KClass label: HighJumpâ”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 44/203 [2m0:02:02 â€¢ 0:12:55[0m [2;4m0.21it/s[0m  
[2KAttention weights: tensor([[0.5886, 0.4114]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 44/203 [2m0:02:02 â€¢ 0:12:55[0m [2;4m0.21it/s[0m  
[2KStep 0 - TTA Loss: 0.4650â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 44/203 [2m0:02:02 â€¢ 0:12:55[0m [2;4m0.21it/s[0m  
[2KAttention weights: tensor([[0.6081, 0.3919]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 44/203 [2m0:02:02 â€¢ 0:12:55[0m [2;4m0.21it/s[0m  
[2KAttention weights: tensor([[0.6353, 0.3647]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 44/203 [2m0:02:02 â€¢ 0:12:55[0m [2;4m0.21it/s[0m  
[2KAttention weights: tensor([[0.6597, 0.3403]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 44/203 [2m0:02:02 â€¢ 0:12:55[0m [2;4m0.21it/s[0m  
[2KAttention weights: tensor([[0.6756, 0.3244]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 44/203 [2m0:02:02 â€¢ 0:12:55[0m [2;4m0.21it/s[0m  
[2KAttention weights: tensor([[0.6821, 0.3179]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 44/203 [2m0:02:02 â€¢ 0:12:55[0m [2;4m0.21it/s[0m  
[2KAttention weights: tensor([[0.6822, 0.3178]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 44/203 [2m0:02:02 â€¢ 0:12:55[0m [2;4m0.21it/s[0m  
[2KAttention weights: tensor([[0.6816, 0.3184]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 44/203 [2m0:02:02 â€¢ 0:12:55[0m [2;4m0.21it/s[0m  
[2KAttention weights: tensor([[0.6820, 0.3180]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 44/203 [2m0:02:02 â€¢ 0:12:55[0m [2;4m0.21it/s[0m  
[2KAttention weights: tensor([[0.6830, 0.3170]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 44/203 [2m0:02:02 â€¢ 0:12:55[0m [2;4m0.21it/s[0m  
[2KAttention weights: tensor([[0.5546, 0.4454]], device='cuda:0')7mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 44/203 [2m0:02:02 â€¢ 0:12:55[0m [2;4m0.21it/s[0m  
[2KAttention weights: tensor([[0.6797, 0.3203],224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 44/203 [2m0:02:02 â€¢ 0:12:55[0m [2;4m0.21it/s[0m  
        [0.6189, 0.3811],
        [0.6303, 0.3697],
        [0.6845, 0.3155],
        [0.6650, 0.3350],
        [0.6836, 0.3164],
        [0.6263, 0.3737],
        [0.6950, 0.3050],
        [0.7057, 0.2943],
[2K        [0.7108, 0.2892]], device='cuda:0');224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 44/203 [2m0:02:02 â€¢ 0:12:55[0m [2;4m0.21it/s[0m  
[2KAttention weights: tensor([[0.5576, 0.4424],8;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 45/203 [2m0:02:18 â€¢ 0:18:03[0m [2;4m0.15it/s[0m  
        [0.5534, 0.4466],
        [0.5541, 0.4459],
        [0.5562, 0.4438],
        [0.5554, 0.4446],
        [0.5526, 0.4474],
        [0.5519, 0.4481],
        [0.5573, 0.4427],
        [0.5573, 0.4427],
[2K        [0.5551, 0.4449]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 45/203 [2m0:02:18 â€¢ 0:18:03[0m [2;4m0.15it/s[0m  
[2KClass label: GolfSwingâ”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 45/203 [2m0:02:18 â€¢ 0:18:03[0m [2;4m0.15it/s[0m  
[2KAttention weights: tensor([[0.6243, 0.3757]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 45/203 [2m0:02:18 â€¢ 0:18:03[0m [2;4m0.15it/s[0m  
[2KStep 0 - TTA Loss: 0.7933â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 45/203 [2m0:02:18 â€¢ 0:18:03[0m [2;4m0.15it/s[0m  
[2KAttention weights: tensor([[0.6243, 0.3757]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 45/203 [2m0:02:18 â€¢ 0:18:03[0m [2;4m0.15it/s[0m  
[2KAttention weights: tensor([[0.6249, 0.3751]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 45/203 [2m0:02:18 â€¢ 0:18:03[0m [2;4m0.15it/s[0m  
[2KAttention weights: tensor([[0.6273, 0.3727]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 45/203 [2m0:02:18 â€¢ 0:18:03[0m [2;4m0.15it/s[0m  
[2KAttention weights: tensor([[0.6320, 0.3680]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 45/203 [2m0:02:18 â€¢ 0:18:03[0m [2;4m0.15it/s[0m  
[2KAttention weights: tensor([[0.6395, 0.3605]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 45/203 [2m0:02:18 â€¢ 0:18:03[0m [2;4m0.15it/s[0m  
[2KAttention weights: tensor([[0.6470, 0.3530]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 45/203 [2m0:02:18 â€¢ 0:18:03[0m [2;4m0.15it/s[0m  
[2KAttention weights: tensor([[0.6513, 0.3487]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 45/203 [2m0:02:18 â€¢ 0:18:03[0m [2;4m0.15it/s[0m  
[2KAttention weights: tensor([[0.6489, 0.3511]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 45/203 [2m0:02:18 â€¢ 0:18:03[0m [2;4m0.15it/s[0m  
[2KAttention weights: tensor([[0.6331, 0.3669]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 45/203 [2m0:02:18 â€¢ 0:18:03[0m [2;4m0.15it/s[0m  
[2KAttention weights: tensor([[0.5549, 0.4451]], device='cuda:0')7mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 45/203 [2m0:02:18 â€¢ 0:18:03[0m [2;4m0.15it/s[0m  
[2KAttention weights: tensor([[0.6069, 0.3931],224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 45/203 [2m0:02:18 â€¢ 0:18:03[0m [2;4m0.15it/s[0m  
        [0.5810, 0.4190],
        [0.5717, 0.4283],
        [0.6075, 0.3925],
        [0.5875, 0.4125],
        [0.6104, 0.3896],
        [0.5589, 0.4411],
        [0.6391, 0.3609],
        [0.6417, 0.3583],
[2K        [0.6359, 0.3641]], device='cuda:0');224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 45/203 [2m0:02:18 â€¢ 0:18:03[0m [2;4m0.15it/s[0m  
[2KAttention weights: tensor([[0.5576, 0.4424],237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 46/203 [2m0:02:24 â€¢ 0:18:27[0m [2;4m0.14it/s[0m   
        [0.5534, 0.4466],
        [0.5542, 0.4458],
        [0.5562, 0.4438],
        [0.5554, 0.4446],
        [0.5526, 0.4474],
        [0.5519, 0.4481],
        [0.5573, 0.4427],
        [0.5573, 0.4427],
[2K        [0.5551, 0.4449]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 46/203 [2m0:02:24 â€¢ 0:18:27[0m [2;4m0.14it/s[0m  
[2KClass label: GolfSwingâ”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 46/203 [2m0:02:24 â€¢ 0:18:27[0m [2;4m0.14it/s[0m  
[2KAttention weights: tensor([[0.6220, 0.3780]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 46/203 [2m0:02:24 â€¢ 0:18:27[0m [2;4m0.14it/s[0m  
[2KStep 0 - TTA Loss: 0.7422â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 46/203 [2m0:02:24 â€¢ 0:18:27[0m [2;4m0.14it/s[0m  
[2KAttention weights: tensor([[0.5969, 0.4031]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 46/203 [2m0:02:24 â€¢ 0:18:27[0m [2;4m0.14it/s[0m  
[2KAttention weights: tensor([[0.5742, 0.4258]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 46/203 [2m0:02:24 â€¢ 0:18:27[0m [2;4m0.14it/s[0m  
[2KAttention weights: tensor([[0.5467, 0.4533]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 46/203 [2m0:02:24 â€¢ 0:18:27[0m [2;4m0.14it/s[0m  
[2KAttention weights: tensor([[0.5147, 0.4853]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 46/203 [2m0:02:24 â€¢ 0:18:27[0m [2;4m0.14it/s[0m  
[2KAttention weights: tensor([[0.4736, 0.5264]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 46/203 [2m0:02:24 â€¢ 0:18:27[0m [2;4m0.14it/s[0m  
[2KAttention weights: tensor([[0.4358, 0.5642]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 46/203 [2m0:02:24 â€¢ 0:18:27[0m [2;4m0.14it/s[0m  
[2KAttention weights: tensor([[0.4067, 0.5933]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 46/203 [2m0:02:24 â€¢ 0:18:27[0m [2;4m0.14it/s[0m  
[2KAttention weights: tensor([[0.3891, 0.6109]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 46/203 [2m0:02:24 â€¢ 0:18:27[0m [2;4m0.14it/s[0m  
[2KAttention weights: tensor([[0.3811, 0.6189]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 46/203 [2m0:02:24 â€¢ 0:18:27[0m [2;4m0.14it/s[0m  
[2KAttention weights: tensor([[0.5501, 0.4499]], device='cuda:0')â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 46/203 [2m0:02:24 â€¢ 0:18:27[0m [2;4m0.14it/s[0m  
[2KAttention weights: tensor([[0.4246, 0.5754],â•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 46/203 [2m0:02:24 â€¢ 0:18:27[0m [2;4m0.14it/s[0m  
        [0.4788, 0.5212],
        [0.4487, 0.5513],
        [0.3790, 0.6210],
        [0.4243, 0.5757],
        [0.4668, 0.5332],
        [0.4242, 0.5758],
        [0.5258, 0.4742],
        [0.4756, 0.5244],
[2K        [0.4645, 0.5355]], device='cuda:0')mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 46/203 [2m0:02:24 â€¢ 0:18:27[0m [2;4m0.14it/s[0m  
[2KAttention weights: tensor([[0.5576, 0.4424],237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 47/203 [2m0:02:27 â€¢ 0:22:21[0m [2;4m0.12it/s[0m  
        [0.5534, 0.4466],
        [0.5541, 0.4459],
        [0.5561, 0.4439],
        [0.5553, 0.4447],
        [0.5526, 0.4474],
        [0.5518, 0.4482],
        [0.5572, 0.4428],
        [0.5572, 0.4428],
[2K        [0.5551, 0.4449]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 47/203 [2m0:02:27 â€¢ 0:22:21[0m [2;4m0.12it/s[0m  
[2KClass label: ThrowDiscusâ”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 47/203 [2m0:02:27 â€¢ 0:22:21[0m [2;4m0.12it/s[0m  
[2KAttention weights: tensor([[0.6304, 0.3696]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 47/203 [2m0:02:27 â€¢ 0:22:21[0m [2;4m0.12it/s[0m  
[2KStep 0 - TTA Loss: 0.6322â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 47/203 [2m0:02:27 â€¢ 0:22:21[0m [2;4m0.12it/s[0m  
[2KAttention weights: tensor([[0.6304, 0.3696]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 47/203 [2m0:02:27 â€¢ 0:22:21[0m [2;4m0.12it/s[0m  
[2KAttention weights: tensor([[0.6304, 0.3696]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 47/203 [2m0:02:27 â€¢ 0:22:21[0m [2;4m0.12it/s[0m  
[2KAttention weights: tensor([[0.6327, 0.3673]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 47/203 [2m0:02:27 â€¢ 0:22:21[0m [2;4m0.12it/s[0m  
[2KAttention weights: tensor([[0.6415, 0.3585]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 47/203 [2m0:02:27 â€¢ 0:22:21[0m [2;4m0.12it/s[0m  
[2KAttention weights: tensor([[0.6609, 0.3391]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 47/203 [2m0:02:27 â€¢ 0:22:21[0m [2;4m0.12it/s[0m  
[2KAttention weights: tensor([[0.6927, 0.3073]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 47/203 [2m0:02:27 â€¢ 0:22:21[0m [2;4m0.12it/s[0m  
[2KAttention weights: tensor([[0.7343, 0.2657]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 47/203 [2m0:02:27 â€¢ 0:22:21[0m [2;4m0.12it/s[0m  
[2KAttention weights: tensor([[0.7733, 0.2267]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 47/203 [2m0:02:27 â€¢ 0:22:21[0m [2;4m0.12it/s[0m  
[2KAttention weights: tensor([[0.7986, 0.2014]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 47/203 [2m0:02:27 â€¢ 0:22:21[0m [2;4m0.12it/s[0m  
[2KAttention weights: tensor([[0.5599, 0.4401]], device='cuda:0')â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 47/203 [2m0:02:27 â€¢ 0:22:21[0m [2;4m0.12it/s[0m  
[2KAttention weights: tensor([[0.7624, 0.2376],â•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 47/203 [2m0:02:27 â€¢ 0:22:21[0m [2;4m0.12it/s[0m  
        [0.6680, 0.3320],
        [0.7086, 0.2914],
        [0.7177, 0.2823],
        [0.7768, 0.2232],
        [0.7674, 0.2326],
        [0.7170, 0.2830],
        [0.7520, 0.2480],
        [0.7602, 0.2398],
[2K        [0.8252, 0.1748]], device='cuda:0')mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 47/203 [2m0:02:27 â€¢ 0:22:21[0m [2;4m0.12it/s[0m  
[2KAttention weights: tensor([[0.5576, 0.4424],237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 48/203 [2m0:02:42 â€¢ 0:20:30[0m [2;4m0.13it/s[0m  
        [0.5534, 0.4466],
        [0.5542, 0.4458],
        [0.5561, 0.4439],
        [0.5554, 0.4446],
        [0.5527, 0.4473],
        [0.5519, 0.4481],
        [0.5573, 0.4427],
        [0.5572, 0.4428],
[2K        [0.5552, 0.4448]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 48/203 [2m0:02:42 â€¢ 0:20:30[0m [2;4m0.13it/s[0m  
[2KClass label: TennisSwingâ”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 48/203 [2m0:02:42 â€¢ 0:20:30[0m [2;4m0.13it/s[0m  
[2KAttention weights: tensor([[0.6473, 0.3527]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 48/203 [2m0:02:42 â€¢ 0:20:30[0m [2;4m0.13it/s[0m  
[2KStep 0 - TTA Loss: 0.7442â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 48/203 [2m0:02:42 â€¢ 0:20:30[0m [2;4m0.13it/s[0m  
[2KAttention weights: tensor([[0.6688, 0.3312]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 48/203 [2m0:02:42 â€¢ 0:20:30[0m [2;4m0.13it/s[0m  
[2KAttention weights: tensor([[0.6876, 0.3124]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 48/203 [2m0:02:42 â€¢ 0:20:30[0m [2;4m0.13it/s[0m  
[2KAttention weights: tensor([[0.7032, 0.2968]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 48/203 [2m0:02:42 â€¢ 0:20:30[0m [2;4m0.13it/s[0m  
[2KAttention weights: tensor([[0.7109, 0.2891]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 48/203 [2m0:02:42 â€¢ 0:20:30[0m [2;4m0.13it/s[0m  
[2KAttention weights: tensor([[0.7116, 0.2884]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 48/203 [2m0:02:42 â€¢ 0:20:30[0m [2;4m0.13it/s[0m  
[2KAttention weights: tensor([[0.7064, 0.2936]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 48/203 [2m0:02:42 â€¢ 0:20:30[0m [2;4m0.13it/s[0m  
[2KAttention weights: tensor([[0.6982, 0.3018]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 48/203 [2m0:02:42 â€¢ 0:20:30[0m [2;4m0.13it/s[0m  
[2KAttention weights: tensor([[0.6901, 0.3099]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 48/203 [2m0:02:42 â€¢ 0:20:30[0m [2;4m0.13it/s[0m  
[2KAttention weights: tensor([[0.6851, 0.3149]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 48/203 [2m0:02:42 â€¢ 0:20:30[0m [2;4m0.13it/s[0m  
[2KAttention weights: tensor([[0.5576, 0.4424]], device='cuda:0')â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 48/203 [2m0:02:42 â€¢ 0:20:30[0m [2;4m0.13it/s[0m  
[2KAttention weights: tensor([[0.6940, 0.3060],â•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 48/203 [2m0:02:42 â€¢ 0:20:30[0m [2;4m0.13it/s[0m  
        [0.6199, 0.3801],
        [0.6500, 0.3500],
        [0.6653, 0.3347],
        [0.7030, 0.2970],
        [0.6966, 0.3034],
        [0.6514, 0.3486],
        [0.7000, 0.3000],
        [0.6836, 0.3164],
[2K        [0.7533, 0.2467]], device='cuda:0')mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 48/203 [2m0:02:42 â€¢ 0:20:30[0m [2;4m0.13it/s[0m  
[2KAttention weights: tensor([[0.5577, 0.4423],98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 49/203 [2m0:02:44 â€¢ 0:16:18[0m [2;4m0.16it/s[0m  
        [0.5534, 0.4466],
        [0.5542, 0.4458],
        [0.5562, 0.4438],
        [0.5555, 0.4445],
        [0.5527, 0.4473],
        [0.5520, 0.4480],
        [0.5573, 0.4427],
        [0.5573, 0.4427],
[2K        [0.5553, 0.4447]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 49/203 [2m0:02:44 â€¢ 0:16:18[0m [2;4m0.16it/s[0m  
[2KClass label: CleanAndJerkâ”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 49/203 [2m0:02:44 â€¢ 0:16:18[0m [2;4m0.16it/s[0m  
[2KAttention weights: tensor([[0.5663, 0.4337]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 49/203 [2m0:02:44 â€¢ 0:16:18[0m [2;4m0.16it/s[0m  
[2KStep 0 - TTA Loss: 0.5762â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 49/203 [2m0:02:44 â€¢ 0:16:18[0m [2;4m0.16it/s[0m  
[2KAttention weights: tensor([[0.5663, 0.4337]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 49/203 [2m0:02:44 â€¢ 0:16:18[0m [2;4m0.16it/s[0m  
[2KAttention weights: tensor([[0.5663, 0.4337]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 49/203 [2m0:02:44 â€¢ 0:16:18[0m [2;4m0.16it/s[0m  
[2KAttention weights: tensor([[0.5675, 0.4325]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 49/203 [2m0:02:44 â€¢ 0:16:18[0m [2;4m0.16it/s[0m  
[2KAttention weights: tensor([[0.5720, 0.4280]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 49/203 [2m0:02:44 â€¢ 0:16:18[0m [2;4m0.16it/s[0m  
[2KAttention weights: tensor([[0.5823, 0.4177]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 49/203 [2m0:02:44 â€¢ 0:16:18[0m [2;4m0.16it/s[0m  
[2KAttention weights: tensor([[0.6000, 0.4000]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 49/203 [2m0:02:44 â€¢ 0:16:18[0m [2;4m0.16it/s[0m  
[2KAttention weights: tensor([[0.6233, 0.3767]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 49/203 [2m0:02:44 â€¢ 0:16:18[0m [2;4m0.16it/s[0m  
[2KAttention weights: tensor([[0.6453, 0.3547]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 49/203 [2m0:02:44 â€¢ 0:16:18[0m [2;4m0.16it/s[0m  
[2KAttention weights: tensor([[0.6606, 0.3394]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 49/203 [2m0:02:44 â€¢ 0:16:18[0m [2;4m0.16it/s[0m  
[2KAttention weights: tensor([[0.5565, 0.4435]], device='cuda:0')37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 49/203 [2m0:02:44 â€¢ 0:16:18[0m [2;4m0.16it/s[0m  
[2KAttention weights: tensor([[0.5885, 0.4115],;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 49/203 [2m0:02:44 â€¢ 0:16:18[0m [2;4m0.16it/s[0m  
        [0.5615, 0.4385],
        [0.6714, 0.3286],
        [0.5980, 0.4020],
        [0.6081, 0.3919],
        [0.6026, 0.3974],
        [0.5786, 0.4214],
        [0.6253, 0.3747],
        [0.5580, 0.4420],
[2K        [0.6426, 0.3574]], device='cuda:0')6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 49/203 [2m0:02:44 â€¢ 0:16:18[0m [2;4m0.16it/s[0m  
[2KAttention weights: tensor([[0.5577, 0.4423],98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 50/203 [2m0:02:49 â€¢ 0:16:08[0m [2;4m0.16it/s[0m  
        [0.5534, 0.4466],
        [0.5543, 0.4457],
        [0.5562, 0.4438],
        [0.5555, 0.4445],
        [0.5527, 0.4473],
        [0.5520, 0.4480],
        [0.5573, 0.4427],
        [0.5573, 0.4427],
[2K        [0.5554, 0.4446]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 50/203 [2m0:02:49 â€¢ 0:16:08[0m [2;4m0.16it/s[0m  
[2KClass label: ThrowDiscusâ”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 50/203 [2m0:02:49 â€¢ 0:16:08[0m [2;4m0.16it/s[0m  
[2KAttention weights: tensor([[0.6366, 0.3634]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 50/203 [2m0:02:49 â€¢ 0:16:08[0m [2;4m0.16it/s[0m  
[2KStep 0 - TTA Loss: 0.5919â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 50/203 [2m0:02:49 â€¢ 0:16:08[0m [2;4m0.16it/s[0m  
[2KAttention weights: tensor([[0.6317, 0.3683]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 50/203 [2m0:02:49 â€¢ 0:16:08[0m [2;4m0.16it/s[0m  
[2KAttention weights: tensor([[0.6214, 0.3786]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 50/203 [2m0:02:49 â€¢ 0:16:08[0m [2;4m0.16it/s[0m  
[2KAttention weights: tensor([[0.6015, 0.3985]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 50/203 [2m0:02:49 â€¢ 0:16:08[0m [2;4m0.16it/s[0m  
[2KAttention weights: tensor([[0.5797, 0.4203]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 50/203 [2m0:02:49 â€¢ 0:16:08[0m [2;4m0.16it/s[0m  
[2KAttention weights: tensor([[0.5722, 0.4278]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 50/203 [2m0:02:49 â€¢ 0:16:08[0m [2;4m0.16it/s[0m  
[2KAttention weights: tensor([[0.5852, 0.4148]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 50/203 [2m0:02:49 â€¢ 0:16:08[0m [2;4m0.16it/s[0m  
[2KAttention weights: tensor([[0.6052, 0.3948]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 50/203 [2m0:02:49 â€¢ 0:16:08[0m [2;4m0.16it/s[0m  
[2KAttention weights: tensor([[0.6245, 0.3755]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 50/203 [2m0:02:49 â€¢ 0:16:08[0m [2;4m0.16it/s[0m  
[2KAttention weights: tensor([[0.6357, 0.3643]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 50/203 [2m0:02:49 â€¢ 0:16:08[0m [2;4m0.16it/s[0m  
[2KAttention weights: tensor([[0.5550, 0.4450]], device='cuda:0')37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 50/203 [2m0:02:49 â€¢ 0:16:08[0m [2;4m0.16it/s[0m  
[2KAttention weights: tensor([[0.6002, 0.3998],;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 50/203 [2m0:02:49 â€¢ 0:16:08[0m [2;4m0.16it/s[0m  
        [0.5670, 0.4330],
        [0.6176, 0.3824],
        [0.6081, 0.3919],
        [0.5972, 0.4028],
        [0.5967, 0.4033],
        [0.5663, 0.4337],
        [0.6287, 0.3713],
        [0.5866, 0.4134],
[2K        [0.6389, 0.3611]], device='cuda:0')6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 50/203 [2m0:02:49 â€¢ 0:16:08[0m [2;4m0.16it/s[0m  
[2KAttention weights: tensor([[0.5576, 0.4424],;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 51/203 [2m0:02:55 â€¢ 0:17:21[0m [2;4m0.15it/s[0m   
        [0.5534, 0.4466],
        [0.5543, 0.4457],
        [0.5561, 0.4439],
        [0.5555, 0.4445],
        [0.5527, 0.4473],
        [0.5520, 0.4480],
        [0.5573, 0.4427],
        [0.5572, 0.4428],
[2K        [0.5553, 0.4447]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 51/203 [2m0:02:55 â€¢ 0:17:21[0m [2;4m0.15it/s[0m  
[2KClass label: BaseballPitchâ”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 51/203 [2m0:02:55 â€¢ 0:17:21[0m [2;4m0.15it/s[0m  
[2KAttention weights: tensor([[0.6128, 0.3872]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 51/203 [2m0:02:55 â€¢ 0:17:21[0m [2;4m0.15it/s[0m  
[2KStep 0 - TTA Loss: 0.9886â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 51/203 [2m0:02:55 â€¢ 0:17:21[0m [2;4m0.15it/s[0m  
[2KAttention weights: tensor([[0.6128, 0.3872]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 51/203 [2m0:02:55 â€¢ 0:17:21[0m [2;4m0.15it/s[0m  
[2KAttention weights: tensor([[0.6151, 0.3849]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 51/203 [2m0:02:55 â€¢ 0:17:21[0m [2;4m0.15it/s[0m  
[2KAttention weights: tensor([[0.6230, 0.3770]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 51/203 [2m0:02:55 â€¢ 0:17:21[0m [2;4m0.15it/s[0m  
[2KAttention weights: tensor([[0.6383, 0.3617]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 51/203 [2m0:02:55 â€¢ 0:17:21[0m [2;4m0.15it/s[0m  
[2KAttention weights: tensor([[0.6611, 0.3389]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 51/203 [2m0:02:55 â€¢ 0:17:21[0m [2;4m0.15it/s[0m  
[2KAttention weights: tensor([[0.6887, 0.3113]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 51/203 [2m0:02:55 â€¢ 0:17:21[0m [2;4m0.15it/s[0m  
[2KAttention weights: tensor([[0.7198, 0.2802]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 51/203 [2m0:02:55 â€¢ 0:17:21[0m [2;4m0.15it/s[0m  
[2KAttention weights: tensor([[0.7410, 0.2590]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 51/203 [2m0:02:55 â€¢ 0:17:21[0m [2;4m0.15it/s[0m  
[2KAttention weights: tensor([[0.7365, 0.2635]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 51/203 [2m0:02:55 â€¢ 0:17:21[0m [2;4m0.15it/s[0m  
[2KAttention weights: tensor([[0.5593, 0.4407]], device='cuda:0')â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 51/203 [2m0:02:55 â€¢ 0:17:21[0m [2;4m0.15it/s[0m  
[2KAttention weights: tensor([[0.7046, 0.2954],mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 51/203 [2m0:02:55 â€¢ 0:17:21[0m [2;4m0.15it/s[0m  
        [0.6536, 0.3464],
        [0.7009, 0.2991],
        [0.7331, 0.2669],
        [0.7433, 0.2567],
        [0.7337, 0.2663],
        [0.6885, 0.3115],
        [0.7213, 0.2787],
        [0.7418, 0.2582],
[2K        [0.7927, 0.2073]], device='cuda:0')7mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 51/203 [2m0:02:55 â€¢ 0:17:21[0m [2;4m0.15it/s[0m  
[2KAttention weights: tensor([[0.5576, 0.4424],;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 52/203 [2m0:02:56 â€¢ 0:14:25[0m [2;4m0.17it/s[0m  
        [0.5534, 0.4466],
        [0.5543, 0.4457],
        [0.5561, 0.4439],
        [0.5555, 0.4445],
        [0.5527, 0.4473],
        [0.5520, 0.4480],
        [0.5573, 0.4427],
        [0.5572, 0.4428],
[2K        [0.5554, 0.4446]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 52/203 [2m0:02:56 â€¢ 0:14:25[0m [2;4m0.17it/s[0m  
[2KClass label: CleanAndJerkâ”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 52/203 [2m0:02:56 â€¢ 0:14:25[0m [2;4m0.17it/s[0m  
[2KAttention weights: tensor([[0.5646, 0.4354]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 52/203 [2m0:02:56 â€¢ 0:14:25[0m [2;4m0.17it/s[0m  
[2KStep 0 - TTA Loss: 0.6432â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 52/203 [2m0:02:56 â€¢ 0:14:25[0m [2;4m0.17it/s[0m  
[2KAttention weights: tensor([[0.5881, 0.4119]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 52/203 [2m0:02:56 â€¢ 0:14:25[0m [2;4m0.17it/s[0m  
[2KAttention weights: tensor([[0.6275, 0.3725]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 52/203 [2m0:02:56 â€¢ 0:14:25[0m [2;4m0.17it/s[0m  
[2KAttention weights: tensor([[0.6705, 0.3295]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 52/203 [2m0:02:56 â€¢ 0:14:25[0m [2;4m0.17it/s[0m  
[2KAttention weights: tensor([[0.7067, 0.2933]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 52/203 [2m0:02:56 â€¢ 0:14:25[0m [2;4m0.17it/s[0m  
[2KAttention weights: tensor([[0.7299, 0.2701]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 52/203 [2m0:02:56 â€¢ 0:14:25[0m [2;4m0.17it/s[0m  
[2KAttention weights: tensor([[0.7426, 0.2574]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 52/203 [2m0:02:56 â€¢ 0:14:25[0m [2;4m0.17it/s[0m  
[2KAttention weights: tensor([[0.7470, 0.2530]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 52/203 [2m0:02:56 â€¢ 0:14:25[0m [2;4m0.17it/s[0m  
[2KAttention weights: tensor([[0.7473, 0.2527]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 52/203 [2m0:02:56 â€¢ 0:14:25[0m [2;4m0.17it/s[0m  
[2KAttention weights: tensor([[0.7464, 0.2536]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 52/203 [2m0:02:56 â€¢ 0:14:25[0m [2;4m0.17it/s[0m  
[2KAttention weights: tensor([[0.5589, 0.4411]], device='cuda:0')â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 52/203 [2m0:02:56 â€¢ 0:14:25[0m [2;4m0.17it/s[0m  
[2KAttention weights: tensor([[0.5164, 0.4836],mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 52/203 [2m0:02:56 â€¢ 0:14:25[0m [2;4m0.17it/s[0m  
        [0.6022, 0.3978],
        [0.7461, 0.2539],
        [0.6343, 0.3657],
        [0.6494, 0.3506],
        [0.6588, 0.3412],
        [0.6177, 0.3823],
        [0.6317, 0.3683],
        [0.6623, 0.3377],
[2K        [0.6949, 0.3051]], device='cuda:0')7mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 52/203 [2m0:02:56 â€¢ 0:14:25[0m [2;4m0.17it/s[0m  
[2KAttention weights: tensor([[0.5575, 0.4425],;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 53/203 [2m0:02:57 â€¢ 0:12:24[0m [2;4m0.20it/s[0m  
        [0.5534, 0.4466],
        [0.5543, 0.4457],
        [0.5561, 0.4439],
        [0.5555, 0.4445],
        [0.5527, 0.4473],
        [0.5519, 0.4481],
        [0.5572, 0.4428],
        [0.5572, 0.4428],
[2K        [0.5554, 0.4446]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 53/203 [2m0:02:57 â€¢ 0:12:24[0m [2;4m0.20it/s[0m  
[2KClass label: Billiardsâ”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 53/203 [2m0:02:57 â€¢ 0:12:24[0m [2;4m0.20it/s[0m  
[2KAttention weights: tensor([[0.5778, 0.4222]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 53/203 [2m0:02:57 â€¢ 0:12:24[0m [2;4m0.20it/s[0m  
[2KStep 0 - TTA Loss: 0.8926â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 53/203 [2m0:02:57 â€¢ 0:12:24[0m [2;4m0.20it/s[0m  
[2KAttention weights: tensor([[0.5778, 0.4222]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 53/203 [2m0:02:57 â€¢ 0:12:24[0m [2;4m0.20it/s[0m  
[2KAttention weights: tensor([[0.5779, 0.4221]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 53/203 [2m0:02:57 â€¢ 0:12:24[0m [2;4m0.20it/s[0m  
[2KAttention weights: tensor([[0.5779, 0.4221]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 53/203 [2m0:02:57 â€¢ 0:12:24[0m [2;4m0.20it/s[0m  
[2KAttention weights: tensor([[0.5783, 0.4217]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 53/203 [2m0:02:57 â€¢ 0:12:24[0m [2;4m0.20it/s[0m  
[2KAttention weights: tensor([[0.5779, 0.4221]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 53/203 [2m0:02:57 â€¢ 0:12:24[0m [2;4m0.20it/s[0m  
[2KAttention weights: tensor([[0.5752, 0.4248]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 53/203 [2m0:02:57 â€¢ 0:12:24[0m [2;4m0.20it/s[0m  
[2KAttention weights: tensor([[0.5638, 0.4362]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 53/203 [2m0:02:57 â€¢ 0:12:24[0m [2;4m0.20it/s[0m  
[2KAttention weights: tensor([[0.5374, 0.4626]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 53/203 [2m0:02:57 â€¢ 0:12:24[0m [2;4m0.20it/s[0m  
[2KAttention weights: tensor([[0.5002, 0.4998]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 53/203 [2m0:02:57 â€¢ 0:12:24[0m [2;4m0.20it/s[0m  
[2KAttention weights: tensor([[0.5506, 0.4494]], device='cuda:0')â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 53/203 [2m0:02:57 â€¢ 0:12:24[0m [2;4m0.20it/s[0m  
[2KAttention weights: tensor([[0.5361, 0.4639],mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 53/203 [2m0:02:57 â€¢ 0:12:24[0m [2;4m0.20it/s[0m  
        [0.4583, 0.5417],
        [0.4920, 0.5080],
        [0.5675, 0.4325],
        [0.5241, 0.4759],
        [0.5343, 0.4657],
        [0.4936, 0.5064],
        [0.5816, 0.4184],
        [0.5837, 0.4163],
[2K        [0.5776, 0.4224]], device='cuda:0')7mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 53/203 [2m0:02:57 â€¢ 0:12:24[0m [2;4m0.20it/s[0m  
[2KAttention weights: tensor([[0.5574, 0.4426],;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 54/203 [2m0:03:01 â€¢ 0:07:56[0m [2;4m0.31it/s[0m  
        [0.5533, 0.4467],
        [0.5543, 0.4457],
        [0.5560, 0.4440],
        [0.5555, 0.4445],
        [0.5527, 0.4473],
        [0.5519, 0.4481],
        [0.5572, 0.4428],
        [0.5572, 0.4428],
[2K        [0.5554, 0.4446]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 54/203 [2m0:03:01 â€¢ 0:07:56[0m [2;4m0.31it/s[0m  
[2KClass label: SoccerPenaltyâ”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 54/203 [2m0:03:01 â€¢ 0:07:56[0m [2;4m0.31it/s[0m  
[2KAttention weights: tensor([[0.6361, 0.3639]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 54/203 [2m0:03:01 â€¢ 0:07:56[0m [2;4m0.31it/s[0m  
[2KStep 0 - TTA Loss: 0.4354â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 54/203 [2m0:03:01 â€¢ 0:07:56[0m [2;4m0.31it/s[0m  
[2KAttention weights: tensor([[0.6467, 0.3533]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 54/203 [2m0:03:01 â€¢ 0:07:56[0m [2;4m0.31it/s[0m  
[2KAttention weights: tensor([[0.6774, 0.3226]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 54/203 [2m0:03:01 â€¢ 0:07:56[0m [2;4m0.31it/s[0m  
[2KAttention weights: tensor([[0.7113, 0.2887]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 54/203 [2m0:03:01 â€¢ 0:07:56[0m [2;4m0.31it/s[0m  
[2KAttention weights: tensor([[0.7366, 0.2634]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 54/203 [2m0:03:01 â€¢ 0:07:56[0m [2;4m0.31it/s[0m  
[2KAttention weights: tensor([[0.7460, 0.2540]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 54/203 [2m0:03:01 â€¢ 0:07:56[0m [2;4m0.31it/s[0m  
[2KAttention weights: tensor([[0.7435, 0.2565]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 54/203 [2m0:03:01 â€¢ 0:07:56[0m [2;4m0.31it/s[0m  
[2KAttention weights: tensor([[0.7380, 0.2620]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 54/203 [2m0:03:01 â€¢ 0:07:56[0m [2;4m0.31it/s[0m  
[2KAttention weights: tensor([[0.7342, 0.2658]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 54/203 [2m0:03:01 â€¢ 0:07:56[0m [2;4m0.31it/s[0m  
[2KAttention weights: tensor([[0.7322, 0.2678]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 54/203 [2m0:03:01 â€¢ 0:07:56[0m [2;4m0.31it/s[0m  
[2KAttention weights: tensor([[0.5587, 0.4413]], device='cuda:0')237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 54/203 [2m0:03:01 â€¢ 0:07:56[0m [2;4m0.31it/s[0m  
[2KAttention weights: tensor([[0.6135, 0.3865],6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 54/203 [2m0:03:01 â€¢ 0:07:56[0m [2;4m0.31it/s[0m  
        [0.4803, 0.5197],
        [0.5408, 0.4592],
        [0.6236, 0.3764],
        [0.6002, 0.3998],
        [0.6111, 0.3889],
        [0.5685, 0.4315],
        [0.7318, 0.2682],
        [0.6299, 0.3701],
[2K        [0.6410, 0.3590]], device='cuda:0');6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 54/203 [2m0:03:01 â€¢ 0:07:56[0m [2;4m0.31it/s[0m  
[2KAttention weights: tensor([[0.5574, 0.4426],;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 55/203 [2m0:03:06 â€¢ 0:08:29[0m [2;4m0.29it/s[0m  
        [0.5532, 0.4468],
        [0.5543, 0.4457],
        [0.5560, 0.4440],
        [0.5554, 0.4446],
        [0.5526, 0.4474],
        [0.5518, 0.4482],
        [0.5571, 0.4429],
        [0.5571, 0.4429],
[2K        [0.5553, 0.4447]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 55/203 [2m0:03:06 â€¢ 0:08:29[0m [2;4m0.29it/s[0m  
[2KClass label: HammerThrowâ”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 55/203 [2m0:03:06 â€¢ 0:08:29[0m [2;4m0.29it/s[0m  
[2KAttention weights: tensor([[0.5805, 0.4195]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 55/203 [2m0:03:06 â€¢ 0:08:29[0m [2;4m0.29it/s[0m  
[2KStep 0 - TTA Loss: 0.6548â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 55/203 [2m0:03:06 â€¢ 0:08:29[0m [2;4m0.29it/s[0m  
[2KAttention weights: tensor([[0.5805, 0.4195]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 55/203 [2m0:03:06 â€¢ 0:08:29[0m [2;4m0.29it/s[0m  
[2KAttention weights: tensor([[0.5809, 0.4191]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 55/203 [2m0:03:06 â€¢ 0:08:29[0m [2;4m0.29it/s[0m  
[2KAttention weights: tensor([[0.5836, 0.4164]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 55/203 [2m0:03:06 â€¢ 0:08:29[0m [2;4m0.29it/s[0m  
[2KAttention weights: tensor([[0.5915, 0.4085]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 55/203 [2m0:03:06 â€¢ 0:08:29[0m [2;4m0.29it/s[0m  
[2KAttention weights: tensor([[0.6073, 0.3927]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 55/203 [2m0:03:06 â€¢ 0:08:29[0m [2;4m0.29it/s[0m  
[2KAttention weights: tensor([[0.6309, 0.3691]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 55/203 [2m0:03:06 â€¢ 0:08:29[0m [2;4m0.29it/s[0m  
[2KAttention weights: tensor([[0.6575, 0.3425]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 55/203 [2m0:03:06 â€¢ 0:08:29[0m [2;4m0.29it/s[0m  
[2KAttention weights: tensor([[0.6822, 0.3178]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 55/203 [2m0:03:06 â€¢ 0:08:29[0m [2;4m0.29it/s[0m  
[2KAttention weights: tensor([[0.7102, 0.2898]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 55/203 [2m0:03:06 â€¢ 0:08:29[0m [2;4m0.29it/s[0m  
[2KAttention weights: tensor([[0.5603, 0.4397]], device='cuda:0')237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 55/203 [2m0:03:06 â€¢ 0:08:29[0m [2;4m0.29it/s[0m  
[2KAttention weights: tensor([[0.7575, 0.2425],6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 55/203 [2m0:03:06 â€¢ 0:08:29[0m [2;4m0.29it/s[0m  
        [0.6399, 0.3601],
        [0.7046, 0.2954],
        [0.7550, 0.2450],
        [0.7911, 0.2089],
        [0.7494, 0.2506],
        [0.7009, 0.2991],
        [0.7348, 0.2652],
        [0.7515, 0.2485],
[2K        [0.7940, 0.2060]], device='cuda:0');6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 55/203 [2m0:03:06 â€¢ 0:08:29[0m [2;4m0.29it/s[0m  
[2KAttention weights: tensor([[0.5574, 0.4426],5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 56/203 [2m0:03:08 â€¢ 0:07:55[0m [2;4m0.31it/s[0m   
        [0.5532, 0.4468],
        [0.5543, 0.4457],
        [0.5560, 0.4440],
        [0.5556, 0.4444],
        [0.5527, 0.4473],
        [0.5519, 0.4481],
        [0.5572, 0.4428],
        [0.5572, 0.4428],
[2K        [0.5554, 0.4446]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 56/203 [2m0:03:08 â€¢ 0:07:55[0m [2;4m0.31it/s[0m  
[2KClass label: HighJumpâ”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 56/203 [2m0:03:08 â€¢ 0:07:55[0m [2;4m0.31it/s[0m  
[2KAttention weights: tensor([[0.5937, 0.4063]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 56/203 [2m0:03:08 â€¢ 0:07:55[0m [2;4m0.31it/s[0m  
[2KStep 0 - TTA Loss: 1.2533â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 56/203 [2m0:03:08 â€¢ 0:07:55[0m [2;4m0.31it/s[0m  
[2KAttention weights: tensor([[0.6653, 0.3347]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 56/203 [2m0:03:08 â€¢ 0:07:55[0m [2;4m0.31it/s[0m  
[2KAttention weights: tensor([[0.7282, 0.2718]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 56/203 [2m0:03:08 â€¢ 0:07:55[0m [2;4m0.31it/s[0m  
[2KAttention weights: tensor([[0.7757, 0.2243]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 56/203 [2m0:03:08 â€¢ 0:07:55[0m [2;4m0.31it/s[0m  
[2KAttention weights: tensor([[0.8047, 0.1953]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 56/203 [2m0:03:08 â€¢ 0:07:55[0m [2;4m0.31it/s[0m  
[2KAttention weights: tensor([[0.8208, 0.1792]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 56/203 [2m0:03:08 â€¢ 0:07:55[0m [2;4m0.31it/s[0m  
[2KAttention weights: tensor([[0.8282, 0.1718]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 56/203 [2m0:03:08 â€¢ 0:07:55[0m [2;4m0.31it/s[0m  
[2KAttention weights: tensor([[0.8263, 0.1737]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 56/203 [2m0:03:08 â€¢ 0:07:55[0m [2;4m0.31it/s[0m  
[2KAttention weights: tensor([[0.8229, 0.1771]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 56/203 [2m0:03:08 â€¢ 0:07:55[0m [2;4m0.31it/s[0m  
[2KAttention weights: tensor([[0.8204, 0.1796]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 56/203 [2m0:03:08 â€¢ 0:07:55[0m [2;4m0.31it/s[0m  
[2KAttention weights: tensor([[0.5594, 0.4406]], device='cuda:0')â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 56/203 [2m0:03:08 â€¢ 0:07:55[0m [2;4m0.31it/s[0m  
[2KAttention weights: tensor([[0.8287, 0.1713],7mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 56/203 [2m0:03:08 â€¢ 0:07:55[0m [2;4m0.31it/s[0m  
        [0.7013, 0.2987],
        [0.7749, 0.2251],
        [0.8169, 0.1831],
        [0.8746, 0.1254],
        [0.8197, 0.1803],
        [0.7786, 0.2214],
        [0.8037, 0.1963],
        [0.8080, 0.1920],
[2K        [0.8632, 0.1368]], device='cuda:0')37mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 56/203 [2m0:03:08 â€¢ 0:07:55[0m [2;4m0.31it/s[0m  
[2KAttention weights: tensor([[0.5575, 0.4425],5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 57/203 [2m0:03:09 â€¢ 0:07:11[0m [2;4m0.34it/s[0m  
        [0.5533, 0.4467],
        [0.5544, 0.4456],
        [0.5561, 0.4439],
        [0.5557, 0.4443],
        [0.5528, 0.4472],
        [0.5520, 0.4480],
        [0.5572, 0.4428],
        [0.5572, 0.4428],
[2K        [0.5555, 0.4445]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 57/203 [2m0:03:09 â€¢ 0:07:11[0m [2;4m0.34it/s[0m  
[2KClass label: HighJumpâ”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 57/203 [2m0:03:09 â€¢ 0:07:11[0m [2;4m0.34it/s[0m  
[2KAttention weights: tensor([[0.5912, 0.4088]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 57/203 [2m0:03:09 â€¢ 0:07:11[0m [2;4m0.34it/s[0m  
[2KStep 0 - TTA Loss: 0.6247â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 57/203 [2m0:03:09 â€¢ 0:07:11[0m [2;4m0.34it/s[0m  
[2KAttention weights: tensor([[0.5912, 0.4088]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 57/203 [2m0:03:09 â€¢ 0:07:11[0m [2;4m0.34it/s[0m  
[2KAttention weights: tensor([[0.5901, 0.4099]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 57/203 [2m0:03:09 â€¢ 0:07:11[0m [2;4m0.34it/s[0m  
[2KAttention weights: tensor([[0.5865, 0.4135]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 57/203 [2m0:03:09 â€¢ 0:07:11[0m [2;4m0.34it/s[0m  
[2KAttention weights: tensor([[0.5795, 0.4205]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 57/203 [2m0:03:09 â€¢ 0:07:11[0m [2;4m0.34it/s[0m  
[2KAttention weights: tensor([[0.5686, 0.4314]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 57/203 [2m0:03:09 â€¢ 0:07:11[0m [2;4m0.34it/s[0m  
[2KAttention weights: tensor([[0.5525, 0.4475]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 57/203 [2m0:03:09 â€¢ 0:07:11[0m [2;4m0.34it/s[0m  
[2KAttention weights: tensor([[0.5294, 0.4706]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 57/203 [2m0:03:09 â€¢ 0:07:11[0m [2;4m0.34it/s[0m  
[2KAttention weights: tensor([[0.5030, 0.4970]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 57/203 [2m0:03:09 â€¢ 0:07:11[0m [2;4m0.34it/s[0m  
[2KAttention weights: tensor([[0.4798, 0.5202]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 57/203 [2m0:03:09 â€¢ 0:07:11[0m [2;4m0.34it/s[0m  
[2KAttention weights: tensor([[0.5495, 0.4505]], device='cuda:0')â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 57/203 [2m0:03:09 â€¢ 0:07:11[0m [2;4m0.34it/s[0m  
[2KAttention weights: tensor([[0.5539, 0.4461],7mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 57/203 [2m0:03:09 â€¢ 0:07:11[0m [2;4m0.34it/s[0m  
        [0.5228, 0.4772],
        [0.5067, 0.4933],
        [0.5773, 0.4227],
        [0.5220, 0.4780],
        [0.4715, 0.5285],
        [0.4489, 0.5511],
        [0.5617, 0.4383],
        [0.5795, 0.4205],
[2K        [0.5656, 0.4344]], device='cuda:0')37mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 57/203 [2m0:03:09 â€¢ 0:07:11[0m [2;4m0.34it/s[0m  
[2KAttention weights: tensor([[0.5575, 0.4425],5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 58/203 [2m0:03:13 â€¢ 0:07:54[0m [2;4m0.31it/s[0m  
        [0.5532, 0.4468],
        [0.5544, 0.4456],
        [0.5560, 0.4440],
        [0.5557, 0.4443],
        [0.5527, 0.4473],
        [0.5520, 0.4480],
        [0.5572, 0.4428],
        [0.5572, 0.4428],
[2K        [0.5555, 0.4445]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 58/203 [2m0:03:13 â€¢ 0:07:54[0m [2;4m0.31it/s[0m  
[2KClass label: SoccerPenaltyâ”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 58/203 [2m0:03:13 â€¢ 0:07:54[0m [2;4m0.31it/s[0m  
[2KAttention weights: tensor([[0.6368, 0.3632]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 58/203 [2m0:03:13 â€¢ 0:07:54[0m [2;4m0.31it/s[0m  
[2KStep 0 - TTA Loss: 0.7864â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 58/203 [2m0:03:13 â€¢ 0:07:54[0m [2;4m0.31it/s[0m  
[2KAttention weights: tensor([[0.6554, 0.3446]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 58/203 [2m0:03:13 â€¢ 0:07:54[0m [2;4m0.31it/s[0m  
[2KAttention weights: tensor([[0.6772, 0.3228]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 58/203 [2m0:03:13 â€¢ 0:07:54[0m [2;4m0.31it/s[0m  
[2KAttention weights: tensor([[0.6916, 0.3084]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 58/203 [2m0:03:13 â€¢ 0:07:54[0m [2;4m0.31it/s[0m  
[2KAttention weights: tensor([[0.7041, 0.2959]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 58/203 [2m0:03:13 â€¢ 0:07:54[0m [2;4m0.31it/s[0m  
[2KAttention weights: tensor([[0.7258, 0.2742]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 58/203 [2m0:03:13 â€¢ 0:07:54[0m [2;4m0.31it/s[0m  
[2KAttention weights: tensor([[0.7547, 0.2453]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 58/203 [2m0:03:13 â€¢ 0:07:54[0m [2;4m0.31it/s[0m  
[2KAttention weights: tensor([[0.7828, 0.2172]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 58/203 [2m0:03:13 â€¢ 0:07:54[0m [2;4m0.31it/s[0m  
[2KAttention weights: tensor([[0.8036, 0.1964]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 58/203 [2m0:03:13 â€¢ 0:07:54[0m [2;4m0.31it/s[0m  
[2KAttention weights: tensor([[0.8144, 0.1856]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 58/203 [2m0:03:13 â€¢ 0:07:54[0m [2;4m0.31it/s[0m  
[2KAttention weights: tensor([[0.5613, 0.4387]], device='cuda:0')â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 58/203 [2m0:03:13 â€¢ 0:07:54[0m [2;4m0.31it/s[0m  
[2KAttention weights: tensor([[0.7047, 0.2953],7mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 58/203 [2m0:03:13 â€¢ 0:07:54[0m [2;4m0.31it/s[0m  
        [0.6504, 0.3496],
        [0.6156, 0.3844],
        [0.6984, 0.3016],
        [0.6850, 0.3150],
        [0.6721, 0.3279],
        [0.6323, 0.3677],
        [0.8176, 0.1824],
        [0.7090, 0.2910],
[2K        [0.7121, 0.2879]], device='cuda:0')37mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 58/203 [2m0:03:13 â€¢ 0:07:54[0m [2;4m0.31it/s[0m  
[2KAttention weights: tensor([[0.5575, 0.4425],2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 59/203 [2m0:03:15 â€¢ 0:06:55[0m [2;4m0.35it/s[0m  
        [0.5533, 0.4467],
        [0.5544, 0.4456],
        [0.5560, 0.4440],
        [0.5557, 0.4443],
        [0.5527, 0.4473],
        [0.5519, 0.4481],
        [0.5572, 0.4428],
        [0.5572, 0.4428],
[2K        [0.5555, 0.4445]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 59/203 [2m0:03:15 â€¢ 0:06:55[0m [2;4m0.35it/s[0m  
[2KClass label: Billiardsâ”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 59/203 [2m0:03:15 â€¢ 0:06:55[0m [2;4m0.35it/s[0m  
[2KAttention weights: tensor([[0.5785, 0.4215]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 59/203 [2m0:03:15 â€¢ 0:06:55[0m [2;4m0.35it/s[0m  
[2KStep 0 - TTA Loss: 0.8410â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 59/203 [2m0:03:15 â€¢ 0:06:55[0m [2;4m0.35it/s[0m  
[2KAttention weights: tensor([[0.5785, 0.4215]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 59/203 [2m0:03:15 â€¢ 0:06:55[0m [2;4m0.35it/s[0m  
[2KAttention weights: tensor([[0.5800, 0.4200]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 59/203 [2m0:03:15 â€¢ 0:06:55[0m [2;4m0.35it/s[0m  
[2KAttention weights: tensor([[0.5854, 0.4146]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 59/203 [2m0:03:15 â€¢ 0:06:55[0m [2;4m0.35it/s[0m  
[2KAttention weights: tensor([[0.5962, 0.4038]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 59/203 [2m0:03:15 â€¢ 0:06:55[0m [2;4m0.35it/s[0m  
[2KAttention weights: tensor([[0.6123, 0.3877]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 59/203 [2m0:03:15 â€¢ 0:06:55[0m [2;4m0.35it/s[0m  
[2KAttention weights: tensor([[0.6313, 0.3687]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 59/203 [2m0:03:15 â€¢ 0:06:55[0m [2;4m0.35it/s[0m  
[2KAttention weights: tensor([[0.6499, 0.3501]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 59/203 [2m0:03:15 â€¢ 0:06:55[0m [2;4m0.35it/s[0m  
[2KAttention weights: tensor([[0.6636, 0.3364]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 59/203 [2m0:03:15 â€¢ 0:06:55[0m [2;4m0.35it/s[0m  
[2KAttention weights: tensor([[0.6709, 0.3291]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 59/203 [2m0:03:15 â€¢ 0:06:55[0m [2;4m0.35it/s[0m  
[2KAttention weights: tensor([[0.5550, 0.4450]], device='cuda:0');237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 59/203 [2m0:03:15 â€¢ 0:06:55[0m [2;4m0.35it/s[0m  
[2KAttention weights: tensor([[0.7578, 0.2422],;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 59/203 [2m0:03:15 â€¢ 0:06:55[0m [2;4m0.35it/s[0m  
        [0.6742, 0.3258],
        [0.6526, 0.3474],
        [0.7383, 0.2617],
        [0.7416, 0.2584],
        [0.7507, 0.2493],
        [0.7078, 0.2922],
        [0.9021, 0.0979],
        [0.7530, 0.2470],
[2K        [0.7610, 0.2390]], device='cuda:0')8;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 59/203 [2m0:03:15 â€¢ 0:06:55[0m [2;4m0.35it/s[0m  
[2KAttention weights: tensor([[0.5575, 0.4425],2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 60/203 [2m0:03:18 â€¢ 0:06:47[0m [2;4m0.35it/s[0m  
        [0.5533, 0.4467],
        [0.5544, 0.4456],
        [0.5561, 0.4439],
        [0.5557, 0.4443],
        [0.5527, 0.4473],
        [0.5520, 0.4480],
        [0.5573, 0.4427],
        [0.5572, 0.4428],
[2K        [0.5555, 0.4445]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 60/203 [2m0:03:18 â€¢ 0:06:47[0m [2;4m0.35it/s[0m  
[2KClass label: CleanAndJerkâ”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 60/203 [2m0:03:18 â€¢ 0:06:47[0m [2;4m0.35it/s[0m  
[2KAttention weights: tensor([[0.5625, 0.4375]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 60/203 [2m0:03:18 â€¢ 0:06:47[0m [2;4m0.35it/s[0m  
[2KStep 0 - TTA Loss: 0.5857â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 60/203 [2m0:03:18 â€¢ 0:06:47[0m [2;4m0.35it/s[0m  
[2KAttention weights: tensor([[0.5937, 0.4063]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 60/203 [2m0:03:18 â€¢ 0:06:47[0m [2;4m0.35it/s[0m  
[2KAttention weights: tensor([[0.6434, 0.3566]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 60/203 [2m0:03:18 â€¢ 0:06:47[0m [2;4m0.35it/s[0m  
[2KAttention weights: tensor([[0.6966, 0.3034]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 60/203 [2m0:03:18 â€¢ 0:06:47[0m [2;4m0.35it/s[0m  
[2KAttention weights: tensor([[0.7389, 0.2611]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 60/203 [2m0:03:18 â€¢ 0:06:47[0m [2;4m0.35it/s[0m  
[2KAttention weights: tensor([[0.7673, 0.2327]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 60/203 [2m0:03:18 â€¢ 0:06:47[0m [2;4m0.35it/s[0m  
[2KAttention weights: tensor([[0.7836, 0.2164]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 60/203 [2m0:03:18 â€¢ 0:06:47[0m [2;4m0.35it/s[0m  
[2KAttention weights: tensor([[0.7932, 0.2068]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 60/203 [2m0:03:18 â€¢ 0:06:47[0m [2;4m0.35it/s[0m  
[2KAttention weights: tensor([[0.7993, 0.2007]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 60/203 [2m0:03:18 â€¢ 0:06:47[0m [2;4m0.35it/s[0m  
[2KAttention weights: tensor([[0.8025, 0.1975]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 60/203 [2m0:03:18 â€¢ 0:06:47[0m [2;4m0.35it/s[0m  
[2KAttention weights: tensor([[0.5611, 0.4389]], device='cuda:0');237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 60/203 [2m0:03:18 â€¢ 0:06:47[0m [2;4m0.35it/s[0m  
[2KAttention weights: tensor([[0.7665, 0.2335],;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 60/203 [2m0:03:18 â€¢ 0:06:47[0m [2;4m0.35it/s[0m  
        [0.6601, 0.3399],
        [0.8035, 0.1965],
        [0.7676, 0.2324],
        [0.7799, 0.2201],
        [0.7789, 0.2211],
        [0.7366, 0.2634],
        [0.8641, 0.1359],
        [0.7747, 0.2253],
[2K        [0.7968, 0.2032]], device='cuda:0')8;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 60/203 [2m0:03:18 â€¢ 0:06:47[0m [2;4m0.35it/s[0m  
[2KAttention weights: tensor([[0.5576, 0.4424],;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 61/203 [2m0:03:23 â€¢ 0:06:45[0m [2;4m0.35it/s[0m   
        [0.5533, 0.4467],
        [0.5545, 0.4455],
        [0.5561, 0.4439],
        [0.5558, 0.4442],
        [0.5527, 0.4473],
        [0.5520, 0.4480],
        [0.5574, 0.4426],
        [0.5573, 0.4427],
[2K        [0.5556, 0.4444]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 61/203 [2m0:03:23 â€¢ 0:06:45[0m [2;4m0.35it/s[0m  
[2KClass label: Billiardsâ”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 61/203 [2m0:03:23 â€¢ 0:06:45[0m [2;4m0.35it/s[0m  
[2KAttention weights: tensor([[0.5763, 0.4237]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 61/203 [2m0:03:23 â€¢ 0:06:45[0m [2;4m0.35it/s[0m  
[2KStep 0 - TTA Loss: 0.8141â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 61/203 [2m0:03:23 â€¢ 0:06:45[0m [2;4m0.35it/s[0m  
[2KAttention weights: tensor([[0.5763, 0.4237]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 61/203 [2m0:03:23 â€¢ 0:06:45[0m [2;4m0.35it/s[0m  
[2KAttention weights: tensor([[0.5756, 0.4244]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 61/203 [2m0:03:23 â€¢ 0:06:45[0m [2;4m0.35it/s[0m  
[2KAttention weights: tensor([[0.5718, 0.4282]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 61/203 [2m0:03:23 â€¢ 0:06:45[0m [2;4m0.35it/s[0m  
[2KAttention weights: tensor([[0.5604, 0.4396]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 61/203 [2m0:03:23 â€¢ 0:06:45[0m [2;4m0.35it/s[0m  
[2KAttention weights: tensor([[0.5361, 0.4639]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 61/203 [2m0:03:23 â€¢ 0:06:45[0m [2;4m0.35it/s[0m  
[2KAttention weights: tensor([[0.4937, 0.5063]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 61/203 [2m0:03:23 â€¢ 0:06:45[0m [2;4m0.35it/s[0m  
[2KAttention weights: tensor([[0.4296, 0.5704]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 61/203 [2m0:03:23 â€¢ 0:06:45[0m [2;4m0.35it/s[0m  
[2KAttention weights: tensor([[0.3486, 0.6514]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 61/203 [2m0:03:23 â€¢ 0:06:45[0m [2;4m0.35it/s[0m  
[2KAttention weights: tensor([[0.2657, 0.7343]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 61/203 [2m0:03:23 â€¢ 0:06:45[0m [2;4m0.35it/s[0m  
[2KAttention weights: tensor([[0.5449, 0.4551]], device='cuda:0')mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 61/203 [2m0:03:23 â€¢ 0:06:45[0m [2;4m0.35it/s[0m  
[2KAttention weights: tensor([[0.5364, 0.4636],37mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 61/203 [2m0:03:23 â€¢ 0:06:45[0m [2;4m0.35it/s[0m  
        [0.1957, 0.8043],
        [0.5690, 0.4310],
        [0.5587, 0.4413],
        [0.5325, 0.4675],
        [0.5233, 0.4767],
        [0.4818, 0.5182],
        [0.5553, 0.4447],
        [0.5395, 0.4605],
[2K        [0.5738, 0.4262]], device='cuda:0')237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 61/203 [2m0:03:23 â€¢ 0:06:45[0m [2;4m0.35it/s[0m  
[2KAttention weights: tensor([[0.5575, 0.4425],;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 62/203 [2m0:03:26 â€¢ 0:07:35[0m [2;4m0.31it/s[0m  
        [0.5532, 0.4468],
        [0.5545, 0.4455],
        [0.5561, 0.4439],
        [0.5557, 0.4443],
        [0.5527, 0.4473],
        [0.5520, 0.4480],
        [0.5573, 0.4427],
        [0.5572, 0.4428],
[2K        [0.5556, 0.4444]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 62/203 [2m0:03:26 â€¢ 0:07:35[0m [2;4m0.31it/s[0m  
[2KClass label: Billiardsâ”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 62/203 [2m0:03:26 â€¢ 0:07:35[0m [2;4m0.31it/s[0m  
[2KAttention weights: tensor([[0.5722, 0.4278]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 62/203 [2m0:03:26 â€¢ 0:07:35[0m [2;4m0.31it/s[0m  
[2KStep 0 - TTA Loss: 0.4142â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 62/203 [2m0:03:26 â€¢ 0:07:35[0m [2;4m0.31it/s[0m  
[2KAttention weights: tensor([[0.4755, 0.5245]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 62/203 [2m0:03:26 â€¢ 0:07:35[0m [2;4m0.31it/s[0m  
[2KAttention weights: tensor([[0.3834, 0.6166]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 62/203 [2m0:03:26 â€¢ 0:07:35[0m [2;4m0.31it/s[0m  
[2KAttention weights: tensor([[0.3068, 0.6932]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 62/203 [2m0:03:26 â€¢ 0:07:35[0m [2;4m0.31it/s[0m  
[2KAttention weights: tensor([[0.2521, 0.7479]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 62/203 [2m0:03:26 â€¢ 0:07:35[0m [2;4m0.31it/s[0m  
[2KAttention weights: tensor([[0.2171, 0.7829]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 62/203 [2m0:03:26 â€¢ 0:07:35[0m [2;4m0.31it/s[0m  
[2KAttention weights: tensor([[0.1964, 0.8036]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 62/203 [2m0:03:26 â€¢ 0:07:35[0m [2;4m0.31it/s[0m  
[2KAttention weights: tensor([[0.1851, 0.8149]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 62/203 [2m0:03:26 â€¢ 0:07:35[0m [2;4m0.31it/s[0m  
[2KAttention weights: tensor([[0.1797, 0.8203]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 62/203 [2m0:03:26 â€¢ 0:07:35[0m [2;4m0.31it/s[0m  
[2KAttention weights: tensor([[0.1777, 0.8223]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 62/203 [2m0:03:26 â€¢ 0:07:35[0m [2;4m0.31it/s[0m  
[2KAttention weights: tensor([[0.5441, 0.4559]], device='cuda:0')mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 62/203 [2m0:03:26 â€¢ 0:07:35[0m [2;4m0.31it/s[0m  
[2KAttention weights: tensor([[0.5088, 0.4912],37mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 62/203 [2m0:03:26 â€¢ 0:07:35[0m [2;4m0.31it/s[0m  
        [0.1772, 0.8228],
        [0.5177, 0.4823],
        [0.5277, 0.4723],
        [0.4968, 0.5032],
        [0.4894, 0.5106],
        [0.4511, 0.5489],
        [0.5208, 0.4792],
        [0.5101, 0.4899],
[2K        [0.5399, 0.4601]], device='cuda:0')237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 62/203 [2m0:03:26 â€¢ 0:07:35[0m [2;4m0.31it/s[0m  
[2KAttention weights: tensor([[0.5575, 0.4425],;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 63/203 [2m0:03:33 â€¢ 0:07:44[0m [2;4m0.30it/s[0m  
        [0.5531, 0.4469],
        [0.5545, 0.4455],
        [0.5561, 0.4439],
        [0.5557, 0.4443],
        [0.5527, 0.4473],
        [0.5519, 0.4481],
        [0.5573, 0.4427],
        [0.5572, 0.4428],
[2K        [0.5555, 0.4445]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 63/203 [2m0:03:33 â€¢ 0:07:44[0m [2;4m0.30it/s[0m  
[2KClass label: CleanAndJerkâ”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 63/203 [2m0:03:33 â€¢ 0:07:44[0m [2;4m0.30it/s[0m  
[2KAttention weights: tensor([[0.5726, 0.4274]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 63/203 [2m0:03:33 â€¢ 0:07:44[0m [2;4m0.30it/s[0m  
[2KStep 0 - TTA Loss: 0.4625â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 63/203 [2m0:03:33 â€¢ 0:07:44[0m [2;4m0.30it/s[0m  
[2KAttention weights: tensor([[0.5726, 0.4274]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 63/203 [2m0:03:33 â€¢ 0:07:44[0m [2;4m0.30it/s[0m  
[2KAttention weights: tensor([[0.5730, 0.4270]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 63/203 [2m0:03:33 â€¢ 0:07:44[0m [2;4m0.30it/s[0m  
[2KAttention weights: tensor([[0.5767, 0.4233]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 63/203 [2m0:03:33 â€¢ 0:07:44[0m [2;4m0.30it/s[0m  
[2KAttention weights: tensor([[0.5855, 0.4145]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 63/203 [2m0:03:33 â€¢ 0:07:44[0m [2;4m0.30it/s[0m  
[2KAttention weights: tensor([[0.6046, 0.3954]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 63/203 [2m0:03:33 â€¢ 0:07:44[0m [2;4m0.30it/s[0m  
[2KAttention weights: tensor([[0.6296, 0.3704]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 63/203 [2m0:03:33 â€¢ 0:07:44[0m [2;4m0.30it/s[0m  
[2KAttention weights: tensor([[0.6573, 0.3427]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 63/203 [2m0:03:33 â€¢ 0:07:44[0m [2;4m0.30it/s[0m  
[2KAttention weights: tensor([[0.6839, 0.3161]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 63/203 [2m0:03:33 â€¢ 0:07:44[0m [2;4m0.30it/s[0m  
[2KAttention weights: tensor([[0.7137, 0.2863]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 63/203 [2m0:03:33 â€¢ 0:07:44[0m [2;4m0.30it/s[0m  
[2KAttention weights: tensor([[0.5588, 0.4412]], device='cuda:0')mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 63/203 [2m0:03:33 â€¢ 0:07:44[0m [2;4m0.30it/s[0m  
[2KAttention weights: tensor([[0.6779, 0.3221],37mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 63/203 [2m0:03:33 â€¢ 0:07:44[0m [2;4m0.30it/s[0m  
        [0.5936, 0.4065],
        [0.7574, 0.2426],
        [0.7019, 0.2981],
        [0.6893, 0.3107],
        [0.6913, 0.3087],
        [0.6421, 0.3579],
        [0.6878, 0.3122],
        [0.7100, 0.2900],
[2K        [0.7258, 0.2742]], device='cuda:0')237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 63/203 [2m0:03:33 â€¢ 0:07:44[0m [2;4m0.30it/s[0m  
[2KAttention weights: tensor([[0.5575, 0.4425],;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 64/203 [2m0:03:38 â€¢ 0:08:35[0m [2;4m0.27it/s[0m  
        [0.5531, 0.4469],
        [0.5545, 0.4455],
        [0.5561, 0.4439],
        [0.5557, 0.4443],
        [0.5527, 0.4473],
        [0.5519, 0.4481],
        [0.5573, 0.4427],
        [0.5572, 0.4428],
[2K        [0.5555, 0.4445]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 64/203 [2m0:03:38 â€¢ 0:08:35[0m [2;4m0.27it/s[0m  
[2KClass label: BaseballPitchâ”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 64/203 [2m0:03:38 â€¢ 0:08:35[0m [2;4m0.27it/s[0m  
[2KAttention weights: tensor([[0.6103, 0.3897]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 64/203 [2m0:03:38 â€¢ 0:08:35[0m [2;4m0.27it/s[0m  
[2KStep 0 - TTA Loss: 0.5693â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 64/203 [2m0:03:38 â€¢ 0:08:35[0m [2;4m0.27it/s[0m  
[2KAttention weights: tensor([[0.6514, 0.3486]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 64/203 [2m0:03:38 â€¢ 0:08:35[0m [2;4m0.27it/s[0m  
[2KAttention weights: tensor([[0.7088, 0.2912]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 64/203 [2m0:03:38 â€¢ 0:08:35[0m [2;4m0.27it/s[0m  
[2KAttention weights: tensor([[0.7672, 0.2328]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 64/203 [2m0:03:38 â€¢ 0:08:35[0m [2;4m0.27it/s[0m  
[2KAttention weights: tensor([[0.8164, 0.1836]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 64/203 [2m0:03:38 â€¢ 0:08:35[0m [2;4m0.27it/s[0m  
[2KAttention weights: tensor([[0.8495, 0.1505]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 64/203 [2m0:03:38 â€¢ 0:08:35[0m [2;4m0.27it/s[0m  
[2KAttention weights: tensor([[0.8667, 0.1333]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 64/203 [2m0:03:38 â€¢ 0:08:35[0m [2;4m0.27it/s[0m  
[2KAttention weights: tensor([[0.8729, 0.1271]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 64/203 [2m0:03:38 â€¢ 0:08:35[0m [2;4m0.27it/s[0m  
[2KAttention weights: tensor([[0.8732, 0.1268]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 64/203 [2m0:03:38 â€¢ 0:08:35[0m [2;4m0.27it/s[0m  
[2KAttention weights: tensor([[0.8721, 0.1279]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 64/203 [2m0:03:38 â€¢ 0:08:35[0m [2;4m0.27it/s[0m  
[2KAttention weights: tensor([[0.5663, 0.4337]], device='cuda:0')5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 64/203 [2m0:03:38 â€¢ 0:08:35[0m [2;4m0.27it/s[0m  
[2KAttention weights: tensor([[0.8716, 0.1284],8;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 64/203 [2m0:03:38 â€¢ 0:08:35[0m [2;4m0.27it/s[0m  
        [0.7005, 0.2995],
        [0.8247, 0.1753],
        [0.8343, 0.1657],
        [0.8220, 0.1780],
        [0.8072, 0.1928],
        [0.7592, 0.2408],
        [0.7999, 0.2001],
        [0.8247, 0.1753],
[2K        [0.8512, 0.1488]], device='cuda:0')98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 64/203 [2m0:03:38 â€¢ 0:08:35[0m [2;4m0.27it/s[0m  
[2KAttention weights: tensor([[0.5576, 0.4424],;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 65/203 [2m0:03:41 â€¢ 0:09:17[0m [2;4m0.25it/s[0m  
        [0.5531, 0.4469],
        [0.5545, 0.4455],
        [0.5561, 0.4439],
        [0.5558, 0.4442],
        [0.5527, 0.4473],
        [0.5520, 0.4480],
        [0.5573, 0.4427],
        [0.5572, 0.4428],
[2K        [0.5556, 0.4444]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 65/203 [2m0:03:41 â€¢ 0:09:17[0m [2;4m0.25it/s[0m  
[2KClass label: BaseballPitchâ”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 65/203 [2m0:03:41 â€¢ 0:09:17[0m [2;4m0.25it/s[0m  
[2KAttention weights: tensor([[0.6132, 0.3868]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 65/203 [2m0:03:41 â€¢ 0:09:17[0m [2;4m0.25it/s[0m  
[2KStep 0 - TTA Loss: 0.9196â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 65/203 [2m0:03:41 â€¢ 0:09:17[0m [2;4m0.25it/s[0m  
[2KAttention weights: tensor([[0.6132, 0.3868]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 65/203 [2m0:03:41 â€¢ 0:09:17[0m [2;4m0.25it/s[0m  
[2KAttention weights: tensor([[0.6125, 0.3875]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 65/203 [2m0:03:41 â€¢ 0:09:17[0m [2;4m0.25it/s[0m  
[2KAttention weights: tensor([[0.6112, 0.3888]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 65/203 [2m0:03:41 â€¢ 0:09:17[0m [2;4m0.25it/s[0m  
[2KAttention weights: tensor([[0.6111, 0.3889]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 65/203 [2m0:03:41 â€¢ 0:09:17[0m [2;4m0.25it/s[0m  
[2KAttention weights: tensor([[0.6143, 0.3857]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 65/203 [2m0:03:41 â€¢ 0:09:17[0m [2;4m0.25it/s[0m  
[2KAttention weights: tensor([[0.6229, 0.3771]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 65/203 [2m0:03:41 â€¢ 0:09:17[0m [2;4m0.25it/s[0m  
[2KAttention weights: tensor([[0.6350, 0.3650]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 65/203 [2m0:03:41 â€¢ 0:09:17[0m [2;4m0.25it/s[0m  
[2KAttention weights: tensor([[0.6457, 0.3543]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 65/203 [2m0:03:41 â€¢ 0:09:17[0m [2;4m0.25it/s[0m  
[2KAttention weights: tensor([[0.6506, 0.3494]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 65/203 [2m0:03:41 â€¢ 0:09:17[0m [2;4m0.25it/s[0m  
[2KAttention weights: tensor([[0.5578, 0.4422]], device='cuda:0')5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 65/203 [2m0:03:41 â€¢ 0:09:17[0m [2;4m0.25it/s[0m  
[2KAttention weights: tensor([[0.6443, 0.3557],8;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 65/203 [2m0:03:41 â€¢ 0:09:17[0m [2;4m0.25it/s[0m  
        [0.5941, 0.4059],
        [0.6174, 0.3826],
        [0.6566, 0.3434],
        [0.6179, 0.3821],
        [0.6240, 0.3760],
        [0.5753, 0.4247],
        [0.6599, 0.3401],
        [0.6710, 0.3290],
[2K        [0.6658, 0.3342]], device='cuda:0')98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 65/203 [2m0:03:41 â€¢ 0:09:17[0m [2;4m0.25it/s[0m  
[2KAttention weights: tensor([[0.5576, 0.4424],8;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 66/203 [2m0:03:42 â€¢ 0:08:16[0m [2;4m0.28it/s[0m   
        [0.5531, 0.4469],
        [0.5545, 0.4455],
        [0.5561, 0.4439],
        [0.5558, 0.4442],
        [0.5527, 0.4473],
        [0.5520, 0.4480],
        [0.5574, 0.4426],
        [0.5572, 0.4428],
[2K        [0.5556, 0.4444]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 66/203 [2m0:03:42 â€¢ 0:08:16[0m [2;4m0.28it/s[0m  
[2KClass label: SoccerPenaltyâ”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 66/203 [2m0:03:42 â€¢ 0:08:16[0m [2;4m0.28it/s[0m  
[2KAttention weights: tensor([[0.6365, 0.3635]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 66/203 [2m0:03:42 â€¢ 0:08:16[0m [2;4m0.28it/s[0m  
[2KStep 0 - TTA Loss: 0.8003â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 66/203 [2m0:03:42 â€¢ 0:08:16[0m [2;4m0.28it/s[0m  
[2KAttention weights: tensor([[0.6378, 0.3622]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 66/203 [2m0:03:42 â€¢ 0:08:16[0m [2;4m0.28it/s[0m  
[2KAttention weights: tensor([[0.6424, 0.3576]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 66/203 [2m0:03:42 â€¢ 0:08:16[0m [2;4m0.28it/s[0m  
[2KAttention weights: tensor([[0.6459, 0.3541]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 66/203 [2m0:03:42 â€¢ 0:08:16[0m [2;4m0.28it/s[0m  
[2KAttention weights: tensor([[0.6525, 0.3475]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 66/203 [2m0:03:42 â€¢ 0:08:16[0m [2;4m0.28it/s[0m  
[2KAttention weights: tensor([[0.6548, 0.3452]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 66/203 [2m0:03:42 â€¢ 0:08:16[0m [2;4m0.28it/s[0m  
[2KAttention weights: tensor([[0.6658, 0.3342]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 66/203 [2m0:03:42 â€¢ 0:08:16[0m [2;4m0.28it/s[0m  
[2KAttention weights: tensor([[0.6702, 0.3298]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 66/203 [2m0:03:42 â€¢ 0:08:16[0m [2;4m0.28it/s[0m  
[2KAttention weights: tensor([[0.6710, 0.3290]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 66/203 [2m0:03:42 â€¢ 0:08:16[0m [2;4m0.28it/s[0m  
[2KAttention weights: tensor([[0.6698, 0.3302]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 66/203 [2m0:03:42 â€¢ 0:08:16[0m [2;4m0.28it/s[0m  
[2KAttention weights: tensor([[0.5581, 0.4419]], device='cuda:0')7mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 66/203 [2m0:03:42 â€¢ 0:08:16[0m [2;4m0.28it/s[0m  
[2KAttention weights: tensor([[0.6051, 0.3949],237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 66/203 [2m0:03:42 â€¢ 0:08:16[0m [2;4m0.28it/s[0m  
        [0.5880, 0.4120],
        [0.5925, 0.4075],
        [0.6290, 0.3710],
        [0.5944, 0.4056],
        [0.6059, 0.3941],
        [0.5633, 0.4367],
        [0.6693, 0.3307],
        [0.6489, 0.3511],
[2K        [0.6403, 0.3597]], device='cuda:0');237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 66/203 [2m0:03:42 â€¢ 0:08:16[0m [2;4m0.28it/s[0m  
[2KAttention weights: tensor([[0.5576, 0.4424],8;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 67/203 [2m0:03:43 â€¢ 0:07:32[0m [2;4m0.30it/s[0m  
        [0.5531, 0.4469],
        [0.5546, 0.4454],
        [0.5561, 0.4439],
        [0.5558, 0.4442],
        [0.5527, 0.4473],
        [0.5520, 0.4480],
        [0.5574, 0.4426],
        [0.5572, 0.4428],
[2K        [0.5556, 0.4444]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 67/203 [2m0:03:43 â€¢ 0:07:32[0m [2;4m0.30it/s[0m  
[2KClass label: HighJumpâ”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 67/203 [2m0:03:43 â€¢ 0:07:32[0m [2;4m0.30it/s[0m  
[2KAttention weights: tensor([[0.5907, 0.4093]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 67/203 [2m0:03:43 â€¢ 0:07:32[0m [2;4m0.30it/s[0m  
[2KStep 0 - TTA Loss: 0.6216â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 67/203 [2m0:03:43 â€¢ 0:07:32[0m [2;4m0.30it/s[0m  
[2KAttention weights: tensor([[0.5907, 0.4093]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 67/203 [2m0:03:43 â€¢ 0:07:32[0m [2;4m0.30it/s[0m  
[2KAttention weights: tensor([[0.5915, 0.4085]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 67/203 [2m0:03:43 â€¢ 0:07:32[0m [2;4m0.30it/s[0m  
[2KAttention weights: tensor([[0.5960, 0.4040]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 67/203 [2m0:03:43 â€¢ 0:07:32[0m [2;4m0.30it/s[0m  
[2KAttention weights: tensor([[0.6096, 0.3904]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 67/203 [2m0:03:43 â€¢ 0:07:32[0m [2;4m0.30it/s[0m  
[2KAttention weights: tensor([[0.6371, 0.3629]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 67/203 [2m0:03:43 â€¢ 0:07:32[0m [2;4m0.30it/s[0m  
[2KAttention weights: tensor([[0.6771, 0.3229]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 67/203 [2m0:03:43 â€¢ 0:07:32[0m [2;4m0.30it/s[0m  
[2KAttention weights: tensor([[0.7241, 0.2759]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 67/203 [2m0:03:43 â€¢ 0:07:32[0m [2;4m0.30it/s[0m  
[2KAttention weights: tensor([[0.7685, 0.2315]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 67/203 [2m0:03:43 â€¢ 0:07:32[0m [2;4m0.30it/s[0m  
[2KAttention weights: tensor([[0.8073, 0.1927]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 67/203 [2m0:03:43 â€¢ 0:07:32[0m [2;4m0.30it/s[0m  
[2KAttention weights: tensor([[0.5598, 0.4402]], device='cuda:0')7mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 67/203 [2m0:03:43 â€¢ 0:07:32[0m [2;4m0.30it/s[0m  
[2KAttention weights: tensor([[0.7882, 0.2118],237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 67/203 [2m0:03:43 â€¢ 0:07:32[0m [2;4m0.30it/s[0m  
        [0.7101, 0.2899],
        [0.7520, 0.2480],
        [0.7831, 0.2169],
        [0.8000, 0.2000],
        [0.8516, 0.1484],
        [0.7908, 0.2092],
        [0.7869, 0.2131],
        [0.8105, 0.1895],
[2K        [0.8283, 0.1717]], device='cuda:0');237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 67/203 [2m0:03:43 â€¢ 0:07:32[0m [2;4m0.30it/s[0m  
[2KAttention weights: tensor([[0.5576, 0.4424],8;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 68/203 [2m0:04:00 â€¢ 0:12:14[0m [2;4m0.18it/s[0m  
        [0.5532, 0.4468],
        [0.5546, 0.4454],
        [0.5561, 0.4439],
        [0.5558, 0.4442],
        [0.5528, 0.4472],
        [0.5520, 0.4480],
        [0.5574, 0.4426],
        [0.5573, 0.4427],
[2K        [0.5556, 0.4444]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 68/203 [2m0:04:00 â€¢ 0:12:14[0m [2;4m0.18it/s[0m  
[2KClass label: TennisSwingâ”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 68/203 [2m0:04:00 â€¢ 0:12:14[0m [2;4m0.18it/s[0m  
[2KAttention weights: tensor([[0.6459, 0.3541]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 68/203 [2m0:04:00 â€¢ 0:12:14[0m [2;4m0.18it/s[0m  
[2KStep 0 - TTA Loss: 0.6780â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 68/203 [2m0:04:00 â€¢ 0:12:14[0m [2;4m0.18it/s[0m  
[2KAttention weights: tensor([[0.6925, 0.3075]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 68/203 [2m0:04:00 â€¢ 0:12:14[0m [2;4m0.18it/s[0m  
[2KAttention weights: tensor([[0.7390, 0.2610]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 68/203 [2m0:04:00 â€¢ 0:12:14[0m [2;4m0.18it/s[0m  
[2KAttention weights: tensor([[0.7828, 0.2172]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 68/203 [2m0:04:00 â€¢ 0:12:14[0m [2;4m0.18it/s[0m  
[2KAttention weights: tensor([[0.8107, 0.1893]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 68/203 [2m0:04:00 â€¢ 0:12:14[0m [2;4m0.18it/s[0m  
[2KAttention weights: tensor([[0.8221, 0.1779]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 68/203 [2m0:04:00 â€¢ 0:12:14[0m [2;4m0.18it/s[0m  
[2KAttention weights: tensor([[0.8209, 0.1791]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 68/203 [2m0:04:00 â€¢ 0:12:14[0m [2;4m0.18it/s[0m  
[2KAttention weights: tensor([[0.8127, 0.1873]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 68/203 [2m0:04:00 â€¢ 0:12:14[0m [2;4m0.18it/s[0m  
[2KAttention weights: tensor([[0.8057, 0.1943]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 68/203 [2m0:04:00 â€¢ 0:12:14[0m [2;4m0.18it/s[0m  
[2KAttention weights: tensor([[0.8015, 0.1985]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 68/203 [2m0:04:00 â€¢ 0:12:14[0m [2;4m0.18it/s[0m  
[2KAttention weights: tensor([[0.5613, 0.4387]], device='cuda:0')7mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 68/203 [2m0:04:00 â€¢ 0:12:14[0m [2;4m0.18it/s[0m  
[2KAttention weights: tensor([[0.7777, 0.2223],237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 68/203 [2m0:04:00 â€¢ 0:12:14[0m [2;4m0.18it/s[0m  
        [0.7016, 0.2984],
        [0.7396, 0.2604],
        [0.7740, 0.2260],
        [0.7852, 0.2148],
        [0.8336, 0.1664],
        [0.7713, 0.2287],
        [0.7810, 0.2190],
        [0.8002, 0.1998],
[2K        [0.8155, 0.1845]], device='cuda:0');237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 68/203 [2m0:04:00 â€¢ 0:12:14[0m [2;4m0.18it/s[0m  
[2KAttention weights: tensor([[0.5576, 0.4424],8;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 69/203 [2m0:04:01 â€¢ 0:10:34[0m [2;4m0.21it/s[0m  
        [0.5532, 0.4468],
        [0.5546, 0.4454],
        [0.5561, 0.4439],
        [0.5558, 0.4442],
        [0.5528, 0.4472],
        [0.5521, 0.4479],
        [0.5574, 0.4426],
        [0.5573, 0.4427],
[2K        [0.5557, 0.4443]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 69/203 [2m0:04:01 â€¢ 0:10:34[0m [2;4m0.21it/s[0m  
[2KClass label: Billiardsâ”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 69/203 [2m0:04:01 â€¢ 0:10:34[0m [2;4m0.21it/s[0m  
[2KAttention weights: tensor([[0.5779, 0.4221]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 69/203 [2m0:04:01 â€¢ 0:10:34[0m [2;4m0.21it/s[0m  
[2KStep 0 - TTA Loss: 0.8880â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 69/203 [2m0:04:01 â€¢ 0:10:34[0m [2;4m0.21it/s[0m  
[2KAttention weights: tensor([[0.5779, 0.4221]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 69/203 [2m0:04:01 â€¢ 0:10:34[0m [2;4m0.21it/s[0m  
[2KAttention weights: tensor([[0.5784, 0.4216]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 69/203 [2m0:04:01 â€¢ 0:10:34[0m [2;4m0.21it/s[0m  
[2KAttention weights: tensor([[0.5824, 0.4176]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 69/203 [2m0:04:01 â€¢ 0:10:34[0m [2;4m0.21it/s[0m  
[2KAttention weights: tensor([[0.5942, 0.4058]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 69/203 [2m0:04:01 â€¢ 0:10:34[0m [2;4m0.21it/s[0m  
[2KAttention weights: tensor([[0.6171, 0.3829]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 69/203 [2m0:04:01 â€¢ 0:10:34[0m [2;4m0.21it/s[0m  
[2KAttention weights: tensor([[0.6490, 0.3510]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 69/203 [2m0:04:01 â€¢ 0:10:34[0m [2;4m0.21it/s[0m  
[2KAttention weights: tensor([[0.6887, 0.3113]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 69/203 [2m0:04:01 â€¢ 0:10:34[0m [2;4m0.21it/s[0m  
[2KAttention weights: tensor([[0.7623, 0.2377]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 69/203 [2m0:04:01 â€¢ 0:10:34[0m [2;4m0.21it/s[0m  
[2KAttention weights: tensor([[0.8608, 0.1392]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 69/203 [2m0:04:01 â€¢ 0:10:34[0m [2;4m0.21it/s[0m  
[2KAttention weights: tensor([[0.5649, 0.4351]], device='cuda:0');5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 69/203 [2m0:04:01 â€¢ 0:10:34[0m [2;4m0.21it/s[0m  
[2KAttention weights: tensor([[0.5576, 0.4424],8;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 70/203 [2m0:04:03 â€¢ 0:09:32[0m [2;4m0.23it/s[0m  
        [0.5532, 0.4468],
        [0.5546, 0.4454],
        [0.5561, 0.4439],
        [0.5558, 0.4442],
        [0.5528, 0.4472],
        [0.5521, 0.4479],
        [0.5574, 0.4426],
        [0.5573, 0.4427],
[2K        [0.5557, 0.4443]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 70/203 [2m0:04:03 â€¢ 0:09:32[0m [2;4m0.23it/s[0m  
[2KClass label: HammerThrowâ”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 70/203 [2m0:04:03 â€¢ 0:09:32[0m [2;4m0.23it/s[0m  
[2KAttention weights: tensor([[0.5873, 0.4127]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 70/203 [2m0:04:03 â€¢ 0:09:32[0m [2;4m0.23it/s[0m  
[2KStep 0 - TTA Loss: 0.5391â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 70/203 [2m0:04:03 â€¢ 0:09:32[0m [2;4m0.23it/s[0m  
[2KAttention weights: tensor([[0.6505, 0.3495]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 70/203 [2m0:04:03 â€¢ 0:09:32[0m [2;4m0.23it/s[0m  
[2KAttention weights: tensor([[0.7219, 0.2781]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 70/203 [2m0:04:03 â€¢ 0:09:32[0m [2;4m0.23it/s[0m  
[2KAttention weights: tensor([[0.7881, 0.2119]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 70/203 [2m0:04:03 â€¢ 0:09:32[0m [2;4m0.23it/s[0m  
[2KAttention weights: tensor([[0.8374, 0.1626]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 70/203 [2m0:04:03 â€¢ 0:09:32[0m [2;4m0.23it/s[0m  
[2KAttention weights: tensor([[0.8689, 0.1311]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 70/203 [2m0:04:03 â€¢ 0:09:32[0m [2;4m0.23it/s[0m  
[2KAttention weights: tensor([[0.8844, 0.1156]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 70/203 [2m0:04:03 â€¢ 0:09:32[0m [2;4m0.23it/s[0m  
[2KAttention weights: tensor([[0.8909, 0.1091]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 70/203 [2m0:04:03 â€¢ 0:09:32[0m [2;4m0.23it/s[0m  
[2KAttention weights: tensor([[0.8924, 0.1076]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 70/203 [2m0:04:03 â€¢ 0:09:32[0m [2;4m0.23it/s[0m  
[2KAttention weights: tensor([[0.8921, 0.1079]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 70/203 [2m0:04:03 â€¢ 0:09:32[0m [2;4m0.23it/s[0m  
[2KAttention weights: tensor([[0.5669, 0.4331]], device='cuda:0');5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 70/203 [2m0:04:03 â€¢ 0:09:32[0m [2;4m0.23it/s[0m  
[2KAttention weights: tensor([[0.8727, 0.1273],98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 70/203 [2m0:04:03 â€¢ 0:09:32[0m [2;4m0.23it/s[0m  
        [0.9761, 0.0239],
        [0.8357, 0.1643],
        [0.8630, 0.1370],
        [0.8919, 0.1081],
        [0.8819, 0.1181],
        [0.8553, 0.1447],
        [0.8965, 0.1035],
        [0.8688, 0.1312],
[2K        [0.8944, 0.1056]], device='cuda:0');98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 70/203 [2m0:04:03 â€¢ 0:09:32[0m [2;4m0.23it/s[0m  
[2KAttention weights: tensor([[0.5578, 0.4422],8;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 71/203 [2m0:04:07 â€¢ 0:09:14[0m [2;4m0.24it/s[0m  
        [0.5535, 0.4465],
        [0.5548, 0.4452],
        [0.5563, 0.4437],
        [0.5560, 0.4440],
        [0.5530, 0.4470],
        [0.5523, 0.4477],
        [0.5576, 0.4424],
        [0.5574, 0.4426],
[2K        [0.5558, 0.4442]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 71/203 [2m0:04:07 â€¢ 0:09:14[0m [2;4m0.24it/s[0m  
[2KClass label: HighJumpâ”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 71/203 [2m0:04:07 â€¢ 0:09:14[0m [2;4m0.24it/s[0m  
[2KAttention weights: tensor([[0.5948, 0.4052]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 71/203 [2m0:04:07 â€¢ 0:09:14[0m [2;4m0.24it/s[0m  
[2KStep 0 - TTA Loss: 0.5976â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 71/203 [2m0:04:07 â€¢ 0:09:14[0m [2;4m0.24it/s[0m  
[2KAttention weights: tensor([[0.5948, 0.4052]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 71/203 [2m0:04:07 â€¢ 0:09:14[0m [2;4m0.24it/s[0m  
[2KAttention weights: tensor([[0.5950, 0.4050]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 71/203 [2m0:04:07 â€¢ 0:09:14[0m [2;4m0.24it/s[0m  
[2KAttention weights: tensor([[0.5961, 0.4039]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 71/203 [2m0:04:07 â€¢ 0:09:14[0m [2;4m0.24it/s[0m  
[2KAttention weights: tensor([[0.6013, 0.3987]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 71/203 [2m0:04:07 â€¢ 0:09:14[0m [2;4m0.24it/s[0m  
[2KAttention weights: tensor([[0.6096, 0.3904]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 71/203 [2m0:04:07 â€¢ 0:09:14[0m [2;4m0.24it/s[0m  
[2KAttention weights: tensor([[0.6214, 0.3786]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 71/203 [2m0:04:07 â€¢ 0:09:14[0m [2;4m0.24it/s[0m  
[2KAttention weights: tensor([[0.6375, 0.3625]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 71/203 [2m0:04:07 â€¢ 0:09:14[0m [2;4m0.24it/s[0m  
[2KAttention weights: tensor([[0.6511, 0.3489]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 71/203 [2m0:04:07 â€¢ 0:09:14[0m [2;4m0.24it/s[0m  
[2KAttention weights: tensor([[0.6644, 0.3356]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 71/203 [2m0:04:07 â€¢ 0:09:14[0m [2;4m0.24it/s[0m  
[2KAttention weights: tensor([[0.5548, 0.4452]], device='cuda:0');5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 71/203 [2m0:04:07 â€¢ 0:09:14[0m [2;4m0.24it/s[0m  
[2KAttention weights: tensor([[0.6550, 0.3450],98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 71/203 [2m0:04:07 â€¢ 0:09:14[0m [2;4m0.24it/s[0m  
        [0.7247, 0.2753],
        [0.6131, 0.3869],
        [0.6686, 0.3314],
        [0.6152, 0.3848],
        [0.6809, 0.3191],
        [0.6231, 0.3769],
        [0.6981, 0.3019],
        [0.7004, 0.2996],
[2K        [0.6788, 0.3212]], device='cuda:0');98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 71/203 [2m0:04:07 â€¢ 0:09:14[0m [2;4m0.24it/s[0m  
[2KAttention weights: tensor([[0.5578, 0.4422],38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 72/203 [2m0:04:12 â€¢ 0:10:49[0m [2;4m0.20it/s[0m   
        [0.5535, 0.4465],
        [0.5548, 0.4452],
        [0.5563, 0.4437],
        [0.5560, 0.4440],
        [0.5530, 0.4470],
        [0.5523, 0.4477],
        [0.5576, 0.4424],
        [0.5574, 0.4426],
[2K        [0.5558, 0.4442]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 72/203 [2m0:04:12 â€¢ 0:10:49[0m [2;4m0.20it/s[0m  
[2KClass label: ThrowDiscusâ”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 72/203 [2m0:04:12 â€¢ 0:10:49[0m [2;4m0.20it/s[0m  
[2KAttention weights: tensor([[0.6336, 0.3664]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 72/203 [2m0:04:12 â€¢ 0:10:49[0m [2;4m0.20it/s[0m  
[2KStep 0 - TTA Loss: 0.5053â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 72/203 [2m0:04:12 â€¢ 0:10:49[0m [2;4m0.20it/s[0m  
[2KAttention weights: tensor([[0.6753, 0.3247]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 72/203 [2m0:04:12 â€¢ 0:10:49[0m [2;4m0.20it/s[0m  
[2KAttention weights: tensor([[0.7389, 0.2611]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 72/203 [2m0:04:12 â€¢ 0:10:49[0m [2;4m0.20it/s[0m  
[2KAttention weights: tensor([[0.8094, 0.1906]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 72/203 [2m0:04:12 â€¢ 0:10:49[0m [2;4m0.20it/s[0m  
[2KAttention weights: tensor([[0.8671, 0.1329]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 72/203 [2m0:04:12 â€¢ 0:10:49[0m [2;4m0.20it/s[0m  
[2KAttention weights: tensor([[0.9054, 0.0946]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 72/203 [2m0:04:12 â€¢ 0:10:49[0m [2;4m0.20it/s[0m  
[2KAttention weights: tensor([[0.9283, 0.0717]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 72/203 [2m0:04:12 â€¢ 0:10:49[0m [2;4m0.20it/s[0m  
[2KAttention weights: tensor([[0.9403, 0.0597]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 72/203 [2m0:04:12 â€¢ 0:10:49[0m [2;4m0.20it/s[0m  
[2KAttention weights: tensor([[0.9458, 0.0542]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 72/203 [2m0:04:12 â€¢ 0:10:49[0m [2;4m0.20it/s[0m  
[2KAttention weights: tensor([[0.9479, 0.0521]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 72/203 [2m0:04:12 â€¢ 0:10:49[0m [2;4m0.20it/s[0m  
[2KAttention weights: tensor([[0.5687, 0.4313]], device='cuda:0')37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 72/203 [2m0:04:12 â€¢ 0:10:49[0m [2;4m0.20it/s[0m  
[2KAttention weights: tensor([[0.9215, 0.0785],;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 72/203 [2m0:04:12 â€¢ 0:10:49[0m [2;4m0.20it/s[0m  
        [0.8470, 0.1530],
        [0.8615, 0.1385],
        [0.9107, 0.0893],
        [0.9217, 0.0783],
        [0.9202, 0.0798],
        [0.8878, 0.1122],
        [0.8861, 0.1139],
        [0.9130, 0.0870],
[2K        [0.9485, 0.0515]], device='cuda:0')5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 72/203 [2m0:04:12 â€¢ 0:10:49[0m [2;4m0.20it/s[0m  
[2KAttention weights: tensor([[0.5579, 0.4421],38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 73/203 [2m0:04:19 â€¢ 0:08:28[0m [2;4m0.26it/s[0m  
        [0.5536, 0.4464],
        [0.5549, 0.4451],
        [0.5564, 0.4436],
        [0.5562, 0.4438],
        [0.5531, 0.4469],
        [0.5524, 0.4476],
        [0.5577, 0.4423],
        [0.5575, 0.4425],
[2K        [0.5560, 0.4440]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 73/203 [2m0:04:19 â€¢ 0:08:28[0m [2;4m0.26it/s[0m  
[2KClass label: GolfSwingâ”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 73/203 [2m0:04:19 â€¢ 0:08:28[0m [2;4m0.26it/s[0m  
[2KAttention weights: tensor([[0.6242, 0.3758]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 73/203 [2m0:04:19 â€¢ 0:08:28[0m [2;4m0.26it/s[0m  
[2KStep 0 - TTA Loss: 0.7836â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 73/203 [2m0:04:19 â€¢ 0:08:28[0m [2;4m0.26it/s[0m  
[2KAttention weights: tensor([[0.6242, 0.3758]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 73/203 [2m0:04:19 â€¢ 0:08:28[0m [2;4m0.26it/s[0m  
[2KAttention weights: tensor([[0.6259, 0.3741]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 73/203 [2m0:04:19 â€¢ 0:08:28[0m [2;4m0.26it/s[0m  
[2KAttention weights: tensor([[0.6321, 0.3679]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 73/203 [2m0:04:19 â€¢ 0:08:28[0m [2;4m0.26it/s[0m  
[2KAttention weights: tensor([[0.6443, 0.3557]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 73/203 [2m0:04:19 â€¢ 0:08:28[0m [2;4m0.26it/s[0m  
[2KAttention weights: tensor([[0.6641, 0.3359]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 73/203 [2m0:04:19 â€¢ 0:08:28[0m [2;4m0.26it/s[0m  
[2KAttention weights: tensor([[0.6900, 0.3100]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 73/203 [2m0:04:19 â€¢ 0:08:28[0m [2;4m0.26it/s[0m  
[2KAttention weights: tensor([[0.7189, 0.2811]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 73/203 [2m0:04:19 â€¢ 0:08:28[0m [2;4m0.26it/s[0m  
[2KAttention weights: tensor([[0.7437, 0.2563]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 73/203 [2m0:04:19 â€¢ 0:08:28[0m [2;4m0.26it/s[0m  
[2KAttention weights: tensor([[0.7577, 0.2423]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 73/203 [2m0:04:19 â€¢ 0:08:28[0m [2;4m0.26it/s[0m  
[2KAttention weights: tensor([[0.5603, 0.4397]], device='cuda:0')37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 73/203 [2m0:04:19 â€¢ 0:08:28[0m [2;4m0.26it/s[0m  
[2KAttention weights: tensor([[0.7607, 0.2393],;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 73/203 [2m0:04:19 â€¢ 0:08:28[0m [2;4m0.26it/s[0m  
        [0.6820, 0.3180],
        [0.6924, 0.3076],
        [0.7609, 0.2391],
        [0.7484, 0.2516],
        [0.7446, 0.2554],
        [0.6963, 0.3037],
        [0.7446, 0.2554],
        [0.7694, 0.2306],
[2K        [0.7997, 0.2003]], device='cuda:0')5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 73/203 [2m0:04:19 â€¢ 0:08:28[0m [2;4m0.26it/s[0m  
[2KAttention weights: tensor([[0.5580, 0.4420],38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 74/203 [2m0:04:21 â€¢ 0:07:35[0m [2;4m0.28it/s[0m  
        [0.5537, 0.4463],
        [0.5550, 0.4450],
        [0.5564, 0.4436],
        [0.5562, 0.4438],
        [0.5532, 0.4468],
        [0.5524, 0.4476],
        [0.5577, 0.4423],
        [0.5576, 0.4424],
[2K        [0.5561, 0.4439]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 74/203 [2m0:04:21 â€¢ 0:07:35[0m [2;4m0.28it/s[0m  
[2KClass label: ThrowDiscusâ”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 74/203 [2m0:04:21 â€¢ 0:07:35[0m [2;4m0.28it/s[0m  
[2KAttention weights: tensor([[0.6375, 0.3625]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 74/203 [2m0:04:21 â€¢ 0:07:35[0m [2;4m0.28it/s[0m  
[2KStep 0 - TTA Loss: 0.7393â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 74/203 [2m0:04:21 â€¢ 0:07:35[0m [2;4m0.28it/s[0m  
[2KAttention weights: tensor([[0.6605, 0.3395]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 74/203 [2m0:04:21 â€¢ 0:07:35[0m [2;4m0.28it/s[0m  
[2KAttention weights: tensor([[0.6827, 0.3173]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 74/203 [2m0:04:21 â€¢ 0:07:35[0m [2;4m0.28it/s[0m  
[2KAttention weights: tensor([[0.7075, 0.2925]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 74/203 [2m0:04:21 â€¢ 0:07:35[0m [2;4m0.28it/s[0m  
[2KAttention weights: tensor([[0.7290, 0.2710]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 74/203 [2m0:04:21 â€¢ 0:07:35[0m [2;4m0.28it/s[0m  
[2KAttention weights: tensor([[0.7429, 0.2571]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 74/203 [2m0:04:21 â€¢ 0:07:35[0m [2;4m0.28it/s[0m  
[2KAttention weights: tensor([[0.7505, 0.2495]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 74/203 [2m0:04:21 â€¢ 0:07:35[0m [2;4m0.28it/s[0m  
[2KAttention weights: tensor([[0.7508, 0.2492]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 74/203 [2m0:04:21 â€¢ 0:07:35[0m [2;4m0.28it/s[0m  
[2KAttention weights: tensor([[0.7488, 0.2512]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 74/203 [2m0:04:21 â€¢ 0:07:35[0m [2;4m0.28it/s[0m  
[2KAttention weights: tensor([[0.7468, 0.2532]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 74/203 [2m0:04:21 â€¢ 0:07:35[0m [2;4m0.28it/s[0m  
[2KAttention weights: tensor([[0.5592, 0.4408]], device='cuda:0')8;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 74/203 [2m0:04:21 â€¢ 0:07:35[0m [2;4m0.28it/s[0m  
[2KAttention weights: tensor([[0.6975, 0.3025],;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 74/203 [2m0:04:21 â€¢ 0:07:35[0m [2;4m0.28it/s[0m  
        [0.6413, 0.3587],
        [0.6478, 0.3522],
        [0.6827, 0.3173],
        [0.6928, 0.3072],
        [0.6952, 0.3048],
        [0.6435, 0.3566],
        [0.7057, 0.2943],
        [0.7142, 0.2858],
[2K        [0.7460, 0.2540]], device='cuda:0')2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 74/203 [2m0:04:21 â€¢ 0:07:35[0m [2;4m0.28it/s[0m  
[2KAttention weights: tensor([[0.5580, 0.4420],38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 75/203 [2m0:04:23 â€¢ 0:06:57[0m [2;4m0.31it/s[0m  
        [0.5537, 0.4463],
        [0.5550, 0.4450],
        [0.5564, 0.4436],
        [0.5563, 0.4437],
        [0.5532, 0.4468],
        [0.5525, 0.4475],
        [0.5577, 0.4423],
        [0.5576, 0.4424],
[2K        [0.5562, 0.4438]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 75/203 [2m0:04:23 â€¢ 0:06:57[0m [2;4m0.31it/s[0m  
[2KClass label: BaseballPitchâ”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 75/203 [2m0:04:23 â€¢ 0:06:57[0m [2;4m0.31it/s[0m  
[2KAttention weights: tensor([[0.6089, 0.3911]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 75/203 [2m0:04:23 â€¢ 0:06:57[0m [2;4m0.31it/s[0m  
[2KStep 0 - TTA Loss: 0.9625â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 75/203 [2m0:04:23 â€¢ 0:06:57[0m [2;4m0.31it/s[0m  
[2KAttention weights: tensor([[0.6089, 0.3911]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 75/203 [2m0:04:23 â€¢ 0:06:57[0m [2;4m0.31it/s[0m  
[2KAttention weights: tensor([[0.6095, 0.3905]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 75/203 [2m0:04:23 â€¢ 0:06:57[0m [2;4m0.31it/s[0m  
[2KAttention weights: tensor([[0.6140, 0.3860]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 75/203 [2m0:04:23 â€¢ 0:06:57[0m [2;4m0.31it/s[0m  
[2KAttention weights: tensor([[0.6303, 0.3697]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 75/203 [2m0:04:23 â€¢ 0:06:57[0m [2;4m0.31it/s[0m  
[2KAttention weights: tensor([[0.6641, 0.3359]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 75/203 [2m0:04:23 â€¢ 0:06:57[0m [2;4m0.31it/s[0m  
[2KAttention weights: tensor([[0.7172, 0.2828]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 75/203 [2m0:04:23 â€¢ 0:06:57[0m [2;4m0.31it/s[0m  
[2KAttention weights: tensor([[0.7821, 0.2179]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 75/203 [2m0:04:23 â€¢ 0:06:57[0m [2;4m0.31it/s[0m  
[2KAttention weights: tensor([[0.8368, 0.1632]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 75/203 [2m0:04:23 â€¢ 0:06:57[0m [2;4m0.31it/s[0m  
[2KAttention weights: tensor([[0.8802, 0.1198]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 75/203 [2m0:04:23 â€¢ 0:06:57[0m [2;4m0.31it/s[0m  
[2KAttention weights: tensor([[0.5675, 0.4325]], device='cuda:0')8;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 75/203 [2m0:04:23 â€¢ 0:06:57[0m [2;4m0.31it/s[0m  
[2KAttention weights: tensor([[0.9477, 0.0523],;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 75/203 [2m0:04:23 â€¢ 0:06:57[0m [2;4m0.31it/s[0m  
        [0.7524, 0.2476],
        [0.7300, 0.2700],
        [0.8823, 0.1177],
        [0.8532, 0.1468],
        [0.8308, 0.1692],
        [0.7802, 0.2198],
        [0.8510, 0.1490],
        [0.8639, 0.1361],
[2K        [0.8818, 0.1182]], device='cuda:0')2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 75/203 [2m0:04:23 â€¢ 0:06:57[0m [2;4m0.31it/s[0m  
[2KAttention weights: tensor([[0.5581, 0.4419],38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 76/203 [2m0:04:24 â€¢ 0:06:26[0m [2;4m0.33it/s[0m  
        [0.5537, 0.4463],
        [0.5550, 0.4450],
        [0.5564, 0.4436],
        [0.5563, 0.4437],
        [0.5532, 0.4468],
        [0.5525, 0.4475],
        [0.5578, 0.4422],
        [0.5576, 0.4424],
[2K        [0.5562, 0.4438]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 76/203 [2m0:04:24 â€¢ 0:06:26[0m [2;4m0.33it/s[0m  
[2KClass label: Billiardsâ”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 76/203 [2m0:04:24 â€¢ 0:06:26[0m [2;4m0.33it/s[0m  
[2KAttention weights: tensor([[0.5767, 0.4233]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 76/203 [2m0:04:24 â€¢ 0:06:26[0m [2;4m0.33it/s[0m  
[2KStep 0 - TTA Loss: 0.5199â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 76/203 [2m0:04:24 â€¢ 0:06:26[0m [2;4m0.33it/s[0m  
[2KAttention weights: tensor([[0.6442, 0.3558]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 76/203 [2m0:04:24 â€¢ 0:06:26[0m [2;4m0.33it/s[0m  
[2KAttention weights: tensor([[0.6932, 0.3068]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 76/203 [2m0:04:24 â€¢ 0:06:26[0m [2;4m0.33it/s[0m  
[2KAttention weights: tensor([[0.7187, 0.2813]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 76/203 [2m0:04:24 â€¢ 0:06:26[0m [2;4m0.33it/s[0m  
[2KAttention weights: tensor([[0.7183, 0.2817]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 76/203 [2m0:04:24 â€¢ 0:06:26[0m [2;4m0.33it/s[0m  
[2KAttention weights: tensor([[0.7092, 0.2908]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 76/203 [2m0:04:24 â€¢ 0:06:26[0m [2;4m0.33it/s[0m  
[2KAttention weights: tensor([[0.7008, 0.2992]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 76/203 [2m0:04:24 â€¢ 0:06:26[0m [2;4m0.33it/s[0m  
[2KAttention weights: tensor([[0.6968, 0.3032]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 76/203 [2m0:04:24 â€¢ 0:06:26[0m [2;4m0.33it/s[0m  
[2KAttention weights: tensor([[0.6962, 0.3038]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 76/203 [2m0:04:24 â€¢ 0:06:26[0m [2;4m0.33it/s[0m  
[2KAttention weights: tensor([[0.6960, 0.3040]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 76/203 [2m0:04:24 â€¢ 0:06:26[0m [2;4m0.33it/s[0m  
[2KAttention weights: tensor([[0.5565, 0.4435]], device='cuda:0')8;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 76/203 [2m0:04:24 â€¢ 0:06:26[0m [2;4m0.33it/s[0m  
[2KAttention weights: tensor([[0.9777, 0.0223],;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 76/203 [2m0:04:24 â€¢ 0:06:26[0m [2;4m0.33it/s[0m  
        [0.6963, 0.3037],
        [0.7780, 0.2220],
        [0.9290, 0.0710],
        [0.9100, 0.0900],
        [0.8845, 0.1155],
        [0.8394, 0.1606],
        [0.8900, 0.1100],
        [0.9047, 0.0953],
[2K        [0.9306, 0.0694]], device='cuda:0')2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 76/203 [2m0:04:24 â€¢ 0:06:26[0m [2;4m0.33it/s[0m  
[2KAttention weights: tensor([[0.5582, 0.4418],[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 77/203 [2m0:04:28 â€¢ 0:06:28[0m [2;4m0.33it/s[0m   
        [0.5538, 0.4462],
        [0.5551, 0.4449],
        [0.5565, 0.4435],
        [0.5564, 0.4436],
        [0.5533, 0.4467],
        [0.5526, 0.4474],
        [0.5579, 0.4421],
        [0.5577, 0.4423],
[2K        [0.5563, 0.4437]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 77/203 [2m0:04:28 â€¢ 0:06:28[0m [2;4m0.33it/s[0m  
[2KClass label: SoccerPenaltyâ”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 77/203 [2m0:04:28 â€¢ 0:06:28[0m [2;4m0.33it/s[0m  
[2KAttention weights: tensor([[0.6423, 0.3577]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 77/203 [2m0:04:28 â€¢ 0:06:28[0m [2;4m0.33it/s[0m  
[2KStep 0 - TTA Loss: 0.6195â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 77/203 [2m0:04:28 â€¢ 0:06:28[0m [2;4m0.33it/s[0m  
[2KAttention weights: tensor([[0.6423, 0.3577]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 77/203 [2m0:04:28 â€¢ 0:06:28[0m [2;4m0.33it/s[0m  
[2KAttention weights: tensor([[0.6439, 0.3561]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 77/203 [2m0:04:28 â€¢ 0:06:28[0m [2;4m0.33it/s[0m  
[2KAttention weights: tensor([[0.6519, 0.3481]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 77/203 [2m0:04:28 â€¢ 0:06:28[0m [2;4m0.33it/s[0m  
[2KAttention weights: tensor([[0.6710, 0.3290]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 77/203 [2m0:04:28 â€¢ 0:06:28[0m [2;4m0.33it/s[0m  
[2KAttention weights: tensor([[0.7046, 0.2954]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 77/203 [2m0:04:28 â€¢ 0:06:28[0m [2;4m0.33it/s[0m  
[2KAttention weights: tensor([[0.7507, 0.2493]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 77/203 [2m0:04:28 â€¢ 0:06:28[0m [2;4m0.33it/s[0m  
[2KAttention weights: tensor([[0.7965, 0.2035]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 77/203 [2m0:04:28 â€¢ 0:06:28[0m [2;4m0.33it/s[0m  
[2KAttention weights: tensor([[0.8363, 0.1637]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 77/203 [2m0:04:28 â€¢ 0:06:28[0m [2;4m0.33it/s[0m  
[2KAttention weights: tensor([[0.8665, 0.1335]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 77/203 [2m0:04:28 â€¢ 0:06:28[0m [2;4m0.33it/s[0m  
[2KAttention weights: tensor([[0.5648, 0.4352]], device='cuda:0')237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 77/203 [2m0:04:28 â€¢ 0:06:28[0m [2;4m0.33it/s[0m  
[2KAttention weights: tensor([[0.8522, 0.1478],5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 77/203 [2m0:04:28 â€¢ 0:06:28[0m [2;4m0.33it/s[0m  
        [0.7152, 0.2848],
        [0.6991, 0.3009],
        [0.8075, 0.1925],
        [0.8021, 0.1979],
        [0.8035, 0.1965],
        [0.7596, 0.2404],
        [0.9101, 0.0899],
        [0.8094, 0.1906],
[2K        [0.8239, 0.1761]], device='cuda:0');5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 77/203 [2m0:04:28 â€¢ 0:06:28[0m [2;4m0.33it/s[0m  
[2KAttention weights: tensor([[0.5582, 0.4418],[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 78/203 [2m0:04:29 â€¢ 0:06:07[0m [2;4m0.34it/s[0m  
        [0.5537, 0.4463],
        [0.5550, 0.4450],
        [0.5565, 0.4435],
        [0.5563, 0.4437],
        [0.5533, 0.4467],
        [0.5526, 0.4474],
        [0.5578, 0.4422],
        [0.5577, 0.4423],
[2K        [0.5562, 0.4438]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 78/203 [2m0:04:29 â€¢ 0:06:07[0m [2;4m0.34it/s[0m  
[2KClass label: HighJumpâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 78/203 [2m0:04:29 â€¢ 0:06:07[0m [2;4m0.34it/s[0m  
[2KAttention weights: tensor([[0.5922, 0.4078]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 78/203 [2m0:04:29 â€¢ 0:06:07[0m [2;4m0.34it/s[0m  
[2KStep 0 - TTA Loss: 0.6146â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 78/203 [2m0:04:29 â€¢ 0:06:07[0m [2;4m0.34it/s[0m  
[2KAttention weights: tensor([[0.6639, 0.3361]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 78/203 [2m0:04:29 â€¢ 0:06:07[0m [2;4m0.34it/s[0m  
[2KAttention weights: tensor([[0.7353, 0.2647]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 78/203 [2m0:04:29 â€¢ 0:06:07[0m [2;4m0.34it/s[0m  
[2KAttention weights: tensor([[0.7968, 0.2032]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 78/203 [2m0:04:29 â€¢ 0:06:07[0m [2;4m0.34it/s[0m  
[2KAttention weights: tensor([[0.8425, 0.1575]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 78/203 [2m0:04:29 â€¢ 0:06:07[0m [2;4m0.34it/s[0m  
[2KAttention weights: tensor([[0.8711, 0.1289]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 78/203 [2m0:04:29 â€¢ 0:06:07[0m [2;4m0.34it/s[0m  
[2KAttention weights: tensor([[0.8868, 0.1132]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 78/203 [2m0:04:29 â€¢ 0:06:07[0m [2;4m0.34it/s[0m  
[2KAttention weights: tensor([[0.8961, 0.1039]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 78/203 [2m0:04:29 â€¢ 0:06:07[0m [2;4m0.34it/s[0m  
[2KAttention weights: tensor([[0.9006, 0.0994]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 78/203 [2m0:04:29 â€¢ 0:06:07[0m [2;4m0.34it/s[0m  
[2KAttention weights: tensor([[0.9026, 0.0974]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 78/203 [2m0:04:29 â€¢ 0:06:07[0m [2;4m0.34it/s[0m  
[2KAttention weights: tensor([[0.5641, 0.4359]], device='cuda:0')237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 78/203 [2m0:04:29 â€¢ 0:06:07[0m [2;4m0.34it/s[0m  
[2KAttention weights: tensor([[0.8954, 0.1046],5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 78/203 [2m0:04:29 â€¢ 0:06:07[0m [2;4m0.34it/s[0m  
        [0.7903, 0.2097],
        [0.7951, 0.2049],
        [0.8632, 0.1368],
        [0.8829, 0.1171],
        [0.9034, 0.0966],
        [0.8636, 0.1364],
        [0.9477, 0.0523],
        [0.8728, 0.1272],
[2K        [0.8931, 0.1069]], device='cuda:0');5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 78/203 [2m0:04:29 â€¢ 0:06:07[0m [2;4m0.34it/s[0m  
[2KAttention weights: tensor([[0.5582, 0.4418],[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 79/203 [2m0:04:37 â€¢ 0:07:43[0m [2;4m0.27it/s[0m  
        [0.5537, 0.4463],
        [0.5550, 0.4450],
        [0.5565, 0.4435],
        [0.5563, 0.4437],
        [0.5532, 0.4468],
        [0.5525, 0.4475],
        [0.5577, 0.4423],
        [0.5576, 0.4424],
[2K        [0.5562, 0.4438]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 79/203 [2m0:04:37 â€¢ 0:07:43[0m [2;4m0.27it/s[0m  
[2KClass label: ThrowDiscusâ”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 79/203 [2m0:04:37 â€¢ 0:07:43[0m [2;4m0.27it/s[0m  
[2KAttention weights: tensor([[0.6342, 0.3658]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 79/203 [2m0:04:37 â€¢ 0:07:43[0m [2;4m0.27it/s[0m  
[2KStep 0 - TTA Loss: 0.4628â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 79/203 [2m0:04:37 â€¢ 0:07:43[0m [2;4m0.27it/s[0m  
[2KAttention weights: tensor([[0.6342, 0.3658]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 79/203 [2m0:04:37 â€¢ 0:07:43[0m [2;4m0.27it/s[0m  
[2KAttention weights: tensor([[0.6348, 0.3652]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 79/203 [2m0:04:37 â€¢ 0:07:43[0m [2;4m0.27it/s[0m  
[2KAttention weights: tensor([[0.6361, 0.3639]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 79/203 [2m0:04:37 â€¢ 0:07:43[0m [2;4m0.27it/s[0m  
[2KAttention weights: tensor([[0.6366, 0.3634]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 79/203 [2m0:04:37 â€¢ 0:07:43[0m [2;4m0.27it/s[0m  
[2KAttention weights: tensor([[0.6334, 0.3666]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 79/203 [2m0:04:37 â€¢ 0:07:43[0m [2;4m0.27it/s[0m  
[2KAttention weights: tensor([[0.6231, 0.3769]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 79/203 [2m0:04:37 â€¢ 0:07:43[0m [2;4m0.27it/s[0m  
[2KAttention weights: tensor([[0.6039, 0.3961]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 79/203 [2m0:04:37 â€¢ 0:07:43[0m [2;4m0.27it/s[0m  
[2KAttention weights: tensor([[0.5829, 0.4171]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 79/203 [2m0:04:37 â€¢ 0:07:43[0m [2;4m0.27it/s[0m  
[2KAttention weights: tensor([[0.5706, 0.4294]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 79/203 [2m0:04:37 â€¢ 0:07:43[0m [2;4m0.27it/s[0m  
[2KAttention weights: tensor([[0.5542, 0.4458]], device='cuda:0')38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 79/203 [2m0:04:37 â€¢ 0:07:43[0m [2;4m0.27it/s[0m  
[2KAttention weights: tensor([[0.5924, 0.4076],2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 79/203 [2m0:04:37 â€¢ 0:07:43[0m [2;4m0.27it/s[0m  
        [0.5801, 0.4199],
        [0.5451, 0.4549],
        [0.5992, 0.4008],
        [0.5556, 0.4444],
        [0.6056, 0.3944],
        [0.5528, 0.4472],
        [0.6831, 0.3169],
        [0.6271, 0.3729],
[2K        [0.5880, 0.4120]], device='cuda:0');2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 79/203 [2m0:04:37 â€¢ 0:07:43[0m [2;4m0.27it/s[0m  
[2KAttention weights: tensor([[0.5582, 0.4418],[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 80/203 [2m0:04:39 â€¢ 0:07:03[0m [2;4m0.29it/s[0m  
        [0.5537, 0.4463],
        [0.5550, 0.4450],
        [0.5565, 0.4435],
        [0.5563, 0.4437],
        [0.5532, 0.4468],
        [0.5525, 0.4475],
        [0.5577, 0.4423],
        [0.5576, 0.4424],
[2K        [0.5561, 0.4439]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 80/203 [2m0:04:39 â€¢ 0:07:03[0m [2;4m0.29it/s[0m  
[2KClass label: BaseballPitchâ”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 80/203 [2m0:04:39 â€¢ 0:07:03[0m [2;4m0.29it/s[0m  
[2KAttention weights: tensor([[0.6159, 0.3841]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 80/203 [2m0:04:39 â€¢ 0:07:03[0m [2;4m0.29it/s[0m  
[2KStep 0 - TTA Loss: 1.0572â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 80/203 [2m0:04:39 â€¢ 0:07:03[0m [2;4m0.29it/s[0m  
[2KAttention weights: tensor([[0.6378, 0.3622]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 80/203 [2m0:04:39 â€¢ 0:07:03[0m [2;4m0.29it/s[0m  
[2KAttention weights: tensor([[0.6569, 0.3431]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 80/203 [2m0:04:39 â€¢ 0:07:03[0m [2;4m0.29it/s[0m  
[2KAttention weights: tensor([[0.6779, 0.3221]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 80/203 [2m0:04:39 â€¢ 0:07:03[0m [2;4m0.29it/s[0m  
[2KAttention weights: tensor([[0.6960, 0.3040]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 80/203 [2m0:04:39 â€¢ 0:07:03[0m [2;4m0.29it/s[0m  
[2KAttention weights: tensor([[0.7104, 0.2896]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 80/203 [2m0:04:39 â€¢ 0:07:03[0m [2;4m0.29it/s[0m  
[2KAttention weights: tensor([[0.7159, 0.2841]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 80/203 [2m0:04:39 â€¢ 0:07:03[0m [2;4m0.29it/s[0m  
[2KAttention weights: tensor([[0.7193, 0.2807]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 80/203 [2m0:04:39 â€¢ 0:07:03[0m [2;4m0.29it/s[0m  
[2KAttention weights: tensor([[0.7211, 0.2789]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 80/203 [2m0:04:39 â€¢ 0:07:03[0m [2;4m0.29it/s[0m  
[2KAttention weights: tensor([[0.7209, 0.2791]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 80/203 [2m0:04:39 â€¢ 0:07:03[0m [2;4m0.29it/s[0m  
[2KAttention weights: tensor([[0.5604, 0.4396]], device='cuda:0')38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 80/203 [2m0:04:39 â€¢ 0:07:03[0m [2;4m0.29it/s[0m  
[2KAttention weights: tensor([[0.7206, 0.2794],2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 80/203 [2m0:04:39 â€¢ 0:07:03[0m [2;4m0.29it/s[0m  
        [0.6387, 0.3613],
        [0.6367, 0.3633],
        [0.7079, 0.2921],
        [0.6846, 0.3154],
        [0.7033, 0.2967],
        [0.6483, 0.3517],
        [0.7355, 0.2645],
        [0.7230, 0.2770],
[2K        [0.7259, 0.2741]], device='cuda:0');2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 80/203 [2m0:04:39 â€¢ 0:07:03[0m [2;4m0.29it/s[0m  
[2KAttention weights: tensor([[0.5581, 0.4419],[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 81/203 [2m0:04:40 â€¢ 0:06:25[0m [2;4m0.32it/s[0m  
        [0.5536, 0.4464],
        [0.5549, 0.4451],
        [0.5564, 0.4436],
        [0.5562, 0.4438],
        [0.5532, 0.4468],
        [0.5524, 0.4476],
        [0.5577, 0.4423],
        [0.5575, 0.4425],
[2K        [0.5561, 0.4439]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 81/203 [2m0:04:40 â€¢ 0:06:25[0m [2;4m0.32it/s[0m  
[2KClass label: TennisSwingâ”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 81/203 [2m0:04:40 â€¢ 0:06:25[0m [2;4m0.32it/s[0m  
[2KAttention weights: tensor([[0.6483, 0.3517]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 81/203 [2m0:04:40 â€¢ 0:06:25[0m [2;4m0.32it/s[0m  
[2KStep 0 - TTA Loss: 0.7759â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 81/203 [2m0:04:40 â€¢ 0:06:25[0m [2;4m0.32it/s[0m  
[2KAttention weights: tensor([[0.6483, 0.3517]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 81/203 [2m0:04:40 â€¢ 0:06:25[0m [2;4m0.32it/s[0m  
[2KAttention weights: tensor([[0.6480, 0.3520]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 81/203 [2m0:04:40 â€¢ 0:06:25[0m [2;4m0.32it/s[0m  
[2KAttention weights: tensor([[0.6468, 0.3532]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 81/203 [2m0:04:40 â€¢ 0:06:25[0m [2;4m0.32it/s[0m  
[2KAttention weights: tensor([[0.6440, 0.3560]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 81/203 [2m0:04:40 â€¢ 0:06:25[0m [2;4m0.32it/s[0m  
[2KAttention weights: tensor([[0.6391, 0.3609]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 81/203 [2m0:04:40 â€¢ 0:06:25[0m [2;4m0.32it/s[0m  
[2KAttention weights: tensor([[0.6310, 0.3690]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 81/203 [2m0:04:40 â€¢ 0:06:25[0m [2;4m0.32it/s[0m  
[2KAttention weights: tensor([[0.6196, 0.3804]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 81/203 [2m0:04:40 â€¢ 0:06:25[0m [2;4m0.32it/s[0m  
[2KAttention weights: tensor([[0.6053, 0.3947]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 81/203 [2m0:04:40 â€¢ 0:06:25[0m [2;4m0.32it/s[0m  
[2KAttention weights: tensor([[0.5864, 0.4136]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 81/203 [2m0:04:40 â€¢ 0:06:25[0m [2;4m0.32it/s[0m  
[2KAttention weights: tensor([[0.5545, 0.4455]], device='cuda:0')38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 81/203 [2m0:04:40 â€¢ 0:06:25[0m [2;4m0.32it/s[0m  
[2KAttention weights: tensor([[0.5401, 0.4599],2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 81/203 [2m0:04:40 â€¢ 0:06:25[0m [2;4m0.32it/s[0m  
        [0.5431, 0.4569],
        [0.5326, 0.4674],
        [0.5666, 0.4334],
        [0.5337, 0.4663],
        [0.5492, 0.4508],
        [0.5132, 0.4868],
        [0.6035, 0.3965],
        [0.5646, 0.4354],
[2K        [0.5788, 0.4212]], device='cuda:0');2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 81/203 [2m0:04:40 â€¢ 0:06:25[0m [2;4m0.32it/s[0m  
[2KAttention weights: tensor([[0.5580, 0.4420],[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 82/203 [2m0:04:41 â€¢ 0:05:53[0m [2;4m0.34it/s[0m   
        [0.5536, 0.4464],
        [0.5549, 0.4451],
        [0.5564, 0.4436],
        [0.5562, 0.4438],
        [0.5531, 0.4469],
        [0.5524, 0.4476],
        [0.5576, 0.4424],
        [0.5575, 0.4425],
[2K        [0.5560, 0.4440]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 82/203 [2m0:04:41 â€¢ 0:05:53[0m [2;4m0.34it/s[0m  
[2KClass label: SoccerPenaltyâ”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 82/203 [2m0:04:41 â€¢ 0:05:53[0m [2;4m0.34it/s[0m  
[2KAttention weights: tensor([[0.6397, 0.3603]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 82/203 [2m0:04:41 â€¢ 0:05:53[0m [2;4m0.34it/s[0m  
[2KStep 0 - TTA Loss: 0.8348â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 82/203 [2m0:04:41 â€¢ 0:05:53[0m [2;4m0.34it/s[0m  
[2KAttention weights: tensor([[0.6357, 0.3643]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 82/203 [2m0:04:41 â€¢ 0:05:53[0m [2;4m0.34it/s[0m  
[2KAttention weights: tensor([[0.6371, 0.3629]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 82/203 [2m0:04:41 â€¢ 0:05:53[0m [2;4m0.34it/s[0m  
[2KAttention weights: tensor([[0.6407, 0.3593]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 82/203 [2m0:04:41 â€¢ 0:05:53[0m [2;4m0.34it/s[0m  
[2KAttention weights: tensor([[0.6460, 0.3540]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 82/203 [2m0:04:41 â€¢ 0:05:53[0m [2;4m0.34it/s[0m  
[2KAttention weights: tensor([[0.6512, 0.3488]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 82/203 [2m0:04:41 â€¢ 0:05:53[0m [2;4m0.34it/s[0m  
[2KAttention weights: tensor([[0.6556, 0.3444]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 82/203 [2m0:04:41 â€¢ 0:05:53[0m [2;4m0.34it/s[0m  
[2KAttention weights: tensor([[0.6585, 0.3415]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 82/203 [2m0:04:41 â€¢ 0:05:53[0m [2;4m0.34it/s[0m  
[2KAttention weights: tensor([[0.6600, 0.3400]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 82/203 [2m0:04:41 â€¢ 0:05:53[0m [2;4m0.34it/s[0m  
[2KAttention weights: tensor([[0.6607, 0.3393]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 82/203 [2m0:04:41 â€¢ 0:05:53[0m [2;4m0.34it/s[0m  
[2KAttention weights: tensor([[0.5584, 0.4416]], device='cuda:0');237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 82/203 [2m0:04:41 â€¢ 0:05:53[0m [2;4m0.34it/s[0m  
[2KAttention weights: tensor([[0.5778, 0.4222],;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 82/203 [2m0:04:41 â€¢ 0:05:53[0m [2;4m0.34it/s[0m  
        [0.5615, 0.4385],
        [0.5487, 0.4513],
        [0.5897, 0.4103],
        [0.5641, 0.4359],
        [0.5756, 0.4244],
        [0.5419, 0.4581],
        [0.6608, 0.3392],
        [0.5830, 0.4170],
[2K        [0.6050, 0.3950]], device='cuda:0')8;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 82/203 [2m0:04:41 â€¢ 0:05:53[0m [2;4m0.34it/s[0m  
[2KAttention weights: tensor([[0.5580, 0.4420],[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 83/203 [2m0:04:42 â€¢ 0:04:35[0m [2;4m0.44it/s[0m  
        [0.5536, 0.4464],
        [0.5549, 0.4451],
        [0.5563, 0.4437],
        [0.5561, 0.4439],
        [0.5531, 0.4469],
        [0.5524, 0.4476],
        [0.5576, 0.4424],
        [0.5575, 0.4425],
[2K        [0.5560, 0.4440]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 83/203 [2m0:04:42 â€¢ 0:04:35[0m [2;4m0.44it/s[0m  
[2KClass label: HighJumpâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 83/203 [2m0:04:42 â€¢ 0:04:35[0m [2;4m0.44it/s[0m  
[2KAttention weights: tensor([[0.5909, 0.4091]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 83/203 [2m0:04:42 â€¢ 0:04:35[0m [2;4m0.44it/s[0m  
[2KStep 0 - TTA Loss: 0.6392â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 83/203 [2m0:04:42 â€¢ 0:04:35[0m [2;4m0.44it/s[0m  
[2KAttention weights: tensor([[0.5909, 0.4091]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 83/203 [2m0:04:42 â€¢ 0:04:35[0m [2;4m0.44it/s[0m  
[2KAttention weights: tensor([[0.5916, 0.4084]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 83/203 [2m0:04:42 â€¢ 0:04:35[0m [2;4m0.44it/s[0m  
[2KAttention weights: tensor([[0.5956, 0.4044]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 83/203 [2m0:04:42 â€¢ 0:04:35[0m [2;4m0.44it/s[0m  
[2KAttention weights: tensor([[0.6061, 0.3939]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 83/203 [2m0:04:42 â€¢ 0:04:35[0m [2;4m0.44it/s[0m  
[2KAttention weights: tensor([[0.6237, 0.3763]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 83/203 [2m0:04:42 â€¢ 0:04:35[0m [2;4m0.44it/s[0m  
[2KAttention weights: tensor([[0.6494, 0.3506]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 83/203 [2m0:04:42 â€¢ 0:04:35[0m [2;4m0.44it/s[0m  
[2KAttention weights: tensor([[0.6858, 0.3142]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 83/203 [2m0:04:42 â€¢ 0:04:35[0m [2;4m0.44it/s[0m  
[2KAttention weights: tensor([[0.7227, 0.2773]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 83/203 [2m0:04:42 â€¢ 0:04:35[0m [2;4m0.44it/s[0m  
[2KAttention weights: tensor([[0.7583, 0.2417]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 83/203 [2m0:04:42 â€¢ 0:04:35[0m [2;4m0.44it/s[0m  
[2KAttention weights: tensor([[0.5579, 0.4421]], device='cuda:0');237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 83/203 [2m0:04:42 â€¢ 0:04:35[0m [2;4m0.44it/s[0m  
[2KAttention weights: tensor([[0.7468, 0.2532],;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 83/203 [2m0:04:42 â€¢ 0:04:35[0m [2;4m0.44it/s[0m  
        [0.6820, 0.3180],
        [0.7036, 0.2964],
        [0.7439, 0.2561],
        [0.7512, 0.2488],
        [0.7951, 0.2049],
        [0.7347, 0.2653],
        [0.7765, 0.2235],
        [0.7641, 0.2359],
[2K        [0.7832, 0.2168]], device='cuda:0')8;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 83/203 [2m0:04:42 â€¢ 0:04:35[0m [2;4m0.44it/s[0m  
[2KAttention weights: tensor([[0.5580, 0.4420],[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 84/203 [2m0:04:44 â€¢ 0:04:31[0m [2;4m0.44it/s[0m  
        [0.5536, 0.4464],
        [0.5549, 0.4451],
        [0.5563, 0.4437],
        [0.5561, 0.4439],
        [0.5531, 0.4469],
        [0.5524, 0.4476],
        [0.5576, 0.4424],
        [0.5575, 0.4425],
[2K        [0.5560, 0.4440]], device='cuda:0', grad_fn=<SoftmaxBackward0>)mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 84/203 [2m0:04:44 â€¢ 0:04:31[0m [2;4m0.44it/s[0m  
[2KClass label: HighJumpâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 84/203 [2m0:04:44 â€¢ 0:04:31[0m [2;4m0.44it/s[0m  
[2KAttention weights: tensor([[0.5908, 0.4092]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 84/203 [2m0:04:44 â€¢ 0:04:31[0m [2;4m0.44it/s[0m  
[2KStep 0 - TTA Loss: 0.6508â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 84/203 [2m0:04:44 â€¢ 0:04:31[0m [2;4m0.44it/s[0m  
[2KAttention weights: tensor([[0.6465, 0.3535]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 84/203 [2m0:04:44 â€¢ 0:04:31[0m [2;4m0.44it/s[0m  
[2KAttention weights: tensor([[0.7051, 0.2949]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 84/203 [2m0:04:44 â€¢ 0:04:31[0m [2;4m0.44it/s[0m  
[2KAttention weights: tensor([[0.7551, 0.2449]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 84/203 [2m0:04:44 â€¢ 0:04:31[0m [2;4m0.44it/s[0m  
[2KAttention weights: tensor([[0.7924, 0.2076]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 84/203 [2m0:04:44 â€¢ 0:04:31[0m [2;4m0.44it/s[0m  
[2KAttention weights: tensor([[0.8131, 0.1869]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 84/203 [2m0:04:44 â€¢ 0:04:31[0m [2;4m0.44it/s[0m  
[2KAttention weights: tensor([[0.8247, 0.1753]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 84/203 [2m0:04:44 â€¢ 0:04:31[0m [2;4m0.44it/s[0m  
[2KAttention weights: tensor([[0.8308, 0.1692]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 84/203 [2m0:04:44 â€¢ 0:04:31[0m [2;4m0.44it/s[0m  
[2KAttention weights: tensor([[0.8336, 0.1664]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 84/203 [2m0:04:44 â€¢ 0:04:31[0m [2;4m0.44it/s[0m  
[2KAttention weights: tensor([[0.8349, 0.1651]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 84/203 [2m0:04:44 â€¢ 0:04:31[0m [2;4m0.44it/s[0m  
[2KAttention weights: tensor([[0.5593, 0.4407]], device='cuda:0')[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 84/203 [2m0:04:44 â€¢ 0:04:31[0m [2;4m0.44it/s[0m  
[2KAttention weights: tensor([[0.7796, 0.2204],;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 84/203 [2m0:04:44 â€¢ 0:04:31[0m [2;4m0.44it/s[0m  
        [0.7076, 0.2924],
        [0.7367, 0.2633],
        [0.7747, 0.2253],
        [0.7899, 0.2101],
        [0.8353, 0.1647],
        [0.7773, 0.2227],
        [0.8032, 0.1968],
        [0.7972, 0.2028],
[2K        [0.8176, 0.1824]], device='cuda:0')8;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 84/203 [2m0:04:44 â€¢ 0:04:31[0m [2;4m0.44it/s[0m  
[2KAttention weights: tensor([[0.5580, 0.4420],[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 85/203 [2m0:04:47 â€¢ 0:04:30[0m [2;4m0.44it/s[0m  
        [0.5536, 0.4464],
        [0.5549, 0.4451],
        [0.5563, 0.4437],
        [0.5561, 0.4439],
        [0.5531, 0.4469],
        [0.5524, 0.4476],
        [0.5576, 0.4424],
        [0.5575, 0.4425],
[2K        [0.5560, 0.4440]], device='cuda:0', grad_fn=<SoftmaxBackward0>)mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 85/203 [2m0:04:47 â€¢ 0:04:30[0m [2;4m0.44it/s[0m  
[2KClass label: TennisSwingâ”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 85/203 [2m0:04:47 â€¢ 0:04:30[0m [2;4m0.44it/s[0m  
[2KAttention weights: tensor([[0.6437, 0.3563]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 85/203 [2m0:04:47 â€¢ 0:04:30[0m [2;4m0.44it/s[0m  
[2KStep 0 - TTA Loss: 0.4232â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 85/203 [2m0:04:47 â€¢ 0:04:30[0m [2;4m0.44it/s[0m  
[2KAttention weights: tensor([[0.6437, 0.3563]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 85/203 [2m0:04:47 â€¢ 0:04:30[0m [2;4m0.44it/s[0m  
[2KAttention weights: tensor([[0.6444, 0.3556]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 85/203 [2m0:04:47 â€¢ 0:04:30[0m [2;4m0.44it/s[0m  
[2KAttention weights: tensor([[0.6483, 0.3517]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 85/203 [2m0:04:47 â€¢ 0:04:30[0m [2;4m0.44it/s[0m  
[2KAttention weights: tensor([[0.6563, 0.3437]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 85/203 [2m0:04:47 â€¢ 0:04:30[0m [2;4m0.44it/s[0m  
[2KAttention weights: tensor([[0.6726, 0.3274]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 85/203 [2m0:04:47 â€¢ 0:04:30[0m [2;4m0.44it/s[0m  
[2KAttention weights: tensor([[0.6959, 0.3041]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 85/203 [2m0:04:47 â€¢ 0:04:30[0m [2;4m0.44it/s[0m  
[2KAttention weights: tensor([[0.7217, 0.2783]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 85/203 [2m0:04:47 â€¢ 0:04:30[0m [2;4m0.44it/s[0m  
[2KAttention weights: tensor([[0.7413, 0.2587]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 85/203 [2m0:04:47 â€¢ 0:04:30[0m [2;4m0.44it/s[0m  
[2KAttention weights: tensor([[0.7543, 0.2457]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 85/203 [2m0:04:47 â€¢ 0:04:30[0m [2;4m0.44it/s[0m  
[2KAttention weights: tensor([[0.5591, 0.4409]], device='cuda:0')[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 85/203 [2m0:04:47 â€¢ 0:04:30[0m [2;4m0.44it/s[0m  
[2KAttention weights: tensor([[0.6906, 0.3094],;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 85/203 [2m0:04:47 â€¢ 0:04:30[0m [2;4m0.44it/s[0m  
        [0.6404, 0.3596],
        [0.6306, 0.3694],
        [0.7047, 0.2953],
        [0.6623, 0.3377],
        [0.6800, 0.3200],
        [0.6152, 0.3848],
        [0.6958, 0.3042],
        [0.7530, 0.2470],
[2K        [0.7135, 0.2865]], device='cuda:0')8;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 85/203 [2m0:04:47 â€¢ 0:04:30[0m [2;4m0.44it/s[0m  
[2KAttention weights: tensor([[0.5580, 0.4420],[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 86/203 [2m0:04:50 â€¢ 0:04:43[0m [2;4m0.41it/s[0m  
        [0.5536, 0.4464],
        [0.5549, 0.4451],
        [0.5564, 0.4436],
        [0.5561, 0.4439],
        [0.5531, 0.4469],
        [0.5524, 0.4476],
        [0.5576, 0.4424],
        [0.5575, 0.4425],
[2K        [0.5560, 0.4440]], device='cuda:0', grad_fn=<SoftmaxBackward0>)mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 86/203 [2m0:04:50 â€¢ 0:04:43[0m [2;4m0.41it/s[0m  
[2KClass label: HammerThrowâ”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 86/203 [2m0:04:50 â€¢ 0:04:43[0m [2;4m0.41it/s[0m  
[2KAttention weights: tensor([[0.5833, 0.4167]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 86/203 [2m0:04:50 â€¢ 0:04:43[0m [2;4m0.41it/s[0m  
[2KStep 0 - TTA Loss: 0.5641â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 86/203 [2m0:04:50 â€¢ 0:04:43[0m [2;4m0.41it/s[0m  
[2KAttention weights: tensor([[0.6154, 0.3846]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 86/203 [2m0:04:50 â€¢ 0:04:43[0m [2;4m0.41it/s[0m  
[2KAttention weights: tensor([[0.6697, 0.3303]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 86/203 [2m0:04:50 â€¢ 0:04:43[0m [2;4m0.41it/s[0m  
[2KAttention weights: tensor([[0.7283, 0.2717]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 86/203 [2m0:04:50 â€¢ 0:04:43[0m [2;4m0.41it/s[0m  
[2KAttention weights: tensor([[0.7719, 0.2281]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 86/203 [2m0:04:50 â€¢ 0:04:43[0m [2;4m0.41it/s[0m  
[2KAttention weights: tensor([[0.8016, 0.1984]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 86/203 [2m0:04:50 â€¢ 0:04:43[0m [2;4m0.41it/s[0m  
[2KAttention weights: tensor([[0.8284, 0.1716]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 86/203 [2m0:04:50 â€¢ 0:04:43[0m [2;4m0.41it/s[0m  
[2KAttention weights: tensor([[0.8530, 0.1470]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 86/203 [2m0:04:50 â€¢ 0:04:43[0m [2;4m0.41it/s[0m  
[2KAttention weights: tensor([[0.8709, 0.1291]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 86/203 [2m0:04:50 â€¢ 0:04:43[0m [2;4m0.41it/s[0m  
[2KAttention weights: tensor([[0.8806, 0.1194]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 86/203 [2m0:04:50 â€¢ 0:04:43[0m [2;4m0.41it/s[0m  
[2KAttention weights: tensor([[0.5665, 0.4335]], device='cuda:0')[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 86/203 [2m0:04:50 â€¢ 0:04:43[0m [2;4m0.41it/s[0m  
[2KAttention weights: tensor([[0.8422, 0.1578],;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 86/203 [2m0:04:50 â€¢ 0:04:43[0m [2;4m0.41it/s[0m  
        [0.7250, 0.2750],
        [0.7891, 0.2109],
        [0.8294, 0.1706],
        [0.8835, 0.1165],
        [0.8400, 0.1600],
        [0.8001, 0.1999],
        [0.8305, 0.1695],
        [0.8190, 0.1810],
[2K        [0.8736, 0.1264]], device='cuda:0')8;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 86/203 [2m0:04:50 â€¢ 0:04:43[0m [2;4m0.41it/s[0m  
[2KAttention weights: tensor([[0.5581, 0.4419],m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 87/203 [2m0:04:52 â€¢ 0:04:49[0m [2;4m0.40it/s[0m   
        [0.5537, 0.4463],
        [0.5549, 0.4451],
        [0.5564, 0.4436],
        [0.5562, 0.4438],
        [0.5532, 0.4468],
        [0.5524, 0.4476],
        [0.5577, 0.4423],
        [0.5576, 0.4424],
[2K        [0.5561, 0.4439]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 87/203 [2m0:04:52 â€¢ 0:04:49[0m [2;4m0.40it/s[0m  
[2KClass label: HighJumpâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 87/203 [2m0:04:52 â€¢ 0:04:49[0m [2;4m0.40it/s[0m  
[2KAttention weights: tensor([[0.5947, 0.4053]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 87/203 [2m0:04:52 â€¢ 0:04:49[0m [2;4m0.40it/s[0m  
[2KStep 0 - TTA Loss: 0.7359â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 87/203 [2m0:04:52 â€¢ 0:04:49[0m [2;4m0.40it/s[0m  
[2KAttention weights: tensor([[0.5947, 0.4053]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 87/203 [2m0:04:52 â€¢ 0:04:49[0m [2;4m0.40it/s[0m  
[2KAttention weights: tensor([[0.5997, 0.4003]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 87/203 [2m0:04:52 â€¢ 0:04:49[0m [2;4m0.40it/s[0m  
[2KAttention weights: tensor([[0.6192, 0.3808]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 87/203 [2m0:04:52 â€¢ 0:04:49[0m [2;4m0.40it/s[0m  
[2KAttention weights: tensor([[0.6613, 0.3387]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 87/203 [2m0:04:52 â€¢ 0:04:49[0m [2;4m0.40it/s[0m  
[2KAttention weights: tensor([[0.7287, 0.2713]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 87/203 [2m0:04:52 â€¢ 0:04:49[0m [2;4m0.40it/s[0m  
[2KAttention weights: tensor([[0.8115, 0.1885]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 87/203 [2m0:04:52 â€¢ 0:04:49[0m [2;4m0.40it/s[0m  
[2KAttention weights: tensor([[0.8883, 0.1117]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 87/203 [2m0:04:52 â€¢ 0:04:49[0m [2;4m0.40it/s[0m  
[2KAttention weights: tensor([[0.9429, 0.0571]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 87/203 [2m0:04:52 â€¢ 0:04:49[0m [2;4m0.40it/s[0m  
[2KAttention weights: tensor([[0.9718, 0.0282]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 87/203 [2m0:04:52 â€¢ 0:04:49[0m [2;4m0.40it/s[0m  
[2KAttention weights: tensor([[0.5721, 0.4279]], device='cuda:0')5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 87/203 [2m0:04:52 â€¢ 0:04:49[0m [2;4m0.40it/s[0m  
[2KAttention weights: tensor([[0.9716, 0.0284],8;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 87/203 [2m0:04:52 â€¢ 0:04:49[0m [2;4m0.40it/s[0m  
        [0.8990, 0.1010],
        [0.9562, 0.0438],
        [0.9624, 0.0376],
        [0.9867, 0.0133],
        [0.9868, 0.0132],
        [0.9747, 0.0253],
        [0.9666, 0.0334],
        [0.9635, 0.0365],
[2K        [0.9835, 0.0165]], device='cuda:0')38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 87/203 [2m0:04:52 â€¢ 0:04:49[0m [2;4m0.40it/s[0m  
[2KAttention weights: tensor([[0.5581, 0.4419],m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 88/203 [2m0:04:58 â€¢ 0:05:36[0m [2;4m0.34it/s[0m  
        [0.5537, 0.4463],
        [0.5550, 0.4450],
        [0.5565, 0.4435],
        [0.5563, 0.4437],
        [0.5532, 0.4468],
        [0.5525, 0.4475],
        [0.5577, 0.4423],
        [0.5577, 0.4423],
[2K        [0.5562, 0.4438]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 88/203 [2m0:04:58 â€¢ 0:05:36[0m [2;4m0.34it/s[0m  
[2KClass label: CleanAndJerkâ”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 88/203 [2m0:04:58 â€¢ 0:05:36[0m [2;4m0.34it/s[0m  
[2KAttention weights: tensor([[0.5655, 0.4345]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 88/203 [2m0:04:58 â€¢ 0:05:36[0m [2;4m0.34it/s[0m  
[2KStep 0 - TTA Loss: 0.5898â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 88/203 [2m0:04:58 â€¢ 0:05:36[0m [2;4m0.34it/s[0m  
[2KAttention weights: tensor([[0.7034, 0.2966]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 88/203 [2m0:04:58 â€¢ 0:05:36[0m [2;4m0.34it/s[0m  
[2KAttention weights: tensor([[0.8195, 0.1805]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 88/203 [2m0:04:58 â€¢ 0:05:36[0m [2;4m0.34it/s[0m  
[2KAttention weights: tensor([[0.8977, 0.1023]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 88/203 [2m0:04:58 â€¢ 0:05:36[0m [2;4m0.34it/s[0m  
[2KAttention weights: tensor([[0.9387, 0.0613]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 88/203 [2m0:04:58 â€¢ 0:05:36[0m [2;4m0.34it/s[0m  
[2KAttention weights: tensor([[0.9572, 0.0428]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 88/203 [2m0:04:58 â€¢ 0:05:36[0m [2;4m0.34it/s[0m  
[2KAttention weights: tensor([[0.9657, 0.0343]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 88/203 [2m0:04:58 â€¢ 0:05:36[0m [2;4m0.34it/s[0m  
[2KAttention weights: tensor([[0.9703, 0.0297]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 88/203 [2m0:04:58 â€¢ 0:05:36[0m [2;4m0.34it/s[0m  
[2KAttention weights: tensor([[0.9740, 0.0260]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 88/203 [2m0:04:58 â€¢ 0:05:36[0m [2;4m0.34it/s[0m  
[2KAttention weights: tensor([[0.9756, 0.0244]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 88/203 [2m0:04:58 â€¢ 0:05:36[0m [2;4m0.34it/s[0m  
[2KAttention weights: tensor([[0.5736, 0.4264]], device='cuda:0')5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 88/203 [2m0:04:58 â€¢ 0:05:36[0m [2;4m0.34it/s[0m  
[2KAttention weights: tensor([[0.9608, 0.0392],8;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 88/203 [2m0:04:58 â€¢ 0:05:36[0m [2;4m0.34it/s[0m  
        [0.8936, 0.1064],
        [0.9762, 0.0238],
        [0.9561, 0.0439],
        [0.9816, 0.0184],
        [0.9828, 0.0172],
        [0.9687, 0.0313],
        [0.9546, 0.0454],
        [0.9585, 0.0415],
[2K        [0.9790, 0.0210]], device='cuda:0')38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 88/203 [2m0:04:58 â€¢ 0:05:36[0m [2;4m0.34it/s[0m  
[2KAttention weights: tensor([[0.5582, 0.4418],m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 89/203 [2m0:05:05 â€¢ 0:05:24[0m [2;4m0.35it/s[0m  
        [0.5538, 0.4462],
        [0.5552, 0.4448],
        [0.5566, 0.4434],
        [0.5565, 0.4435],
        [0.5534, 0.4466],
        [0.5527, 0.4473],
        [0.5578, 0.4422],
        [0.5578, 0.4422],
[2K        [0.5563, 0.4437]], device='cuda:0', grad_fn=<SoftmaxBackward0>)7mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 89/203 [2m0:05:05 â€¢ 0:05:24[0m [2;4m0.35it/s[0m  
[2KClass label: HighJumpâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 89/203 [2m0:05:05 â€¢ 0:05:24[0m [2;4m0.35it/s[0m  
[2KAttention weights: tensor([[0.5920, 0.4080]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 89/203 [2m0:05:05 â€¢ 0:05:24[0m [2;4m0.35it/s[0m  
[2KStep 0 - TTA Loss: 0.7149â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 89/203 [2m0:05:05 â€¢ 0:05:24[0m [2;4m0.35it/s[0m  
[2KAttention weights: tensor([[0.5920, 0.4080]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 89/203 [2m0:05:05 â€¢ 0:05:24[0m [2;4m0.35it/s[0m  
[2KAttention weights: tensor([[0.5954, 0.4046]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 89/203 [2m0:05:05 â€¢ 0:05:24[0m [2;4m0.35it/s[0m  
[2KAttention weights: tensor([[0.6086, 0.3914]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 89/203 [2m0:05:05 â€¢ 0:05:24[0m [2;4m0.35it/s[0m  
[2KAttention weights: tensor([[0.6354, 0.3646]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 89/203 [2m0:05:05 â€¢ 0:05:24[0m [2;4m0.35it/s[0m  
[2KAttention weights: tensor([[0.6755, 0.3245]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 89/203 [2m0:05:05 â€¢ 0:05:24[0m [2;4m0.35it/s[0m  
[2KAttention weights: tensor([[0.7286, 0.2714]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 89/203 [2m0:05:05 â€¢ 0:05:24[0m [2;4m0.35it/s[0m  
[2KAttention weights: tensor([[0.7864, 0.2136]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 89/203 [2m0:05:05 â€¢ 0:05:24[0m [2;4m0.35it/s[0m  
[2KAttention weights: tensor([[0.8451, 0.1549]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 89/203 [2m0:05:05 â€¢ 0:05:24[0m [2;4m0.35it/s[0m  
[2KAttention weights: tensor([[0.8923, 0.1077]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 89/203 [2m0:05:05 â€¢ 0:05:24[0m [2;4m0.35it/s[0m  
[2KAttention weights: tensor([[0.5652, 0.4348]], device='cuda:0')[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 89/203 [2m0:05:05 â€¢ 0:05:24[0m [2;4m0.35it/s[0m  
[2KAttention weights: tensor([[0.8732, 0.1268],8;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 89/203 [2m0:05:05 â€¢ 0:05:24[0m [2;4m0.35it/s[0m  
        [0.8016, 0.1984],
        [0.9313, 0.0687],
        [0.8766, 0.1234],
        [0.9099, 0.0901],
        [0.9238, 0.0762],
        [0.8855, 0.1145],
        [0.8717, 0.1283],
        [0.8877, 0.1123],
[2K        [0.9163, 0.0837]], device='cuda:0')38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 89/203 [2m0:05:05 â€¢ 0:05:24[0m [2;4m0.35it/s[0m  
[2KAttention weights: tensor([[0.5583, 0.4417],m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 90/203 [2m0:05:14 â€¢ 0:09:15[0m [2;4m0.20it/s[0m  
        [0.5538, 0.4462],
        [0.5553, 0.4447],
        [0.5566, 0.4434],
        [0.5565, 0.4435],
        [0.5534, 0.4466],
        [0.5527, 0.4473],
        [0.5579, 0.4421],
        [0.5578, 0.4422],
[2K        [0.5563, 0.4437]], device='cuda:0', grad_fn=<SoftmaxBackward0>)7mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 90/203 [2m0:05:14 â€¢ 0:09:15[0m [2;4m0.20it/s[0m  
[2KClass label: HammerThrowâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 90/203 [2m0:05:14 â€¢ 0:09:15[0m [2;4m0.20it/s[0m  
[2KAttention weights: tensor([[0.5803, 0.4197]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 90/203 [2m0:05:14 â€¢ 0:09:15[0m [2;4m0.20it/s[0m  
[2KStep 0 - TTA Loss: 0.7590â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 90/203 [2m0:05:14 â€¢ 0:09:15[0m [2;4m0.20it/s[0m  
[2KAttention weights: tensor([[0.6576, 0.3424]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 90/203 [2m0:05:14 â€¢ 0:09:15[0m [2;4m0.20it/s[0m  
[2KAttention weights: tensor([[0.7246, 0.2754]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 90/203 [2m0:05:14 â€¢ 0:09:15[0m [2;4m0.20it/s[0m  
[2KAttention weights: tensor([[0.7775, 0.2225]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 90/203 [2m0:05:14 â€¢ 0:09:15[0m [2;4m0.20it/s[0m  
[2KAttention weights: tensor([[0.8156, 0.1844]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 90/203 [2m0:05:14 â€¢ 0:09:15[0m [2;4m0.20it/s[0m  
[2KAttention weights: tensor([[0.8384, 0.1616]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 90/203 [2m0:05:14 â€¢ 0:09:15[0m [2;4m0.20it/s[0m  
[2KAttention weights: tensor([[0.8489, 0.1511]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 90/203 [2m0:05:14 â€¢ 0:09:15[0m [2;4m0.20it/s[0m  
[2KAttention weights: tensor([[0.8523, 0.1477]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 90/203 [2m0:05:14 â€¢ 0:09:15[0m [2;4m0.20it/s[0m  
[2KAttention weights: tensor([[0.8511, 0.1489]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 90/203 [2m0:05:14 â€¢ 0:09:15[0m [2;4m0.20it/s[0m  
[2KAttention weights: tensor([[0.8491, 0.1509]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 90/203 [2m0:05:14 â€¢ 0:09:15[0m [2;4m0.20it/s[0m  
[2KAttention weights: tensor([[0.5650, 0.4350]], device='cuda:0')[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 90/203 [2m0:05:14 â€¢ 0:09:15[0m [2;4m0.20it/s[0m  
[2KAttention weights: tensor([[0.8165, 0.1835],8;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 90/203 [2m0:05:14 â€¢ 0:09:15[0m [2;4m0.20it/s[0m  
        [0.7438, 0.2562],
        [0.8657, 0.1343],
        [0.8222, 0.1778],
        [0.8485, 0.1515],
        [0.8656, 0.1344],
        [0.8159, 0.1841],
        [0.8197, 0.1803],
        [0.8359, 0.1641],
[2K        [0.8630, 0.1370]], device='cuda:0')38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 90/203 [2m0:05:14 â€¢ 0:09:15[0m [2;4m0.20it/s[0m  
[2KAttention weights: tensor([[0.5583, 0.4417],m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 91/203 [2m0:05:16 â€¢ 0:09:02[0m [2;4m0.21it/s[0m  
        [0.5539, 0.4461],
        [0.5553, 0.4447],
        [0.5566, 0.4434],
        [0.5565, 0.4435],
        [0.5534, 0.4466],
        [0.5527, 0.4473],
        [0.5579, 0.4421],
        [0.5578, 0.4422],
[2K        [0.5564, 0.4436]], device='cuda:0', grad_fn=<SoftmaxBackward0>)7mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 91/203 [2m0:05:16 â€¢ 0:09:02[0m [2;4m0.21it/s[0m  
[2KClass label: SoccerPenaltyâ”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 91/203 [2m0:05:16 â€¢ 0:09:02[0m [2;4m0.21it/s[0m  
[2KAttention weights: tensor([[0.6381, 0.3619]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 91/203 [2m0:05:16 â€¢ 0:09:02[0m [2;4m0.21it/s[0m  
[2KStep 0 - TTA Loss: 1.0842â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 91/203 [2m0:05:16 â€¢ 0:09:02[0m [2;4m0.21it/s[0m  
[2KAttention weights: tensor([[0.6381, 0.3619]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 91/203 [2m0:05:16 â€¢ 0:09:02[0m [2;4m0.21it/s[0m  
[2KAttention weights: tensor([[0.6375, 0.3625]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 91/203 [2m0:05:16 â€¢ 0:09:02[0m [2;4m0.21it/s[0m  
[2KAttention weights: tensor([[0.6353, 0.3647]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 91/203 [2m0:05:16 â€¢ 0:09:02[0m [2;4m0.21it/s[0m  
[2KAttention weights: tensor([[0.6314, 0.3686]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 91/203 [2m0:05:16 â€¢ 0:09:02[0m [2;4m0.21it/s[0m  
[2KAttention weights: tensor([[0.6254, 0.3746]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 91/203 [2m0:05:16 â€¢ 0:09:02[0m [2;4m0.21it/s[0m  
[2KAttention weights: tensor([[0.6176, 0.3824]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 91/203 [2m0:05:16 â€¢ 0:09:02[0m [2;4m0.21it/s[0m  
[2KAttention weights: tensor([[0.6080, 0.3920]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 91/203 [2m0:05:16 â€¢ 0:09:02[0m [2;4m0.21it/s[0m  
[2KAttention weights: tensor([[0.5950, 0.4050]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 91/203 [2m0:05:16 â€¢ 0:09:02[0m [2;4m0.21it/s[0m  
[2KAttention weights: tensor([[0.5781, 0.4219]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 91/203 [2m0:05:16 â€¢ 0:09:02[0m [2;4m0.21it/s[0m  
[2KAttention weights: tensor([[0.5549, 0.4451]], device='cuda:0')[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 91/203 [2m0:05:16 â€¢ 0:09:02[0m [2;4m0.21it/s[0m  
[2KAttention weights: tensor([[0.5251, 0.4749],8;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 91/203 [2m0:05:16 â€¢ 0:09:02[0m [2;4m0.21it/s[0m  
        [0.5383, 0.4617],
        [0.5220, 0.4780],
        [0.5541, 0.4459],
        [0.4574, 0.5426],
        [0.5167, 0.4833],
        [0.4713, 0.5287],
        [0.5530, 0.4470],
        [0.5844, 0.4156],
[2K        [0.5395, 0.4605]], device='cuda:0')38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 91/203 [2m0:05:16 â€¢ 0:09:02[0m [2;4m0.21it/s[0m  
[2KAttention weights: tensor([[0.5583, 0.4417],0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 92/203 [2m0:05:16 â€¢ 0:07:51[0m [2;4m0.24it/s[0m   
        [0.5538, 0.4462],
        [0.5553, 0.4447],
        [0.5566, 0.4434],
        [0.5565, 0.4435],
        [0.5534, 0.4466],
        [0.5527, 0.4473],
        [0.5578, 0.4422],
        [0.5578, 0.4422],
[2K        [0.5563, 0.4437]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 92/203 [2m0:05:16 â€¢ 0:07:51[0m [2;4m0.24it/s[0m  
[2KClass label: BaseballPitchâ”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 92/203 [2m0:05:16 â€¢ 0:07:51[0m [2;4m0.24it/s[0m  
[2KAttention weights: tensor([[0.6168, 0.3832]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 92/203 [2m0:05:16 â€¢ 0:07:51[0m [2;4m0.24it/s[0m  
[2KStep 0 - TTA Loss: 0.9812â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 92/203 [2m0:05:16 â€¢ 0:07:51[0m [2;4m0.24it/s[0m  
[2KAttention weights: tensor([[0.6077, 0.3923]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 92/203 [2m0:05:16 â€¢ 0:07:51[0m [2;4m0.24it/s[0m  
[2KAttention weights: tensor([[0.6053, 0.3947]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 92/203 [2m0:05:16 â€¢ 0:07:51[0m [2;4m0.24it/s[0m  
[2KAttention weights: tensor([[0.6087, 0.3913]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 92/203 [2m0:05:16 â€¢ 0:07:51[0m [2;4m0.24it/s[0m  
[2KAttention weights: tensor([[0.6171, 0.3829]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 92/203 [2m0:05:16 â€¢ 0:07:51[0m [2;4m0.24it/s[0m  
[2KAttention weights: tensor([[0.6258, 0.3742]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 92/203 [2m0:05:16 â€¢ 0:07:51[0m [2;4m0.24it/s[0m  
[2KAttention weights: tensor([[0.6356, 0.3644]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 92/203 [2m0:05:16 â€¢ 0:07:51[0m [2;4m0.24it/s[0m  
[2KAttention weights: tensor([[0.6425, 0.3575]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 92/203 [2m0:05:16 â€¢ 0:07:51[0m [2;4m0.24it/s[0m  
[2KAttention weights: tensor([[0.6466, 0.3534]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 92/203 [2m0:05:16 â€¢ 0:07:51[0m [2;4m0.24it/s[0m  
[2KAttention weights: tensor([[0.6482, 0.3518]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 92/203 [2m0:05:16 â€¢ 0:07:51[0m [2;4m0.24it/s[0m  
[2KAttention weights: tensor([[0.5595, 0.4405]], device='cuda:0');5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 92/203 [2m0:05:16 â€¢ 0:07:51[0m [2;4m0.24it/s[0m  
[2KAttention weights: tensor([[0.6488, 0.3512],38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 92/203 [2m0:05:16 â€¢ 0:07:51[0m [2;4m0.24it/s[0m  
        [0.5759, 0.4241],
        [0.5667, 0.4333],
        [0.6373, 0.3627],
        [0.5544, 0.4456],
        [0.5838, 0.4162],
        [0.5316, 0.4684],
        [0.5977, 0.4023],
        [0.6517, 0.3483],
[2K        [0.6304, 0.3696]], device='cuda:0')[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 92/203 [2m0:05:16 â€¢ 0:07:51[0m [2;4m0.24it/s[0m  
[2KAttention weights: tensor([[0.5582, 0.4418],0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 93/203 [2m0:05:17 â€¢ 0:07:12[0m [2;4m0.25it/s[0m  
        [0.5538, 0.4462],
        [0.5553, 0.4447],
        [0.5566, 0.4434],
        [0.5565, 0.4435],
        [0.5534, 0.4466],
        [0.5527, 0.4473],
        [0.5578, 0.4422],
        [0.5578, 0.4422],
[2K        [0.5563, 0.4437]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 93/203 [2m0:05:17 â€¢ 0:07:12[0m [2;4m0.25it/s[0m  
[2KClass label: SoccerPenaltyâ”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 93/203 [2m0:05:17 â€¢ 0:07:12[0m [2;4m0.25it/s[0m  
[2KAttention weights: tensor([[0.6420, 0.3580]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 93/203 [2m0:05:17 â€¢ 0:07:12[0m [2;4m0.25it/s[0m  
[2KStep 0 - TTA Loss: 0.7639â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 93/203 [2m0:05:17 â€¢ 0:07:12[0m [2;4m0.25it/s[0m  
[2KAttention weights: tensor([[0.6420, 0.3580]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 93/203 [2m0:05:17 â€¢ 0:07:12[0m [2;4m0.25it/s[0m  
[2KAttention weights: tensor([[0.6430, 0.3570]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 93/203 [2m0:05:17 â€¢ 0:07:12[0m [2;4m0.25it/s[0m  
[2KAttention weights: tensor([[0.6480, 0.3520]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 93/203 [2m0:05:17 â€¢ 0:07:12[0m [2;4m0.25it/s[0m  
[2KAttention weights: tensor([[0.6607, 0.3393]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 93/203 [2m0:05:17 â€¢ 0:07:12[0m [2;4m0.25it/s[0m  
[2KAttention weights: tensor([[0.6834, 0.3166]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 93/203 [2m0:05:17 â€¢ 0:07:12[0m [2;4m0.25it/s[0m  
[2KAttention weights: tensor([[0.7186, 0.2814]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 93/203 [2m0:05:17 â€¢ 0:07:12[0m [2;4m0.25it/s[0m  
[2KAttention weights: tensor([[0.7607, 0.2393]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 93/203 [2m0:05:17 â€¢ 0:07:12[0m [2;4m0.25it/s[0m  
[2KAttention weights: tensor([[0.7997, 0.2003]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 93/203 [2m0:05:17 â€¢ 0:07:12[0m [2;4m0.25it/s[0m  
[2KAttention weights: tensor([[0.8306, 0.1694]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 93/203 [2m0:05:17 â€¢ 0:07:12[0m [2;4m0.25it/s[0m  
[2KAttention weights: tensor([[0.5626, 0.4374]], device='cuda:0');5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 93/203 [2m0:05:17 â€¢ 0:07:12[0m [2;4m0.25it/s[0m  
[2KAttention weights: tensor([[0.7551, 0.2449],38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 93/203 [2m0:05:17 â€¢ 0:07:12[0m [2;4m0.25it/s[0m  
        [0.6782, 0.3218],
        [0.6467, 0.3533],
        [0.7330, 0.2670],
        [0.7124, 0.2876],
        [0.7222, 0.2778],
        [0.6749, 0.3251],
        [0.8370, 0.1630],
        [0.7443, 0.2557],
[2K        [0.7466, 0.2534]], device='cuda:0')[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 93/203 [2m0:05:17 â€¢ 0:07:12[0m [2;4m0.25it/s[0m  
[2KAttention weights: tensor([[0.5583, 0.4417],0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 94/203 [2m0:05:19 â€¢ 0:06:36[0m [2;4m0.28it/s[0m  
        [0.5539, 0.4461],
        [0.5553, 0.4447],
        [0.5566, 0.4434],
        [0.5565, 0.4435],
        [0.5534, 0.4466],
        [0.5527, 0.4473],
        [0.5578, 0.4422],
        [0.5578, 0.4422],
[2K        [0.5563, 0.4437]], device='cuda:0', grad_fn=<SoftmaxBackward0>)37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 94/203 [2m0:05:19 â€¢ 0:06:36[0m [2;4m0.28it/s[0m  
[2KClass label: SoccerPenaltyâ”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 94/203 [2m0:05:19 â€¢ 0:06:36[0m [2;4m0.28it/s[0m  
[2KAttention weights: tensor([[0.6345, 0.3655]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 94/203 [2m0:05:19 â€¢ 0:06:36[0m [2;4m0.28it/s[0m  
[2KStep 0 - TTA Loss: 0.6536â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 94/203 [2m0:05:19 â€¢ 0:06:36[0m [2;4m0.28it/s[0m  
[2KAttention weights: tensor([[0.6635, 0.3365]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 94/203 [2m0:05:19 â€¢ 0:06:36[0m [2;4m0.28it/s[0m  
[2KAttention weights: tensor([[0.6932, 0.3068]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 94/203 [2m0:05:19 â€¢ 0:06:36[0m [2;4m0.28it/s[0m  
[2KAttention weights: tensor([[0.7129, 0.2871]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 94/203 [2m0:05:19 â€¢ 0:06:36[0m [2;4m0.28it/s[0m  
[2KAttention weights: tensor([[0.7130, 0.2870]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 94/203 [2m0:05:19 â€¢ 0:06:36[0m [2;4m0.28it/s[0m  
[2KAttention weights: tensor([[0.6952, 0.3048]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 94/203 [2m0:05:19 â€¢ 0:06:36[0m [2;4m0.28it/s[0m  
[2KAttention weights: tensor([[0.6729, 0.3271]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 94/203 [2m0:05:19 â€¢ 0:06:36[0m [2;4m0.28it/s[0m  
[2KAttention weights: tensor([[0.6606, 0.3394]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 94/203 [2m0:05:19 â€¢ 0:06:36[0m [2;4m0.28it/s[0m  
[2KAttention weights: tensor([[0.6611, 0.3389]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 94/203 [2m0:05:19 â€¢ 0:06:36[0m [2;4m0.28it/s[0m  
[2KAttention weights: tensor([[0.6661, 0.3339]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 94/203 [2m0:05:19 â€¢ 0:06:36[0m [2;4m0.28it/s[0m  
[2KAttention weights: tensor([[0.5571, 0.4429]], device='cuda:0')m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 94/203 [2m0:05:19 â€¢ 0:06:36[0m [2;4m0.28it/s[0m  
[2KAttention weights: tensor([[0.6577, 0.3423],38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 94/203 [2m0:05:19 â€¢ 0:06:36[0m [2;4m0.28it/s[0m  
        [0.5976, 0.4024],
        [0.5846, 0.4154],
        [0.6567, 0.3433],
        [0.6111, 0.3889],
        [0.6185, 0.3815],
        [0.5705, 0.4295],
        [0.6684, 0.3316],
        [0.6694, 0.3306],
[2K        [0.6620, 0.3380]], device='cuda:0')[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 94/203 [2m0:05:19 â€¢ 0:06:36[0m [2;4m0.28it/s[0m  
[2KAttention weights: tensor([[0.5583, 0.4417],0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 95/203 [2m0:05:21 â€¢ 0:06:20[0m [2;4m0.28it/s[0m  
        [0.5539, 0.4461],
        [0.5553, 0.4447],
        [0.5566, 0.4434],
        [0.5565, 0.4435],
        [0.5534, 0.4466],
        [0.5527, 0.4473],
        [0.5579, 0.4421],
        [0.5578, 0.4422],
[2K        [0.5563, 0.4437]], device='cuda:0', grad_fn=<SoftmaxBackward0>)37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 95/203 [2m0:05:21 â€¢ 0:06:20[0m [2;4m0.28it/s[0m  
[2KClass label: HammerThrowâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 95/203 [2m0:05:21 â€¢ 0:06:20[0m [2;4m0.28it/s[0m  
[2KAttention weights: tensor([[0.5789, 0.4211]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 95/203 [2m0:05:21 â€¢ 0:06:20[0m [2;4m0.28it/s[0m  
[2KStep 0 - TTA Loss: 0.6792â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 95/203 [2m0:05:21 â€¢ 0:06:20[0m [2;4m0.28it/s[0m  
[2KAttention weights: tensor([[0.5789, 0.4211]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 95/203 [2m0:05:21 â€¢ 0:06:20[0m [2;4m0.28it/s[0m  
[2KAttention weights: tensor([[0.5809, 0.4191]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 95/203 [2m0:05:21 â€¢ 0:06:20[0m [2;4m0.28it/s[0m  
[2KAttention weights: tensor([[0.5901, 0.4099]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 95/203 [2m0:05:21 â€¢ 0:06:20[0m [2;4m0.28it/s[0m  
[2KAttention weights: tensor([[0.6126, 0.3874]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 95/203 [2m0:05:21 â€¢ 0:06:20[0m [2;4m0.28it/s[0m  
[2KAttention weights: tensor([[0.6531, 0.3469]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 95/203 [2m0:05:21 â€¢ 0:06:20[0m [2;4m0.28it/s[0m  
[2KAttention weights: tensor([[0.7148, 0.2852]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 95/203 [2m0:05:21 â€¢ 0:06:20[0m [2;4m0.28it/s[0m  
[2KAttention weights: tensor([[0.7912, 0.2088]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 95/203 [2m0:05:21 â€¢ 0:06:20[0m [2;4m0.28it/s[0m  
[2KAttention weights: tensor([[0.8684, 0.1316]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 95/203 [2m0:05:21 â€¢ 0:06:20[0m [2;4m0.28it/s[0m  
[2KAttention weights: tensor([[0.9248, 0.0752]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 95/203 [2m0:05:21 â€¢ 0:06:20[0m [2;4m0.28it/s[0m  
[2KAttention weights: tensor([[0.5716, 0.4284]], device='cuda:0')m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 95/203 [2m0:05:21 â€¢ 0:06:20[0m [2;4m0.28it/s[0m  
[2KAttention weights: tensor([[0.9317, 0.0683],38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 95/203 [2m0:05:21 â€¢ 0:06:20[0m [2;4m0.28it/s[0m  
        [0.8297, 0.1703],
        [0.8821, 0.1179],
        [0.9156, 0.0844],
        [0.9595, 0.0405],
        [0.9315, 0.0685],
        [0.9072, 0.0928],
        [0.9459, 0.0541],
        [0.9084, 0.0916],
[2K        [0.9482, 0.0518]], device='cuda:0')[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 95/203 [2m0:05:21 â€¢ 0:06:20[0m [2;4m0.28it/s[0m  
[2KAttention weights: tensor([[0.5584, 0.4416],0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 96/203 [2m0:05:24 â€¢ 0:05:45[0m [2;4m0.31it/s[0m  
        [0.5539, 0.4461],
        [0.5554, 0.4446],
        [0.5567, 0.4433],
        [0.5566, 0.4434],
        [0.5535, 0.4465],
        [0.5528, 0.4472],
        [0.5579, 0.4421],
        [0.5579, 0.4421],
[2K        [0.5564, 0.4436]], device='cuda:0', grad_fn=<SoftmaxBackward0>)37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 96/203 [2m0:05:24 â€¢ 0:05:45[0m [2;4m0.31it/s[0m  
[2KClass label: PoleVaultâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 96/203 [2m0:05:24 â€¢ 0:05:45[0m [2;4m0.31it/s[0m  
[2KAttention weights: tensor([[0.5508, 0.4492]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 96/203 [2m0:05:24 â€¢ 0:05:45[0m [2;4m0.31it/s[0m  
[2KStep 0 - TTA Loss: 0.6445â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 96/203 [2m0:05:24 â€¢ 0:05:45[0m [2;4m0.31it/s[0m  
[2KAttention weights: tensor([[0.6705, 0.3295]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 96/203 [2m0:05:24 â€¢ 0:05:45[0m [2;4m0.31it/s[0m  
[2KAttention weights: tensor([[0.7741, 0.2259]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 96/203 [2m0:05:24 â€¢ 0:05:45[0m [2;4m0.31it/s[0m  
[2KAttention weights: tensor([[0.8522, 0.1478]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 96/203 [2m0:05:24 â€¢ 0:05:45[0m [2;4m0.31it/s[0m  
[2KAttention weights: tensor([[0.8980, 0.1020]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 96/203 [2m0:05:24 â€¢ 0:05:45[0m [2;4m0.31it/s[0m  
[2KAttention weights: tensor([[0.9219, 0.0781]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 96/203 [2m0:05:24 â€¢ 0:05:45[0m [2;4m0.31it/s[0m  
[2KAttention weights: tensor([[0.9307, 0.0693]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 96/203 [2m0:05:24 â€¢ 0:05:45[0m [2;4m0.31it/s[0m  
[2KAttention weights: tensor([[0.9317, 0.0683]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 96/203 [2m0:05:24 â€¢ 0:05:45[0m [2;4m0.31it/s[0m  
[2KAttention weights: tensor([[0.9302, 0.0698]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 96/203 [2m0:05:24 â€¢ 0:05:45[0m [2;4m0.31it/s[0m  
[2KAttention weights: tensor([[0.9284, 0.0716]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 96/203 [2m0:05:24 â€¢ 0:05:45[0m [2;4m0.31it/s[0m  
[2KAttention weights: tensor([[0.5666, 0.4334]], device='cuda:0')m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 96/203 [2m0:05:24 â€¢ 0:05:45[0m [2;4m0.31it/s[0m  
[2KAttention weights: tensor([[0.9346, 0.0654],38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 96/203 [2m0:05:24 â€¢ 0:05:45[0m [2;4m0.31it/s[0m  
        [0.8368, 0.1632],
        [0.8937, 0.1063],
        [0.9215, 0.0785],
        [0.9622, 0.0378],
        [0.9402, 0.0598],
        [0.9279, 0.0721],
        [0.9412, 0.0588],
        [0.9101, 0.0899],
[2K        [0.9527, 0.0473]], device='cuda:0')[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 96/203 [2m0:05:24 â€¢ 0:05:45[0m [2;4m0.31it/s[0m  
[2KAttention weights: tensor([[0.5584, 0.4416],[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 97/203 [2m0:05:26 â€¢ 0:05:24[0m [2;4m0.33it/s[0m   
        [0.5540, 0.4460],
        [0.5555, 0.4445],
        [0.5567, 0.4433],
        [0.5567, 0.4433],
        [0.5535, 0.4465],
        [0.5528, 0.4472],
        [0.5580, 0.4420],
        [0.5579, 0.4421],
[2K        [0.5565, 0.4435]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 97/203 [2m0:05:26 â€¢ 0:05:24[0m [2;4m0.33it/s[0m  
[2KClass label: TennisSwingâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 97/203 [2m0:05:26 â€¢ 0:05:24[0m [2;4m0.33it/s[0m  
[2KAttention weights: tensor([[0.6461, 0.3539]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 97/203 [2m0:05:26 â€¢ 0:05:24[0m [2;4m0.33it/s[0m  
[2KStep 0 - TTA Loss: 0.5297â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 97/203 [2m0:05:26 â€¢ 0:05:24[0m [2;4m0.33it/s[0m  
[2KAttention weights: tensor([[0.6461, 0.3539]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 97/203 [2m0:05:26 â€¢ 0:05:24[0m [2;4m0.33it/s[0m  
[2KAttention weights: tensor([[0.6457, 0.3543]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 97/203 [2m0:05:26 â€¢ 0:05:24[0m [2;4m0.33it/s[0m  
[2KAttention weights: tensor([[0.6445, 0.3555]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 97/203 [2m0:05:26 â€¢ 0:05:24[0m [2;4m0.33it/s[0m  
[2KAttention weights: tensor([[0.6418, 0.3582]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 97/203 [2m0:05:26 â€¢ 0:05:24[0m [2;4m0.33it/s[0m  
[2KAttention weights: tensor([[0.6375, 0.3625]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 97/203 [2m0:05:26 â€¢ 0:05:24[0m [2;4m0.33it/s[0m  
[2KAttention weights: tensor([[0.6322, 0.3678]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 97/203 [2m0:05:26 â€¢ 0:05:24[0m [2;4m0.33it/s[0m  
[2KAttention weights: tensor([[0.6234, 0.3766]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 97/203 [2m0:05:26 â€¢ 0:05:24[0m [2;4m0.33it/s[0m  
[2KAttention weights: tensor([[0.6159, 0.3841]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 97/203 [2m0:05:26 â€¢ 0:05:24[0m [2;4m0.33it/s[0m  
[2KAttention weights: tensor([[0.6170, 0.3830]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 97/203 [2m0:05:26 â€¢ 0:05:24[0m [2;4m0.33it/s[0m  
[2KAttention weights: tensor([[0.5565, 0.4435]], device='cuda:0')8;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 97/203 [2m0:05:26 â€¢ 0:05:24[0m [2;4m0.33it/s[0m  
[2KAttention weights: tensor([[0.5643, 0.4357],[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 97/203 [2m0:05:26 â€¢ 0:05:24[0m [2;4m0.33it/s[0m  
        [0.5339, 0.4661],
        [0.4976, 0.5024],
        [0.5822, 0.4178],
        [0.5228, 0.4772],
        [0.4738, 0.5262],
        [0.3534, 0.6466],
        [0.5771, 0.4229],
        [0.6355, 0.3645],
[2K        [0.5666, 0.4334]], device='cuda:0')[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 97/203 [2m0:05:26 â€¢ 0:05:24[0m [2;4m0.33it/s[0m  
[2KAttention weights: tensor([[0.5584, 0.4416],[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 98/203 [2m0:05:28 â€¢ 0:05:08[0m [2;4m0.34it/s[0m  
        [0.5539, 0.4461],
        [0.5554, 0.4446],
        [0.5567, 0.4433],
        [0.5567, 0.4433],
        [0.5535, 0.4465],
        [0.5527, 0.4473],
        [0.5580, 0.4420],
        [0.5579, 0.4421],
[2K        [0.5565, 0.4435]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 98/203 [2m0:05:28 â€¢ 0:05:08[0m [2;4m0.34it/s[0m  
[2KClass label: HighJumpâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 98/203 [2m0:05:28 â€¢ 0:05:08[0m [2;4m0.34it/s[0m  
[2KAttention weights: tensor([[0.5896, 0.4104]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 98/203 [2m0:05:28 â€¢ 0:05:08[0m [2;4m0.34it/s[0m  
[2KStep 0 - TTA Loss: 1.0703â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 98/203 [2m0:05:28 â€¢ 0:05:08[0m [2;4m0.34it/s[0m  
[2KAttention weights: tensor([[0.5876, 0.4124]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 98/203 [2m0:05:28 â€¢ 0:05:08[0m [2;4m0.34it/s[0m  
[2KAttention weights: tensor([[0.5872, 0.4128]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 98/203 [2m0:05:28 â€¢ 0:05:08[0m [2;4m0.34it/s[0m  
[2KAttention weights: tensor([[0.5866, 0.4134]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 98/203 [2m0:05:28 â€¢ 0:05:08[0m [2;4m0.34it/s[0m  
[2KAttention weights: tensor([[0.5844, 0.4156]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 98/203 [2m0:05:28 â€¢ 0:05:08[0m [2;4m0.34it/s[0m  
[2KAttention weights: tensor([[0.5839, 0.4161]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 98/203 [2m0:05:28 â€¢ 0:05:08[0m [2;4m0.34it/s[0m  
[2KAttention weights: tensor([[0.5823, 0.4177]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 98/203 [2m0:05:28 â€¢ 0:05:08[0m [2;4m0.34it/s[0m  
[2KAttention weights: tensor([[0.5833, 0.4167]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 98/203 [2m0:05:28 â€¢ 0:05:08[0m [2;4m0.34it/s[0m  
[2KAttention weights: tensor([[0.5839, 0.4161]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 98/203 [2m0:05:28 â€¢ 0:05:08[0m [2;4m0.34it/s[0m  
[2KAttention weights: tensor([[0.5839, 0.4161]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 98/203 [2m0:05:28 â€¢ 0:05:08[0m [2;4m0.34it/s[0m  
[2KAttention weights: tensor([[0.5531, 0.4469]], device='cuda:0')8;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 98/203 [2m0:05:28 â€¢ 0:05:08[0m [2;4m0.34it/s[0m  
[2KAttention weights: tensor([[0.6385, 0.3615],[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 98/203 [2m0:05:28 â€¢ 0:05:08[0m [2;4m0.34it/s[0m  
        [0.5920, 0.4080],
        [0.5701, 0.4299],
        [0.6555, 0.3445],
        [0.6038, 0.3962],
        [0.5840, 0.4160],
        [0.4687, 0.5313],
        [0.6433, 0.3567],
        [0.7199, 0.2801],
[2K        [0.6516, 0.3484]], device='cuda:0')[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 98/203 [2m0:05:28 â€¢ 0:05:08[0m [2;4m0.34it/s[0m  
[2KAttention weights: tensor([[0.5584, 0.4416],[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 99/203 [2m0:05:28 â€¢ 0:04:44[0m [2;4m0.37it/s[0m  
        [0.5539, 0.4461],
        [0.5554, 0.4446],
        [0.5567, 0.4433],
        [0.5566, 0.4434],
        [0.5534, 0.4466],
        [0.5527, 0.4473],
        [0.5580, 0.4420],
        [0.5579, 0.4421],
[2K        [0.5565, 0.4435]], device='cuda:0', grad_fn=<SoftmaxBackward0>)237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 99/203 [2m0:05:28 â€¢ 0:04:44[0m [2;4m0.37it/s[0m  
[2KClass label: HighJumpâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 99/203 [2m0:05:28 â€¢ 0:04:44[0m [2;4m0.37it/s[0m  
[2KAttention weights: tensor([[0.5979, 0.4021]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 99/203 [2m0:05:28 â€¢ 0:04:44[0m [2;4m0.37it/s[0m  
[2KStep 0 - TTA Loss: 0.7111â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 99/203 [2m0:05:28 â€¢ 0:04:44[0m [2;4m0.37it/s[0m  
[2KAttention weights: tensor([[0.5979, 0.4021]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 99/203 [2m0:05:28 â€¢ 0:04:44[0m [2;4m0.37it/s[0m  
[2KAttention weights: tensor([[0.6006, 0.3994]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 99/203 [2m0:05:28 â€¢ 0:04:44[0m [2;4m0.37it/s[0m  
[2KAttention weights: tensor([[0.6152, 0.3848]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 99/203 [2m0:05:28 â€¢ 0:04:44[0m [2;4m0.37it/s[0m  
[2KAttention weights: tensor([[0.6536, 0.3464]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 99/203 [2m0:05:28 â€¢ 0:04:44[0m [2;4m0.37it/s[0m  
[2KAttention weights: tensor([[0.7236, 0.2764]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 99/203 [2m0:05:28 â€¢ 0:04:44[0m [2;4m0.37it/s[0m  
[2KAttention weights: tensor([[0.8206, 0.1794]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 99/203 [2m0:05:28 â€¢ 0:04:44[0m [2;4m0.37it/s[0m  
[2KAttention weights: tensor([[0.9123, 0.0877]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 99/203 [2m0:05:28 â€¢ 0:04:44[0m [2;4m0.37it/s[0m  
[2KAttention weights: tensor([[0.9632, 0.0368]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 99/203 [2m0:05:28 â€¢ 0:04:44[0m [2;4m0.37it/s[0m  
[2KAttention weights: tensor([[0.9821, 0.0179]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 99/203 [2m0:05:28 â€¢ 0:04:44[0m [2;4m0.37it/s[0m  
[2KAttention weights: tensor([[0.5757, 0.4243]], device='cuda:0')0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 99/203 [2m0:05:28 â€¢ 0:04:44[0m [2;4m0.37it/s[0m  
[2KAttention weights: tensor([[0.9682, 0.0318],[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 99/203 [2m0:05:28 â€¢ 0:04:44[0m [2;4m0.37it/s[0m  
        [0.9128, 0.0872],
        [0.9542, 0.0458],
        [0.9589, 0.0411],
        [0.9792, 0.0208],
        [0.9920, 0.0080],
        [0.9799, 0.0201],
        [0.9697, 0.0303],
        [0.9706, 0.0294],
[2K        [0.9816, 0.0184]], device='cuda:0')[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 99/203 [2m0:05:28 â€¢ 0:04:44[0m [2;4m0.37it/s[0m  
[2KAttention weights: tensor([[0.5585, 0.4415],[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 100/203 [2m0:05:31 â€¢ 0:04:06[0m [2;4m0.42it/s[0m  
        [0.5540, 0.4460],
        [0.5555, 0.4445],
        [0.5568, 0.4432],
        [0.5567, 0.4433],
        [0.5536, 0.4464],
        [0.5528, 0.4472],
        [0.5581, 0.4419],
        [0.5580, 0.4420],
[2K        [0.5565, 0.4435]], device='cuda:0', grad_fn=<SoftmaxBackward0>)237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 100/203 [2m0:05:31 â€¢ 0:04:06[0m [2;4m0.42it/s[0m  
[2KClass label: PoleVaultâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 100/203 [2m0:05:31 â€¢ 0:04:06[0m [2;4m0.42it/s[0m  
[2KAttention weights: tensor([[0.5470, 0.4530]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 100/203 [2m0:05:31 â€¢ 0:04:06[0m [2;4m0.42it/s[0m  
[2KStep 0 - TTA Loss: 0.7454â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 100/203 [2m0:05:31 â€¢ 0:04:06[0m [2;4m0.42it/s[0m  
[2KAttention weights: tensor([[0.7034, 0.2966]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 100/203 [2m0:05:31 â€¢ 0:04:06[0m [2;4m0.42it/s[0m  
[2KAttention weights: tensor([[0.8168, 0.1832]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 100/203 [2m0:05:31 â€¢ 0:04:06[0m [2;4m0.42it/s[0m  
[2KAttention weights: tensor([[0.8977, 0.1023]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 100/203 [2m0:05:31 â€¢ 0:04:06[0m [2;4m0.42it/s[0m  
[2KAttention weights: tensor([[0.9431, 0.0569]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 100/203 [2m0:05:31 â€¢ 0:04:06[0m [2;4m0.42it/s[0m  
[2KAttention weights: tensor([[0.9660, 0.0340]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 100/203 [2m0:05:31 â€¢ 0:04:06[0m [2;4m0.42it/s[0m  
[2KAttention weights: tensor([[0.9772, 0.0228]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 100/203 [2m0:05:31 â€¢ 0:04:06[0m [2;4m0.42it/s[0m  
[2KAttention weights: tensor([[0.9812, 0.0188]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 100/203 [2m0:05:31 â€¢ 0:04:06[0m [2;4m0.42it/s[0m  
[2KAttention weights: tensor([[0.9819, 0.0181]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 100/203 [2m0:05:31 â€¢ 0:04:06[0m [2;4m0.42it/s[0m  
[2KAttention weights: tensor([[0.9818, 0.0182]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 100/203 [2m0:05:31 â€¢ 0:04:06[0m [2;4m0.42it/s[0m  
[2KAttention weights: tensor([[0.5738, 0.4262]], device='cuda:0')0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 100/203 [2m0:05:31 â€¢ 0:04:06[0m [2;4m0.42it/s[0m  
[2KAttention weights: tensor([[0.9604, 0.0396],[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 100/203 [2m0:05:31 â€¢ 0:04:06[0m [2;4m0.42it/s[0m  
        [0.9007, 0.0993],
        [0.9450, 0.0550],
        [0.9509, 0.0491],
        [0.9738, 0.0262],
        [0.9883, 0.0117],
        [0.9816, 0.0184],
        [0.9639, 0.0361],
        [0.9573, 0.0427],
[2K        [0.9766, 0.0234]], device='cuda:0')[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 100/203 [2m0:05:31 â€¢ 0:04:06[0m [2;4m0.42it/s[0m  
[2KAttention weights: tensor([[0.5586, 0.4414],[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 101/203 [2m0:05:35 â€¢ 0:03:20[0m [2;4m0.51it/s[0m  
        [0.5541, 0.4459],
        [0.5556, 0.4444],
        [0.5569, 0.4431],
        [0.5569, 0.4431],
        [0.5538, 0.4462],
        [0.5530, 0.4470],
        [0.5582, 0.4418],
        [0.5581, 0.4419],
[2K        [0.5567, 0.4433]], device='cuda:0', grad_fn=<SoftmaxBackward0>)237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 101/203 [2m0:05:35 â€¢ 0:03:20[0m [2;4m0.51it/s[0m  
[2KClass label: Billiardsâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 101/203 [2m0:05:35 â€¢ 0:03:20[0m [2;4m0.51it/s[0m  
[2KAttention weights: tensor([[0.5856, 0.4144]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 101/203 [2m0:05:35 â€¢ 0:03:20[0m [2;4m0.51it/s[0m  
[2KStep 0 - TTA Loss: 0.5809â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 101/203 [2m0:05:35 â€¢ 0:03:20[0m [2;4m0.51it/s[0m  
[2KAttention weights: tensor([[0.5856, 0.4144]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 101/203 [2m0:05:35 â€¢ 0:03:20[0m [2;4m0.51it/s[0m  
[2KAttention weights: tensor([[0.5835, 0.4165]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 101/203 [2m0:05:35 â€¢ 0:03:20[0m [2;4m0.51it/s[0m  
[2KAttention weights: tensor([[0.5735, 0.4265]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 101/203 [2m0:05:35 â€¢ 0:03:20[0m [2;4m0.51it/s[0m  
[2KAttention weights: tensor([[0.5480, 0.4520]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 101/203 [2m0:05:35 â€¢ 0:03:20[0m [2;4m0.51it/s[0m  
[2KAttention weights: tensor([[0.4984, 0.5016]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 101/203 [2m0:05:35 â€¢ 0:03:20[0m [2;4m0.51it/s[0m  
[2KAttention weights: tensor([[0.4196, 0.5804]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 101/203 [2m0:05:35 â€¢ 0:03:20[0m [2;4m0.51it/s[0m  
[2KAttention weights: tensor([[0.3265, 0.6735]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 101/203 [2m0:05:35 â€¢ 0:03:20[0m [2;4m0.51it/s[0m  
[2KAttention weights: tensor([[0.2548, 0.7452]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 101/203 [2m0:05:35 â€¢ 0:03:20[0m [2;4m0.51it/s[0m  
[2KAttention weights: tensor([[0.2175, 0.7825]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 101/203 [2m0:05:35 â€¢ 0:03:20[0m [2;4m0.51it/s[0m  
[2KAttention weights: tensor([[0.5463, 0.4537]], device='cuda:0')0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 101/203 [2m0:05:35 â€¢ 0:03:20[0m [2;4m0.51it/s[0m  
[2KAttention weights: tensor([[0.3948, 0.6052],[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 101/203 [2m0:05:35 â€¢ 0:03:20[0m [2;4m0.51it/s[0m  
        [0.2074, 0.7926],
        [0.3597, 0.6403],
        [0.4184, 0.5816],
        [0.3343, 0.6657],
        [0.3293, 0.6707],
        [0.2106, 0.7894],
        [0.3917, 0.6083],
        [0.4652, 0.5348],
[2K        [0.3894, 0.6106]], device='cuda:0')[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 101/203 [2m0:05:35 â€¢ 0:03:20[0m [2;4m0.51it/s[0m  
[2KAttention weights: tensor([[0.5586, 0.4414],[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 102/203 [2m0:05:38 â€¢ 0:03:25[0m [2;4m0.49it/s[0m   
        [0.5540, 0.4460],
        [0.5556, 0.4444],
        [0.5569, 0.4431],
        [0.5568, 0.4432],
        [0.5538, 0.4462],
        [0.5529, 0.4471],
        [0.5581, 0.4419],
        [0.5581, 0.4419],
[2K        [0.5566, 0.4434]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 102/203 [2m0:05:38 â€¢ 0:03:25[0m [2;4m0.49it/s[0m  
[2KClass label: CleanAndJerkâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 102/203 [2m0:05:38 â€¢ 0:03:25[0m [2;4m0.49it/s[0m  
[2KAttention weights: tensor([[0.5683, 0.4317]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 102/203 [2m0:05:38 â€¢ 0:03:25[0m [2;4m0.49it/s[0m  
[2KStep 0 - TTA Loss: 0.7531â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 102/203 [2m0:05:38 â€¢ 0:03:25[0m [2;4m0.49it/s[0m  
[2KAttention weights: tensor([[0.5644, 0.4356]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 102/203 [2m0:05:38 â€¢ 0:03:25[0m [2;4m0.49it/s[0m  
[2KAttention weights: tensor([[0.5688, 0.4312]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 102/203 [2m0:05:38 â€¢ 0:03:25[0m [2;4m0.49it/s[0m  
[2KAttention weights: tensor([[0.5804, 0.4196]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 102/203 [2m0:05:38 â€¢ 0:03:25[0m [2;4m0.49it/s[0m  
[2KAttention weights: tensor([[0.5959, 0.4041]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 102/203 [2m0:05:38 â€¢ 0:03:25[0m [2;4m0.49it/s[0m  
[2KAttention weights: tensor([[0.6124, 0.3876]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 102/203 [2m0:05:38 â€¢ 0:03:25[0m [2;4m0.49it/s[0m  
[2KAttention weights: tensor([[0.6259, 0.3741]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 102/203 [2m0:05:38 â€¢ 0:03:25[0m [2;4m0.49it/s[0m  
[2KAttention weights: tensor([[0.6352, 0.3648]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 102/203 [2m0:05:38 â€¢ 0:03:25[0m [2;4m0.49it/s[0m  
[2KAttention weights: tensor([[0.6406, 0.3594]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 102/203 [2m0:05:38 â€¢ 0:03:25[0m [2;4m0.49it/s[0m  
[2KAttention weights: tensor([[0.6431, 0.3569]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 102/203 [2m0:05:38 â€¢ 0:03:25[0m [2;4m0.49it/s[0m  
[2KAttention weights: tensor([[0.5578, 0.4422]], device='cuda:0')38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 102/203 [2m0:05:38 â€¢ 0:03:25[0m [2;4m0.49it/s[0m  
[2KAttention weights: tensor([[0.5841, 0.4159],[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 102/203 [2m0:05:38 â€¢ 0:03:25[0m [2;4m0.49it/s[0m  
        [0.5657, 0.4343],
        [0.6437, 0.3563],
        [0.6141, 0.3859],
        [0.5645, 0.4355],
        [0.5605, 0.4395],
        [0.4352, 0.5648],
        [0.5925, 0.4075],
        [0.6596, 0.3404],
[2K        [0.6137, 0.3863]], device='cuda:0')m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 102/203 [2m0:05:38 â€¢ 0:03:25[0m [2;4m0.49it/s[0m  
[2KAttention weights: tensor([[0.5585, 0.4415],[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 103/203 [2m0:05:40 â€¢ 0:03:20[0m [2;4m0.50it/s[0m  
        [0.5540, 0.4460],
        [0.5556, 0.4444],
        [0.5568, 0.4432],
        [0.5568, 0.4432],
        [0.5538, 0.4462],
        [0.5529, 0.4471],
        [0.5581, 0.4419],
        [0.5581, 0.4419],
[2K        [0.5566, 0.4434]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 103/203 [2m0:05:40 â€¢ 0:03:20[0m [2;4m0.50it/s[0m  
[2KClass label: TennisSwingâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 103/203 [2m0:05:40 â€¢ 0:03:20[0m [2;4m0.50it/s[0m  
[2KAttention weights: tensor([[0.6435, 0.3565]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 103/203 [2m0:05:40 â€¢ 0:03:20[0m [2;4m0.50it/s[0m  
[2KStep 0 - TTA Loss: 0.4103â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 103/203 [2m0:05:40 â€¢ 0:03:20[0m [2;4m0.50it/s[0m  
[2KAttention weights: tensor([[0.6435, 0.3565]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 103/203 [2m0:05:40 â€¢ 0:03:20[0m [2;4m0.50it/s[0m  
[2KAttention weights: tensor([[0.6443, 0.3557]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 103/203 [2m0:05:40 â€¢ 0:03:20[0m [2;4m0.50it/s[0m  
[2KAttention weights: tensor([[0.6483, 0.3517]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 103/203 [2m0:05:40 â€¢ 0:03:20[0m [2;4m0.50it/s[0m  
[2KAttention weights: tensor([[0.6582, 0.3418]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 103/203 [2m0:05:40 â€¢ 0:03:20[0m [2;4m0.50it/s[0m  
[2KAttention weights: tensor([[0.6761, 0.3239]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 103/203 [2m0:05:40 â€¢ 0:03:20[0m [2;4m0.50it/s[0m  
[2KAttention weights: tensor([[0.7019, 0.2981]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 103/203 [2m0:05:40 â€¢ 0:03:20[0m [2;4m0.50it/s[0m  
[2KAttention weights: tensor([[0.7326, 0.2674]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 103/203 [2m0:05:40 â€¢ 0:03:20[0m [2;4m0.50it/s[0m  
[2KAttention weights: tensor([[0.7652, 0.2348]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 103/203 [2m0:05:40 â€¢ 0:03:20[0m [2;4m0.50it/s[0m  
[2KAttention weights: tensor([[0.7941, 0.2059]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 103/203 [2m0:05:40 â€¢ 0:03:20[0m [2;4m0.50it/s[0m  
[2KAttention weights: tensor([[0.5631, 0.4369]], device='cuda:0')38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 103/203 [2m0:05:40 â€¢ 0:03:20[0m [2;4m0.50it/s[0m  
[2KAttention weights: tensor([[0.7304, 0.2696],[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 103/203 [2m0:05:40 â€¢ 0:03:20[0m [2;4m0.50it/s[0m  
        [0.6737, 0.3263],
        [0.6964, 0.3036],
        [0.7528, 0.2472],
        [0.7021, 0.2979],
        [0.7117, 0.2883],
        [0.6212, 0.3788],
        [0.7172, 0.2828],
        [0.8195, 0.1805],
[2K        [0.7538, 0.2462]], device='cuda:0')m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 103/203 [2m0:05:40 â€¢ 0:03:20[0m [2;4m0.50it/s[0m  
[2KAttention weights: tensor([[0.5585, 0.4415],[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 104/203 [2m0:05:40 â€¢ 0:03:07[0m [2;4m0.53it/s[0m  
        [0.5540, 0.4460],
        [0.5556, 0.4444],
        [0.5568, 0.4432],
        [0.5568, 0.4432],
        [0.5538, 0.4462],
        [0.5529, 0.4471],
        [0.5581, 0.4419],
        [0.5580, 0.4420],
[2K        [0.5566, 0.4434]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 104/203 [2m0:05:40 â€¢ 0:03:07[0m [2;4m0.53it/s[0m  
[2KClass label: HammerThrowâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 104/203 [2m0:05:40 â€¢ 0:03:07[0m [2;4m0.53it/s[0m  
[2KAttention weights: tensor([[0.5848, 0.4152]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 104/203 [2m0:05:40 â€¢ 0:03:07[0m [2;4m0.53it/s[0m  
[2KStep 0 - TTA Loss: 0.6410â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 104/203 [2m0:05:40 â€¢ 0:03:07[0m [2;4m0.53it/s[0m  
[2KAttention weights: tensor([[0.6228, 0.3772]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 104/203 [2m0:05:40 â€¢ 0:03:07[0m [2;4m0.53it/s[0m  
[2KAttention weights: tensor([[0.6743, 0.3257]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 104/203 [2m0:05:40 â€¢ 0:03:07[0m [2;4m0.53it/s[0m  
[2KAttention weights: tensor([[0.7242, 0.2758]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 104/203 [2m0:05:40 â€¢ 0:03:07[0m [2;4m0.53it/s[0m  
[2KAttention weights: tensor([[0.7632, 0.2368]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 104/203 [2m0:05:40 â€¢ 0:03:07[0m [2;4m0.53it/s[0m  
[2KAttention weights: tensor([[0.7913, 0.2087]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 104/203 [2m0:05:40 â€¢ 0:03:07[0m [2;4m0.53it/s[0m  
[2KAttention weights: tensor([[0.8085, 0.1915]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 104/203 [2m0:05:40 â€¢ 0:03:07[0m [2;4m0.53it/s[0m  
[2KAttention weights: tensor([[0.8171, 0.1829]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 104/203 [2m0:05:40 â€¢ 0:03:07[0m [2;4m0.53it/s[0m  
[2KAttention weights: tensor([[0.8200, 0.1800]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 104/203 [2m0:05:40 â€¢ 0:03:07[0m [2;4m0.53it/s[0m  
[2KAttention weights: tensor([[0.8207, 0.1793]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 104/203 [2m0:05:40 â€¢ 0:03:07[0m [2;4m0.53it/s[0m  
[2KAttention weights: tensor([[0.5648, 0.4352]], device='cuda:0')38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 104/203 [2m0:05:40 â€¢ 0:03:07[0m [2;4m0.53it/s[0m  
[2KAttention weights: tensor([[0.8099, 0.1901],[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 104/203 [2m0:05:40 â€¢ 0:03:07[0m [2;4m0.53it/s[0m  
        [0.7157, 0.2843],
        [0.7644, 0.2356],
        [0.8136, 0.1864],
        [0.8209, 0.1791],
        [0.7949, 0.2051],
        [0.7259, 0.2741],
        [0.7902, 0.2098],
        [0.8463, 0.1537],
[2K        [0.8357, 0.1643]], device='cuda:0')m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 104/203 [2m0:05:40 â€¢ 0:03:07[0m [2;4m0.53it/s[0m  
[2KAttention weights: tensor([[0.5585, 0.4415],[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 105/203 [2m0:05:45 â€¢ 0:03:25[0m [2;4m0.48it/s[0m  
        [0.5540, 0.4460],
        [0.5556, 0.4444],
        [0.5568, 0.4432],
        [0.5568, 0.4432],
        [0.5538, 0.4462],
        [0.5529, 0.4471],
        [0.5581, 0.4419],
        [0.5580, 0.4420],
[2K        [0.5566, 0.4434]], device='cuda:0', grad_fn=<SoftmaxBackward0>);237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 105/203 [2m0:05:45 â€¢ 0:03:25[0m [2;4m0.48it/s[0m  
[2KClass label: HighJumpâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 105/203 [2m0:05:45 â€¢ 0:03:25[0m [2;4m0.48it/s[0m  
[2KAttention weights: tensor([[0.5947, 0.4053]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 105/203 [2m0:05:45 â€¢ 0:03:25[0m [2;4m0.48it/s[0m  
[2KStep 0 - TTA Loss: 0.8008â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 105/203 [2m0:05:45 â€¢ 0:03:25[0m [2;4m0.48it/s[0m  
[2KAttention weights: tensor([[0.5947, 0.4053]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 105/203 [2m0:05:45 â€¢ 0:03:25[0m [2;4m0.48it/s[0m  
[2KAttention weights: tensor([[0.5956, 0.4044]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 105/203 [2m0:05:45 â€¢ 0:03:25[0m [2;4m0.48it/s[0m  
[2KAttention weights: tensor([[0.6015, 0.3985]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 105/203 [2m0:05:45 â€¢ 0:03:25[0m [2;4m0.48it/s[0m  
[2KAttention weights: tensor([[0.6175, 0.3825]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 105/203 [2m0:05:45 â€¢ 0:03:25[0m [2;4m0.48it/s[0m  
[2KAttention weights: tensor([[0.6508, 0.3492]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 105/203 [2m0:05:45 â€¢ 0:03:25[0m [2;4m0.48it/s[0m  
[2KAttention weights: tensor([[0.7040, 0.2960]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 105/203 [2m0:05:45 â€¢ 0:03:25[0m [2;4m0.48it/s[0m  
[2KAttention weights: tensor([[0.7736, 0.2264]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 105/203 [2m0:05:45 â€¢ 0:03:25[0m [2;4m0.48it/s[0m  
[2KAttention weights: tensor([[0.8414, 0.1586]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 105/203 [2m0:05:45 â€¢ 0:03:25[0m [2;4m0.48it/s[0m  
[2KAttention weights: tensor([[0.8920, 0.1080]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 105/203 [2m0:05:45 â€¢ 0:03:25[0m [2;4m0.48it/s[0m  
[2KAttention weights: tensor([[0.5647, 0.4353]], device='cuda:0')[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 105/203 [2m0:05:45 â€¢ 0:03:25[0m [2;4m0.48it/s[0m  
[2KAttention weights: tensor([[0.8676, 0.1324],[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 105/203 [2m0:05:45 â€¢ 0:03:25[0m [2;4m0.48it/s[0m  
        [0.7817, 0.2183],
        [0.8314, 0.1686],
        [0.8576, 0.1424],
        [0.8814, 0.1186],
        [0.9234, 0.0766],
        [0.8742, 0.1258],
        [0.8737, 0.1263],
        [0.8824, 0.1176],
[2K        [0.8989, 0.1011]], device='cuda:0')m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 105/203 [2m0:05:45 â€¢ 0:03:25[0m [2;4m0.48it/s[0m  
[2KAttention weights: tensor([[0.5585, 0.4415],[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 106/203 [2m0:05:49 â€¢ 0:04:00[0m [2;4m0.40it/s[0m  
        [0.5540, 0.4460],
        [0.5556, 0.4444],
        [0.5568, 0.4432],
        [0.5569, 0.4431],
        [0.5539, 0.4461],
        [0.5529, 0.4471],
        [0.5581, 0.4419],
        [0.5581, 0.4419],
[2K        [0.5567, 0.4433]], device='cuda:0', grad_fn=<SoftmaxBackward0>);237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 106/203 [2m0:05:49 â€¢ 0:04:00[0m [2;4m0.40it/s[0m  
[2KClass label: TennisSwingâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 106/203 [2m0:05:49 â€¢ 0:04:00[0m [2;4m0.40it/s[0m  
[2KAttention weights: tensor([[0.6442, 0.3558]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 106/203 [2m0:05:49 â€¢ 0:04:00[0m [2;4m0.40it/s[0m  
[2KStep 0 - TTA Loss: 0.6471â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 106/203 [2m0:05:49 â€¢ 0:04:00[0m [2;4m0.40it/s[0m  
[2KAttention weights: tensor([[0.6581, 0.3419]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 106/203 [2m0:05:49 â€¢ 0:04:00[0m [2;4m0.40it/s[0m  
[2KAttention weights: tensor([[0.6239, 0.3761]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 106/203 [2m0:05:49 â€¢ 0:04:00[0m [2;4m0.40it/s[0m  
[2KAttention weights: tensor([[0.5459, 0.4541]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 106/203 [2m0:05:49 â€¢ 0:04:00[0m [2;4m0.40it/s[0m  
[2KAttention weights: tensor([[0.4471, 0.5529]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 106/203 [2m0:05:49 â€¢ 0:04:00[0m [2;4m0.40it/s[0m  
[2KAttention weights: tensor([[0.3666, 0.6334]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 106/203 [2m0:05:49 â€¢ 0:04:00[0m [2;4m0.40it/s[0m  
[2KAttention weights: tensor([[0.3228, 0.6772]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 106/203 [2m0:05:49 â€¢ 0:04:00[0m [2;4m0.40it/s[0m  
[2KAttention weights: tensor([[0.3064, 0.6936]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 106/203 [2m0:05:49 â€¢ 0:04:00[0m [2;4m0.40it/s[0m  
[2KAttention weights: tensor([[0.3035, 0.6965]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 106/203 [2m0:05:49 â€¢ 0:04:00[0m [2;4m0.40it/s[0m  
[2KAttention weights: tensor([[0.3048, 0.6952]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 106/203 [2m0:05:49 â€¢ 0:04:00[0m [2;4m0.40it/s[0m  
[2KAttention weights: tensor([[0.5489, 0.4511]], device='cuda:0')[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 106/203 [2m0:05:49 â€¢ 0:04:00[0m [2;4m0.40it/s[0m  
[2KAttention weights: tensor([[0.5071, 0.4929],[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 106/203 [2m0:05:49 â€¢ 0:04:00[0m [2;4m0.40it/s[0m  
        [0.4828, 0.5172],
        [0.5416, 0.4584],
        [0.4657, 0.5343],
        [0.5613, 0.4387],
        [0.6260, 0.3740],
        [0.6243, 0.3757],
        [0.6197, 0.3803],
        [0.3057, 0.6943],
[2K        [0.5647, 0.4353]], device='cuda:0')m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 106/203 [2m0:05:49 â€¢ 0:04:00[0m [2;4m0.40it/s[0m  
[2KAttention weights: tensor([[0.5585, 0.4415],â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 107/203 [2m0:05:51 â€¢ 0:03:58[0m [2;4m0.40it/s[0m   
        [0.5540, 0.4460],
        [0.5556, 0.4444],
        [0.5568, 0.4432],
        [0.5568, 0.4432],
        [0.5539, 0.4461],
        [0.5529, 0.4471],
        [0.5581, 0.4419],
        [0.5580, 0.4420],
[2K        [0.5566, 0.4434]], device='cuda:0', grad_fn=<SoftmaxBackward0>)mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 107/203 [2m0:05:51 â€¢ 0:03:58[0m [2;4m0.40it/s[0m  
[2KClass label: HighJumpâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 107/203 [2m0:05:51 â€¢ 0:03:58[0m [2;4m0.40it/s[0m  
[2KAttention weights: tensor([[0.5990, 0.4010]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 107/203 [2m0:05:51 â€¢ 0:03:58[0m [2;4m0.40it/s[0m  
[2KStep 0 - TTA Loss: 0.5922â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 107/203 [2m0:05:51 â€¢ 0:03:58[0m [2;4m0.40it/s[0m  
[2KAttention weights: tensor([[0.5990, 0.4010]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 107/203 [2m0:05:51 â€¢ 0:03:58[0m [2;4m0.40it/s[0m  
[2KAttention weights: tensor([[0.6016, 0.3984]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 107/203 [2m0:05:51 â€¢ 0:03:58[0m [2;4m0.40it/s[0m  
[2KAttention weights: tensor([[0.6143, 0.3857]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 107/203 [2m0:05:51 â€¢ 0:03:58[0m [2;4m0.40it/s[0m  
[2KAttention weights: tensor([[0.6456, 0.3544]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 107/203 [2m0:05:51 â€¢ 0:03:58[0m [2;4m0.40it/s[0m  
[2KAttention weights: tensor([[0.7030, 0.2970]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 107/203 [2m0:05:51 â€¢ 0:03:58[0m [2;4m0.40it/s[0m  
[2KAttention weights: tensor([[0.7855, 0.2145]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 107/203 [2m0:05:51 â€¢ 0:03:58[0m [2;4m0.40it/s[0m  
[2KAttention weights: tensor([[0.8745, 0.1255]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 107/203 [2m0:05:51 â€¢ 0:03:58[0m [2;4m0.40it/s[0m  
[2KAttention weights: tensor([[0.9413, 0.0587]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 107/203 [2m0:05:51 â€¢ 0:03:58[0m [2;4m0.40it/s[0m  
[2KAttention weights: tensor([[0.9758, 0.0242]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 107/203 [2m0:05:51 â€¢ 0:03:58[0m [2;4m0.40it/s[0m  
[2KAttention weights: tensor([[0.5740, 0.4260]], device='cuda:0')[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 107/203 [2m0:05:51 â€¢ 0:03:58[0m [2;4m0.40it/s[0m  
[2KAttention weights: tensor([[0.9635, 0.0365],m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 107/203 [2m0:05:51 â€¢ 0:03:58[0m [2;4m0.40it/s[0m  
        [0.8994, 0.1006],
        [0.9470, 0.0530],
        [0.9540, 0.0460],
        [0.9747, 0.0253],
        [0.9894, 0.0106],
        [0.9754, 0.0246],
        [0.9639, 0.0361],
        [0.9664, 0.0336],
[2K        [0.9780, 0.0220]], device='cuda:0')0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 107/203 [2m0:05:51 â€¢ 0:03:58[0m [2;4m0.40it/s[0m  
[2KAttention weights: tensor([[0.5586, 0.4414],â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 108/203 [2m0:05:56 â€¢ 0:04:29[0m [2;4m0.35it/s[0m  
        [0.5541, 0.4459],
        [0.5557, 0.4443],
        [0.5569, 0.4431],
        [0.5569, 0.4431],
        [0.5540, 0.4460],
        [0.5531, 0.4469],
        [0.5582, 0.4418],
        [0.5581, 0.4419],
[2K        [0.5567, 0.4433]], device='cuda:0', grad_fn=<SoftmaxBackward0>)mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 108/203 [2m0:05:56 â€¢ 0:04:29[0m [2;4m0.35it/s[0m  
[2KClass label: CleanAndJerkâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 108/203 [2m0:05:56 â€¢ 0:04:29[0m [2;4m0.35it/s[0m  
[2KAttention weights: tensor([[0.5638, 0.4362]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 108/203 [2m0:05:56 â€¢ 0:04:29[0m [2;4m0.35it/s[0m  
[2KStep 0 - TTA Loss: 0.6099â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 108/203 [2m0:05:56 â€¢ 0:04:29[0m [2;4m0.35it/s[0m  
[2KAttention weights: tensor([[0.6881, 0.3119]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 108/203 [2m0:05:56 â€¢ 0:04:29[0m [2;4m0.35it/s[0m  
[2KAttention weights: tensor([[0.7897, 0.2103]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 108/203 [2m0:05:56 â€¢ 0:04:29[0m [2;4m0.35it/s[0m  
[2KAttention weights: tensor([[0.8595, 0.1405]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 108/203 [2m0:05:56 â€¢ 0:04:29[0m [2;4m0.35it/s[0m  
[2KAttention weights: tensor([[0.9007, 0.0993]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 108/203 [2m0:05:56 â€¢ 0:04:29[0m [2;4m0.35it/s[0m  
[2KAttention weights: tensor([[0.9212, 0.0788]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 108/203 [2m0:05:56 â€¢ 0:04:29[0m [2;4m0.35it/s[0m  
[2KAttention weights: tensor([[0.9300, 0.0700]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 108/203 [2m0:05:56 â€¢ 0:04:29[0m [2;4m0.35it/s[0m  
[2KAttention weights: tensor([[0.9317, 0.0683]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 108/203 [2m0:05:56 â€¢ 0:04:29[0m [2;4m0.35it/s[0m  
[2KAttention weights: tensor([[0.9308, 0.0692]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 108/203 [2m0:05:56 â€¢ 0:04:29[0m [2;4m0.35it/s[0m  
[2KAttention weights: tensor([[0.9298, 0.0702]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 108/203 [2m0:05:56 â€¢ 0:04:29[0m [2;4m0.35it/s[0m  
[2KAttention weights: tensor([[0.5695, 0.4305]], device='cuda:0')[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 108/203 [2m0:05:56 â€¢ 0:04:29[0m [2;4m0.35it/s[0m  
[2KAttention weights: tensor([[0.9402, 0.0598],m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 108/203 [2m0:05:56 â€¢ 0:04:29[0m [2;4m0.35it/s[0m  
        [0.8674, 0.1326],
        [0.9294, 0.0706],
        [0.9297, 0.0703],
        [0.9561, 0.0439],
        [0.9777, 0.0223],
        [0.9550, 0.0450],
        [0.9410, 0.0590],
        [0.9450, 0.0550],
[2K        [0.9614, 0.0386]], device='cuda:0')0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 108/203 [2m0:05:56 â€¢ 0:04:29[0m [2;4m0.35it/s[0m  
[2KAttention weights: tensor([[0.5587, 0.4413],â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 109/203 [2m0:06:00 â€¢ 0:05:00[0m [2;4m0.31it/s[0m  
        [0.5542, 0.4458],
        [0.5558, 0.4442],
        [0.5570, 0.4430],
        [0.5571, 0.4429],
        [0.5542, 0.4458],
        [0.5532, 0.4468],
        [0.5583, 0.4417],
        [0.5582, 0.4418],
[2K        [0.5568, 0.4432]], device='cuda:0', grad_fn=<SoftmaxBackward0>)mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 109/203 [2m0:06:00 â€¢ 0:05:00[0m [2;4m0.31it/s[0m  
[2KClass label: ThrowDiscusâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 109/203 [2m0:06:00 â€¢ 0:05:00[0m [2;4m0.31it/s[0m  
[2KAttention weights: tensor([[0.6375, 0.3625]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 109/203 [2m0:06:00 â€¢ 0:05:00[0m [2;4m0.31it/s[0m  
[2KStep 0 - TTA Loss: 0.8261â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 109/203 [2m0:06:00 â€¢ 0:05:00[0m [2;4m0.31it/s[0m  
[2KAttention weights: tensor([[0.6375, 0.3625]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 109/203 [2m0:06:00 â€¢ 0:05:00[0m [2;4m0.31it/s[0m  
[2KAttention weights: tensor([[0.6384, 0.3616]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 109/203 [2m0:06:00 â€¢ 0:05:00[0m [2;4m0.31it/s[0m  
[2KAttention weights: tensor([[0.6432, 0.3568]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 109/203 [2m0:06:00 â€¢ 0:05:00[0m [2;4m0.31it/s[0m  
[2KAttention weights: tensor([[0.6571, 0.3429]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 109/203 [2m0:06:00 â€¢ 0:05:00[0m [2;4m0.31it/s[0m  
[2KAttention weights: tensor([[0.6853, 0.3147]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 109/203 [2m0:06:00 â€¢ 0:05:00[0m [2;4m0.31it/s[0m  
[2KAttention weights: tensor([[0.7304, 0.2696]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 109/203 [2m0:06:00 â€¢ 0:05:00[0m [2;4m0.31it/s[0m  
[2KAttention weights: tensor([[0.7888, 0.2112]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 109/203 [2m0:06:00 â€¢ 0:05:00[0m [2;4m0.31it/s[0m  
[2KAttention weights: tensor([[0.8491, 0.1509]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 109/203 [2m0:06:00 â€¢ 0:05:00[0m [2;4m0.31it/s[0m  
[2KAttention weights: tensor([[0.9031, 0.0969]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 109/203 [2m0:06:00 â€¢ 0:05:00[0m [2;4m0.31it/s[0m  
[2KAttention weights: tensor([[0.5686, 0.4314]], device='cuda:0')[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 109/203 [2m0:06:00 â€¢ 0:05:00[0m [2;4m0.31it/s[0m  
[2KAttention weights: tensor([[0.9104, 0.0896],m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 109/203 [2m0:06:00 â€¢ 0:05:00[0m [2;4m0.31it/s[0m  
        [0.7680, 0.2320],
        [0.7152, 0.2848],
        [0.8894, 0.1106],
        [0.9008, 0.0992],
        [0.8974, 0.1026],
        [0.8567, 0.1433],
        [0.8699, 0.1301],
        [0.8912, 0.1088],
[2K        [0.9333, 0.0667]], device='cuda:0')0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 109/203 [2m0:06:00 â€¢ 0:05:00[0m [2;4m0.31it/s[0m  
[2KAttention weights: tensor([[0.5588, 0.4412],â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 110/203 [2m0:06:03 â€¢ 0:04:48[0m [2;4m0.32it/s[0m  
        [0.5542, 0.4458],
        [0.5559, 0.4441],
        [0.5570, 0.4430],
        [0.5572, 0.4428],
        [0.5543, 0.4457],
        [0.5533, 0.4467],
        [0.5584, 0.4416],
        [0.5583, 0.4417],
[2K        [0.5570, 0.4430]], device='cuda:0', grad_fn=<SoftmaxBackward0>)5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 110/203 [2m0:06:03 â€¢ 0:04:48[0m [2;4m0.32it/s[0m  
[2KClass label: HighJumpâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 110/203 [2m0:06:03 â€¢ 0:04:48[0m [2;4m0.32it/s[0m  
[2KAttention weights: tensor([[0.5942, 0.4058]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 110/203 [2m0:06:03 â€¢ 0:04:48[0m [2;4m0.32it/s[0m  
[2KStep 0 - TTA Loss: 0.6668â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 110/203 [2m0:06:03 â€¢ 0:04:48[0m [2;4m0.32it/s[0m  
[2KAttention weights: tensor([[0.6788, 0.3212]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 110/203 [2m0:06:03 â€¢ 0:04:48[0m [2;4m0.32it/s[0m  
[2KAttention weights: tensor([[0.7596, 0.2404]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 110/203 [2m0:06:03 â€¢ 0:04:48[0m [2;4m0.32it/s[0m  
[2KAttention weights: tensor([[0.8301, 0.1699]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 110/203 [2m0:06:03 â€¢ 0:04:48[0m [2;4m0.32it/s[0m  
[2KAttention weights: tensor([[0.8798, 0.1202]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 110/203 [2m0:06:03 â€¢ 0:04:48[0m [2;4m0.32it/s[0m  
[2KAttention weights: tensor([[0.9115, 0.0885]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 110/203 [2m0:06:03 â€¢ 0:04:48[0m [2;4m0.32it/s[0m  
[2KAttention weights: tensor([[0.9281, 0.0719]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 110/203 [2m0:06:03 â€¢ 0:04:48[0m [2;4m0.32it/s[0m  
[2KAttention weights: tensor([[0.9358, 0.0642]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 110/203 [2m0:06:03 â€¢ 0:04:48[0m [2;4m0.32it/s[0m  
[2KAttention weights: tensor([[0.9387, 0.0613]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 110/203 [2m0:06:03 â€¢ 0:04:48[0m [2;4m0.32it/s[0m  
[2KAttention weights: tensor([[0.9397, 0.0603]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 110/203 [2m0:06:03 â€¢ 0:04:48[0m [2;4m0.32it/s[0m  
[2KAttention weights: tensor([[0.5686, 0.4314]], device='cuda:0')[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 110/203 [2m0:06:03 â€¢ 0:04:48[0m [2;4m0.32it/s[0m  
[2KAttention weights: tensor([[0.9265, 0.0735],m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 110/203 [2m0:06:03 â€¢ 0:04:48[0m [2;4m0.32it/s[0m  
        [0.8112, 0.1888],
        [0.8126, 0.1874],
        [0.9098, 0.0902],
        [0.9290, 0.0710],
        [0.9400, 0.0600],
        [0.9051, 0.0949],
        [0.9035, 0.0965],
        [0.9162, 0.0838],
[2K        [0.9492, 0.0508]], device='cuda:0')0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 110/203 [2m0:06:03 â€¢ 0:04:48[0m [2;4m0.32it/s[0m  
[2KAttention weights: tensor([[0.5588, 0.4412],â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 111/203 [2m0:06:05 â€¢ 0:04:34[0m [2;4m0.34it/s[0m  
        [0.5542, 0.4458],
        [0.5560, 0.4440],
        [0.5571, 0.4429],
        [0.5572, 0.4428],
        [0.5544, 0.4456],
        [0.5534, 0.4466],
        [0.5584, 0.4416],
        [0.5583, 0.4417],
[2K        [0.5571, 0.4429]], device='cuda:0', grad_fn=<SoftmaxBackward0>)5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 111/203 [2m0:06:05 â€¢ 0:04:34[0m [2;4m0.34it/s[0m  
[2KClass label: HammerThrowâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 111/203 [2m0:06:05 â€¢ 0:04:34[0m [2;4m0.34it/s[0m  
[2KAttention weights: tensor([[0.5875, 0.4125]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 111/203 [2m0:06:05 â€¢ 0:04:34[0m [2;4m0.34it/s[0m  
[2KStep 0 - TTA Loss: 0.5378â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 111/203 [2m0:06:05 â€¢ 0:04:34[0m [2;4m0.34it/s[0m  
[2KAttention weights: tensor([[0.5875, 0.4125]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 111/203 [2m0:06:05 â€¢ 0:04:34[0m [2;4m0.34it/s[0m  
[2KAttention weights: tensor([[0.5884, 0.4116]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 111/203 [2m0:06:05 â€¢ 0:04:34[0m [2;4m0.34it/s[0m  
[2KAttention weights: tensor([[0.5916, 0.4084]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 111/203 [2m0:06:05 â€¢ 0:04:34[0m [2;4m0.34it/s[0m  
[2KAttention weights: tensor([[0.5987, 0.4013]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 111/203 [2m0:06:05 â€¢ 0:04:34[0m [2;4m0.34it/s[0m  
[2KAttention weights: tensor([[0.6097, 0.3903]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 111/203 [2m0:06:05 â€¢ 0:04:34[0m [2;4m0.34it/s[0m  
[2KAttention weights: tensor([[0.6227, 0.3773]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 111/203 [2m0:06:05 â€¢ 0:04:34[0m [2;4m0.34it/s[0m  
[2KAttention weights: tensor([[0.6394, 0.3606]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 111/203 [2m0:06:05 â€¢ 0:04:34[0m [2;4m0.34it/s[0m  
[2KAttention weights: tensor([[0.6623, 0.3377]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 111/203 [2m0:06:05 â€¢ 0:04:34[0m [2;4m0.34it/s[0m  
[2KAttention weights: tensor([[0.7086, 0.2914]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 111/203 [2m0:06:05 â€¢ 0:04:34[0m [2;4m0.34it/s[0m  
[2KAttention weights: tensor([[0.5620, 0.4380]], device='cuda:0')[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 111/203 [2m0:06:05 â€¢ 0:04:34[0m [2;4m0.34it/s[0m  
[2KAttention weights: tensor([[0.7769, 0.2231],m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 111/203 [2m0:06:05 â€¢ 0:04:34[0m [2;4m0.34it/s[0m  
        [0.6756, 0.3244],
        [0.6949, 0.3051],
        [0.7715, 0.2285],
        [0.7923, 0.2077],
        [0.7593, 0.2407],
        [0.7135, 0.2865],
        [0.7667, 0.2333],
        [0.7720, 0.2280],
[2K        [0.8094, 0.1906]], device='cuda:0')0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 111/203 [2m0:06:05 â€¢ 0:04:34[0m [2;4m0.34it/s[0m  
[2KAttention weights: tensor([[0.5588, 0.4412],â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 112/203 [2m0:06:09 â€¢ 0:04:56[0m [2;4m0.31it/s[0m   
        [0.5543, 0.4457],
        [0.5560, 0.4440],
        [0.5571, 0.4429],
        [0.5572, 0.4428],
        [0.5544, 0.4456],
        [0.5534, 0.4466],
        [0.5584, 0.4416],
        [0.5583, 0.4417],
[2K        [0.5571, 0.4429]], device='cuda:0', grad_fn=<SoftmaxBackward0>)7mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 112/203 [2m0:06:09 â€¢ 0:04:56[0m [2;4m0.31it/s[0m  
[2KClass label: GolfSwingâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 112/203 [2m0:06:09 â€¢ 0:04:56[0m [2;4m0.31it/s[0m  
[2KAttention weights: tensor([[0.6292, 0.3708]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 112/203 [2m0:06:09 â€¢ 0:04:56[0m [2;4m0.31it/s[0m  
[2KStep 0 - TTA Loss: 0.8440â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 112/203 [2m0:06:09 â€¢ 0:04:56[0m [2;4m0.31it/s[0m  
[2KAttention weights: tensor([[0.6974, 0.3026]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 112/203 [2m0:06:09 â€¢ 0:04:56[0m [2;4m0.31it/s[0m  
[2KAttention weights: tensor([[0.7615, 0.2385]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 112/203 [2m0:06:09 â€¢ 0:04:56[0m [2;4m0.31it/s[0m  
[2KAttention weights: tensor([[0.8125, 0.1875]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 112/203 [2m0:06:09 â€¢ 0:04:56[0m [2;4m0.31it/s[0m  
[2KAttention weights: tensor([[0.8496, 0.1504]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 112/203 [2m0:06:09 â€¢ 0:04:56[0m [2;4m0.31it/s[0m  
[2KAttention weights: tensor([[0.8746, 0.1254]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 112/203 [2m0:06:09 â€¢ 0:04:56[0m [2;4m0.31it/s[0m  
[2KAttention weights: tensor([[0.8909, 0.1091]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 112/203 [2m0:06:09 â€¢ 0:04:56[0m [2;4m0.31it/s[0m  
[2KAttention weights: tensor([[0.9006, 0.0994]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 112/203 [2m0:06:09 â€¢ 0:04:56[0m [2;4m0.31it/s[0m  
[2KAttention weights: tensor([[0.9057, 0.0943]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 112/203 [2m0:06:09 â€¢ 0:04:56[0m [2;4m0.31it/s[0m  
[2KAttention weights: tensor([[0.9078, 0.0922]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 112/203 [2m0:06:09 â€¢ 0:04:56[0m [2;4m0.31it/s[0m  
[2KAttention weights: tensor([[0.5683, 0.4317]], device='cuda:0')[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 112/203 [2m0:06:09 â€¢ 0:04:56[0m [2;4m0.31it/s[0m  
[2KAttention weights: tensor([[0.9062, 0.0938],0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 112/203 [2m0:06:09 â€¢ 0:04:56[0m [2;4m0.31it/s[0m  
        [0.7804, 0.2196],
        [0.8381, 0.1619],
        [0.9084, 0.0916],
        [0.9253, 0.0747],
        [0.8870, 0.1130],
        [0.8534, 0.1466],
        [0.8714, 0.1286],
        [0.8869, 0.1131],
[2K        [0.9232, 0.0768]], device='cuda:0')[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 112/203 [2m0:06:09 â€¢ 0:04:56[0m [2;4m0.31it/s[0m  
[2KAttention weights: tensor([[0.5589, 0.4411],â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 113/203 [2m0:06:11 â€¢ 0:04:54[0m [2;4m0.31it/s[0m  
        [0.5543, 0.4457],
        [0.5561, 0.4439],
        [0.5571, 0.4429],
        [0.5573, 0.4427],
        [0.5544, 0.4456],
        [0.5534, 0.4466],
        [0.5585, 0.4415],
        [0.5584, 0.4416],
[2K        [0.5571, 0.4429]], device='cuda:0', grad_fn=<SoftmaxBackward0>)7mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 113/203 [2m0:06:11 â€¢ 0:04:54[0m [2;4m0.31it/s[0m  
[2KClass label: TennisSwingâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 113/203 [2m0:06:11 â€¢ 0:04:54[0m [2;4m0.31it/s[0m  
[2KAttention weights: tensor([[0.6447, 0.3553]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 113/203 [2m0:06:11 â€¢ 0:04:54[0m [2;4m0.31it/s[0m  
[2KStep 0 - TTA Loss: 0.4208â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 113/203 [2m0:06:11 â€¢ 0:04:54[0m [2;4m0.31it/s[0m  
[2KAttention weights: tensor([[0.6447, 0.3553]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 113/203 [2m0:06:11 â€¢ 0:04:54[0m [2;4m0.31it/s[0m  
[2KAttention weights: tensor([[0.6455, 0.3545]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 113/203 [2m0:06:11 â€¢ 0:04:54[0m [2;4m0.31it/s[0m  
[2KAttention weights: tensor([[0.6491, 0.3509]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 113/203 [2m0:06:11 â€¢ 0:04:54[0m [2;4m0.31it/s[0m  
[2KAttention weights: tensor([[0.6581, 0.3419]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 113/203 [2m0:06:11 â€¢ 0:04:54[0m [2;4m0.31it/s[0m  
[2KAttention weights: tensor([[0.6736, 0.3264]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 113/203 [2m0:06:11 â€¢ 0:04:54[0m [2;4m0.31it/s[0m  
[2KAttention weights: tensor([[0.6944, 0.3056]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 113/203 [2m0:06:11 â€¢ 0:04:54[0m [2;4m0.31it/s[0m  
[2KAttention weights: tensor([[0.7155, 0.2845]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 113/203 [2m0:06:11 â€¢ 0:04:54[0m [2;4m0.31it/s[0m  
[2KAttention weights: tensor([[0.7330, 0.2670]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 113/203 [2m0:06:11 â€¢ 0:04:54[0m [2;4m0.31it/s[0m  
[2KAttention weights: tensor([[0.7383, 0.2617]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 113/203 [2m0:06:11 â€¢ 0:04:54[0m [2;4m0.31it/s[0m  
[2KAttention weights: tensor([[0.5598, 0.4402]], device='cuda:0')[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 113/203 [2m0:06:11 â€¢ 0:04:54[0m [2;4m0.31it/s[0m  
[2KAttention weights: tensor([[0.7272, 0.2728],0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 113/203 [2m0:06:11 â€¢ 0:04:54[0m [2;4m0.31it/s[0m  
        [0.6462, 0.3538],
        [0.6510, 0.3490],
        [0.7454, 0.2546],
        [0.7112, 0.2888],
        [0.6952, 0.3048],
        [0.6444, 0.3556],
        [0.7158, 0.2842],
        [0.7445, 0.2555],
[2K        [0.7468, 0.2532]], device='cuda:0')[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 113/203 [2m0:06:11 â€¢ 0:04:54[0m [2;4m0.31it/s[0m  
[2KAttention weights: tensor([[0.5589, 0.4411],â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 114/203 [2m0:06:15 â€¢ 0:04:56[0m [2;4m0.30it/s[0m  
        [0.5543, 0.4457],
        [0.5561, 0.4439],
        [0.5572, 0.4428],
        [0.5573, 0.4427],
        [0.5545, 0.4455],
        [0.5534, 0.4466],
        [0.5585, 0.4415],
        [0.5584, 0.4416],
[2K        [0.5572, 0.4428]], device='cuda:0', grad_fn=<SoftmaxBackward0>)7mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 114/203 [2m0:06:15 â€¢ 0:04:56[0m [2;4m0.30it/s[0m  
[2KClass label: HammerThrowâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 114/203 [2m0:06:15 â€¢ 0:04:56[0m [2;4m0.30it/s[0m  
[2KAttention weights: tensor([[0.5828, 0.4172]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 114/203 [2m0:06:15 â€¢ 0:04:56[0m [2;4m0.30it/s[0m  
[2KStep 0 - TTA Loss: 0.5621â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 114/203 [2m0:06:15 â€¢ 0:04:56[0m [2;4m0.30it/s[0m  
[2KAttention weights: tensor([[0.6289, 0.3711]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 114/203 [2m0:06:15 â€¢ 0:04:56[0m [2;4m0.30it/s[0m  
[2KAttention weights: tensor([[0.7096, 0.2904]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 114/203 [2m0:06:15 â€¢ 0:04:56[0m [2;4m0.30it/s[0m  
[2KAttention weights: tensor([[0.8068, 0.1932]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 114/203 [2m0:06:15 â€¢ 0:04:56[0m [2;4m0.30it/s[0m  
[2KAttention weights: tensor([[0.8885, 0.1115]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 114/203 [2m0:06:15 â€¢ 0:04:56[0m [2;4m0.30it/s[0m  
[2KAttention weights: tensor([[0.9421, 0.0579]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 114/203 [2m0:06:15 â€¢ 0:04:56[0m [2;4m0.30it/s[0m  
[2KAttention weights: tensor([[0.9683, 0.0317]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 114/203 [2m0:06:15 â€¢ 0:04:56[0m [2;4m0.30it/s[0m  
[2KAttention weights: tensor([[0.9792, 0.0208]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 114/203 [2m0:06:15 â€¢ 0:04:56[0m [2;4m0.30it/s[0m  
[2KAttention weights: tensor([[0.9832, 0.0168]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 114/203 [2m0:06:15 â€¢ 0:04:56[0m [2;4m0.30it/s[0m  
[2KAttention weights: tensor([[0.9844, 0.0156]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 114/203 [2m0:06:15 â€¢ 0:04:56[0m [2;4m0.30it/s[0m  
[2KAttention weights: tensor([[0.5808, 0.4192]], device='cuda:0')[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 114/203 [2m0:06:15 â€¢ 0:04:56[0m [2;4m0.30it/s[0m  
[2KAttention weights: tensor([[0.9639, 0.0361],0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 114/203 [2m0:06:15 â€¢ 0:04:56[0m [2;4m0.30it/s[0m  
        [0.8569, 0.1431],
        [0.9356, 0.0644],
        [0.9547, 0.0453],
        [0.9846, 0.0154],
        [0.9612, 0.0388],
        [0.9453, 0.0547],
        [0.9451, 0.0549],
        [0.9383, 0.0617],
[2K        [0.9762, 0.0238]], device='cuda:0')[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 114/203 [2m0:06:15 â€¢ 0:04:56[0m [2;4m0.30it/s[0m  
[2KAttention weights: tensor([[0.5590, 0.4410],â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 115/203 [2m0:06:31 â€¢ 0:08:02[0m [2;4m0.18it/s[0m  
        [0.5544, 0.4456],
        [0.5562, 0.4438],
        [0.5572, 0.4428],
        [0.5575, 0.4425],
        [0.5546, 0.4454],
        [0.5535, 0.4465],
        [0.5586, 0.4414],
        [0.5585, 0.4415],
[2K        [0.5573, 0.4427]], device='cuda:0', grad_fn=<SoftmaxBackward0>);5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 115/203 [2m0:06:31 â€¢ 0:08:02[0m [2;4m0.18it/s[0m  
[2KClass label: HammerThrowâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 115/203 [2m0:06:31 â€¢ 0:08:02[0m [2;4m0.18it/s[0m  
[2KAttention weights: tensor([[0.5823, 0.4177]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 115/203 [2m0:06:31 â€¢ 0:08:02[0m [2;4m0.18it/s[0m  
[2KStep 0 - TTA Loss: 0.7709â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 115/203 [2m0:06:31 â€¢ 0:08:02[0m [2;4m0.18it/s[0m  
[2KAttention weights: tensor([[0.5823, 0.4177]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 115/203 [2m0:06:31 â€¢ 0:08:02[0m [2;4m0.18it/s[0m  
[2KAttention weights: tensor([[0.5852, 0.4148]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 115/203 [2m0:06:31 â€¢ 0:08:02[0m [2;4m0.18it/s[0m  
[2KAttention weights: tensor([[0.5965, 0.4035]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 115/203 [2m0:06:31 â€¢ 0:08:02[0m [2;4m0.18it/s[0m  
[2KAttention weights: tensor([[0.6201, 0.3799]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 115/203 [2m0:06:31 â€¢ 0:08:02[0m [2;4m0.18it/s[0m  
[2KAttention weights: tensor([[0.6580, 0.3420]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 115/203 [2m0:06:31 â€¢ 0:08:02[0m [2;4m0.18it/s[0m  
[2KAttention weights: tensor([[0.7087, 0.2913]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 115/203 [2m0:06:31 â€¢ 0:08:02[0m [2;4m0.18it/s[0m  
[2KAttention weights: tensor([[0.7692, 0.2308]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 115/203 [2m0:06:31 â€¢ 0:08:02[0m [2;4m0.18it/s[0m  
[2KAttention weights: tensor([[0.8301, 0.1699]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 115/203 [2m0:06:31 â€¢ 0:08:02[0m [2;4m0.18it/s[0m  
[2KAttention weights: tensor([[0.8857, 0.1143]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 115/203 [2m0:06:31 â€¢ 0:08:02[0m [2;4m0.18it/s[0m  
[2KAttention weights: tensor([[0.5720, 0.4280]], device='cuda:0')â•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 115/203 [2m0:06:31 â€¢ 0:08:02[0m [2;4m0.18it/s[0m  
[2KAttention weights: tensor([[0.8854, 0.1146],0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 115/203 [2m0:06:31 â€¢ 0:08:02[0m [2;4m0.18it/s[0m  
        [0.7599, 0.2401],
        [0.8343, 0.1657],
        [0.8721, 0.1279],
        [0.9237, 0.0763],
        [0.8784, 0.1216],
        [0.8437, 0.1563],
        [0.8632, 0.1368],
        [0.8583, 0.1417],
[2K        [0.9113, 0.0887]], device='cuda:0')[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 115/203 [2m0:06:31 â€¢ 0:08:02[0m [2;4m0.18it/s[0m  
[2KAttention weights: tensor([[0.5590, 0.4410],â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 116/203 [2m0:06:32 â€¢ 0:06:59[0m [2;4m0.21it/s[0m  
        [0.5544, 0.4456],
        [0.5562, 0.4438],
        [0.5573, 0.4427],
        [0.5576, 0.4424],
        [0.5546, 0.4454],
        [0.5536, 0.4464],
        [0.5586, 0.4414],
        [0.5585, 0.4415],
[2K        [0.5573, 0.4427]], device='cuda:0', grad_fn=<SoftmaxBackward0>);5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 116/203 [2m0:06:32 â€¢ 0:06:59[0m [2;4m0.21it/s[0m  
[2KClass label: HammerThrowâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 116/203 [2m0:06:32 â€¢ 0:06:59[0m [2;4m0.21it/s[0m  
[2KAttention weights: tensor([[0.5857, 0.4143]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 116/203 [2m0:06:32 â€¢ 0:06:59[0m [2;4m0.21it/s[0m  
[2KStep 0 - TTA Loss: 0.5721â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 116/203 [2m0:06:32 â€¢ 0:06:59[0m [2;4m0.21it/s[0m  
[2KAttention weights: tensor([[0.6964, 0.3036]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 116/203 [2m0:06:32 â€¢ 0:06:59[0m [2;4m0.21it/s[0m  
[2KAttention weights: tensor([[0.7928, 0.2072]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 116/203 [2m0:06:32 â€¢ 0:06:59[0m [2;4m0.21it/s[0m  
[2KAttention weights: tensor([[0.8666, 0.1334]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 116/203 [2m0:06:32 â€¢ 0:06:59[0m [2;4m0.21it/s[0m  
[2KAttention weights: tensor([[0.9094, 0.0906]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 116/203 [2m0:06:32 â€¢ 0:06:59[0m [2;4m0.21it/s[0m  
[2KAttention weights: tensor([[0.9316, 0.0684]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 116/203 [2m0:06:32 â€¢ 0:06:59[0m [2;4m0.21it/s[0m  
[2KAttention weights: tensor([[0.9441, 0.0559]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 116/203 [2m0:06:32 â€¢ 0:06:59[0m [2;4m0.21it/s[0m  
[2KAttention weights: tensor([[0.9537, 0.0463]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 116/203 [2m0:06:32 â€¢ 0:06:59[0m [2;4m0.21it/s[0m  
[2KAttention weights: tensor([[0.9605, 0.0395]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 116/203 [2m0:06:32 â€¢ 0:06:59[0m [2;4m0.21it/s[0m  
[2KAttention weights: tensor([[0.9641, 0.0359]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 116/203 [2m0:06:32 â€¢ 0:06:59[0m [2;4m0.21it/s[0m  
[2KAttention weights: tensor([[0.5747, 0.4253]], device='cuda:0')â•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 116/203 [2m0:06:32 â€¢ 0:06:59[0m [2;4m0.21it/s[0m  
[2KAttention weights: tensor([[0.9334, 0.0666],0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 116/203 [2m0:06:32 â€¢ 0:06:59[0m [2;4m0.21it/s[0m  
        [0.8133, 0.1867],
        [0.8958, 0.1042],
        [0.9210, 0.0790],
        [0.9653, 0.0347],
        [0.9311, 0.0689],
        [0.9067, 0.0933],
        [0.9122, 0.0878],
        [0.9071, 0.0929],
[2K        [0.9534, 0.0466]], device='cuda:0')[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 116/203 [2m0:06:32 â€¢ 0:06:59[0m [2;4m0.21it/s[0m  
[2KAttention weights: tensor([[0.5591, 0.4409],â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 117/203 [2m0:06:34 â€¢ 0:06:53[0m [2;4m0.21it/s[0m   
        [0.5545, 0.4455],
        [0.5562, 0.4438],
        [0.5573, 0.4427],
        [0.5577, 0.4423],
        [0.5546, 0.4454],
        [0.5537, 0.4463],
        [0.5586, 0.4414],
        [0.5586, 0.4414],
[2K        [0.5574, 0.4426]], device='cuda:0', grad_fn=<SoftmaxBackward0>)37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 117/203 [2m0:06:34 â€¢ 0:06:53[0m [2;4m0.21it/s[0m  
[2KClass label: HammerThrowâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 117/203 [2m0:06:34 â€¢ 0:06:53[0m [2;4m0.21it/s[0m  
[2KAttention weights: tensor([[0.5869, 0.4131]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 117/203 [2m0:06:34 â€¢ 0:06:53[0m [2;4m0.21it/s[0m  
[2KStep 0 - TTA Loss: 0.7244â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 117/203 [2m0:06:34 â€¢ 0:06:53[0m [2;4m0.21it/s[0m  
[2KAttention weights: tensor([[0.5869, 0.4131]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 117/203 [2m0:06:34 â€¢ 0:06:53[0m [2;4m0.21it/s[0m  
[2KAttention weights: tensor([[0.5951, 0.4049]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 117/203 [2m0:06:34 â€¢ 0:06:53[0m [2;4m0.21it/s[0m  
[2KAttention weights: tensor([[0.6266, 0.3734]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 117/203 [2m0:06:34 â€¢ 0:06:53[0m [2;4m0.21it/s[0m  
[2KAttention weights: tensor([[0.6906, 0.3094]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 117/203 [2m0:06:34 â€¢ 0:06:53[0m [2;4m0.21it/s[0m  
[2KAttention weights: tensor([[0.7862, 0.2138]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 117/203 [2m0:06:34 â€¢ 0:06:53[0m [2;4m0.21it/s[0m  
[2KAttention weights: tensor([[0.8901, 0.1099]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 117/203 [2m0:06:34 â€¢ 0:06:53[0m [2;4m0.21it/s[0m  
[2KAttention weights: tensor([[0.9655, 0.0345]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 117/203 [2m0:06:34 â€¢ 0:06:53[0m [2;4m0.21it/s[0m  
[2KAttention weights: tensor([[0.9951, 0.0049]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 117/203 [2m0:06:34 â€¢ 0:06:53[0m [2;4m0.21it/s[0m  
[2KAttention weights: tensor([[9.9934e-01, 6.6023e-04]], device='cuda:0', grad_fn=<SoftmaxBackward0>)/203 [2m0:06:34 â€¢ 0:06:53[0m [2;4m0.21it/s[0m  
[2KAttention weights: tensor([[0.5997, 0.4003]], device='cuda:0')m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 117/203 [2m0:06:34 â€¢ 0:06:53[0m [2;4m0.21it/s[0m  
[2KAttention weights: tensor([[9.9904e-01, 9.5935e-04],5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 117/203 [2m0:06:34 â€¢ 0:06:53[0m [2;4m0.21it/s[0m  
        [9.7757e-01, 2.2429e-02],
        [9.9716e-01, 2.8402e-03],
        [9.9810e-01, 1.9048e-03],
        [9.9989e-01, 1.0684e-04],
        [9.9909e-01, 9.1041e-04],
        [9.9826e-01, 1.7392e-03],
        [9.9727e-01, 2.7326e-03],
        [9.9646e-01, 3.5372e-03],
[2K        [9.9961e-01, 3.8550e-04]], device='cuda:0');5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 117/203 [2m0:06:34 â€¢ 0:06:53[0m [2;4m0.21it/s[0m  
[2KAttention weights: tensor([[0.5592, 0.4408],â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 118/203 [2m0:06:36 â€¢ 0:06:25[0m [2;4m0.22it/s[0m  
        [0.5545, 0.4455],
        [0.5564, 0.4436],
        [0.5574, 0.4426],
        [0.5579, 0.4421],
        [0.5548, 0.4452],
        [0.5538, 0.4462],
        [0.5587, 0.4413],
        [0.5587, 0.4413],
[2K        [0.5576, 0.4424]], device='cuda:0', grad_fn=<SoftmaxBackward0>)37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 118/203 [2m0:06:36 â€¢ 0:06:25[0m [2;4m0.22it/s[0m  
[2KClass label: Billiardsâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 118/203 [2m0:06:36 â€¢ 0:06:25[0m [2;4m0.22it/s[0m  
[2KAttention weights: tensor([[0.5795, 0.4205]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 118/203 [2m0:06:36 â€¢ 0:06:25[0m [2;4m0.22it/s[0m  
[2KStep 0 - TTA Loss: 0.5002â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 118/203 [2m0:06:36 â€¢ 0:06:25[0m [2;4m0.22it/s[0m  
[2KAttention weights: tensor([[0.7518, 0.2482]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 118/203 [2m0:06:36 â€¢ 0:06:25[0m [2;4m0.22it/s[0m  
[2KAttention weights: tensor([[0.8696, 0.1304]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 118/203 [2m0:06:36 â€¢ 0:06:25[0m [2;4m0.22it/s[0m  
[2KAttention weights: tensor([[0.9280, 0.0720]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 118/203 [2m0:06:36 â€¢ 0:06:25[0m [2;4m0.22it/s[0m  
[2KAttention weights: tensor([[0.9561, 0.0439]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 118/203 [2m0:06:36 â€¢ 0:06:25[0m [2;4m0.22it/s[0m  
[2KAttention weights: tensor([[0.9741, 0.0259]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 118/203 [2m0:06:36 â€¢ 0:06:25[0m [2;4m0.22it/s[0m  
[2KAttention weights: tensor([[0.9851, 0.0149]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 118/203 [2m0:06:36 â€¢ 0:06:25[0m [2;4m0.22it/s[0m  
[2KAttention weights: tensor([[0.9905, 0.0095]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 118/203 [2m0:06:36 â€¢ 0:06:25[0m [2;4m0.22it/s[0m  
[2KAttention weights: tensor([[0.9928, 0.0072]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 118/203 [2m0:06:36 â€¢ 0:06:25[0m [2;4m0.22it/s[0m  
[2KAttention weights: tensor([[0.9936, 0.0064]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 118/203 [2m0:06:36 â€¢ 0:06:25[0m [2;4m0.22it/s[0m  
[2KAttention weights: tensor([[0.5839, 0.4161]], device='cuda:0')m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 118/203 [2m0:06:36 â€¢ 0:06:25[0m [2;4m0.22it/s[0m  
[2KAttention weights: tensor([[9.9814e-01, 1.8598e-03],5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 118/203 [2m0:06:36 â€¢ 0:06:25[0m [2;4m0.22it/s[0m  
        [9.9378e-01, 6.2235e-03],
        [9.9510e-01, 4.8989e-03],
        [9.9673e-01, 3.2691e-03],
        [9.9967e-01, 3.2992e-04],
        [9.9823e-01, 1.7669e-03],
        [9.9680e-01, 3.2028e-03],
        [9.9612e-01, 3.8809e-03],
        [9.9542e-01, 4.5836e-03],
[2K        [9.9912e-01, 8.8180e-04]], device='cuda:0');5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 118/203 [2m0:06:36 â€¢ 0:06:25[0m [2;4m0.22it/s[0m  
[2KAttention weights: tensor([[0.5593, 0.4407],â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 119/203 [2m0:06:45 â€¢ 0:08:14[0m [2;4m0.17it/s[0m  
        [0.5546, 0.4454],
        [0.5565, 0.4435],
        [0.5575, 0.4425],
        [0.5581, 0.4419],
        [0.5549, 0.4451],
        [0.5539, 0.4461],
        [0.5588, 0.4412],
        [0.5588, 0.4412],
[2K        [0.5577, 0.4423]], device='cuda:0', grad_fn=<SoftmaxBackward0>)37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 119/203 [2m0:06:45 â€¢ 0:08:14[0m [2;4m0.17it/s[0m  
[2KClass label: HammerThrowâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 119/203 [2m0:06:45 â€¢ 0:08:14[0m [2;4m0.17it/s[0m  
[2KAttention weights: tensor([[0.5864, 0.4136]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 119/203 [2m0:06:45 â€¢ 0:08:14[0m [2;4m0.17it/s[0m  
[2KStep 0 - TTA Loss: 0.6334â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 119/203 [2m0:06:45 â€¢ 0:08:14[0m [2;4m0.17it/s[0m  
[2KAttention weights: tensor([[0.5864, 0.4136]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 119/203 [2m0:06:45 â€¢ 0:08:14[0m [2;4m0.17it/s[0m  
[2KAttention weights: tensor([[0.5921, 0.4079]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 119/203 [2m0:06:45 â€¢ 0:08:14[0m [2;4m0.17it/s[0m  
[2KAttention weights: tensor([[0.6149, 0.3851]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 119/203 [2m0:06:45 â€¢ 0:08:14[0m [2;4m0.17it/s[0m  
[2KAttention weights: tensor([[0.6634, 0.3366]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 119/203 [2m0:06:45 â€¢ 0:08:14[0m [2;4m0.17it/s[0m  
[2KAttention weights: tensor([[0.7399, 0.2601]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 119/203 [2m0:06:45 â€¢ 0:08:14[0m [2;4m0.17it/s[0m  
[2KAttention weights: tensor([[0.8345, 0.1655]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 119/203 [2m0:06:45 â€¢ 0:08:14[0m [2;4m0.17it/s[0m  
[2KAttention weights: tensor([[0.9196, 0.0804]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 119/203 [2m0:06:45 â€¢ 0:08:14[0m [2;4m0.17it/s[0m  
[2KAttention weights: tensor([[0.9693, 0.0307]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 119/203 [2m0:06:45 â€¢ 0:08:14[0m [2;4m0.17it/s[0m  
[2KAttention weights: tensor([[0.9888, 0.0112]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 119/203 [2m0:06:45 â€¢ 0:08:14[0m [2;4m0.17it/s[0m  
[2KAttention weights: tensor([[0.5838, 0.4162]], device='cuda:0')m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 119/203 [2m0:06:45 â€¢ 0:08:14[0m [2;4m0.17it/s[0m  
[2KAttention weights: tensor([[0.9870, 0.0130],[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 119/203 [2m0:06:45 â€¢ 0:08:14[0m [2;4m0.17it/s[0m  
        [0.9794, 0.0206],
        [0.9740, 0.0260],
        [0.9817, 0.0183],
        [0.9954, 0.0046],
        [0.9871, 0.0129],
        [0.9798, 0.0202],
        [0.9807, 0.0193],
        [0.9789, 0.0211],
[2K        [0.9921, 0.0079]], device='cuda:0')[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 119/203 [2m0:06:45 â€¢ 0:08:14[0m [2;4m0.17it/s[0m  
[2KAttention weights: tensor([[0.5594, 0.4406],â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 120/203 [2m0:06:51 â€¢ 0:05:34[0m [2;4m0.25it/s[0m  
        [0.5547, 0.4453],
        [0.5566, 0.4434],
        [0.5576, 0.4424],
        [0.5582, 0.4418],
        [0.5550, 0.4450],
        [0.5540, 0.4460],
        [0.5589, 0.4411],
        [0.5589, 0.4411],
[2K        [0.5578, 0.4422]], device='cuda:0', grad_fn=<SoftmaxBackward0>)8;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 120/203 [2m0:06:51 â€¢ 0:05:34[0m [2;4m0.25it/s[0m  
[2KClass label: SoccerPenaltyâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 120/203 [2m0:06:51 â€¢ 0:05:34[0m [2;4m0.25it/s[0m  
[2KAttention weights: tensor([[0.6355, 0.3645]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 120/203 [2m0:06:51 â€¢ 0:05:34[0m [2;4m0.25it/s[0m  
[2KStep 0 - TTA Loss: 0.9686â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 120/203 [2m0:06:51 â€¢ 0:05:34[0m [2;4m0.25it/s[0m  
[2KAttention weights: tensor([[0.7634, 0.2366]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 120/203 [2m0:06:51 â€¢ 0:05:34[0m [2;4m0.25it/s[0m  
[2KAttention weights: tensor([[0.8583, 0.1417]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 120/203 [2m0:06:51 â€¢ 0:05:34[0m [2;4m0.25it/s[0m  
[2KAttention weights: tensor([[0.9266, 0.0734]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 120/203 [2m0:06:51 â€¢ 0:05:34[0m [2;4m0.25it/s[0m  
[2KAttention weights: tensor([[0.9614, 0.0386]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 120/203 [2m0:06:51 â€¢ 0:05:34[0m [2;4m0.25it/s[0m  
[2KAttention weights: tensor([[0.9784, 0.0216]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 120/203 [2m0:06:51 â€¢ 0:05:34[0m [2;4m0.25it/s[0m  
[2KAttention weights: tensor([[0.9822, 0.0178]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 120/203 [2m0:06:51 â€¢ 0:05:34[0m [2;4m0.25it/s[0m  
[2KAttention weights: tensor([[0.9840, 0.0160]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 120/203 [2m0:06:51 â€¢ 0:05:34[0m [2;4m0.25it/s[0m  
[2KAttention weights: tensor([[0.9825, 0.0175]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 120/203 [2m0:06:51 â€¢ 0:05:34[0m [2;4m0.25it/s[0m  
[2KAttention weights: tensor([[0.9816, 0.0184]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 120/203 [2m0:06:51 â€¢ 0:05:34[0m [2;4m0.25it/s[0m  
[2KAttention weights: tensor([[0.5778, 0.4222]], device='cuda:0')mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 120/203 [2m0:06:51 â€¢ 0:05:34[0m [2;4m0.25it/s[0m  
[2KAttention weights: tensor([[0.9741, 0.0259],[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 120/203 [2m0:06:51 â€¢ 0:05:34[0m [2;4m0.25it/s[0m  
        [0.9567, 0.0433],
        [0.9461, 0.0539],
        [0.9642, 0.0358],
        [0.9872, 0.0128],
        [0.9743, 0.0257],
        [0.9620, 0.0380],
        [0.9813, 0.0187],
        [0.9612, 0.0388],
[2K        [0.9814, 0.0186]], device='cuda:0')[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 120/203 [2m0:06:51 â€¢ 0:05:34[0m [2;4m0.25it/s[0m  
[2KAttention weights: tensor([[0.5595, 0.4405],â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 121/203 [2m0:06:51 â€¢ 0:04:46[0m [2;4m0.29it/s[0m  
        [0.5548, 0.4452],
        [0.5567, 0.4433],
        [0.5576, 0.4424],
        [0.5584, 0.4416],
        [0.5551, 0.4449],
        [0.5542, 0.4458],
        [0.5590, 0.4410],
        [0.5589, 0.4411],
[2K        [0.5580, 0.4420]], device='cuda:0', grad_fn=<SoftmaxBackward0>)8;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 121/203 [2m0:06:51 â€¢ 0:04:46[0m [2;4m0.29it/s[0m  
[2KClass label: SoccerPenaltyâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 121/203 [2m0:06:51 â€¢ 0:04:46[0m [2;4m0.29it/s[0m  
[2KAttention weights: tensor([[0.6382, 0.3618]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 121/203 [2m0:06:51 â€¢ 0:04:46[0m [2;4m0.29it/s[0m  
[2KStep 0 - TTA Loss: 0.9655â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 121/203 [2m0:06:51 â€¢ 0:04:46[0m [2;4m0.29it/s[0m  
[2KAttention weights: tensor([[0.6382, 0.3618]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 121/203 [2m0:06:51 â€¢ 0:04:46[0m [2;4m0.29it/s[0m  
[2KAttention weights: tensor([[0.6366, 0.3634]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 121/203 [2m0:06:51 â€¢ 0:04:46[0m [2;4m0.29it/s[0m  
[2KAttention weights: tensor([[0.6339, 0.3661]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 121/203 [2m0:06:51 â€¢ 0:04:46[0m [2;4m0.29it/s[0m  
[2KAttention weights: tensor([[0.6331, 0.3669]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 121/203 [2m0:06:51 â€¢ 0:04:46[0m [2;4m0.29it/s[0m  
[2KAttention weights: tensor([[0.6428, 0.3572]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 121/203 [2m0:06:51 â€¢ 0:04:46[0m [2;4m0.29it/s[0m  
[2KAttention weights: tensor([[0.6682, 0.3318]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 121/203 [2m0:06:51 â€¢ 0:04:46[0m [2;4m0.29it/s[0m  
[2KAttention weights: tensor([[0.7062, 0.2938]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 121/203 [2m0:06:51 â€¢ 0:04:46[0m [2;4m0.29it/s[0m  
[2KAttention weights: tensor([[0.7477, 0.2523]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 121/203 [2m0:06:51 â€¢ 0:04:46[0m [2;4m0.29it/s[0m  
[2KAttention weights: tensor([[0.7809, 0.2191]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 121/203 [2m0:06:51 â€¢ 0:04:46[0m [2;4m0.29it/s[0m  
[2KAttention weights: tensor([[0.5618, 0.4382]], device='cuda:0')mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 121/203 [2m0:06:51 â€¢ 0:04:46[0m [2;4m0.29it/s[0m  
[2KAttention weights: tensor([[0.7597, 0.2403],[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 121/203 [2m0:06:51 â€¢ 0:04:46[0m [2;4m0.29it/s[0m  
        [0.7159, 0.2841],
        [0.6937, 0.3063],
        [0.7532, 0.2468],
        [0.7636, 0.2364],
        [0.7481, 0.2519],
        [0.7002, 0.2998],
        [0.8032, 0.1968],
        [0.7642, 0.2358],
[2K        [0.7804, 0.2196]], device='cuda:0')[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 121/203 [2m0:06:51 â€¢ 0:04:46[0m [2;4m0.29it/s[0m  
[2KAttention weights: tensor([[0.5596, 0.4404],â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 122/203 [2m0:06:52 â€¢ 0:04:07[0m [2;4m0.33it/s[0m   
        [0.5548, 0.4452],
        [0.5567, 0.4433],
        [0.5577, 0.4423],
        [0.5584, 0.4416],
        [0.5551, 0.4449],
        [0.5542, 0.4458],
        [0.5590, 0.4410],
        [0.5590, 0.4410],
[2K        [0.5580, 0.4420]], device='cuda:0', grad_fn=<SoftmaxBackward0>)237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 122/203 [2m0:06:52 â€¢ 0:04:07[0m [2;4m0.33it/s[0m  
[2KClass label: SoccerPenaltyâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 122/203 [2m0:06:52 â€¢ 0:04:07[0m [2;4m0.33it/s[0m  
[2KAttention weights: tensor([[0.6376, 0.3624]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 122/203 [2m0:06:52 â€¢ 0:04:07[0m [2;4m0.33it/s[0m  
[2KStep 0 - TTA Loss: 0.3545â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 122/203 [2m0:06:52 â€¢ 0:04:07[0m [2;4m0.33it/s[0m  
[2KAttention weights: tensor([[0.6959, 0.3041]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 122/203 [2m0:06:52 â€¢ 0:04:07[0m [2;4m0.33it/s[0m  
[2KAttention weights: tensor([[0.7615, 0.2385]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 122/203 [2m0:06:52 â€¢ 0:04:07[0m [2;4m0.33it/s[0m  
[2KAttention weights: tensor([[0.8132, 0.1868]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 122/203 [2m0:06:52 â€¢ 0:04:07[0m [2;4m0.33it/s[0m  
[2KAttention weights: tensor([[0.8473, 0.1527]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 122/203 [2m0:06:52 â€¢ 0:04:07[0m [2;4m0.33it/s[0m  
[2KAttention weights: tensor([[0.8704, 0.1296]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 122/203 [2m0:06:52 â€¢ 0:04:07[0m [2;4m0.33it/s[0m  
[2KAttention weights: tensor([[0.8883, 0.1117]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 122/203 [2m0:06:52 â€¢ 0:04:07[0m [2;4m0.33it/s[0m  
[2KAttention weights: tensor([[0.9024, 0.0976]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 122/203 [2m0:06:52 â€¢ 0:04:07[0m [2;4m0.33it/s[0m  
[2KAttention weights: tensor([[0.9123, 0.0877]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 122/203 [2m0:06:52 â€¢ 0:04:07[0m [2;4m0.33it/s[0m  
[2KAttention weights: tensor([[0.9175, 0.0825]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 122/203 [2m0:06:52 â€¢ 0:04:07[0m [2;4m0.33it/s[0m  
[2KAttention weights: tensor([[0.5664, 0.4336]], device='cuda:0')0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 122/203 [2m0:06:52 â€¢ 0:04:07[0m [2;4m0.33it/s[0m  
[2KAttention weights: tensor([[0.8142, 0.1858],[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 122/203 [2m0:06:52 â€¢ 0:04:07[0m [2;4m0.33it/s[0m  
        [0.7634, 0.2366],
        [0.7206, 0.2794],
        [0.7959, 0.2041],
        [0.8141, 0.1859],
        [0.8097, 0.1903],
        [0.7698, 0.2302],
        [0.9190, 0.0810],
        [0.8070, 0.1930],
[2K        [0.8230, 0.1770]], device='cuda:0')â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 122/203 [2m0:06:52 â€¢ 0:04:07[0m [2;4m0.33it/s[0m  
[2KAttention weights: tensor([[0.5596, 0.4404],â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 123/203 [2m0:06:53 â€¢ 0:03:48[0m [2;4m0.35it/s[0m  
        [0.5549, 0.4451],
        [0.5567, 0.4433],
        [0.5577, 0.4423],
        [0.5585, 0.4415],
        [0.5552, 0.4448],
        [0.5542, 0.4458],
        [0.5591, 0.4409],
        [0.5590, 0.4410],
[2K        [0.5580, 0.4420]], device='cuda:0', grad_fn=<SoftmaxBackward0>)237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 123/203 [2m0:06:53 â€¢ 0:03:48[0m [2;4m0.35it/s[0m  
[2KClass label: TennisSwingâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 123/203 [2m0:06:53 â€¢ 0:03:48[0m [2;4m0.35it/s[0m  
[2KAttention weights: tensor([[0.6464, 0.3536]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 123/203 [2m0:06:53 â€¢ 0:03:48[0m [2;4m0.35it/s[0m  
[2KStep 0 - TTA Loss: 0.5140â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 123/203 [2m0:06:53 â€¢ 0:03:48[0m [2;4m0.35it/s[0m  
[2KAttention weights: tensor([[0.6464, 0.3536]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 123/203 [2m0:06:53 â€¢ 0:03:48[0m [2;4m0.35it/s[0m  
[2KAttention weights: tensor([[0.6496, 0.3504]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 123/203 [2m0:06:53 â€¢ 0:03:48[0m [2;4m0.35it/s[0m  
[2KAttention weights: tensor([[0.6649, 0.3351]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 123/203 [2m0:06:53 â€¢ 0:03:48[0m [2;4m0.35it/s[0m  
[2KAttention weights: tensor([[0.6992, 0.3008]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 123/203 [2m0:06:53 â€¢ 0:03:48[0m [2;4m0.35it/s[0m  
[2KAttention weights: tensor([[0.7569, 0.2431]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 123/203 [2m0:06:53 â€¢ 0:03:48[0m [2;4m0.35it/s[0m  
[2KAttention weights: tensor([[0.8408, 0.1592]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 123/203 [2m0:06:53 â€¢ 0:03:48[0m [2;4m0.35it/s[0m  
[2KAttention weights: tensor([[0.9230, 0.0770]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 123/203 [2m0:06:53 â€¢ 0:03:48[0m [2;4m0.35it/s[0m  
[2KAttention weights: tensor([[0.9734, 0.0266]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 123/203 [2m0:06:53 â€¢ 0:03:48[0m [2;4m0.35it/s[0m  
[2KAttention weights: tensor([[0.9917, 0.0083]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 123/203 [2m0:06:53 â€¢ 0:03:48[0m [2;4m0.35it/s[0m  
[2KAttention weights: tensor([[0.5841, 0.4159]], device='cuda:0')0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 123/203 [2m0:06:53 â€¢ 0:03:48[0m [2;4m0.35it/s[0m  
[2KAttention weights: tensor([[0.9821, 0.0179],[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 123/203 [2m0:06:53 â€¢ 0:03:48[0m [2;4m0.35it/s[0m  
        [0.9547, 0.0453],
        [0.9380, 0.0620],
        [0.9841, 0.0159],
        [0.9729, 0.0271],
        [0.9778, 0.0222],
        [0.9385, 0.0615],
        [0.9853, 0.0147],
        [0.9972, 0.0028],
[2K        [0.9829, 0.0171]], device='cuda:0')â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 123/203 [2m0:06:53 â€¢ 0:03:48[0m [2;4m0.35it/s[0m  
[2KAttention weights: tensor([[0.5597, 0.4403],â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 124/203 [2m0:06:57 â€¢ 0:03:52[0m [2;4m0.34it/s[0m  
        [0.5549, 0.4451],
        [0.5568, 0.4432],
        [0.5578, 0.4422],
        [0.5585, 0.4415],
        [0.5552, 0.4448],
        [0.5543, 0.4457],
        [0.5592, 0.4408],
        [0.5591, 0.4409],
[2K        [0.5581, 0.4419]], device='cuda:0', grad_fn=<SoftmaxBackward0>)237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 124/203 [2m0:06:57 â€¢ 0:03:52[0m [2;4m0.34it/s[0m  
[2KClass label: SoccerPenaltyâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 124/203 [2m0:06:57 â€¢ 0:03:52[0m [2;4m0.34it/s[0m  
[2KAttention weights: tensor([[0.6365, 0.3635]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 124/203 [2m0:06:57 â€¢ 0:03:52[0m [2;4m0.34it/s[0m  
[2KStep 0 - TTA Loss: 0.7484â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 124/203 [2m0:06:57 â€¢ 0:03:52[0m [2;4m0.34it/s[0m  
[2KAttention weights: tensor([[0.7929, 0.2071]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 124/203 [2m0:06:57 â€¢ 0:03:52[0m [2;4m0.34it/s[0m  
[2KAttention weights: tensor([[0.9018, 0.0982]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 124/203 [2m0:06:57 â€¢ 0:03:52[0m [2;4m0.34it/s[0m  
[2KAttention weights: tensor([[0.9580, 0.0420]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 124/203 [2m0:06:57 â€¢ 0:03:52[0m [2;4m0.34it/s[0m  
[2KAttention weights: tensor([[0.9807, 0.0193]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 124/203 [2m0:06:57 â€¢ 0:03:52[0m [2;4m0.34it/s[0m  
[2KAttention weights: tensor([[0.9893, 0.0107]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 124/203 [2m0:06:57 â€¢ 0:03:52[0m [2;4m0.34it/s[0m  
[2KAttention weights: tensor([[0.9926, 0.0074]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 124/203 [2m0:06:57 â€¢ 0:03:52[0m [2;4m0.34it/s[0m  
[2KAttention weights: tensor([[0.9936, 0.0064]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 124/203 [2m0:06:57 â€¢ 0:03:52[0m [2;4m0.34it/s[0m  
[2KAttention weights: tensor([[0.9934, 0.0066]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 124/203 [2m0:06:57 â€¢ 0:03:52[0m [2;4m0.34it/s[0m  
[2KAttention weights: tensor([[0.9932, 0.0068]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 124/203 [2m0:06:57 â€¢ 0:03:52[0m [2;4m0.34it/s[0m  
[2KAttention weights: tensor([[0.5819, 0.4181]], device='cuda:0')0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 124/203 [2m0:06:57 â€¢ 0:03:52[0m [2;4m0.34it/s[0m  
[2KAttention weights: tensor([[0.9823, 0.0177],[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 124/203 [2m0:06:57 â€¢ 0:03:52[0m [2;4m0.34it/s[0m  
        [0.9566, 0.0434],
        [0.9340, 0.0660],
        [0.9823, 0.0177],
        [0.9750, 0.0250],
        [0.9796, 0.0204],
        [0.9485, 0.0515],
        [0.9930, 0.0070],
        [0.9960, 0.0040],
[2K        [0.9824, 0.0176]], device='cuda:0')â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 124/203 [2m0:06:57 â€¢ 0:03:52[0m [2;4m0.34it/s[0m  
[2KAttention weights: tensor([[0.5597, 0.4403],â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 125/203 [2m0:06:59 â€¢ 0:03:41[0m [2;4m0.35it/s[0m  
        [0.5549, 0.4451],
        [0.5568, 0.4432],
        [0.5578, 0.4422],
        [0.5585, 0.4415],
        [0.5552, 0.4448],
        [0.5543, 0.4457],
        [0.5592, 0.4408],
        [0.5591, 0.4409],
[2K        [0.5581, 0.4419]], device='cuda:0', grad_fn=<SoftmaxBackward0>)38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 125/203 [2m0:06:59 â€¢ 0:03:41[0m [2;4m0.35it/s[0m  
[2KClass label: Billiardsâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 125/203 [2m0:06:59 â€¢ 0:03:41[0m [2;4m0.35it/s[0m  
[2KAttention weights: tensor([[0.5808, 0.4192]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 125/203 [2m0:06:59 â€¢ 0:03:41[0m [2;4m0.35it/s[0m  
[2KStep 0 - TTA Loss: 0.5709â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 125/203 [2m0:06:59 â€¢ 0:03:41[0m [2;4m0.35it/s[0m  
[2KAttention weights: tensor([[0.5808, 0.4192]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 125/203 [2m0:06:59 â€¢ 0:03:41[0m [2;4m0.35it/s[0m  
[2KAttention weights: tensor([[0.5810, 0.4190]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 125/203 [2m0:06:59 â€¢ 0:03:41[0m [2;4m0.35it/s[0m  
[2KAttention weights: tensor([[0.5837, 0.4163]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 125/203 [2m0:06:59 â€¢ 0:03:41[0m [2;4m0.35it/s[0m  
[2KAttention weights: tensor([[0.5931, 0.4069]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 125/203 [2m0:06:59 â€¢ 0:03:41[0m [2;4m0.35it/s[0m  
[2KAttention weights: tensor([[0.6130, 0.3870]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 125/203 [2m0:06:59 â€¢ 0:03:41[0m [2;4m0.35it/s[0m  
[2KAttention weights: tensor([[0.6446, 0.3554]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 125/203 [2m0:06:59 â€¢ 0:03:41[0m [2;4m0.35it/s[0m  
[2KAttention weights: tensor([[0.6828, 0.3172]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 125/203 [2m0:06:59 â€¢ 0:03:41[0m [2;4m0.35it/s[0m  
[2KAttention weights: tensor([[0.7198, 0.2802]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 125/203 [2m0:06:59 â€¢ 0:03:41[0m [2;4m0.35it/s[0m  
[2KAttention weights: tensor([[0.7546, 0.2454]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 125/203 [2m0:06:59 â€¢ 0:03:41[0m [2;4m0.35it/s[0m  
[2KAttention weights: tensor([[0.5593, 0.4407]], device='cuda:0')4mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 125/203 [2m0:06:59 â€¢ 0:03:41[0m [2;4m0.35it/s[0m  
[2KAttention weights: tensor([[0.6183, 0.3817],[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 125/203 [2m0:06:59 â€¢ 0:03:41[0m [2;4m0.35it/s[0m  
        [0.7991, 0.2009],
        [0.6186, 0.3814],
        [0.6782, 0.3218],
        [0.5698, 0.4302],
        [0.5834, 0.4166],
        [0.5111, 0.4889],
        [0.3698, 0.6302],
        [0.7599, 0.2401],
[2K        [0.6588, 0.3412]], device='cuda:0')â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 125/203 [2m0:06:59 â€¢ 0:03:41[0m [2;4m0.35it/s[0m  
[2KAttention weights: tensor([[0.5596, 0.4404],â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 126/203 [2m0:07:02 â€¢ 0:04:04[0m [2;4m0.32it/s[0m  
        [0.5549, 0.4451],
        [0.5567, 0.4433],
        [0.5577, 0.4423],
        [0.5584, 0.4416],
        [0.5551, 0.4449],
        [0.5542, 0.4458],
        [0.5590, 0.4410],
        [0.5590, 0.4410],
[2K        [0.5580, 0.4420]], device='cuda:0', grad_fn=<SoftmaxBackward0>)38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 126/203 [2m0:07:02 â€¢ 0:04:04[0m [2;4m0.32it/s[0m  
[2KClass label: BaseballPitchâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 126/203 [2m0:07:02 â€¢ 0:04:04[0m [2;4m0.32it/s[0m  
[2KAttention weights: tensor([[0.6176, 0.3824]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 126/203 [2m0:07:02 â€¢ 0:04:04[0m [2;4m0.32it/s[0m  
[2KStep 0 - TTA Loss: 0.7143â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 126/203 [2m0:07:02 â€¢ 0:04:04[0m [2;4m0.32it/s[0m  
[2KAttention weights: tensor([[0.6674, 0.3326]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 126/203 [2m0:07:02 â€¢ 0:04:04[0m [2;4m0.32it/s[0m  
[2KAttention weights: tensor([[0.7417, 0.2583]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 126/203 [2m0:07:02 â€¢ 0:04:04[0m [2;4m0.32it/s[0m  
[2KAttention weights: tensor([[0.8226, 0.1774]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 126/203 [2m0:07:02 â€¢ 0:04:04[0m [2;4m0.32it/s[0m  
[2KAttention weights: tensor([[0.8881, 0.1119]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 126/203 [2m0:07:02 â€¢ 0:04:04[0m [2;4m0.32it/s[0m  
[2KAttention weights: tensor([[0.9317, 0.0683]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 126/203 [2m0:07:02 â€¢ 0:04:04[0m [2;4m0.32it/s[0m  
[2KAttention weights: tensor([[0.9542, 0.0458]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 126/203 [2m0:07:02 â€¢ 0:04:04[0m [2;4m0.32it/s[0m  
[2KAttention weights: tensor([[0.9645, 0.0355]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 126/203 [2m0:07:02 â€¢ 0:04:04[0m [2;4m0.32it/s[0m  
[2KAttention weights: tensor([[0.9689, 0.0311]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 126/203 [2m0:07:02 â€¢ 0:04:04[0m [2;4m0.32it/s[0m  
[2KAttention weights: tensor([[0.9715, 0.0285]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 126/203 [2m0:07:02 â€¢ 0:04:04[0m [2;4m0.32it/s[0m  
[2KAttention weights: tensor([[0.5768, 0.4232]], device='cuda:0')4mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 126/203 [2m0:07:02 â€¢ 0:04:04[0m [2;4m0.32it/s[0m  
[2KAttention weights: tensor([[0.9721, 0.0279],[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 126/203 [2m0:07:02 â€¢ 0:04:04[0m [2;4m0.32it/s[0m  
        [0.9134, 0.0866],
        [0.8235, 0.1765],
        [0.9383, 0.0617],
        [0.9056, 0.0944],
        [0.8884, 0.1116],
        [0.8357, 0.1643],
        [0.8049, 0.1951],
        [0.9386, 0.0614],
[2K        [0.9364, 0.0636]], device='cuda:0')â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 126/203 [2m0:07:02 â€¢ 0:04:04[0m [2;4m0.32it/s[0m  
[2KAttention weights: tensor([[0.5595, 0.4405],â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 127/203 [2m0:07:05 â€¢ 0:04:01[0m [2;4m0.32it/s[0m   
        [0.5549, 0.4451],
        [0.5567, 0.4433],
        [0.5577, 0.4423],
        [0.5584, 0.4416],
        [0.5551, 0.4449],
        [0.5542, 0.4458],
        [0.5589, 0.4411],
        [0.5590, 0.4410],
[2K        [0.5580, 0.4420]], device='cuda:0', grad_fn=<SoftmaxBackward0>);237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 127/203 [2m0:07:05 â€¢ 0:04:01[0m [2;4m0.32it/s[0m  
[2KClass label: ThrowDiscusâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 127/203 [2m0:07:05 â€¢ 0:04:01[0m [2;4m0.32it/s[0m  
[2KAttention weights: tensor([[0.6331, 0.3669]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 127/203 [2m0:07:05 â€¢ 0:04:01[0m [2;4m0.32it/s[0m  
[2KStep 0 - TTA Loss: 0.6748â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 127/203 [2m0:07:05 â€¢ 0:04:01[0m [2;4m0.32it/s[0m  
[2KAttention weights: tensor([[0.6331, 0.3669]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 127/203 [2m0:07:05 â€¢ 0:04:01[0m [2;4m0.32it/s[0m  
[2KAttention weights: tensor([[0.6366, 0.3634]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 127/203 [2m0:07:05 â€¢ 0:04:01[0m [2;4m0.32it/s[0m  
[2KAttention weights: tensor([[0.6503, 0.3497]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 127/203 [2m0:07:05 â€¢ 0:04:01[0m [2;4m0.32it/s[0m  
[2KAttention weights: tensor([[0.6798, 0.3202]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 127/203 [2m0:07:05 â€¢ 0:04:01[0m [2;4m0.32it/s[0m  
[2KAttention weights: tensor([[0.7299, 0.2701]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 127/203 [2m0:07:05 â€¢ 0:04:01[0m [2;4m0.32it/s[0m  
[2KAttention weights: tensor([[0.8014, 0.1986]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 127/203 [2m0:07:05 â€¢ 0:04:01[0m [2;4m0.32it/s[0m  
[2KAttention weights: tensor([[0.8810, 0.1190]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 127/203 [2m0:07:05 â€¢ 0:04:01[0m [2;4m0.32it/s[0m  
[2KAttention weights: tensor([[0.9489, 0.0511]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 127/203 [2m0:07:05 â€¢ 0:04:01[0m [2;4m0.32it/s[0m  
[2KAttention weights: tensor([[0.9874, 0.0126]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 127/203 [2m0:07:05 â€¢ 0:04:01[0m [2;4m0.32it/s[0m  
[2KAttention weights: tensor([[0.5898, 0.4102]], device='cuda:0')[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 127/203 [2m0:07:05 â€¢ 0:04:01[0m [2;4m0.32it/s[0m  
[2KAttention weights: tensor([[0.9972, 0.0028],â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 127/203 [2m0:07:05 â€¢ 0:04:01[0m [2;4m0.32it/s[0m  
        [0.9542, 0.0458],
        [0.9781, 0.0219],
        [0.9937, 0.0063],
        [0.9957, 0.0043],
        [0.9926, 0.0074],
        [0.9867, 0.0133],
        [0.9790, 0.0210],
        [0.9917, 0.0083],
[2K        [0.9979, 0.0021]], device='cuda:0')â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 127/203 [2m0:07:05 â€¢ 0:04:01[0m [2;4m0.32it/s[0m  
[2KAttention weights: tensor([[0.5596, 0.4404],â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 128/203 [2m0:07:09 â€¢ 0:03:22[0m [2;4m0.37it/s[0m  
        [0.5549, 0.4451],
        [0.5567, 0.4433],
        [0.5577, 0.4423],
        [0.5585, 0.4415],
        [0.5551, 0.4449],
        [0.5542, 0.4458],
        [0.5589, 0.4411],
        [0.5590, 0.4410],
[2K        [0.5581, 0.4419]], device='cuda:0', grad_fn=<SoftmaxBackward0>);237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 128/203 [2m0:07:09 â€¢ 0:03:22[0m [2;4m0.37it/s[0m  
[2KClass label: Billiardsâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 128/203 [2m0:07:09 â€¢ 0:03:22[0m [2;4m0.37it/s[0m  
[2KAttention weights: tensor([[0.5817, 0.4183]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 128/203 [2m0:07:09 â€¢ 0:03:22[0m [2;4m0.37it/s[0m  
[2KStep 0 - TTA Loss: 0.4218â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 128/203 [2m0:07:09 â€¢ 0:03:22[0m [2;4m0.37it/s[0m  
[2KAttention weights: tensor([[0.7696, 0.2304]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 128/203 [2m0:07:09 â€¢ 0:03:22[0m [2;4m0.37it/s[0m  
[2KAttention weights: tensor([[0.8894, 0.1106]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 128/203 [2m0:07:09 â€¢ 0:03:22[0m [2;4m0.37it/s[0m  
[2KAttention weights: tensor([[0.9470, 0.0530]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 128/203 [2m0:07:09 â€¢ 0:03:22[0m [2;4m0.37it/s[0m  
[2KAttention weights: tensor([[0.9707, 0.0293]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 128/203 [2m0:07:09 â€¢ 0:03:22[0m [2;4m0.37it/s[0m  
[2KAttention weights: tensor([[0.9808, 0.0192]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 128/203 [2m0:07:09 â€¢ 0:03:22[0m [2;4m0.37it/s[0m  
[2KAttention weights: tensor([[0.9851, 0.0149]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 128/203 [2m0:07:09 â€¢ 0:03:22[0m [2;4m0.37it/s[0m  
[2KAttention weights: tensor([[0.9874, 0.0126]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 128/203 [2m0:07:09 â€¢ 0:03:22[0m [2;4m0.37it/s[0m  
[2KAttention weights: tensor([[0.9886, 0.0114]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 128/203 [2m0:07:09 â€¢ 0:03:22[0m [2;4m0.37it/s[0m  
[2KAttention weights: tensor([[0.9890, 0.0110]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 128/203 [2m0:07:09 â€¢ 0:03:22[0m [2;4m0.37it/s[0m  
[2KAttention weights: tensor([[0.5784, 0.4216]], device='cuda:0')[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 128/203 [2m0:07:09 â€¢ 0:03:22[0m [2;4m0.37it/s[0m  
[2KAttention weights: tensor([[9.9922e-01, 7.8000e-04],8;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 128/203 [2m0:07:09 â€¢ 0:03:22[0m [2;4m0.37it/s[0m  
        [9.8916e-01, 1.0837e-02],
        [9.9341e-01, 6.5855e-03],
        [9.9826e-01, 1.7410e-03],
        [9.9910e-01, 9.0383e-04],
        [9.9825e-01, 1.7491e-03],
        [9.9651e-01, 3.4874e-03],
        [9.9303e-01, 6.9684e-03],
        [9.9774e-01, 2.2577e-03],
[2K        [9.9962e-01, 3.7576e-04]], device='cuda:0')38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 128/203 [2m0:07:09 â€¢ 0:03:22[0m [2;4m0.37it/s[0m  
[2KAttention weights: tensor([[0.5596, 0.4404],â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 129/203 [2m0:07:13 â€¢ 0:03:33[0m [2;4m0.35it/s[0m  
        [0.5549, 0.4451],
        [0.5568, 0.4432],
        [0.5578, 0.4422],
        [0.5585, 0.4415],
        [0.5552, 0.4448],
        [0.5543, 0.4457],
        [0.5589, 0.4411],
        [0.5591, 0.4409],
[2K        [0.5582, 0.4418]], device='cuda:0', grad_fn=<SoftmaxBackward0>);237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 129/203 [2m0:07:13 â€¢ 0:03:33[0m [2;4m0.35it/s[0m  
[2KClass label: Billiardsâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 129/203 [2m0:07:13 â€¢ 0:03:33[0m [2;4m0.35it/s[0m  
[2KAttention weights: tensor([[0.5794, 0.4206]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 129/203 [2m0:07:13 â€¢ 0:03:33[0m [2;4m0.35it/s[0m  
[2KStep 0 - TTA Loss: 0.5320â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 129/203 [2m0:07:13 â€¢ 0:03:33[0m [2;4m0.35it/s[0m  
[2KAttention weights: tensor([[0.5794, 0.4206]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 129/203 [2m0:07:13 â€¢ 0:03:33[0m [2;4m0.35it/s[0m  
[2KAttention weights: tensor([[0.5819, 0.4181]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 129/203 [2m0:07:13 â€¢ 0:03:33[0m [2;4m0.35it/s[0m  
[2KAttention weights: tensor([[0.5917, 0.4083]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 129/203 [2m0:07:13 â€¢ 0:03:33[0m [2;4m0.35it/s[0m  
[2KAttention weights: tensor([[0.6128, 0.3872]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 129/203 [2m0:07:13 â€¢ 0:03:33[0m [2;4m0.35it/s[0m  
[2KAttention weights: tensor([[0.6467, 0.3533]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 129/203 [2m0:07:13 â€¢ 0:03:33[0m [2;4m0.35it/s[0m  
[2KAttention weights: tensor([[0.6896, 0.3104]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 129/203 [2m0:07:13 â€¢ 0:03:33[0m [2;4m0.35it/s[0m  
[2KAttention weights: tensor([[0.7281, 0.2719]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 129/203 [2m0:07:13 â€¢ 0:03:33[0m [2;4m0.35it/s[0m  
[2KAttention weights: tensor([[0.7644, 0.2356]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 129/203 [2m0:07:13 â€¢ 0:03:33[0m [2;4m0.35it/s[0m  
[2KAttention weights: tensor([[0.8312, 0.1688]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 129/203 [2m0:07:13 â€¢ 0:03:33[0m [2;4m0.35it/s[0m  
[2KAttention weights: tensor([[0.5650, 0.4350]], device='cuda:0')[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 129/203 [2m0:07:13 â€¢ 0:03:33[0m [2;4m0.35it/s[0m  
[2KAttention weights: tensor([[0.8987, 0.1013],â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 129/203 [2m0:07:13 â€¢ 0:03:33[0m [2;4m0.35it/s[0m  
        [0.9342, 0.0658],
        [0.8292, 0.1708],
        [0.8877, 0.1123],
        [0.8864, 0.1136],
        [0.8800, 0.1200],
        [0.8430, 0.1570],
        [0.8717, 0.1283],
        [0.8989, 0.1011],
[2K        [0.9160, 0.0840]], device='cuda:0')â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 129/203 [2m0:07:13 â€¢ 0:03:33[0m [2;4m0.35it/s[0m  
[2KAttention weights: tensor([[0.5597, 0.4403],â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 130/203 [2m0:07:17 â€¢ 0:03:14[0m [2;4m0.38it/s[0m  
        [0.5549, 0.4451],
        [0.5568, 0.4432],
        [0.5578, 0.4422],
        [0.5585, 0.4415],
        [0.5552, 0.4448],
        [0.5543, 0.4457],
        [0.5589, 0.4411],
        [0.5591, 0.4409],
[2K        [0.5582, 0.4418]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 130/203 [2m0:07:17 â€¢ 0:03:14[0m [2;4m0.38it/s[0m  
[2KClass label: PoleVaultâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 130/203 [2m0:07:17 â€¢ 0:03:14[0m [2;4m0.38it/s[0m  
[2KAttention weights: tensor([[0.5457, 0.4543]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 130/203 [2m0:07:17 â€¢ 0:03:14[0m [2;4m0.38it/s[0m  
[2KStep 0 - TTA Loss: 0.8942â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 130/203 [2m0:07:17 â€¢ 0:03:14[0m [2;4m0.38it/s[0m  
[2KAttention weights: tensor([[0.6646, 0.3354]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 130/203 [2m0:07:17 â€¢ 0:03:14[0m [2;4m0.38it/s[0m  
[2KAttention weights: tensor([[0.7752, 0.2248]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 130/203 [2m0:07:17 â€¢ 0:03:14[0m [2;4m0.38it/s[0m  
[2KAttention weights: tensor([[0.8554, 0.1446]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 130/203 [2m0:07:17 â€¢ 0:03:14[0m [2;4m0.38it/s[0m  
[2KAttention weights: tensor([[0.9073, 0.0927]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 130/203 [2m0:07:17 â€¢ 0:03:14[0m [2;4m0.38it/s[0m  
[2KAttention weights: tensor([[0.9400, 0.0600]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 130/203 [2m0:07:17 â€¢ 0:03:14[0m [2;4m0.38it/s[0m  
[2KAttention weights: tensor([[0.9589, 0.0411]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 130/203 [2m0:07:17 â€¢ 0:03:14[0m [2;4m0.38it/s[0m  
[2KAttention weights: tensor([[0.9694, 0.0306]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 130/203 [2m0:07:17 â€¢ 0:03:14[0m [2;4m0.38it/s[0m  
[2KAttention weights: tensor([[0.9749, 0.0251]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 130/203 [2m0:07:17 â€¢ 0:03:14[0m [2;4m0.38it/s[0m  
[2KAttention weights: tensor([[0.9773, 0.0227]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 130/203 [2m0:07:17 â€¢ 0:03:14[0m [2;4m0.38it/s[0m  
[2KAttention weights: tensor([[0.5764, 0.4236]], device='cuda:0')24mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 130/203 [2m0:07:17 â€¢ 0:03:14[0m [2;4m0.38it/s[0m  
[2KAttention weights: tensor([[0.9671, 0.0329],â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 130/203 [2m0:07:17 â€¢ 0:03:14[0m [2;4m0.38it/s[0m  
        [0.9943, 0.0057],
        [0.9432, 0.0568],
        [0.9620, 0.0380],
        [0.9696, 0.0304],
        [0.9760, 0.0240],
        [0.9778, 0.0222],
        [0.9677, 0.0323],
        [0.9653, 0.0347],
[2K        [0.9767, 0.0233]], device='cuda:0')â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 130/203 [2m0:07:17 â€¢ 0:03:14[0m [2;4m0.38it/s[0m  
[2KAttention weights: tensor([[0.5597, 0.4403],â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 131/203 [2m0:07:19 â€¢ 0:03:07[0m [2;4m0.39it/s[0m  
        [0.5550, 0.4450],
        [0.5568, 0.4432],
        [0.5578, 0.4422],
        [0.5585, 0.4415],
        [0.5552, 0.4448],
        [0.5543, 0.4457],
        [0.5590, 0.4410],
        [0.5591, 0.4409],
[2K        [0.5582, 0.4418]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 131/203 [2m0:07:19 â€¢ 0:03:07[0m [2;4m0.39it/s[0m  
[2KClass label: CleanAndJerkâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 131/203 [2m0:07:19 â€¢ 0:03:07[0m [2;4m0.39it/s[0m  
[2KAttention weights: tensor([[0.5694, 0.4306]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 131/203 [2m0:07:19 â€¢ 0:03:07[0m [2;4m0.39it/s[0m  
[2KStep 0 - TTA Loss: 0.4785â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 131/203 [2m0:07:19 â€¢ 0:03:07[0m [2;4m0.39it/s[0m  
[2KAttention weights: tensor([[0.5694, 0.4306]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 131/203 [2m0:07:19 â€¢ 0:03:07[0m [2;4m0.39it/s[0m  
[2KAttention weights: tensor([[0.5731, 0.4269]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 131/203 [2m0:07:19 â€¢ 0:03:07[0m [2;4m0.39it/s[0m  
[2KAttention weights: tensor([[0.5892, 0.4108]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 131/203 [2m0:07:19 â€¢ 0:03:07[0m [2;4m0.39it/s[0m  
[2KAttention weights: tensor([[0.6274, 0.3726]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 131/203 [2m0:07:19 â€¢ 0:03:07[0m [2;4m0.39it/s[0m  
[2KAttention weights: tensor([[0.6929, 0.3071]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 131/203 [2m0:07:19 â€¢ 0:03:07[0m [2;4m0.39it/s[0m  
[2KAttention weights: tensor([[0.7787, 0.2213]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 131/203 [2m0:07:19 â€¢ 0:03:07[0m [2;4m0.39it/s[0m  
[2KAttention weights: tensor([[0.8662, 0.1338]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 131/203 [2m0:07:19 â€¢ 0:03:07[0m [2;4m0.39it/s[0m  
[2KAttention weights: tensor([[0.9293, 0.0707]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 131/203 [2m0:07:19 â€¢ 0:03:07[0m [2;4m0.39it/s[0m  
[2KAttention weights: tensor([[0.9670, 0.0330]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 131/203 [2m0:07:19 â€¢ 0:03:07[0m [2;4m0.39it/s[0m  
[2KAttention weights: tensor([[0.5761, 0.4239]], device='cuda:0')24mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 131/203 [2m0:07:19 â€¢ 0:03:07[0m [2;4m0.39it/s[0m  
[2KAttention weights: tensor([[0.9297, 0.0703],â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 131/203 [2m0:07:19 â€¢ 0:03:07[0m [2;4m0.39it/s[0m  
        [0.9252, 0.0748],
        [0.9877, 0.0123],
        [0.9410, 0.0590],
        [0.9606, 0.0394],
        [0.9636, 0.0364],
        [0.9607, 0.0393],
        [0.9234, 0.0766],
        [0.9373, 0.0627],
[2K        [0.9640, 0.0360]], device='cuda:0')â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 131/203 [2m0:07:19 â€¢ 0:03:07[0m [2;4m0.39it/s[0m  
[2KAttention weights: tensor([[0.5597, 0.4403],â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m 132/203 [2m0:07:21 â€¢ 0:03:31[0m [2;4m0.34it/s[0m   
        [0.5550, 0.4450],
        [0.5568, 0.4432],
        [0.5578, 0.4422],
        [0.5585, 0.4415],
        [0.5552, 0.4448],
        [0.5542, 0.4458],
        [0.5590, 0.4410],
        [0.5591, 0.4409],
[2K        [0.5582, 0.4418]], device='cuda:0', grad_fn=<SoftmaxBackward0>)5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m 132/203 [2m0:07:21 â€¢ 0:03:31[0m [2;4m0.34it/s[0m  
[2KClass label: Billiardsâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m 132/203 [2m0:07:21 â€¢ 0:03:31[0m [2;4m0.34it/s[0m  
[2KAttention weights: tensor([[0.5836, 0.4164]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 132/203 [2m0:07:21 â€¢ 0:03:31[0m [2;4m0.34it/s[0m  
[2KStep 0 - TTA Loss: 0.5570â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m 132/203 [2m0:07:21 â€¢ 0:03:31[0m [2;4m0.34it/s[0m  
[2KAttention weights: tensor([[0.7095, 0.2905]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 132/203 [2m0:07:21 â€¢ 0:03:31[0m [2;4m0.34it/s[0m  
[2KAttention weights: tensor([[0.8179, 0.1821]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 132/203 [2m0:07:21 â€¢ 0:03:31[0m [2;4m0.34it/s[0m  
[2KAttention weights: tensor([[0.8863, 0.1137]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 132/203 [2m0:07:21 â€¢ 0:03:31[0m [2;4m0.34it/s[0m  
[2KAttention weights: tensor([[0.9236, 0.0764]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 132/203 [2m0:07:21 â€¢ 0:03:31[0m [2;4m0.34it/s[0m  
[2KAttention weights: tensor([[0.9464, 0.0536]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 132/203 [2m0:07:21 â€¢ 0:03:31[0m [2;4m0.34it/s[0m  
[2KAttention weights: tensor([[0.9638, 0.0362]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 132/203 [2m0:07:21 â€¢ 0:03:31[0m [2;4m0.34it/s[0m  
[2KAttention weights: tensor([[0.9753, 0.0247]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 132/203 [2m0:07:21 â€¢ 0:03:31[0m [2;4m0.34it/s[0m  
[2KAttention weights: tensor([[0.9821, 0.0179]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 132/203 [2m0:07:21 â€¢ 0:03:31[0m [2;4m0.34it/s[0m  
[2KAttention weights: tensor([[0.9850, 0.0150]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 132/203 [2m0:07:21 â€¢ 0:03:31[0m [2;4m0.34it/s[0m  
[2KAttention weights: tensor([[0.5781, 0.4219]], device='cuda:0')[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m 132/203 [2m0:07:21 â€¢ 0:03:31[0m [2;4m0.34it/s[0m  
[2KAttention weights: tensor([[0.9488, 0.0512],â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m 132/203 [2m0:07:21 â€¢ 0:03:31[0m [2;4m0.34it/s[0m  
        [0.9858, 0.0142],
        [0.9919, 0.0081],
        [0.9578, 0.0422],
        [0.9704, 0.0296],
        [0.9726, 0.0274],
        [0.9664, 0.0336],
        [0.9482, 0.0518],
        [0.9619, 0.0381],
[2K        [0.9731, 0.0269]], device='cuda:0')â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m 132/203 [2m0:07:21 â€¢ 0:03:31[0m [2;4m0.34it/s[0m  
[2KAttention weights: tensor([[0.5597, 0.4403],â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m 133/203 [2m0:07:26 â€¢ 0:03:43[0m [2;4m0.31it/s[0m  
        [0.5550, 0.4450],
        [0.5569, 0.4431],
        [0.5578, 0.4422],
        [0.5585, 0.4415],
        [0.5552, 0.4448],
        [0.5542, 0.4458],
        [0.5590, 0.4410],
        [0.5591, 0.4409],
[2K        [0.5582, 0.4418]], device='cuda:0', grad_fn=<SoftmaxBackward0>)5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m 133/203 [2m0:07:26 â€¢ 0:03:43[0m [2;4m0.31it/s[0m  
[2KClass label: TennisSwingâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m 133/203 [2m0:07:26 â€¢ 0:03:43[0m [2;4m0.31it/s[0m  
[2KAttention weights: tensor([[0.6491, 0.3509]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 133/203 [2m0:07:26 â€¢ 0:03:43[0m [2;4m0.31it/s[0m  
[2KStep 0 - TTA Loss: 0.7004â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m 133/203 [2m0:07:26 â€¢ 0:03:43[0m [2;4m0.31it/s[0m  
[2KAttention weights: tensor([[0.6491, 0.3509]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 133/203 [2m0:07:26 â€¢ 0:03:43[0m [2;4m0.31it/s[0m  
[2KAttention weights: tensor([[0.6525, 0.3475]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 133/203 [2m0:07:26 â€¢ 0:03:43[0m [2;4m0.31it/s[0m  
[2KAttention weights: tensor([[0.6629, 0.3371]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 133/203 [2m0:07:26 â€¢ 0:03:43[0m [2;4m0.31it/s[0m  
[2KAttention weights: tensor([[0.6796, 0.3204]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 133/203 [2m0:07:26 â€¢ 0:03:43[0m [2;4m0.31it/s[0m  
[2KAttention weights: tensor([[0.6983, 0.3017]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 133/203 [2m0:07:26 â€¢ 0:03:43[0m [2;4m0.31it/s[0m  
[2KAttention weights: tensor([[0.7099, 0.2901]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 133/203 [2m0:07:26 â€¢ 0:03:43[0m [2;4m0.31it/s[0m  
[2KAttention weights: tensor([[0.7008, 0.2992]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 133/203 [2m0:07:26 â€¢ 0:03:43[0m [2;4m0.31it/s[0m  
[2KAttention weights: tensor([[0.6714, 0.3286]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 133/203 [2m0:07:26 â€¢ 0:03:43[0m [2;4m0.31it/s[0m  
[2KAttention weights: tensor([[0.6609, 0.3391]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 133/203 [2m0:07:26 â€¢ 0:03:43[0m [2;4m0.31it/s[0m  
[2KAttention weights: tensor([[0.5588, 0.4412]], device='cuda:0')[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m 133/203 [2m0:07:26 â€¢ 0:03:43[0m [2;4m0.31it/s[0m  
[2KAttention weights: tensor([[0.7486, 0.2514],â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m 133/203 [2m0:07:26 â€¢ 0:03:43[0m [2;4m0.31it/s[0m  
        [0.9802, 0.0198],
        [0.8090, 0.1910],
        [0.7486, 0.2514],
        [0.7656, 0.2344],
        [0.7799, 0.2201],
        [0.7797, 0.2203],
        [0.8300, 0.1700],
        [0.7105, 0.2895],
[2K        [0.7841, 0.2159]], device='cuda:0')â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m 133/203 [2m0:07:26 â€¢ 0:03:43[0m [2;4m0.31it/s[0m  
[2KAttention weights: tensor([[0.5597, 0.4403],â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m 134/203 [2m0:07:34 â€¢ 0:04:53[0m [2;4m0.24it/s[0m  
        [0.5550, 0.4450],
        [0.5569, 0.4431],
        [0.5578, 0.4422],
        [0.5585, 0.4415],
        [0.5551, 0.4449],
        [0.5542, 0.4458],
        [0.5589, 0.4411],
        [0.5591, 0.4409],
[2K        [0.5582, 0.4418]], device='cuda:0', grad_fn=<SoftmaxBackward0>)5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m 134/203 [2m0:07:34 â€¢ 0:04:53[0m [2;4m0.24it/s[0m  
[2KClass label: ThrowDiscusâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m 134/203 [2m0:07:34 â€¢ 0:04:53[0m [2;4m0.24it/s[0m  
[2KAttention weights: tensor([[0.6367, 0.3633]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 134/203 [2m0:07:34 â€¢ 0:04:53[0m [2;4m0.24it/s[0m  
[2KStep 0 - TTA Loss: 0.5703â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m 134/203 [2m0:07:34 â€¢ 0:04:53[0m [2;4m0.24it/s[0m  
[2KAttention weights: tensor([[0.7128, 0.2872]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 134/203 [2m0:07:34 â€¢ 0:04:53[0m [2;4m0.24it/s[0m  
[2KAttention weights: tensor([[0.7969, 0.2031]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 134/203 [2m0:07:34 â€¢ 0:04:53[0m [2;4m0.24it/s[0m  
[2KAttention weights: tensor([[0.8794, 0.1206]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 134/203 [2m0:07:34 â€¢ 0:04:53[0m [2;4m0.24it/s[0m  
[2KAttention weights: tensor([[0.9403, 0.0597]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 134/203 [2m0:07:34 â€¢ 0:04:53[0m [2;4m0.24it/s[0m  
[2KAttention weights: tensor([[0.9743, 0.0257]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 134/203 [2m0:07:34 â€¢ 0:04:53[0m [2;4m0.24it/s[0m  
[2KAttention weights: tensor([[0.9891, 0.0109]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 134/203 [2m0:07:34 â€¢ 0:04:53[0m [2;4m0.24it/s[0m  
[2KAttention weights: tensor([[0.9947, 0.0053]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 134/203 [2m0:07:34 â€¢ 0:04:53[0m [2;4m0.24it/s[0m  
[2KAttention weights: tensor([[0.9967, 0.0033]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 134/203 [2m0:07:34 â€¢ 0:04:53[0m [2;4m0.24it/s[0m  
[2KAttention weights: tensor([[0.9973, 0.0027]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 134/203 [2m0:07:34 â€¢ 0:04:53[0m [2;4m0.24it/s[0m  
[2KAttention weights: tensor([[0.5888, 0.4112]], device='cuda:0')[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m 134/203 [2m0:07:34 â€¢ 0:04:53[0m [2;4m0.24it/s[0m  
[2KAttention weights: tensor([[0.9941, 0.0059],â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m 134/203 [2m0:07:34 â€¢ 0:04:53[0m [2;4m0.24it/s[0m  
        [0.9928, 0.0072],
        [0.9858, 0.0142],
        [0.9919, 0.0081],
        [0.9954, 0.0046],
        [0.9933, 0.0067],
        [0.9890, 0.0110],
        [0.9841, 0.0159],
        [0.9911, 0.0089],
[2K        [0.9975, 0.0025]], device='cuda:0')â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m 134/203 [2m0:07:34 â€¢ 0:04:53[0m [2;4m0.24it/s[0m  
[2KAttention weights: tensor([[0.5597, 0.4403],â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m 135/203 [2m0:07:38 â€¢ 0:04:45[0m [2;4m0.24it/s[0m  
        [0.5551, 0.4449],
        [0.5569, 0.4431],
        [0.5578, 0.4422],
        [0.5586, 0.4414],
        [0.5552, 0.4448],
        [0.5542, 0.4458],
        [0.5590, 0.4410],
        [0.5591, 0.4409],
[2K        [0.5583, 0.4417]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m 135/203 [2m0:07:38 â€¢ 0:04:45[0m [2;4m0.24it/s[0m  
[2KClass label: CleanAndJerkâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m 135/203 [2m0:07:38 â€¢ 0:04:45[0m [2;4m0.24it/s[0m  
[2KAttention weights: tensor([[0.5657, 0.4343]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 135/203 [2m0:07:38 â€¢ 0:04:45[0m [2;4m0.24it/s[0m  
[2KStep 0 - TTA Loss: 0.5003â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m 135/203 [2m0:07:38 â€¢ 0:04:45[0m [2;4m0.24it/s[0m  
[2KAttention weights: tensor([[0.5657, 0.4343]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 135/203 [2m0:07:38 â€¢ 0:04:45[0m [2;4m0.24it/s[0m  
[2KAttention weights: tensor([[0.5740, 0.4260]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 135/203 [2m0:07:38 â€¢ 0:04:45[0m [2;4m0.24it/s[0m  
[2KAttention weights: tensor([[0.6050, 0.3950]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 135/203 [2m0:07:38 â€¢ 0:04:45[0m [2;4m0.24it/s[0m  
[2KAttention weights: tensor([[0.6663, 0.3337]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 135/203 [2m0:07:38 â€¢ 0:04:45[0m [2;4m0.24it/s[0m  
[2KAttention weights: tensor([[0.7541, 0.2459]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 135/203 [2m0:07:38 â€¢ 0:04:45[0m [2;4m0.24it/s[0m  
[2KAttention weights: tensor([[0.8474, 0.1526]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 135/203 [2m0:07:38 â€¢ 0:04:45[0m [2;4m0.24it/s[0m  
[2KAttention weights: tensor([[0.9189, 0.0811]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 135/203 [2m0:07:38 â€¢ 0:04:45[0m [2;4m0.24it/s[0m  
[2KAttention weights: tensor([[0.9583, 0.0417]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 135/203 [2m0:07:38 â€¢ 0:04:45[0m [2;4m0.24it/s[0m  
[2KAttention weights: tensor([[0.9768, 0.0232]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 135/203 [2m0:07:38 â€¢ 0:04:45[0m [2;4m0.24it/s[0m  
[2KAttention weights: tensor([[0.5753, 0.4247]], device='cuda:0')224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m 135/203 [2m0:07:38 â€¢ 0:04:45[0m [2;4m0.24it/s[0m  
[2KAttention weights: tensor([[0.9918, 0.0082],â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m 135/203 [2m0:07:38 â€¢ 0:04:45[0m [2;4m0.24it/s[0m  
        [0.9562, 0.0438],
        [0.9884, 0.0116],
        [0.9896, 0.0104],
        [0.9943, 0.0057],
        [0.9912, 0.0088],
        [0.9852, 0.0148],
        [0.9743, 0.0257],
        [0.9877, 0.0123],
[2K        [0.9968, 0.0032]], device='cuda:0')â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m 135/203 [2m0:07:38 â€¢ 0:04:45[0m [2;4m0.24it/s[0m  
[2KAttention weights: tensor([[0.5597, 0.4403],â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m 136/203 [2m0:07:44 â€¢ 0:04:56[0m [2;4m0.23it/s[0m  
        [0.5551, 0.4449],
        [0.5569, 0.4431],
        [0.5578, 0.4422],
        [0.5586, 0.4414],
        [0.5552, 0.4448],
        [0.5542, 0.4458],
        [0.5590, 0.4410],
        [0.5591, 0.4409],
[2K        [0.5584, 0.4416]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m 136/203 [2m0:07:44 â€¢ 0:04:56[0m [2;4m0.23it/s[0m  
[2KClass label: GolfSwingâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m 136/203 [2m0:07:44 â€¢ 0:04:56[0m [2;4m0.23it/s[0m  
[2KAttention weights: tensor([[0.6308, 0.3692]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 136/203 [2m0:07:44 â€¢ 0:04:56[0m [2;4m0.23it/s[0m  
[2KStep 0 - TTA Loss: 0.5320â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m 136/203 [2m0:07:44 â€¢ 0:04:56[0m [2;4m0.23it/s[0m  
[2KAttention weights: tensor([[0.7838, 0.2162]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 136/203 [2m0:07:44 â€¢ 0:04:56[0m [2;4m0.23it/s[0m  
[2KAttention weights: tensor([[0.8976, 0.1024]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 136/203 [2m0:07:44 â€¢ 0:04:56[0m [2;4m0.23it/s[0m  
[2KAttention weights: tensor([[0.9616, 0.0384]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 136/203 [2m0:07:44 â€¢ 0:04:56[0m [2;4m0.23it/s[0m  
[2KAttention weights: tensor([[0.9875, 0.0125]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 136/203 [2m0:07:44 â€¢ 0:04:56[0m [2;4m0.23it/s[0m  
[2KAttention weights: tensor([[0.9953, 0.0047]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 136/203 [2m0:07:44 â€¢ 0:04:56[0m [2;4m0.23it/s[0m  
[2KAttention weights: tensor([[0.9977, 0.0023]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 136/203 [2m0:07:44 â€¢ 0:04:56[0m [2;4m0.23it/s[0m  
[2KAttention weights: tensor([[0.9985, 0.0015]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 136/203 [2m0:07:44 â€¢ 0:04:56[0m [2;4m0.23it/s[0m  
[2KAttention weights: tensor([[0.9988, 0.0012]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 136/203 [2m0:07:44 â€¢ 0:04:56[0m [2;4m0.23it/s[0m  
[2KAttention weights: tensor([[0.9989, 0.0011]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 136/203 [2m0:07:44 â€¢ 0:04:56[0m [2;4m0.23it/s[0m  
[2KAttention weights: tensor([[0.5938, 0.4062]], device='cuda:0')224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m 136/203 [2m0:07:44 â€¢ 0:04:56[0m [2;4m0.23it/s[0m  
[2KAttention weights: tensor([[0.9980, 0.0020],â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m 136/203 [2m0:07:44 â€¢ 0:04:56[0m [2;4m0.23it/s[0m  
        [0.9737, 0.0263],
        [0.9920, 0.0080],
        [0.9990, 0.0010],
        [0.9974, 0.0026],
        [0.9953, 0.0047],
        [0.9919, 0.0081],
        [0.9868, 0.0132],
        [0.9967, 0.0033],
[2K        [0.9986, 0.0014]], device='cuda:0')â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m 136/203 [2m0:07:44 â€¢ 0:04:56[0m [2;4m0.23it/s[0m  
[2KAttention weights: tensor([[0.5598, 0.4402],â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m 137/203 [2m0:07:47 â€¢ 0:05:09[0m [2;4m0.21it/s[0m  
        [0.5551, 0.4449],
        [0.5570, 0.4430],
        [0.5579, 0.4421],
        [0.5586, 0.4414],
        [0.5552, 0.4448],
        [0.5543, 0.4457],
        [0.5591, 0.4409],
        [0.5592, 0.4408],
[2K        [0.5584, 0.4416]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m 137/203 [2m0:07:47 â€¢ 0:05:09[0m [2;4m0.21it/s[0m  
[2KClass label: SoccerPenaltyâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m 137/203 [2m0:07:47 â€¢ 0:05:09[0m [2;4m0.21it/s[0m  
[2KAttention weights: tensor([[0.6326, 0.3674]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 137/203 [2m0:07:47 â€¢ 0:05:09[0m [2;4m0.21it/s[0m  
[2KStep 0 - TTA Loss: 0.8069â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m 137/203 [2m0:07:47 â€¢ 0:05:09[0m [2;4m0.21it/s[0m  
[2KAttention weights: tensor([[0.6326, 0.3674]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 137/203 [2m0:07:47 â€¢ 0:05:09[0m [2;4m0.21it/s[0m  
[2KAttention weights: tensor([[0.6349, 0.3651]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 137/203 [2m0:07:47 â€¢ 0:05:09[0m [2;4m0.21it/s[0m  
[2KAttention weights: tensor([[0.6429, 0.3571]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 137/203 [2m0:07:47 â€¢ 0:05:09[0m [2;4m0.21it/s[0m  
[2KAttention weights: tensor([[0.6578, 0.3422]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 137/203 [2m0:07:47 â€¢ 0:05:09[0m [2;4m0.21it/s[0m  
[2KAttention weights: tensor([[0.6788, 0.3212]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 137/203 [2m0:07:47 â€¢ 0:05:09[0m [2;4m0.21it/s[0m  
[2KAttention weights: tensor([[0.7013, 0.2987]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 137/203 [2m0:07:47 â€¢ 0:05:09[0m [2;4m0.21it/s[0m  
[2KAttention weights: tensor([[0.7200, 0.2800]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 137/203 [2m0:07:47 â€¢ 0:05:09[0m [2;4m0.21it/s[0m  
[2KAttention weights: tensor([[0.7201, 0.2799]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 137/203 [2m0:07:47 â€¢ 0:05:09[0m [2;4m0.21it/s[0m  
[2KAttention weights: tensor([[0.6962, 0.3038]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 137/203 [2m0:07:47 â€¢ 0:05:09[0m [2;4m0.21it/s[0m  
[2KAttention weights: tensor([[0.5587, 0.4413]], device='cuda:0')224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m 137/203 [2m0:07:47 â€¢ 0:05:09[0m [2;4m0.21it/s[0m  
[2KAttention weights: tensor([[0.8462, 0.1538],â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m 137/203 [2m0:07:47 â€¢ 0:05:09[0m [2;4m0.21it/s[0m  
        [0.7129, 0.2871],
        [0.7745, 0.2255],
        [0.8917, 0.1083],
        [0.8096, 0.1904],
        [0.7823, 0.2177],
        [0.7354, 0.2646],
        [0.6741, 0.3259],
        [0.8508, 0.1492],
[2K        [0.8613, 0.1387]], device='cuda:0')â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m 137/203 [2m0:07:47 â€¢ 0:05:09[0m [2;4m0.21it/s[0m  
[2KAttention weights: tensor([[0.5598, 0.4402],â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”[0m 138/203 [2m0:07:49 â€¢ 0:04:38[0m [2;4m0.23it/s[0m   
        [0.5551, 0.4449],
        [0.5570, 0.4430],
        [0.5580, 0.4420],
        [0.5586, 0.4414],
        [0.5553, 0.4447],
        [0.5543, 0.4457],
        [0.5591, 0.4409],
        [0.5592, 0.4408],
[2K        [0.5584, 0.4416]], device='cuda:0', grad_fn=<SoftmaxBackward0>);5;237mâ”â”â”â”â”â”â”â”â”â”â”â”[0m 138/203 [2m0:07:49 â€¢ 0:04:38[0m [2;4m0.23it/s[0m  
[2KClass label: HighJumpâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”[0m 138/203 [2m0:07:49 â€¢ 0:04:38[0m [2;4m0.23it/s[0m  
[2KAttention weights: tensor([[0.5985, 0.4015]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 138/203 [2m0:07:49 â€¢ 0:04:38[0m [2;4m0.23it/s[0m  
[2KStep 0 - TTA Loss: 0.7073â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”[0m 138/203 [2m0:07:49 â€¢ 0:04:38[0m [2;4m0.23it/s[0m  
[2KAttention weights: tensor([[0.6441, 0.3559]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 138/203 [2m0:07:49 â€¢ 0:04:38[0m [2;4m0.23it/s[0m  
[2KAttention weights: tensor([[0.7080, 0.2920]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 138/203 [2m0:07:49 â€¢ 0:04:38[0m [2;4m0.23it/s[0m  
[2KAttention weights: tensor([[0.7763, 0.2237]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 138/203 [2m0:07:49 â€¢ 0:04:38[0m [2;4m0.23it/s[0m  
[2KAttention weights: tensor([[0.8441, 0.1559]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 138/203 [2m0:07:49 â€¢ 0:04:38[0m [2;4m0.23it/s[0m  
[2KAttention weights: tensor([[0.8900, 0.1100]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 138/203 [2m0:07:49 â€¢ 0:04:38[0m [2;4m0.23it/s[0m  
[2KAttention weights: tensor([[0.9142, 0.0858]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 138/203 [2m0:07:49 â€¢ 0:04:38[0m [2;4m0.23it/s[0m  
[2KAttention weights: tensor([[0.9240, 0.0760]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 138/203 [2m0:07:49 â€¢ 0:04:38[0m [2;4m0.23it/s[0m  
[2KAttention weights: tensor([[0.9288, 0.0712]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 138/203 [2m0:07:49 â€¢ 0:04:38[0m [2;4m0.23it/s[0m  
[2KAttention weights: tensor([[0.9301, 0.0699]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 138/203 [2m0:07:49 â€¢ 0:04:38[0m [2;4m0.23it/s[0m  
[2KAttention weights: tensor([[0.5690, 0.4310]], device='cuda:0')â•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”[0m 138/203 [2m0:07:49 â€¢ 0:04:38[0m [2;4m0.23it/s[0m  
[2KAttention weights: tensor([[0.9066, 0.0934],â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”[0m 138/203 [2m0:07:49 â€¢ 0:04:38[0m [2;4m0.23it/s[0m  
        [0.7924, 0.2076],
        [0.8709, 0.1291],
        [0.9215, 0.0785],
        [0.9066, 0.0934],
        [0.9299, 0.0701],
        [0.8869, 0.1131],
        [0.7954, 0.2046],
        [0.9129, 0.0871],
[2K        [0.9304, 0.0696]], device='cuda:0')â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”[0m 138/203 [2m0:07:49 â€¢ 0:04:38[0m [2;4m0.23it/s[0m  
[2KAttention weights: tensor([[0.5598, 0.4402],â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”[0m 139/203 [2m0:07:56 â€¢ 0:04:33[0m [2;4m0.23it/s[0m  
        [0.5552, 0.4448],
        [0.5570, 0.4430],
        [0.5580, 0.4420],
        [0.5587, 0.4413],
        [0.5553, 0.4447],
        [0.5543, 0.4457],
        [0.5590, 0.4410],
        [0.5592, 0.4408],
[2K        [0.5584, 0.4416]], device='cuda:0', grad_fn=<SoftmaxBackward0>);5;237mâ”â”â”â”â”â”â”â”â”â”â”â”[0m 139/203 [2m0:07:56 â€¢ 0:04:33[0m [2;4m0.23it/s[0m  
[2KClass label: HighJumpâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”[0m 139/203 [2m0:07:56 â€¢ 0:04:33[0m [2;4m0.23it/s[0m  
[2KAttention weights: tensor([[0.5930, 0.4070]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 139/203 [2m0:07:56 â€¢ 0:04:33[0m [2;4m0.23it/s[0m  
[2KStep 0 - TTA Loss: 0.6456â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”[0m 139/203 [2m0:07:56 â€¢ 0:04:33[0m [2;4m0.23it/s[0m  
[2KAttention weights: tensor([[0.5930, 0.4070]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 139/203 [2m0:07:56 â€¢ 0:04:33[0m [2;4m0.23it/s[0m  
[2KAttention weights: tensor([[0.5926, 0.4074]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 139/203 [2m0:07:56 â€¢ 0:04:33[0m [2;4m0.23it/s[0m  
[2KAttention weights: tensor([[0.5937, 0.4063]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 139/203 [2m0:07:56 â€¢ 0:04:33[0m [2;4m0.23it/s[0m  
[2KAttention weights: tensor([[0.6003, 0.3997]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 139/203 [2m0:07:56 â€¢ 0:04:33[0m [2;4m0.23it/s[0m  
[2KAttention weights: tensor([[0.6185, 0.3815]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 139/203 [2m0:07:56 â€¢ 0:04:33[0m [2;4m0.23it/s[0m  
[2KAttention weights: tensor([[0.6536, 0.3464]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 139/203 [2m0:07:56 â€¢ 0:04:33[0m [2;4m0.23it/s[0m  
[2KAttention weights: tensor([[0.7114, 0.2886]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 139/203 [2m0:07:56 â€¢ 0:04:33[0m [2;4m0.23it/s[0m  
[2KAttention weights: tensor([[0.7876, 0.2124]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 139/203 [2m0:07:56 â€¢ 0:04:33[0m [2;4m0.23it/s[0m  
[2KAttention weights: tensor([[0.8649, 0.1351]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 139/203 [2m0:07:56 â€¢ 0:04:33[0m [2;4m0.23it/s[0m  
[2KAttention weights: tensor([[0.5689, 0.4311]], device='cuda:0')â•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”[0m 139/203 [2m0:07:56 â€¢ 0:04:33[0m [2;4m0.23it/s[0m  
[2KAttention weights: tensor([[0.8809, 0.1191],â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”[0m 139/203 [2m0:07:56 â€¢ 0:04:33[0m [2;4m0.23it/s[0m  
        [0.7865, 0.2135],
        [0.8441, 0.1559],
        [0.8745, 0.1255],
        [0.8926, 0.1074],
        [0.9312, 0.0688],
        [0.8873, 0.1127],
        [0.8672, 0.1328],
        [0.8877, 0.1123],
[2K        [0.9102, 0.0898]], device='cuda:0')â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”[0m 139/203 [2m0:07:56 â€¢ 0:04:33[0m [2;4m0.23it/s[0m  
[2KAttention weights: tensor([[0.5598, 0.4402],â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”[0m 140/203 [2m0:07:58 â€¢ 0:04:14[0m [2;4m0.25it/s[0m  
        [0.5552, 0.4448],
        [0.5570, 0.4430],
        [0.5580, 0.4420],
        [0.5587, 0.4413],
        [0.5553, 0.4447],
        [0.5543, 0.4457],
        [0.5591, 0.4409],
        [0.5593, 0.4407],
[2K        [0.5585, 0.4415]], device='cuda:0', grad_fn=<SoftmaxBackward0>)m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”[0m 140/203 [2m0:07:58 â€¢ 0:04:14[0m [2;4m0.25it/s[0m  
[2KClass label: HammerThrowâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”[0m 140/203 [2m0:07:58 â€¢ 0:04:14[0m [2;4m0.25it/s[0m  
[2KAttention weights: tensor([[0.5854, 0.4146]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 140/203 [2m0:07:58 â€¢ 0:04:14[0m [2;4m0.25it/s[0m  
[2KStep 0 - TTA Loss: 0.5964â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”[0m 140/203 [2m0:07:58 â€¢ 0:04:14[0m [2;4m0.25it/s[0m  
[2KAttention weights: tensor([[0.7184, 0.2816]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 140/203 [2m0:07:58 â€¢ 0:04:14[0m [2;4m0.25it/s[0m  
[2KAttention weights: tensor([[0.8237, 0.1763]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 140/203 [2m0:07:58 â€¢ 0:04:14[0m [2;4m0.25it/s[0m  
[2KAttention weights: tensor([[0.8934, 0.1066]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 140/203 [2m0:07:58 â€¢ 0:04:14[0m [2;4m0.25it/s[0m  
[2KAttention weights: tensor([[0.9382, 0.0618]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 140/203 [2m0:07:58 â€¢ 0:04:14[0m [2;4m0.25it/s[0m  
[2KAttention weights: tensor([[0.9643, 0.0357]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 140/203 [2m0:07:58 â€¢ 0:04:14[0m [2;4m0.25it/s[0m  
[2KAttention weights: tensor([[0.9778, 0.0222]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 140/203 [2m0:07:58 â€¢ 0:04:14[0m [2;4m0.25it/s[0m  
[2KAttention weights: tensor([[0.9844, 0.0156]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 140/203 [2m0:07:58 â€¢ 0:04:14[0m [2;4m0.25it/s[0m  
[2KAttention weights: tensor([[0.9872, 0.0128]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 140/203 [2m0:07:58 â€¢ 0:04:14[0m [2;4m0.25it/s[0m  
[2KAttention weights: tensor([[0.9883, 0.0117]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 140/203 [2m0:07:58 â€¢ 0:04:14[0m [2;4m0.25it/s[0m  
[2KAttention weights: tensor([[0.5820, 0.4180]], device='cuda:0');224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”[0m 140/203 [2m0:07:58 â€¢ 0:04:14[0m [2;4m0.25it/s[0m  
[2KAttention weights: tensor([[0.9777, 0.0223],â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”[0m 140/203 [2m0:07:58 â€¢ 0:04:14[0m [2;4m0.25it/s[0m  
        [0.9095, 0.0905],
        [0.9625, 0.0375],
        [0.9699, 0.0301],
        [0.9886, 0.0114],
        [0.9907, 0.0093],
        [0.9803, 0.0197],
        [0.9692, 0.0308],
        [0.9712, 0.0288],
[2K        [0.9869, 0.0131]], device='cuda:0')â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”[0m 140/203 [2m0:07:58 â€¢ 0:04:14[0m [2;4m0.25it/s[0m  
[2KAttention weights: tensor([[0.5598, 0.4402],â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”[0m 141/203 [2m0:08:01 â€¢ 0:03:53[0m [2;4m0.27it/s[0m  
        [0.5552, 0.4448],
        [0.5570, 0.4430],
        [0.5580, 0.4420],
        [0.5586, 0.4414],
        [0.5553, 0.4447],
        [0.5543, 0.4457],
        [0.5591, 0.4409],
        [0.5593, 0.4407],
[2K        [0.5584, 0.4416]], device='cuda:0', grad_fn=<SoftmaxBackward0>)m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”[0m 141/203 [2m0:08:01 â€¢ 0:03:53[0m [2;4m0.27it/s[0m  
[2KClass label: TennisSwingâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”[0m 141/203 [2m0:08:01 â€¢ 0:03:53[0m [2;4m0.27it/s[0m  
[2KAttention weights: tensor([[0.6440, 0.3560]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 141/203 [2m0:08:01 â€¢ 0:03:53[0m [2;4m0.27it/s[0m  
[2KStep 0 - TTA Loss: 0.8466â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”[0m 141/203 [2m0:08:01 â€¢ 0:03:53[0m [2;4m0.27it/s[0m  
[2KAttention weights: tensor([[0.6440, 0.3560]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 141/203 [2m0:08:01 â€¢ 0:03:53[0m [2;4m0.27it/s[0m  
[2KAttention weights: tensor([[0.6461, 0.3539]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 141/203 [2m0:08:01 â€¢ 0:03:53[0m [2;4m0.27it/s[0m  
[2KAttention weights: tensor([[0.6531, 0.3469]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 141/203 [2m0:08:01 â€¢ 0:03:53[0m [2;4m0.27it/s[0m  
[2KAttention weights: tensor([[0.6647, 0.3353]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 141/203 [2m0:08:01 â€¢ 0:03:53[0m [2;4m0.27it/s[0m  
[2KAttention weights: tensor([[0.6782, 0.3218]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 141/203 [2m0:08:01 â€¢ 0:03:53[0m [2;4m0.27it/s[0m  
[2KAttention weights: tensor([[0.6979, 0.3021]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 141/203 [2m0:08:01 â€¢ 0:03:53[0m [2;4m0.27it/s[0m  
[2KAttention weights: tensor([[0.7093, 0.2907]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 141/203 [2m0:08:01 â€¢ 0:03:53[0m [2;4m0.27it/s[0m  
[2KAttention weights: tensor([[0.7141, 0.2859]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 141/203 [2m0:08:01 â€¢ 0:03:53[0m [2;4m0.27it/s[0m  
[2KAttention weights: tensor([[0.7105, 0.2895]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 141/203 [2m0:08:01 â€¢ 0:03:53[0m [2;4m0.27it/s[0m  
[2KAttention weights: tensor([[0.5603, 0.4397]], device='cuda:0');224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”[0m 141/203 [2m0:08:01 â€¢ 0:03:53[0m [2;4m0.27it/s[0m  
[2KAttention weights: tensor([[0.8025, 0.1975],â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”[0m 141/203 [2m0:08:01 â€¢ 0:03:53[0m [2;4m0.27it/s[0m  
        [0.6858, 0.3142],
        [0.7646, 0.2354],
        [0.7816, 0.2184],
        [0.8524, 0.1476],
        [0.8248, 0.1752],
        [0.7896, 0.2104],
        [0.8036, 0.1964],
        [0.7334, 0.2666],
[2K        [0.8423, 0.1577]], device='cuda:0')â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”[0m 141/203 [2m0:08:01 â€¢ 0:03:53[0m [2;4m0.27it/s[0m  
[2KAttention weights: tensor([[0.5598, 0.4402],â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”[0m 142/203 [2m0:08:02 â€¢ 0:03:28[0m [2;4m0.29it/s[0m  
        [0.5552, 0.4448],
        [0.5570, 0.4430],
        [0.5580, 0.4420],
        [0.5586, 0.4414],
        [0.5553, 0.4447],
        [0.5543, 0.4457],
        [0.5590, 0.4410],
        [0.5592, 0.4408],
[2K        [0.5584, 0.4416]], device='cuda:0', grad_fn=<SoftmaxBackward0>)m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”[0m 142/203 [2m0:08:02 â€¢ 0:03:28[0m [2;4m0.29it/s[0m  
[2KClass label: PoleVaultâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”[0m 142/203 [2m0:08:02 â€¢ 0:03:28[0m [2;4m0.29it/s[0m  
[2KAttention weights: tensor([[0.5485, 0.4515]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 142/203 [2m0:08:02 â€¢ 0:03:28[0m [2;4m0.29it/s[0m  
[2KStep 0 - TTA Loss: 0.7462â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”[0m 142/203 [2m0:08:02 â€¢ 0:03:28[0m [2;4m0.29it/s[0m  
[2KAttention weights: tensor([[0.6164, 0.3836]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 142/203 [2m0:08:02 â€¢ 0:03:28[0m [2;4m0.29it/s[0m  
[2KAttention weights: tensor([[0.7057, 0.2943]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 142/203 [2m0:08:02 â€¢ 0:03:28[0m [2;4m0.29it/s[0m  
[2KAttention weights: tensor([[0.7933, 0.2067]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 142/203 [2m0:08:02 â€¢ 0:03:28[0m [2;4m0.29it/s[0m  
[2KAttention weights: tensor([[0.8581, 0.1419]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 142/203 [2m0:08:02 â€¢ 0:03:28[0m [2;4m0.29it/s[0m  
[2KAttention weights: tensor([[0.9026, 0.0974]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 142/203 [2m0:08:02 â€¢ 0:03:28[0m [2;4m0.29it/s[0m  
[2KAttention weights: tensor([[0.9243, 0.0757]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 142/203 [2m0:08:02 â€¢ 0:03:28[0m [2;4m0.29it/s[0m  
[2KAttention weights: tensor([[0.9347, 0.0653]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 142/203 [2m0:08:02 â€¢ 0:03:28[0m [2;4m0.29it/s[0m  
[2KAttention weights: tensor([[0.9385, 0.0615]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 142/203 [2m0:08:02 â€¢ 0:03:28[0m [2;4m0.29it/s[0m  
[2KAttention weights: tensor([[0.9394, 0.0606]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 142/203 [2m0:08:02 â€¢ 0:03:28[0m [2;4m0.29it/s[0m  
[2KAttention weights: tensor([[0.5702, 0.4298]], device='cuda:0');224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”[0m 142/203 [2m0:08:02 â€¢ 0:03:28[0m [2;4m0.29it/s[0m  
[2KAttention weights: tensor([[0.8957, 0.1043],â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”[0m 142/203 [2m0:08:02 â€¢ 0:03:28[0m [2;4m0.29it/s[0m  
        [0.7961, 0.2039],
        [0.8662, 0.1338],
        [0.8830, 0.1170],
        [0.9279, 0.0721],
        [0.9322, 0.0678],
        [0.9397, 0.0603],
        [0.8992, 0.1008],
        [0.8534, 0.1466],
[2K        [0.9273, 0.0727]], device='cuda:0')â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”â”[0m 142/203 [2m0:08:02 â€¢ 0:03:28[0m [2;4m0.29it/s[0m  
[2KAttention weights: tensor([[0.5598, 0.4402],â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”[0m 143/203 [2m0:08:04 â€¢ 0:03:19[0m [2;4m0.30it/s[0m   
        [0.5552, 0.4448],
        [0.5569, 0.4431],
        [0.5580, 0.4420],
        [0.5586, 0.4414],
        [0.5553, 0.4447],
        [0.5543, 0.4457],
        [0.5590, 0.4410],
        [0.5592, 0.4408],
[2K        [0.5584, 0.4416]], device='cuda:0', grad_fn=<SoftmaxBackward0>)8;5;237mâ”â”â”â”â”â”â”â”â”â”â”[0m 143/203 [2m0:08:04 â€¢ 0:03:19[0m [2;4m0.30it/s[0m  
[2KClass label: HammerThrowâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”[0m 143/203 [2m0:08:04 â€¢ 0:03:19[0m [2;4m0.30it/s[0m  
[2KAttention weights: tensor([[0.5887, 0.4113]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 143/203 [2m0:08:04 â€¢ 0:03:19[0m [2;4m0.30it/s[0m  
[2KStep 0 - TTA Loss: 0.6224â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”[0m 143/203 [2m0:08:04 â€¢ 0:03:19[0m [2;4m0.30it/s[0m  
[2KAttention weights: tensor([[0.5887, 0.4113]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 143/203 [2m0:08:04 â€¢ 0:03:19[0m [2;4m0.30it/s[0m  
[2KAttention weights: tensor([[0.5916, 0.4084]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 143/203 [2m0:08:04 â€¢ 0:03:19[0m [2;4m0.30it/s[0m  
[2KAttention weights: tensor([[0.6062, 0.3938]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 143/203 [2m0:08:04 â€¢ 0:03:19[0m [2;4m0.30it/s[0m  
[2KAttention weights: tensor([[0.6442, 0.3558]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 143/203 [2m0:08:04 â€¢ 0:03:19[0m [2;4m0.30it/s[0m  
[2KAttention weights: tensor([[0.7144, 0.2856]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 143/203 [2m0:08:04 â€¢ 0:03:19[0m [2;4m0.30it/s[0m  
[2KAttention weights: tensor([[0.8162, 0.1838]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 143/203 [2m0:08:04 â€¢ 0:03:19[0m [2;4m0.30it/s[0m  
[2KAttention weights: tensor([[0.9171, 0.0829]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 143/203 [2m0:08:04 â€¢ 0:03:19[0m [2;4m0.30it/s[0m  
[2KAttention weights: tensor([[0.9777, 0.0223]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 143/203 [2m0:08:04 â€¢ 0:03:19[0m [2;4m0.30it/s[0m  
[2KAttention weights: tensor([[0.9946, 0.0054]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 143/203 [2m0:08:04 â€¢ 0:03:19[0m [2;4m0.30it/s[0m  
[2KAttention weights: tensor([[0.5892, 0.4108]], device='cuda:0')mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”[0m 143/203 [2m0:08:04 â€¢ 0:03:19[0m [2;4m0.30it/s[0m  
[2KAttention weights: tensor([[0.9938, 0.0062],â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”[0m 143/203 [2m0:08:04 â€¢ 0:03:19[0m [2;4m0.30it/s[0m  
        [0.9410, 0.0590],
        [0.9859, 0.0141],
        [0.9900, 0.0100],
        [0.9986, 0.0014],
        [0.9941, 0.0059],
        [0.9901, 0.0099],
        [0.9867, 0.0133],
        [0.9845, 0.0155],
[2K        [0.9968, 0.0032]], device='cuda:0')â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”[0m 143/203 [2m0:08:04 â€¢ 0:03:19[0m [2;4m0.30it/s[0m  
[2KAttention weights: tensor([[0.5598, 0.4402],â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”[0m 144/203 [2m0:08:15 â€¢ 0:03:55[0m [2;4m0.25it/s[0m  
        [0.5552, 0.4448],
        [0.5570, 0.4430],
        [0.5580, 0.4420],
        [0.5587, 0.4413],
        [0.5554, 0.4446],
        [0.5544, 0.4456],
        [0.5591, 0.4409],
        [0.5593, 0.4407],
[2K        [0.5585, 0.4415]], device='cuda:0', grad_fn=<SoftmaxBackward0>)8;5;237mâ”â”â”â”â”â”â”â”â”â”â”[0m 144/203 [2m0:08:15 â€¢ 0:03:55[0m [2;4m0.25it/s[0m  
[2KClass label: PoleVaultâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”[0m 144/203 [2m0:08:15 â€¢ 0:03:55[0m [2;4m0.25it/s[0m  
[2KAttention weights: tensor([[0.5492, 0.4508]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 144/203 [2m0:08:15 â€¢ 0:03:55[0m [2;4m0.25it/s[0m  
[2KStep 0 - TTA Loss: 0.5226â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”[0m 144/203 [2m0:08:15 â€¢ 0:03:55[0m [2;4m0.25it/s[0m  
[2KAttention weights: tensor([[0.7656, 0.2344]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 144/203 [2m0:08:15 â€¢ 0:03:55[0m [2;4m0.25it/s[0m  
[2KAttention weights: tensor([[0.9019, 0.0981]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 144/203 [2m0:08:15 â€¢ 0:03:55[0m [2;4m0.25it/s[0m  
[2KAttention weights: tensor([[0.9638, 0.0362]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 144/203 [2m0:08:15 â€¢ 0:03:55[0m [2;4m0.25it/s[0m  
[2KAttention weights: tensor([[0.9874, 0.0126]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 144/203 [2m0:08:15 â€¢ 0:03:55[0m [2;4m0.25it/s[0m  
[2KAttention weights: tensor([[0.9950, 0.0050]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 144/203 [2m0:08:15 â€¢ 0:03:55[0m [2;4m0.25it/s[0m  
[2KAttention weights: tensor([[0.9974, 0.0026]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 144/203 [2m0:08:15 â€¢ 0:03:55[0m [2;4m0.25it/s[0m  
[2KAttention weights: tensor([[0.9982, 0.0018]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 144/203 [2m0:08:15 â€¢ 0:03:55[0m [2;4m0.25it/s[0m  
[2KAttention weights: tensor([[0.9985, 0.0015]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 144/203 [2m0:08:15 â€¢ 0:03:55[0m [2;4m0.25it/s[0m  
[2KAttention weights: tensor([[0.9986, 0.0014]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 144/203 [2m0:08:15 â€¢ 0:03:55[0m [2;4m0.25it/s[0m  
[2KAttention weights: tensor([[0.5892, 0.4108]], device='cuda:0')mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”[0m 144/203 [2m0:08:15 â€¢ 0:03:55[0m [2;4m0.25it/s[0m  
[2KAttention weights: tensor([[9.9718e-01, 2.8245e-03],[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”[0m 144/203 [2m0:08:15 â€¢ 0:03:55[0m [2;4m0.25it/s[0m  
        [9.6823e-01, 3.1772e-02],
        [9.9369e-01, 6.3062e-03],
        [9.9523e-01, 4.7652e-03],
        [9.9943e-01, 5.7438e-04],
        [9.9850e-01, 1.5013e-03],
        [9.9859e-01, 1.4077e-03],
        [9.9488e-01, 5.1249e-03],
        [9.9105e-01, 8.9496e-03],
[2K        [9.9879e-01, 1.2136e-03]], device='cuda:0')m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”[0m 144/203 [2m0:08:15 â€¢ 0:03:55[0m [2;4m0.25it/s[0m  
[2KAttention weights: tensor([[0.5599, 0.4401],â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”[0m 145/203 [2m0:08:27 â€¢ 0:05:33[0m [2;4m0.17it/s[0m  
        [0.5552, 0.4448],
        [0.5570, 0.4430],
        [0.5580, 0.4420],
        [0.5587, 0.4413],
        [0.5554, 0.4446],
        [0.5544, 0.4456],
        [0.5591, 0.4409],
        [0.5593, 0.4407],
[2K        [0.5585, 0.4415]], device='cuda:0', grad_fn=<SoftmaxBackward0>)0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”[0m 145/203 [2m0:08:27 â€¢ 0:05:33[0m [2;4m0.17it/s[0m  
[2KClass label: TennisSwingâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”[0m 145/203 [2m0:08:27 â€¢ 0:05:33[0m [2;4m0.17it/s[0m  
[2KAttention weights: tensor([[0.6470, 0.3530]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 145/203 [2m0:08:27 â€¢ 0:05:33[0m [2;4m0.17it/s[0m  
[2KStep 0 - TTA Loss: 0.7133â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”[0m 145/203 [2m0:08:27 â€¢ 0:05:33[0m [2;4m0.17it/s[0m  
[2KAttention weights: tensor([[0.6470, 0.3530]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 145/203 [2m0:08:27 â€¢ 0:05:33[0m [2;4m0.17it/s[0m  
[2KAttention weights: tensor([[0.6493, 0.3507]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 145/203 [2m0:08:27 â€¢ 0:05:33[0m [2;4m0.17it/s[0m  
[2KAttention weights: tensor([[0.6591, 0.3409]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 145/203 [2m0:08:27 â€¢ 0:05:33[0m [2;4m0.17it/s[0m  
[2KAttention weights: tensor([[0.6760, 0.3240]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 145/203 [2m0:08:27 â€¢ 0:05:33[0m [2;4m0.17it/s[0m  
[2KAttention weights: tensor([[0.6981, 0.3019]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 145/203 [2m0:08:27 â€¢ 0:05:33[0m [2;4m0.17it/s[0m  
[2KAttention weights: tensor([[0.7343, 0.2657]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 145/203 [2m0:08:27 â€¢ 0:05:33[0m [2;4m0.17it/s[0m  
[2KAttention weights: tensor([[0.7688, 0.2312]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 145/203 [2m0:08:27 â€¢ 0:05:33[0m [2;4m0.17it/s[0m  
[2KAttention weights: tensor([[0.7916, 0.2084]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 145/203 [2m0:08:27 â€¢ 0:05:33[0m [2;4m0.17it/s[0m  
[2KAttention weights: tensor([[0.8185, 0.1815]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 145/203 [2m0:08:27 â€¢ 0:05:33[0m [2;4m0.17it/s[0m  
[2KAttention weights: tensor([[0.5642, 0.4358]], device='cuda:0')6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”[0m 145/203 [2m0:08:27 â€¢ 0:05:33[0m [2;4m0.17it/s[0m  
[2KAttention weights: tensor([[0.8251, 0.1749],â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”[0m 145/203 [2m0:08:27 â€¢ 0:05:33[0m [2;4m0.17it/s[0m  
        [0.7247, 0.2753],
        [0.7679, 0.2321],
        [0.8220, 0.1780],
        [0.8439, 0.1561],
        [0.8216, 0.1784],
        [0.7810, 0.2190],
        [0.8097, 0.1903],
        [0.8376, 0.1624],
[2K        [0.8531, 0.1469]], device='cuda:0')â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”[0m 145/203 [2m0:08:27 â€¢ 0:05:33[0m [2;4m0.17it/s[0m  
[2KAttention weights: tensor([[0.5598, 0.4402],â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”[0m 146/203 [2m0:08:30 â€¢ 0:05:31[0m [2;4m0.17it/s[0m  
        [0.5552, 0.4448],
        [0.5570, 0.4430],
        [0.5580, 0.4420],
        [0.5587, 0.4413],
        [0.5554, 0.4446],
        [0.5544, 0.4456],
        [0.5591, 0.4409],
        [0.5593, 0.4407],
[2K        [0.5585, 0.4415]], device='cuda:0', grad_fn=<SoftmaxBackward0>)0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”[0m 146/203 [2m0:08:30 â€¢ 0:05:31[0m [2;4m0.17it/s[0m  
[2KClass label: HammerThrowâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”[0m 146/203 [2m0:08:30 â€¢ 0:05:31[0m [2;4m0.17it/s[0m  
[2KAttention weights: tensor([[0.5867, 0.4133]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 146/203 [2m0:08:30 â€¢ 0:05:31[0m [2;4m0.17it/s[0m  
[2KStep 0 - TTA Loss: 0.6734â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”[0m 146/203 [2m0:08:30 â€¢ 0:05:31[0m [2;4m0.17it/s[0m  
[2KAttention weights: tensor([[0.6662, 0.3338]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 146/203 [2m0:08:30 â€¢ 0:05:31[0m [2;4m0.17it/s[0m  
[2KAttention weights: tensor([[0.7628, 0.2372]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 146/203 [2m0:08:30 â€¢ 0:05:31[0m [2;4m0.17it/s[0m  
[2KAttention weights: tensor([[0.8592, 0.1408]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 146/203 [2m0:08:30 â€¢ 0:05:31[0m [2;4m0.17it/s[0m  
[2KAttention weights: tensor([[0.9300, 0.0700]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 146/203 [2m0:08:30 â€¢ 0:05:31[0m [2;4m0.17it/s[0m  
[2KAttention weights: tensor([[0.9647, 0.0353]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 146/203 [2m0:08:30 â€¢ 0:05:31[0m [2;4m0.17it/s[0m  
[2KAttention weights: tensor([[0.9804, 0.0196]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 146/203 [2m0:08:30 â€¢ 0:05:31[0m [2;4m0.17it/s[0m  
[2KAttention weights: tensor([[0.9861, 0.0139]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 146/203 [2m0:08:30 â€¢ 0:05:31[0m [2;4m0.17it/s[0m  
[2KAttention weights: tensor([[0.9868, 0.0132]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 146/203 [2m0:08:30 â€¢ 0:05:31[0m [2;4m0.17it/s[0m  
[2KAttention weights: tensor([[0.9866, 0.0134]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 146/203 [2m0:08:30 â€¢ 0:05:31[0m [2;4m0.17it/s[0m  
[2KAttention weights: tensor([[0.5820, 0.4180]], device='cuda:0')6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”[0m 146/203 [2m0:08:30 â€¢ 0:05:31[0m [2;4m0.17it/s[0m  
[2KAttention weights: tensor([[0.9680, 0.0320],â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”[0m 146/203 [2m0:08:30 â€¢ 0:05:31[0m [2;4m0.17it/s[0m  
        [0.8714, 0.1286],
        [0.9425, 0.0575],
        [0.9581, 0.0419],
        [0.9865, 0.0135],
        [0.9683, 0.0317],
        [0.9543, 0.0457],
        [0.9517, 0.0483],
        [0.9488, 0.0512],
[2K        [0.9794, 0.0206]], device='cuda:0')â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”[0m 146/203 [2m0:08:30 â€¢ 0:05:31[0m [2;4m0.17it/s[0m  
[2KAttention weights: tensor([[0.5598, 0.4402],â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”[0m 147/203 [2m0:08:33 â€¢ 0:06:44[0m [2;4m0.14it/s[0m  
        [0.5552, 0.4448],
        [0.5570, 0.4430],
        [0.5580, 0.4420],
        [0.5587, 0.4413],
        [0.5554, 0.4446],
        [0.5544, 0.4456],
        [0.5591, 0.4409],
        [0.5592, 0.4408],
[2K        [0.5585, 0.4415]], device='cuda:0', grad_fn=<SoftmaxBackward0>)0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”[0m 147/203 [2m0:08:33 â€¢ 0:06:44[0m [2;4m0.14it/s[0m  
[2KClass label: GolfSwingâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”[0m 147/203 [2m0:08:33 â€¢ 0:06:44[0m [2;4m0.14it/s[0m  
[2KAttention weights: tensor([[0.6283, 0.3717]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 147/203 [2m0:08:33 â€¢ 0:06:44[0m [2;4m0.14it/s[0m  
[2KStep 0 - TTA Loss: 0.3929â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”[0m 147/203 [2m0:08:33 â€¢ 0:06:44[0m [2;4m0.14it/s[0m  
[2KAttention weights: tensor([[0.6283, 0.3717]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 147/203 [2m0:08:33 â€¢ 0:06:44[0m [2;4m0.14it/s[0m  
[2KAttention weights: tensor([[0.6284, 0.3716]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 147/203 [2m0:08:33 â€¢ 0:06:44[0m [2;4m0.14it/s[0m  
[2KAttention weights: tensor([[0.6294, 0.3706]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 147/203 [2m0:08:33 â€¢ 0:06:44[0m [2;4m0.14it/s[0m  
[2KAttention weights: tensor([[0.6342, 0.3658]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 147/203 [2m0:08:33 â€¢ 0:06:44[0m [2;4m0.14it/s[0m  
[2KAttention weights: tensor([[0.6461, 0.3539]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 147/203 [2m0:08:33 â€¢ 0:06:44[0m [2;4m0.14it/s[0m  
[2KAttention weights: tensor([[0.6608, 0.3392]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 147/203 [2m0:08:33 â€¢ 0:06:44[0m [2;4m0.14it/s[0m  
[2KAttention weights: tensor([[0.6749, 0.3251]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 147/203 [2m0:08:33 â€¢ 0:06:44[0m [2;4m0.14it/s[0m  
[2KAttention weights: tensor([[0.6943, 0.3057]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 147/203 [2m0:08:33 â€¢ 0:06:44[0m [2;4m0.14it/s[0m  
[2KAttention weights: tensor([[0.7197, 0.2803]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 147/203 [2m0:08:33 â€¢ 0:06:44[0m [2;4m0.14it/s[0m  
[2KAttention weights: tensor([[0.5606, 0.4394]], device='cuda:0')6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”[0m 147/203 [2m0:08:33 â€¢ 0:06:44[0m [2;4m0.14it/s[0m  
[2KAttention weights: tensor([[0.7087, 0.2913],â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”[0m 147/203 [2m0:08:33 â€¢ 0:06:44[0m [2;4m0.14it/s[0m  
        [0.6295, 0.3705],
        [0.6201, 0.3799],
        [0.7618, 0.2382],
        [0.6393, 0.3607],
        [0.6523, 0.3477],
        [0.6053, 0.3947],
        [0.6852, 0.3148],
        [0.7366, 0.2634],
[2K        [0.7093, 0.2907]], device='cuda:0')â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”â”[0m 147/203 [2m0:08:33 â€¢ 0:06:44[0m [2;4m0.14it/s[0m  
[2KAttention weights: tensor([[0.5598, 0.4402],â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”[0m 148/203 [2m0:08:36 â€¢ 0:04:47[0m [2;4m0.19it/s[0m   
        [0.5552, 0.4448],
        [0.5570, 0.4430],
        [0.5580, 0.4420],
        [0.5587, 0.4413],
        [0.5554, 0.4446],
        [0.5544, 0.4456],
        [0.5591, 0.4409],
        [0.5592, 0.4408],
[2K        [0.5585, 0.4415]], device='cuda:0', grad_fn=<SoftmaxBackward0>)38;5;237mâ”â”â”â”â”â”â”â”â”â”[0m 148/203 [2m0:08:36 â€¢ 0:04:47[0m [2;4m0.19it/s[0m  
[2KClass label: SoccerPenaltyâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”[0m 148/203 [2m0:08:36 â€¢ 0:04:47[0m [2;4m0.19it/s[0m  
[2KAttention weights: tensor([[0.6364, 0.3636]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 148/203 [2m0:08:36 â€¢ 0:04:47[0m [2;4m0.19it/s[0m  
[2KStep 0 - TTA Loss: 0.7882â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”[0m 148/203 [2m0:08:36 â€¢ 0:04:47[0m [2;4m0.19it/s[0m  
[2KAttention weights: tensor([[0.6952, 0.3048]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 148/203 [2m0:08:36 â€¢ 0:04:47[0m [2;4m0.19it/s[0m  
[2KAttention weights: tensor([[0.7808, 0.2192]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 148/203 [2m0:08:36 â€¢ 0:04:47[0m [2;4m0.19it/s[0m  
[2KAttention weights: tensor([[0.8645, 0.1355]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 148/203 [2m0:08:36 â€¢ 0:04:47[0m [2;4m0.19it/s[0m  
[2KAttention weights: tensor([[0.9257, 0.0743]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 148/203 [2m0:08:36 â€¢ 0:04:47[0m [2;4m0.19it/s[0m  
[2KAttention weights: tensor([[0.9590, 0.0410]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 148/203 [2m0:08:36 â€¢ 0:04:47[0m [2;4m0.19it/s[0m  
[2KAttention weights: tensor([[0.9703, 0.0297]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 148/203 [2m0:08:36 â€¢ 0:04:47[0m [2;4m0.19it/s[0m  
[2KAttention weights: tensor([[0.9722, 0.0278]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 148/203 [2m0:08:36 â€¢ 0:04:47[0m [2;4m0.19it/s[0m  
[2KAttention weights: tensor([[0.9710, 0.0290]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 148/203 [2m0:08:36 â€¢ 0:04:47[0m [2;4m0.19it/s[0m  
[2KAttention weights: tensor([[0.9687, 0.0313]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 148/203 [2m0:08:36 â€¢ 0:04:47[0m [2;4m0.19it/s[0m  
[2KAttention weights: tensor([[0.5746, 0.4254]], device='cuda:0')7mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”[0m 148/203 [2m0:08:36 â€¢ 0:04:47[0m [2;4m0.19it/s[0m  
[2KAttention weights: tensor([[0.8993, 0.1007],â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”[0m 148/203 [2m0:08:36 â€¢ 0:04:47[0m [2;4m0.19it/s[0m  
        [0.8233, 0.1767],
        [0.7767, 0.2233],
        [0.9043, 0.0957],
        [0.8710, 0.1290],
        [0.8769, 0.1231],
        [0.8429, 0.1571],
        [0.9679, 0.0321],
        [0.8888, 0.1112],
[2K        [0.8883, 0.1117]], device='cuda:0')â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”[0m 148/203 [2m0:08:36 â€¢ 0:04:47[0m [2;4m0.19it/s[0m  
[2KAttention weights: tensor([[0.5598, 0.4402],â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”[0m 149/203 [2m0:08:39 â€¢ 0:04:16[0m [2;4m0.21it/s[0m  
        [0.5552, 0.4448],
        [0.5570, 0.4430],
        [0.5580, 0.4420],
        [0.5587, 0.4413],
        [0.5554, 0.4446],
        [0.5544, 0.4456],
        [0.5591, 0.4409],
        [0.5592, 0.4408],
[2K        [0.5585, 0.4415]], device='cuda:0', grad_fn=<SoftmaxBackward0>)38;5;237mâ”â”â”â”â”â”â”â”â”â”[0m 149/203 [2m0:08:39 â€¢ 0:04:16[0m [2;4m0.21it/s[0m  
[2KClass label: HighJumpâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”[0m 149/203 [2m0:08:39 â€¢ 0:04:16[0m [2;4m0.21it/s[0m  
[2KAttention weights: tensor([[0.5972, 0.4028]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 149/203 [2m0:08:39 â€¢ 0:04:16[0m [2;4m0.21it/s[0m  
[2KStep 0 - TTA Loss: 0.7137â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”[0m 149/203 [2m0:08:39 â€¢ 0:04:16[0m [2;4m0.21it/s[0m  
[2KAttention weights: tensor([[0.5972, 0.4028]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 149/203 [2m0:08:39 â€¢ 0:04:16[0m [2;4m0.21it/s[0m  
[2KAttention weights: tensor([[0.5949, 0.4051]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 149/203 [2m0:08:39 â€¢ 0:04:16[0m [2;4m0.21it/s[0m  
[2KAttention weights: tensor([[0.5875, 0.4125]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 149/203 [2m0:08:39 â€¢ 0:04:16[0m [2;4m0.21it/s[0m  
[2KAttention weights: tensor([[0.5734, 0.4266]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 149/203 [2m0:08:39 â€¢ 0:04:16[0m [2;4m0.21it/s[0m  
[2KAttention weights: tensor([[0.5542, 0.4458]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 149/203 [2m0:08:39 â€¢ 0:04:16[0m [2;4m0.21it/s[0m  
[2KAttention weights: tensor([[0.5332, 0.4668]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 149/203 [2m0:08:39 â€¢ 0:04:16[0m [2;4m0.21it/s[0m  
[2KAttention weights: tensor([[0.5158, 0.4842]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 149/203 [2m0:08:39 â€¢ 0:04:16[0m [2;4m0.21it/s[0m  
[2KAttention weights: tensor([[0.5011, 0.4989]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 149/203 [2m0:08:39 â€¢ 0:04:16[0m [2;4m0.21it/s[0m  
[2KAttention weights: tensor([[0.4873, 0.5127]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 149/203 [2m0:08:39 â€¢ 0:04:16[0m [2;4m0.21it/s[0m  
[2KAttention weights: tensor([[0.5518, 0.4482]], device='cuda:0')7mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”[0m 149/203 [2m0:08:39 â€¢ 0:04:16[0m [2;4m0.21it/s[0m  
[2KAttention weights: tensor([[0.4714, 0.5286],â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”[0m 149/203 [2m0:08:39 â€¢ 0:04:16[0m [2;4m0.21it/s[0m  
        [0.4476, 0.5524],
        [0.5165, 0.4835],
        [0.5415, 0.4585],
        [0.4383, 0.5617],
        [0.4690, 0.5310],
        [0.4128, 0.5872],
        [0.1960, 0.8040],
        [0.5528, 0.4472],
[2K        [0.5283, 0.4717]], device='cuda:0')â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”[0m 149/203 [2m0:08:39 â€¢ 0:04:16[0m [2;4m0.21it/s[0m  
[2KAttention weights: tensor([[0.5598, 0.4402],â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”[0m 150/203 [2m0:08:42 â€¢ 0:04:01[0m [2;4m0.22it/s[0m  
        [0.5552, 0.4448],
        [0.5570, 0.4430],
        [0.5580, 0.4420],
        [0.5587, 0.4413],
        [0.5553, 0.4447],
        [0.5544, 0.4456],
        [0.5590, 0.4410],
        [0.5592, 0.4408],
[2K        [0.5584, 0.4416]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”[0m 150/203 [2m0:08:42 â€¢ 0:04:01[0m [2;4m0.22it/s[0m  
[2KClass label: BaseballPitchâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”[0m 150/203 [2m0:08:42 â€¢ 0:04:01[0m [2;4m0.22it/s[0m  
[2KAttention weights: tensor([[0.6188, 0.3812]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 150/203 [2m0:08:42 â€¢ 0:04:01[0m [2;4m0.22it/s[0m  
[2KStep 0 - TTA Loss: 0.7352â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”[0m 150/203 [2m0:08:42 â€¢ 0:04:01[0m [2;4m0.22it/s[0m  
[2KAttention weights: tensor([[0.6439, 0.3561]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 150/203 [2m0:08:42 â€¢ 0:04:01[0m [2;4m0.22it/s[0m  
[2KAttention weights: tensor([[0.6983, 0.3017]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 150/203 [2m0:08:42 â€¢ 0:04:01[0m [2;4m0.22it/s[0m  
[2KAttention weights: tensor([[0.7583, 0.2417]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 150/203 [2m0:08:42 â€¢ 0:04:01[0m [2;4m0.22it/s[0m  
[2KAttention weights: tensor([[0.8004, 0.1996]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 150/203 [2m0:08:42 â€¢ 0:04:01[0m [2;4m0.22it/s[0m  
[2KAttention weights: tensor([[0.8228, 0.1772]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 150/203 [2m0:08:42 â€¢ 0:04:01[0m [2;4m0.22it/s[0m  
[2KAttention weights: tensor([[0.8335, 0.1665]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 150/203 [2m0:08:42 â€¢ 0:04:01[0m [2;4m0.22it/s[0m  
[2KAttention weights: tensor([[0.8386, 0.1614]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 150/203 [2m0:08:42 â€¢ 0:04:01[0m [2;4m0.22it/s[0m  
[2KAttention weights: tensor([[0.8400, 0.1600]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 150/203 [2m0:08:42 â€¢ 0:04:01[0m [2;4m0.22it/s[0m  
[2KAttention weights: tensor([[0.8399, 0.1601]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 150/203 [2m0:08:42 â€¢ 0:04:01[0m [2;4m0.22it/s[0m  
[2KAttention weights: tensor([[0.5669, 0.4331]], device='cuda:0');6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”[0m 150/203 [2m0:08:42 â€¢ 0:04:01[0m [2;4m0.22it/s[0m  
[2KAttention weights: tensor([[0.8398, 0.1602],â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”[0m 150/203 [2m0:08:42 â€¢ 0:04:01[0m [2;4m0.22it/s[0m  
        [0.6312, 0.3688],
        [0.6678, 0.3322],
        [0.7883, 0.2117],
        [0.7235, 0.2765],
        [0.7194, 0.2806],
        [0.6514, 0.3486],
        [0.5172, 0.4828],
        [0.7733, 0.2267],
[2K        [0.7883, 0.2117]], device='cuda:0')â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”[0m 150/203 [2m0:08:42 â€¢ 0:04:01[0m [2;4m0.22it/s[0m  
[2KAttention weights: tensor([[0.5598, 0.4402],â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”[0m 151/203 [2m0:08:44 â€¢ 0:03:33[0m [2;4m0.24it/s[0m  
        [0.5551, 0.4449],
        [0.5570, 0.4430],
        [0.5580, 0.4420],
        [0.5586, 0.4414],
        [0.5553, 0.4447],
        [0.5543, 0.4457],
        [0.5590, 0.4410],
        [0.5592, 0.4408],
[2K        [0.5584, 0.4416]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”[0m 151/203 [2m0:08:44 â€¢ 0:03:33[0m [2;4m0.24it/s[0m  
[2KClass label: GolfSwingâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”[0m 151/203 [2m0:08:44 â€¢ 0:03:33[0m [2;4m0.24it/s[0m  
[2KAttention weights: tensor([[0.6326, 0.3674]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 151/203 [2m0:08:44 â€¢ 0:03:33[0m [2;4m0.24it/s[0m  
[2KStep 0 - TTA Loss: 0.7798â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”[0m 151/203 [2m0:08:44 â€¢ 0:03:33[0m [2;4m0.24it/s[0m  
[2KAttention weights: tensor([[0.6326, 0.3674]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 151/203 [2m0:08:44 â€¢ 0:03:33[0m [2;4m0.24it/s[0m  
[2KAttention weights: tensor([[0.6338, 0.3662]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 151/203 [2m0:08:44 â€¢ 0:03:33[0m [2;4m0.24it/s[0m  
[2KAttention weights: tensor([[0.6401, 0.3599]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 151/203 [2m0:08:44 â€¢ 0:03:33[0m [2;4m0.24it/s[0m  
[2KAttention weights: tensor([[0.6571, 0.3429]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 151/203 [2m0:08:44 â€¢ 0:03:33[0m [2;4m0.24it/s[0m  
[2KAttention weights: tensor([[0.6897, 0.3103]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 151/203 [2m0:08:44 â€¢ 0:03:33[0m [2;4m0.24it/s[0m  
[2KAttention weights: tensor([[0.7396, 0.2604]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 151/203 [2m0:08:44 â€¢ 0:03:33[0m [2;4m0.24it/s[0m  
[2KAttention weights: tensor([[0.7994, 0.2006]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 151/203 [2m0:08:44 â€¢ 0:03:33[0m [2;4m0.24it/s[0m  
[2KAttention weights: tensor([[0.8603, 0.1397]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 151/203 [2m0:08:44 â€¢ 0:03:33[0m [2;4m0.24it/s[0m  
[2KAttention weights: tensor([[0.9126, 0.0874]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 151/203 [2m0:08:44 â€¢ 0:03:33[0m [2;4m0.24it/s[0m  
[2KAttention weights: tensor([[0.5721, 0.4279]], device='cuda:0');6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”[0m 151/203 [2m0:08:44 â€¢ 0:03:33[0m [2;4m0.24it/s[0m  
[2KAttention weights: tensor([[0.9063, 0.0937],â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”[0m 151/203 [2m0:08:44 â€¢ 0:03:33[0m [2;4m0.24it/s[0m  
        [0.7729, 0.2271],
        [0.8109, 0.1891],
        [0.9484, 0.0516],
        [0.8678, 0.1322],
        [0.8471, 0.1529],
        [0.8071, 0.1929],
        [0.8112, 0.1888],
        [0.9068, 0.0932],
[2K        [0.9030, 0.0970]], device='cuda:0')â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”[0m 151/203 [2m0:08:44 â€¢ 0:03:33[0m [2;4m0.24it/s[0m  
[2KAttention weights: tensor([[0.5598, 0.4402],â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”[0m 152/203 [2m0:08:46 â€¢ 0:02:16[0m [2;4m0.38it/s[0m  
        [0.5552, 0.4448],
        [0.5570, 0.4430],
        [0.5580, 0.4420],
        [0.5587, 0.4413],
        [0.5553, 0.4447],
        [0.5544, 0.4456],
        [0.5590, 0.4410],
        [0.5592, 0.4408],
[2K        [0.5585, 0.4415]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”[0m 152/203 [2m0:08:46 â€¢ 0:02:16[0m [2;4m0.38it/s[0m  
[2KClass label: PoleVaultâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”[0m 152/203 [2m0:08:46 â€¢ 0:02:16[0m [2;4m0.38it/s[0m  
[2KAttention weights: tensor([[0.5511, 0.4489]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 152/203 [2m0:08:46 â€¢ 0:02:16[0m [2;4m0.38it/s[0m  
[2KStep 0 - TTA Loss: 0.5534â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”[0m 152/203 [2m0:08:46 â€¢ 0:02:16[0m [2;4m0.38it/s[0m  
[2KAttention weights: tensor([[0.6294, 0.3706]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 152/203 [2m0:08:46 â€¢ 0:02:16[0m [2;4m0.38it/s[0m  
[2KAttention weights: tensor([[0.7149, 0.2851]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 152/203 [2m0:08:46 â€¢ 0:02:16[0m [2;4m0.38it/s[0m  
[2KAttention weights: tensor([[0.7946, 0.2054]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 152/203 [2m0:08:46 â€¢ 0:02:16[0m [2;4m0.38it/s[0m  
[2KAttention weights: tensor([[0.8562, 0.1438]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 152/203 [2m0:08:46 â€¢ 0:02:16[0m [2;4m0.38it/s[0m  
[2KAttention weights: tensor([[0.8968, 0.1032]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 152/203 [2m0:08:46 â€¢ 0:02:16[0m [2;4m0.38it/s[0m  
[2KAttention weights: tensor([[0.9199, 0.0801]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 152/203 [2m0:08:46 â€¢ 0:02:16[0m [2;4m0.38it/s[0m  
[2KAttention weights: tensor([[0.9313, 0.0687]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 152/203 [2m0:08:46 â€¢ 0:02:16[0m [2;4m0.38it/s[0m  
[2KAttention weights: tensor([[0.9389, 0.0611]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 152/203 [2m0:08:46 â€¢ 0:02:16[0m [2;4m0.38it/s[0m  
[2KAttention weights: tensor([[0.9419, 0.0581]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 152/203 [2m0:08:46 â€¢ 0:02:16[0m [2;4m0.38it/s[0m  
[2KAttention weights: tensor([[0.5706, 0.4294]], device='cuda:0');6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”[0m 152/203 [2m0:08:46 â€¢ 0:02:16[0m [2;4m0.38it/s[0m  
[2KAttention weights: tensor([[0.9502, 0.0498],â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”[0m 152/203 [2m0:08:46 â€¢ 0:02:16[0m [2;4m0.38it/s[0m  
        [0.8490, 0.1510],
        [0.8955, 0.1045],
        [0.9698, 0.0302],
        [0.9407, 0.0593],
        [0.9410, 0.0590],
        [0.9425, 0.0575],
        [0.9060, 0.0940],
        [0.9398, 0.0602],
[2K        [0.9556, 0.0444]], device='cuda:0')â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”â”[0m 152/203 [2m0:08:46 â€¢ 0:02:16[0m [2;4m0.38it/s[0m  
[2KAttention weights: tensor([[0.5598, 0.4402],â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”[0m 153/203 [2m0:09:09 â€¢ 0:07:34[0m [2;4m0.11it/s[0m   
        [0.5552, 0.4448],
        [0.5570, 0.4430],
        [0.5581, 0.4419],
        [0.5587, 0.4413],
        [0.5554, 0.4446],
        [0.5544, 0.4456],
        [0.5590, 0.4410],
        [0.5593, 0.4407],
[2K        [0.5585, 0.4415]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[38;5;237mâ”â”â”â”â”â”â”â”â”[0m 153/203 [2m0:09:09 â€¢ 0:07:34[0m [2;4m0.11it/s[0m  
[2KClass label: ThrowDiscusâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”[0m 153/203 [2m0:09:09 â€¢ 0:07:34[0m [2;4m0.11it/s[0m  
[2KAttention weights: tensor([[0.6388, 0.3612]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 153/203 [2m0:09:09 â€¢ 0:07:34[0m [2;4m0.11it/s[0m  
[2KStep 0 - TTA Loss: 0.6288â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”[0m 153/203 [2m0:09:09 â€¢ 0:07:34[0m [2;4m0.11it/s[0m  
[2KAttention weights: tensor([[0.6388, 0.3612]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 153/203 [2m0:09:09 â€¢ 0:07:34[0m [2;4m0.11it/s[0m  
[2KAttention weights: tensor([[0.6418, 0.3582]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 153/203 [2m0:09:09 â€¢ 0:07:34[0m [2;4m0.11it/s[0m  
[2KAttention weights: tensor([[0.6552, 0.3448]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 153/203 [2m0:09:09 â€¢ 0:07:34[0m [2;4m0.11it/s[0m  
[2KAttention weights: tensor([[0.6852, 0.3148]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 153/203 [2m0:09:09 â€¢ 0:07:34[0m [2;4m0.11it/s[0m  
[2KAttention weights: tensor([[0.7383, 0.2617]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 153/203 [2m0:09:09 â€¢ 0:07:34[0m [2;4m0.11it/s[0m  
[2KAttention weights: tensor([[0.8140, 0.1860]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 153/203 [2m0:09:09 â€¢ 0:07:34[0m [2;4m0.11it/s[0m  
[2KAttention weights: tensor([[0.8950, 0.1050]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 153/203 [2m0:09:09 â€¢ 0:07:34[0m [2;4m0.11it/s[0m  
[2KAttention weights: tensor([[0.9594, 0.0406]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 153/203 [2m0:09:09 â€¢ 0:07:34[0m [2;4m0.11it/s[0m  
[2KAttention weights: tensor([[0.9917, 0.0083]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 153/203 [2m0:09:09 â€¢ 0:07:34[0m [2;4m0.11it/s[0m  
[2KAttention weights: tensor([[0.5895, 0.4105]], device='cuda:0')37mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”[0m 153/203 [2m0:09:09 â€¢ 0:07:34[0m [2;4m0.11it/s[0m  
[2KAttention weights: tensor([[0.9951, 0.0049],â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”[0m 153/203 [2m0:09:09 â€¢ 0:07:34[0m [2;4m0.11it/s[0m  
        [0.9472, 0.0528],
        [0.9822, 0.0178],
        [0.9935, 0.0065],
        [0.9960, 0.0040],
        [0.9938, 0.0062],
        [0.9903, 0.0097],
        [0.9803, 0.0197],
        [0.9908, 0.0092],
[2K        [0.9980, 0.0020]], device='cuda:0')â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”[0m 153/203 [2m0:09:09 â€¢ 0:07:34[0m [2;4m0.11it/s[0m  
[2KAttention weights: tensor([[0.5599, 0.4401],â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”[0m 154/203 [2m0:09:12 â€¢ 0:06:06[0m [2;4m0.13it/s[0m  
        [0.5552, 0.4448],
        [0.5571, 0.4429],
        [0.5581, 0.4419],
        [0.5587, 0.4413],
        [0.5554, 0.4446],
        [0.5545, 0.4455],
        [0.5590, 0.4410],
        [0.5593, 0.4407],
[2K        [0.5586, 0.4414]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[38;5;237mâ”â”â”â”â”â”â”â”â”[0m 154/203 [2m0:09:12 â€¢ 0:06:06[0m [2;4m0.13it/s[0m  
[2KClass label: HighJumpâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”[0m 154/203 [2m0:09:12 â€¢ 0:06:06[0m [2;4m0.13it/s[0m  
[2KAttention weights: tensor([[0.5978, 0.4022]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 154/203 [2m0:09:12 â€¢ 0:06:06[0m [2;4m0.13it/s[0m  
[2KStep 0 - TTA Loss: 0.6568â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”[0m 154/203 [2m0:09:12 â€¢ 0:06:06[0m [2;4m0.13it/s[0m  
[2KAttention weights: tensor([[0.8344, 0.1656]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 154/203 [2m0:09:12 â€¢ 0:06:06[0m [2;4m0.13it/s[0m  
[2KAttention weights: tensor([[0.9581, 0.0419]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 154/203 [2m0:09:12 â€¢ 0:06:06[0m [2;4m0.13it/s[0m  
[2KAttention weights: tensor([[0.9928, 0.0072]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 154/203 [2m0:09:12 â€¢ 0:06:06[0m [2;4m0.13it/s[0m  
[2KAttention weights: tensor([[0.9968, 0.0032]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 154/203 [2m0:09:12 â€¢ 0:06:06[0m [2;4m0.13it/s[0m  
[2KAttention weights: tensor([[0.9959, 0.0041]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 154/203 [2m0:09:12 â€¢ 0:06:06[0m [2;4m0.13it/s[0m  
[2KAttention weights: tensor([[0.9929, 0.0071]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 154/203 [2m0:09:12 â€¢ 0:06:06[0m [2;4m0.13it/s[0m  
[2KAttention weights: tensor([[0.9872, 0.0128]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 154/203 [2m0:09:12 â€¢ 0:06:06[0m [2;4m0.13it/s[0m  
[2KAttention weights: tensor([[0.9810, 0.0190]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 154/203 [2m0:09:12 â€¢ 0:06:06[0m [2;4m0.13it/s[0m  
[2KAttention weights: tensor([[0.9770, 0.0230]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 154/203 [2m0:09:12 â€¢ 0:06:06[0m [2;4m0.13it/s[0m  
[2KAttention weights: tensor([[0.5749, 0.4251]], device='cuda:0')37mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”[0m 154/203 [2m0:09:12 â€¢ 0:06:06[0m [2;4m0.13it/s[0m  
[2KAttention weights: tensor([[0.9877, 0.0123],â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”[0m 154/203 [2m0:09:12 â€¢ 0:06:06[0m [2;4m0.13it/s[0m  
        [0.9046, 0.0954],
        [0.9584, 0.0416],
        [0.9844, 0.0156],
        [0.9882, 0.0118],
        [0.9758, 0.0242],
        [0.9681, 0.0319],
        [0.9532, 0.0468],
        [0.9781, 0.0219],
[2K        [0.9942, 0.0058]], device='cuda:0')â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”â”[0m 154/203 [2m0:09:12 â€¢ 0:06:06[0m [2;4m0.13it/s[0m  
[2KAttention weights: tensor([[0.5600, 0.4400],â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”[0m 155/203 [2m0:09:15 â€¢ 0:07:52[0m [2;4m0.10it/s[0m  
        [0.5553, 0.4447],
        [0.5571, 0.4429],
        [0.5582, 0.4418],
        [0.5588, 0.4412],
        [0.5555, 0.4445],
        [0.5546, 0.4454],
        [0.5591, 0.4409],
        [0.5594, 0.4406],
[2K        [0.5587, 0.4413]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m[38;5;237mâ”â”â”â”â”â”â”â”â”[0m 155/203 [2m0:09:15 â€¢ 0:07:52[0m [2;4m0.10it/s[0m  
[2KClass label: HighJumpâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”[0m 155/203 [2m0:09:15 â€¢ 0:07:52[0m [2;4m0.10it/s[0m  
[2KAttention weights: tensor([[0.5918, 0.4082]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 155/203 [2m0:09:15 â€¢ 0:07:52[0m [2;4m0.10it/s[0m  
[2KStep 0 - TTA Loss: 0.5325â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”[0m 155/203 [2m0:09:15 â€¢ 0:07:52[0m [2;4m0.10it/s[0m  
[2KAttention weights: tensor([[0.5918, 0.4082]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 155/203 [2m0:09:15 â€¢ 0:07:52[0m [2;4m0.10it/s[0m  
[2KAttention weights: tensor([[0.5816, 0.4184]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 155/203 [2m0:09:15 â€¢ 0:07:52[0m [2;4m0.10it/s[0m  
[2KAttention weights: tensor([[0.5454, 0.4546]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 155/203 [2m0:09:15 â€¢ 0:07:52[0m [2;4m0.10it/s[0m  
[2KAttention weights: tensor([[0.4752, 0.5248]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 155/203 [2m0:09:15 â€¢ 0:07:52[0m [2;4m0.10it/s[0m  
[2KAttention weights: tensor([[0.3733, 0.6267]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 155/203 [2m0:09:15 â€¢ 0:07:52[0m [2;4m0.10it/s[0m  
[2KAttention weights: tensor([[0.2593, 0.7407]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 155/203 [2m0:09:15 â€¢ 0:07:52[0m [2;4m0.10it/s[0m  
[2KAttention weights: tensor([[0.1593, 0.8407]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 155/203 [2m0:09:15 â€¢ 0:07:52[0m [2;4m0.10it/s[0m  
[2KAttention weights: tensor([[0.0893, 0.9107]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 155/203 [2m0:09:15 â€¢ 0:07:52[0m [2;4m0.10it/s[0m  
[2KAttention weights: tensor([[0.0473, 0.9527]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 155/203 [2m0:09:15 â€¢ 0:07:52[0m [2;4m0.10it/s[0m  
[2KAttention weights: tensor([[0.5343, 0.4657]], device='cuda:0')8;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”[0m 155/203 [2m0:09:15 â€¢ 0:07:52[0m [2;4m0.10it/s[0m  
[2KAttention weights: tensor([[0.1281, 0.8719],â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”[0m 155/203 [2m0:09:15 â€¢ 0:07:52[0m [2;4m0.10it/s[0m  
        [0.2007, 0.7993],
        [0.1106, 0.8894],
        [0.1780, 0.8220],
        [0.0712, 0.9288],
        [0.0243, 0.9757],
        [0.0416, 0.9584],
        [0.1197, 0.8803],
        [0.1458, 0.8542],
[2K        [0.1018, 0.8982]], device='cuda:0')â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”[0m 155/203 [2m0:09:15 â€¢ 0:07:52[0m [2;4m0.10it/s[0m  
[2KAttention weights: tensor([[0.5600, 0.4400],â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”[0m 156/203 [2m0:09:24 â€¢ 0:03:45[0m [2;4m0.21it/s[0m  
        [0.5553, 0.4447],
        [0.5571, 0.4429],
        [0.5582, 0.4418],
        [0.5588, 0.4412],
        [0.5555, 0.4445],
        [0.5546, 0.4454],
        [0.5591, 0.4409],
        [0.5594, 0.4406],
[2K        [0.5587, 0.4413]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m[38;5;237mâ”â”â”â”â”â”â”â”â”[0m 156/203 [2m0:09:24 â€¢ 0:03:45[0m [2;4m0.21it/s[0m  
[2KClass label: CleanAndJerkâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”[0m 156/203 [2m0:09:24 â€¢ 0:03:45[0m [2;4m0.21it/s[0m  
[2KAttention weights: tensor([[0.5676, 0.4324]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 156/203 [2m0:09:24 â€¢ 0:03:45[0m [2;4m0.21it/s[0m  
[2KStep 0 - TTA Loss: 0.5342â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”[0m 156/203 [2m0:09:24 â€¢ 0:03:45[0m [2;4m0.21it/s[0m  
[2KAttention weights: tensor([[0.5017, 0.4983]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 156/203 [2m0:09:24 â€¢ 0:03:45[0m [2;4m0.21it/s[0m  
[2KAttention weights: tensor([[0.4593, 0.5407]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 156/203 [2m0:09:24 â€¢ 0:03:45[0m [2;4m0.21it/s[0m  
[2KAttention weights: tensor([[0.4339, 0.5661]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 156/203 [2m0:09:24 â€¢ 0:03:45[0m [2;4m0.21it/s[0m  
[2KAttention weights: tensor([[0.4192, 0.5808]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 156/203 [2m0:09:24 â€¢ 0:03:45[0m [2;4m0.21it/s[0m  
[2KAttention weights: tensor([[0.4102, 0.5898]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 156/203 [2m0:09:24 â€¢ 0:03:45[0m [2;4m0.21it/s[0m  
[2KAttention weights: tensor([[0.4046, 0.5954]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 156/203 [2m0:09:24 â€¢ 0:03:45[0m [2;4m0.21it/s[0m  
[2KAttention weights: tensor([[0.4012, 0.5988]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 156/203 [2m0:09:24 â€¢ 0:03:45[0m [2;4m0.21it/s[0m  
[2KAttention weights: tensor([[0.3994, 0.6006]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 156/203 [2m0:09:24 â€¢ 0:03:45[0m [2;4m0.21it/s[0m  
[2KAttention weights: tensor([[0.3986, 0.6014]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 156/203 [2m0:09:24 â€¢ 0:03:45[0m [2;4m0.21it/s[0m  
[2KAttention weights: tensor([[0.5531, 0.4469]], device='cuda:0')8;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”[0m 156/203 [2m0:09:24 â€¢ 0:03:45[0m [2;4m0.21it/s[0m  
[2KAttention weights: tensor([[0.3059, 0.6941],â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”[0m 156/203 [2m0:09:24 â€¢ 0:03:45[0m [2;4m0.21it/s[0m  
        [0.3656, 0.6344],
        [0.3983, 0.6017],
        [0.3807, 0.6193],
        [0.2443, 0.7557],
        [0.1314, 0.8686],
        [0.1665, 0.8335],
        [0.2895, 0.7105],
        [0.3479, 0.6521],
[2K        [0.3026, 0.6974]], device='cuda:0')â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”[0m 156/203 [2m0:09:24 â€¢ 0:03:45[0m [2;4m0.21it/s[0m  
[2KAttention weights: tensor([[0.5600, 0.4400],â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”[0m 157/203 [2m0:09:31 â€¢ 0:04:11[0m [2;4m0.18it/s[0m  
        [0.5553, 0.4447],
        [0.5571, 0.4429],
        [0.5582, 0.4418],
        [0.5588, 0.4412],
        [0.5555, 0.4445],
        [0.5545, 0.4455],
        [0.5591, 0.4409],
        [0.5594, 0.4406],
[2K        [0.5587, 0.4413]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m[38;5;237mâ”â”â”â”â”â”â”â”â”[0m 157/203 [2m0:09:31 â€¢ 0:04:11[0m [2;4m0.18it/s[0m  
[2KClass label: GolfSwingâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”[0m 157/203 [2m0:09:31 â€¢ 0:04:11[0m [2;4m0.18it/s[0m  
[2KAttention weights: tensor([[0.6319, 0.3681]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 157/203 [2m0:09:31 â€¢ 0:04:11[0m [2;4m0.18it/s[0m  
[2KStep 0 - TTA Loss: 0.6488â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”[0m 157/203 [2m0:09:31 â€¢ 0:04:11[0m [2;4m0.18it/s[0m  
[2KAttention weights: tensor([[0.6319, 0.3681]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 157/203 [2m0:09:31 â€¢ 0:04:11[0m [2;4m0.18it/s[0m  
[2KAttention weights: tensor([[0.6320, 0.3680]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 157/203 [2m0:09:31 â€¢ 0:04:11[0m [2;4m0.18it/s[0m  
[2KAttention weights: tensor([[0.6340, 0.3660]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 157/203 [2m0:09:31 â€¢ 0:04:11[0m [2;4m0.18it/s[0m  
[2KAttention weights: tensor([[0.6388, 0.3612]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 157/203 [2m0:09:31 â€¢ 0:04:11[0m [2;4m0.18it/s[0m  
[2KAttention weights: tensor([[0.6489, 0.3511]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 157/203 [2m0:09:31 â€¢ 0:04:11[0m [2;4m0.18it/s[0m  
[2KAttention weights: tensor([[0.6639, 0.3361]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 157/203 [2m0:09:31 â€¢ 0:04:11[0m [2;4m0.18it/s[0m  
[2KAttention weights: tensor([[0.6814, 0.3186]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 157/203 [2m0:09:31 â€¢ 0:04:11[0m [2;4m0.18it/s[0m  
[2KAttention weights: tensor([[0.7013, 0.2987]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 157/203 [2m0:09:31 â€¢ 0:04:11[0m [2;4m0.18it/s[0m  
[2KAttention weights: tensor([[0.7122, 0.2878]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 157/203 [2m0:09:31 â€¢ 0:04:11[0m [2;4m0.18it/s[0m  
[2KAttention weights: tensor([[0.5599, 0.4401]], device='cuda:0')8;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”[0m 157/203 [2m0:09:31 â€¢ 0:04:11[0m [2;4m0.18it/s[0m  
[2KAttention weights: tensor([[0.6671, 0.3329],â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”[0m 157/203 [2m0:09:31 â€¢ 0:04:11[0m [2;4m0.18it/s[0m  
        [0.6041, 0.3959],
        [0.6222, 0.3778],
        [0.7173, 0.2827],
        [0.6186, 0.3814],
        [0.5802, 0.4198],
        [0.5466, 0.4534],
        [0.6428, 0.3572],
        [0.6923, 0.3077],
[2K        [0.6774, 0.3226]], device='cuda:0')â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”â”[0m 157/203 [2m0:09:31 â€¢ 0:04:11[0m [2;4m0.18it/s[0m  
[2KAttention weights: tensor([[0.5600, 0.4400],â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”[0m 158/203 [2m0:09:35 â€¢ 0:03:51[0m [2;4m0.20it/s[0m   
        [0.5553, 0.4447],
        [0.5571, 0.4429],
        [0.5582, 0.4418],
        [0.5588, 0.4412],
        [0.5555, 0.4445],
        [0.5546, 0.4454],
        [0.5591, 0.4409],
        [0.5594, 0.4406],
[2K        [0.5587, 0.4413]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[38;5;237mâ”â”â”â”â”â”â”â”[0m 158/203 [2m0:09:35 â€¢ 0:03:51[0m [2;4m0.20it/s[0m  
[2KClass label: BaseballPitchâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”[0m 158/203 [2m0:09:35 â€¢ 0:03:51[0m [2;4m0.20it/s[0m  
[2KAttention weights: tensor([[0.6165, 0.3835]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 158/203 [2m0:09:35 â€¢ 0:03:51[0m [2;4m0.20it/s[0m  
[2KStep 0 - TTA Loss: 0.7813â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”[0m 158/203 [2m0:09:35 â€¢ 0:03:51[0m [2;4m0.20it/s[0m  
[2KAttention weights: tensor([[0.6503, 0.3497]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 158/203 [2m0:09:35 â€¢ 0:03:51[0m [2;4m0.20it/s[0m  
[2KAttention weights: tensor([[0.7085, 0.2915]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 158/203 [2m0:09:35 â€¢ 0:03:51[0m [2;4m0.20it/s[0m  
[2KAttention weights: tensor([[0.7798, 0.2202]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 158/203 [2m0:09:35 â€¢ 0:03:51[0m [2;4m0.20it/s[0m  
[2KAttention weights: tensor([[0.8430, 0.1570]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 158/203 [2m0:09:35 â€¢ 0:03:51[0m [2;4m0.20it/s[0m  
[2KAttention weights: tensor([[0.8907, 0.1093]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 158/203 [2m0:09:35 â€¢ 0:03:51[0m [2;4m0.20it/s[0m  
[2KAttention weights: tensor([[0.9201, 0.0799]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 158/203 [2m0:09:35 â€¢ 0:03:51[0m [2;4m0.20it/s[0m  
[2KAttention weights: tensor([[0.9369, 0.0631]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 158/203 [2m0:09:35 â€¢ 0:03:51[0m [2;4m0.20it/s[0m  
[2KAttention weights: tensor([[0.9455, 0.0545]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 158/203 [2m0:09:35 â€¢ 0:03:51[0m [2;4m0.20it/s[0m  
[2KAttention weights: tensor([[0.9489, 0.0511]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 158/203 [2m0:09:35 â€¢ 0:03:51[0m [2;4m0.20it/s[0m  
[2KAttention weights: tensor([[0.5738, 0.4262]], device='cuda:0')237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”[0m 158/203 [2m0:09:35 â€¢ 0:03:51[0m [2;4m0.20it/s[0m  
[2KAttention weights: tensor([[0.9498, 0.0502],â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”[0m 158/203 [2m0:09:35 â€¢ 0:03:51[0m [2;4m0.20it/s[0m  
        [0.7592, 0.2408],
        [0.7646, 0.2354],
        [0.9020, 0.0980],
        [0.8636, 0.1364],
        [0.8246, 0.1754],
        [0.7785, 0.2215],
        [0.8456, 0.1544],
        [0.8771, 0.1229],
[2K        [0.8970, 0.1030]], device='cuda:0')â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”[0m 158/203 [2m0:09:35 â€¢ 0:03:51[0m [2;4m0.20it/s[0m  
[2KAttention weights: tensor([[0.5600, 0.4400],â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”[0m 159/203 [2m0:09:36 â€¢ 0:03:14[0m [2;4m0.23it/s[0m  
        [0.5553, 0.4447],
        [0.5572, 0.4428],
        [0.5582, 0.4418],
        [0.5589, 0.4411],
        [0.5556, 0.4444],
        [0.5546, 0.4454],
        [0.5591, 0.4409],
        [0.5594, 0.4406],
[2K        [0.5587, 0.4413]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[38;5;237mâ”â”â”â”â”â”â”â”[0m 159/203 [2m0:09:36 â€¢ 0:03:14[0m [2;4m0.23it/s[0m  
[2KClass label: Billiardsâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”[0m 159/203 [2m0:09:36 â€¢ 0:03:14[0m [2;4m0.23it/s[0m  
[2KAttention weights: tensor([[0.5814, 0.4186]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 159/203 [2m0:09:36 â€¢ 0:03:14[0m [2;4m0.23it/s[0m  
[2KStep 0 - TTA Loss: 0.5184â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”[0m 159/203 [2m0:09:36 â€¢ 0:03:14[0m [2;4m0.23it/s[0m  
[2KAttention weights: tensor([[0.5814, 0.4186]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 159/203 [2m0:09:36 â€¢ 0:03:14[0m [2;4m0.23it/s[0m  
[2KAttention weights: tensor([[0.5839, 0.4161]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 159/203 [2m0:09:36 â€¢ 0:03:14[0m [2;4m0.23it/s[0m  
[2KAttention weights: tensor([[0.5957, 0.4043]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 159/203 [2m0:09:36 â€¢ 0:03:14[0m [2;4m0.23it/s[0m  
[2KAttention weights: tensor([[0.6243, 0.3757]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 159/203 [2m0:09:36 â€¢ 0:03:14[0m [2;4m0.23it/s[0m  
[2KAttention weights: tensor([[0.6729, 0.3271]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 159/203 [2m0:09:36 â€¢ 0:03:14[0m [2;4m0.23it/s[0m  
[2KAttention weights: tensor([[0.7415, 0.2585]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 159/203 [2m0:09:36 â€¢ 0:03:14[0m [2;4m0.23it/s[0m  
[2KAttention weights: tensor([[0.8170, 0.1830]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 159/203 [2m0:09:36 â€¢ 0:03:14[0m [2;4m0.23it/s[0m  
[2KAttention weights: tensor([[0.8789, 0.1211]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 159/203 [2m0:09:36 â€¢ 0:03:14[0m [2;4m0.23it/s[0m  
[2KAttention weights: tensor([[0.9185, 0.0815]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 159/203 [2m0:09:36 â€¢ 0:03:14[0m [2;4m0.23it/s[0m  
[2KAttention weights: tensor([[0.5666, 0.4334]], device='cuda:0')237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”[0m 159/203 [2m0:09:36 â€¢ 0:03:14[0m [2;4m0.23it/s[0m  
[2KAttention weights: tensor([[0.9167, 0.0833],â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”[0m 159/203 [2m0:09:36 â€¢ 0:03:14[0m [2;4m0.23it/s[0m  
        [0.9388, 0.0612],
        [0.7807, 0.2193],
        [0.8789, 0.1211],
        [0.8503, 0.1497],
        [0.8436, 0.1564],
        [0.7997, 0.2003],
        [0.8689, 0.1311],
        [0.8855, 0.1145],
[2K        [0.8822, 0.1178]], device='cuda:0')â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”â”[0m 159/203 [2m0:09:36 â€¢ 0:03:14[0m [2;4m0.23it/s[0m  
[2KAttention weights: tensor([[0.5600, 0.4400],â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”[0m 160/203 [2m0:09:37 â€¢ 0:02:52[0m [2;4m0.25it/s[0m  
        [0.5553, 0.4447],
        [0.5572, 0.4428],
        [0.5582, 0.4418],
        [0.5589, 0.4411],
        [0.5556, 0.4444],
        [0.5546, 0.4454],
        [0.5591, 0.4409],
        [0.5594, 0.4406],
[2K        [0.5587, 0.4413]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”[0m 160/203 [2m0:09:37 â€¢ 0:02:52[0m [2;4m0.25it/s[0m  
[2KClass label: Billiardsâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”[0m 160/203 [2m0:09:37 â€¢ 0:02:52[0m [2;4m0.25it/s[0m  
[2KAttention weights: tensor([[0.5845, 0.4155]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 160/203 [2m0:09:37 â€¢ 0:02:52[0m [2;4m0.25it/s[0m  
[2KStep 0 - TTA Loss: 0.7162â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”[0m 160/203 [2m0:09:37 â€¢ 0:02:52[0m [2;4m0.25it/s[0m  
[2KAttention weights: tensor([[0.6653, 0.3347]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 160/203 [2m0:09:37 â€¢ 0:02:52[0m [2;4m0.25it/s[0m  
[2KAttention weights: tensor([[0.7367, 0.2633]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 160/203 [2m0:09:37 â€¢ 0:02:52[0m [2;4m0.25it/s[0m  
[2KAttention weights: tensor([[0.7865, 0.2135]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 160/203 [2m0:09:37 â€¢ 0:02:52[0m [2;4m0.25it/s[0m  
[2KAttention weights: tensor([[0.8162, 0.1838]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 160/203 [2m0:09:37 â€¢ 0:02:52[0m [2;4m0.25it/s[0m  
[2KAttention weights: tensor([[0.8317, 0.1683]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 160/203 [2m0:09:37 â€¢ 0:02:52[0m [2;4m0.25it/s[0m  
[2KAttention weights: tensor([[0.8411, 0.1589]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 160/203 [2m0:09:37 â€¢ 0:02:52[0m [2;4m0.25it/s[0m  
[2KAttention weights: tensor([[0.8475, 0.1525]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 160/203 [2m0:09:37 â€¢ 0:02:52[0m [2;4m0.25it/s[0m  
[2KAttention weights: tensor([[0.8541, 0.1459]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 160/203 [2m0:09:37 â€¢ 0:02:52[0m [2;4m0.25it/s[0m  
[2KAttention weights: tensor([[0.8577, 0.1423]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 160/203 [2m0:09:37 â€¢ 0:02:52[0m [2;4m0.25it/s[0m  
[2KAttention weights: tensor([[0.5620, 0.4380]], device='cuda:0')98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”[0m 160/203 [2m0:09:37 â€¢ 0:02:52[0m [2;4m0.25it/s[0m  
[2KAttention weights: tensor([[0.8460, 0.1540],â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”[0m 160/203 [2m0:09:37 â€¢ 0:02:52[0m [2;4m0.25it/s[0m  
        [0.8591, 0.1409],
        [0.7088, 0.2912],
        [0.8104, 0.1896],
        [0.7722, 0.2278],
        [0.7687, 0.2313],
        [0.7187, 0.2813],
        [0.8014, 0.1986],
        [0.8192, 0.1808],
[2K        [0.8137, 0.1863]], device='cuda:0')â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”[0m 160/203 [2m0:09:37 â€¢ 0:02:52[0m [2;4m0.25it/s[0m  
[2KAttention weights: tensor([[0.5601, 0.4399],â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”[0m 161/203 [2m0:09:39 â€¢ 0:02:45[0m [2;4m0.26it/s[0m  
        [0.5553, 0.4447],
        [0.5572, 0.4428],
        [0.5582, 0.4418],
        [0.5589, 0.4411],
        [0.5556, 0.4444],
        [0.5546, 0.4454],
        [0.5592, 0.4408],
        [0.5594, 0.4406],
[2K        [0.5588, 0.4412]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”[0m 161/203 [2m0:09:39 â€¢ 0:02:45[0m [2;4m0.26it/s[0m  
[2KClass label: Billiardsâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”[0m 161/203 [2m0:09:39 â€¢ 0:02:45[0m [2;4m0.26it/s[0m  
[2KAttention weights: tensor([[0.5832, 0.4168]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 161/203 [2m0:09:39 â€¢ 0:02:45[0m [2;4m0.26it/s[0m  
[2KStep 0 - TTA Loss: 0.7161â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”[0m 161/203 [2m0:09:39 â€¢ 0:02:45[0m [2;4m0.26it/s[0m  
[2KAttention weights: tensor([[0.5832, 0.4168]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 161/203 [2m0:09:39 â€¢ 0:02:45[0m [2;4m0.26it/s[0m  
[2KAttention weights: tensor([[0.5864, 0.4136]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 161/203 [2m0:09:39 â€¢ 0:02:45[0m [2;4m0.26it/s[0m  
[2KAttention weights: tensor([[0.6001, 0.3999]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 161/203 [2m0:09:39 â€¢ 0:02:45[0m [2;4m0.26it/s[0m  
[2KAttention weights: tensor([[0.6308, 0.3692]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 161/203 [2m0:09:39 â€¢ 0:02:45[0m [2;4m0.26it/s[0m  
[2KAttention weights: tensor([[0.6804, 0.3196]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 161/203 [2m0:09:39 â€¢ 0:02:45[0m [2;4m0.26it/s[0m  
[2KAttention weights: tensor([[0.7415, 0.2585]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 161/203 [2m0:09:39 â€¢ 0:02:45[0m [2;4m0.26it/s[0m  
[2KAttention weights: tensor([[0.8036, 0.1964]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 161/203 [2m0:09:39 â€¢ 0:02:45[0m [2;4m0.26it/s[0m  
[2KAttention weights: tensor([[0.8740, 0.1260]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 161/203 [2m0:09:39 â€¢ 0:02:45[0m [2;4m0.26it/s[0m  
[2KAttention weights: tensor([[0.9574, 0.0426]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 161/203 [2m0:09:39 â€¢ 0:02:45[0m [2;4m0.26it/s[0m  
[2KAttention weights: tensor([[0.5789, 0.4211]], device='cuda:0')98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”[0m 161/203 [2m0:09:39 â€¢ 0:02:45[0m [2;4m0.26it/s[0m  
[2KAttention weights: tensor([[0.9008, 0.0992],â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”[0m 161/203 [2m0:09:39 â€¢ 0:02:45[0m [2;4m0.26it/s[0m  
        [0.9965, 0.0035],
        [0.8525, 0.1475],
        [0.8976, 0.1024],
        [0.8780, 0.1220],
        [0.8944, 0.1056],
        [0.8613, 0.1387],
        [0.9223, 0.0777],
        [0.9319, 0.0681],
[2K        [0.9036, 0.0964]], device='cuda:0')â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”[0m 161/203 [2m0:09:39 â€¢ 0:02:45[0m [2;4m0.26it/s[0m  
[2KAttention weights: tensor([[0.5601, 0.4399],â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”[0m 162/203 [2m0:09:41 â€¢ 0:02:31[0m [2;4m0.27it/s[0m  
        [0.5554, 0.4446],
        [0.5572, 0.4428],
        [0.5583, 0.4417],
        [0.5589, 0.4411],
        [0.5556, 0.4444],
        [0.5546, 0.4454],
        [0.5592, 0.4408],
        [0.5594, 0.4406],
[2K        [0.5588, 0.4412]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”[0m 162/203 [2m0:09:41 â€¢ 0:02:31[0m [2;4m0.27it/s[0m  
[2KClass label: HighJumpâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”[0m 162/203 [2m0:09:41 â€¢ 0:02:31[0m [2;4m0.27it/s[0m  
[2KAttention weights: tensor([[0.5981, 0.4019]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 162/203 [2m0:09:41 â€¢ 0:02:31[0m [2;4m0.27it/s[0m  
[2KStep 0 - TTA Loss: 0.5128â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”[0m 162/203 [2m0:09:41 â€¢ 0:02:31[0m [2;4m0.27it/s[0m  
[2KAttention weights: tensor([[0.7755, 0.2245]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 162/203 [2m0:09:41 â€¢ 0:02:31[0m [2;4m0.27it/s[0m  
[2KAttention weights: tensor([[0.8960, 0.1040]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 162/203 [2m0:09:41 â€¢ 0:02:31[0m [2;4m0.27it/s[0m  
[2KAttention weights: tensor([[0.9608, 0.0392]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 162/203 [2m0:09:41 â€¢ 0:02:31[0m [2;4m0.27it/s[0m  
[2KAttention weights: tensor([[0.9885, 0.0115]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 162/203 [2m0:09:41 â€¢ 0:02:31[0m [2;4m0.27it/s[0m  
[2KAttention weights: tensor([[0.9959, 0.0041]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 162/203 [2m0:09:41 â€¢ 0:02:31[0m [2;4m0.27it/s[0m  
[2KAttention weights: tensor([[0.9977, 0.0023]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 162/203 [2m0:09:41 â€¢ 0:02:31[0m [2;4m0.27it/s[0m  
[2KAttention weights: tensor([[0.9982, 0.0018]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 162/203 [2m0:09:41 â€¢ 0:02:31[0m [2;4m0.27it/s[0m  
[2KAttention weights: tensor([[0.9983, 0.0017]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 162/203 [2m0:09:41 â€¢ 0:02:31[0m [2;4m0.27it/s[0m  
[2KAttention weights: tensor([[0.9983, 0.0017]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 162/203 [2m0:09:41 â€¢ 0:02:31[0m [2;4m0.27it/s[0m  
[2KAttention weights: tensor([[0.5931, 0.4069]], device='cuda:0')98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”[0m 162/203 [2m0:09:41 â€¢ 0:02:31[0m [2;4m0.27it/s[0m  
[2KAttention weights: tensor([[9.9556e-01, 4.4443e-03],[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”[0m 162/203 [2m0:09:41 â€¢ 0:02:31[0m [2;4m0.27it/s[0m  
        [9.9999e-01, 9.9395e-06],
        [9.9113e-01, 8.8672e-03],
        [9.9410e-01, 5.8985e-03],
        [9.9594e-01, 4.0580e-03],
        [9.9828e-01, 1.7177e-03],
        [9.9596e-01, 4.0418e-03],
        [9.9719e-01, 2.8064e-03],
        [9.9764e-01, 2.3634e-03],
[2K        [9.9677e-01, 3.2337e-03]], device='cuda:0')[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”â”[0m 162/203 [2m0:09:41 â€¢ 0:02:31[0m [2;4m0.27it/s[0m  
[2KAttention weights: tensor([[0.5602, 0.4398],â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”[0m 163/203 [2m0:09:48 â€¢ 0:02:18[0m [2;4m0.29it/s[0m   
        [0.5556, 0.4444],
        [0.5573, 0.4427],
        [0.5583, 0.4417],
        [0.5590, 0.4410],
        [0.5557, 0.4443],
        [0.5547, 0.4453],
        [0.5593, 0.4407],
        [0.5595, 0.4405],
[2K        [0.5588, 0.4412]], device='cuda:0', grad_fn=<SoftmaxBackward0>)m[38;5;237mâ”â”â”â”â”â”â”[0m 163/203 [2m0:09:48 â€¢ 0:02:18[0m [2;4m0.29it/s[0m  
[2KClass label: BaseballPitchâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”[0m 163/203 [2m0:09:48 â€¢ 0:02:18[0m [2;4m0.29it/s[0m  
[2KAttention weights: tensor([[0.6161, 0.3839]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 163/203 [2m0:09:48 â€¢ 0:02:18[0m [2;4m0.29it/s[0m  
[2KStep 0 - TTA Loss: 0.6846â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”[0m 163/203 [2m0:09:48 â€¢ 0:02:18[0m [2;4m0.29it/s[0m  
[2KAttention weights: tensor([[0.6161, 0.3839]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 163/203 [2m0:09:48 â€¢ 0:02:18[0m [2;4m0.29it/s[0m  
[2KAttention weights: tensor([[0.6170, 0.3830]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 163/203 [2m0:09:48 â€¢ 0:02:18[0m [2;4m0.29it/s[0m  
[2KAttention weights: tensor([[0.6224, 0.3776]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 163/203 [2m0:09:48 â€¢ 0:02:18[0m [2;4m0.29it/s[0m  
[2KAttention weights: tensor([[0.6387, 0.3613]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 163/203 [2m0:09:48 â€¢ 0:02:18[0m [2;4m0.29it/s[0m  
[2KAttention weights: tensor([[0.6704, 0.3296]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 163/203 [2m0:09:48 â€¢ 0:02:18[0m [2;4m0.29it/s[0m  
[2KAttention weights: tensor([[0.7202, 0.2798]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 163/203 [2m0:09:48 â€¢ 0:02:18[0m [2;4m0.29it/s[0m  
[2KAttention weights: tensor([[0.7831, 0.2169]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 163/203 [2m0:09:48 â€¢ 0:02:18[0m [2;4m0.29it/s[0m  
[2KAttention weights: tensor([[0.8507, 0.1493]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 163/203 [2m0:09:48 â€¢ 0:02:18[0m [2;4m0.29it/s[0m  
[2KAttention weights: tensor([[0.9072, 0.0928]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 163/203 [2m0:09:48 â€¢ 0:02:18[0m [2;4m0.29it/s[0m  
[2KAttention weights: tensor([[0.5717, 0.4283]], device='cuda:0');237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”[0m 163/203 [2m0:09:48 â€¢ 0:02:18[0m [2;4m0.29it/s[0m  
[2KAttention weights: tensor([[0.9416, 0.0584],â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”[0m 163/203 [2m0:09:48 â€¢ 0:02:18[0m [2;4m0.29it/s[0m  
        [0.9276, 0.0724],
        [0.7254, 0.2746],
        [0.8876, 0.1124],
        [0.8322, 0.1678],
        [0.7761, 0.2239],
        [0.7381, 0.2619],
        [0.8505, 0.1495],
        [0.8785, 0.1215],
[2K        [0.8725, 0.1275]], device='cuda:0')â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”[0m 163/203 [2m0:09:48 â€¢ 0:02:18[0m [2;4m0.29it/s[0m  
[2KAttention weights: tensor([[0.5602, 0.4398],â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”[0m 164/203 [2m0:09:49 â€¢ 0:02:06[0m [2;4m0.31it/s[0m  
        [0.5556, 0.4444],
        [0.5574, 0.4426],
        [0.5584, 0.4416],
        [0.5591, 0.4409],
        [0.5558, 0.4442],
        [0.5548, 0.4452],
        [0.5593, 0.4407],
        [0.5596, 0.4404],
[2K        [0.5589, 0.4411]], device='cuda:0', grad_fn=<SoftmaxBackward0>)m[38;5;237mâ”â”â”â”â”â”â”[0m 164/203 [2m0:09:49 â€¢ 0:02:06[0m [2;4m0.31it/s[0m  
[2KClass label: Billiardsâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”[0m 164/203 [2m0:09:49 â€¢ 0:02:06[0m [2;4m0.31it/s[0m  
[2KAttention weights: tensor([[0.5836, 0.4164]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 164/203 [2m0:09:49 â€¢ 0:02:06[0m [2;4m0.31it/s[0m  
[2KStep 0 - TTA Loss: 0.7242â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”[0m 164/203 [2m0:09:49 â€¢ 0:02:06[0m [2;4m0.31it/s[0m  
[2KAttention weights: tensor([[0.6825, 0.3175]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 164/203 [2m0:09:49 â€¢ 0:02:06[0m [2;4m0.31it/s[0m  
[2KAttention weights: tensor([[0.7703, 0.2297]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 164/203 [2m0:09:49 â€¢ 0:02:06[0m [2;4m0.31it/s[0m  
[2KAttention weights: tensor([[0.8329, 0.1671]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 164/203 [2m0:09:49 â€¢ 0:02:06[0m [2;4m0.31it/s[0m  
[2KAttention weights: tensor([[0.8700, 0.1300]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 164/203 [2m0:09:49 â€¢ 0:02:06[0m [2;4m0.31it/s[0m  
[2KAttention weights: tensor([[0.8864, 0.1136]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 164/203 [2m0:09:49 â€¢ 0:02:06[0m [2;4m0.31it/s[0m  
[2KAttention weights: tensor([[0.8882, 0.1118]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 164/203 [2m0:09:49 â€¢ 0:02:06[0m [2;4m0.31it/s[0m  
[2KAttention weights: tensor([[0.8831, 0.1169]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 164/203 [2m0:09:49 â€¢ 0:02:06[0m [2;4m0.31it/s[0m  
[2KAttention weights: tensor([[0.8762, 0.1238]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 164/203 [2m0:09:49 â€¢ 0:02:06[0m [2;4m0.31it/s[0m  
[2KAttention weights: tensor([[0.8712, 0.1288]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 164/203 [2m0:09:49 â€¢ 0:02:06[0m [2;4m0.31it/s[0m  
[2KAttention weights: tensor([[0.5647, 0.4353]], device='cuda:0');237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”[0m 164/203 [2m0:09:49 â€¢ 0:02:06[0m [2;4m0.31it/s[0m  
[2KAttention weights: tensor([[0.9179, 0.0821],â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”[0m 164/203 [2m0:09:49 â€¢ 0:02:06[0m [2;4m0.31it/s[0m  
        [0.8697, 0.1303],
        [0.7096, 0.2904],
        [0.8597, 0.1403],
        [0.8090, 0.1910],
        [0.7662, 0.2338],
        [0.7231, 0.2769],
        [0.8258, 0.1742],
        [0.8510, 0.1490],
[2K        [0.8510, 0.1490]], device='cuda:0')â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”â”[0m 164/203 [2m0:09:49 â€¢ 0:02:06[0m [2;4m0.31it/s[0m  
[2KAttention weights: tensor([[0.5603, 0.4397],â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”[0m 165/203 [2m0:09:53 â€¢ 0:02:06[0m [2;4m0.30it/s[0m  
        [0.5557, 0.4443],
        [0.5574, 0.4426],
        [0.5584, 0.4416],
        [0.5591, 0.4409],
        [0.5559, 0.4441],
        [0.5549, 0.4451],
        [0.5593, 0.4407],
        [0.5596, 0.4404],
[2K        [0.5589, 0.4411]], device='cuda:0', grad_fn=<SoftmaxBackward0>)mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”[0m 165/203 [2m0:09:53 â€¢ 0:02:06[0m [2;4m0.30it/s[0m  
[2KClass label: BaseballPitchâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”[0m 165/203 [2m0:09:53 â€¢ 0:02:06[0m [2;4m0.30it/s[0m  
[2KAttention weights: tensor([[0.6105, 0.3895]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 165/203 [2m0:09:53 â€¢ 0:02:06[0m [2;4m0.30it/s[0m  
[2KStep 0 - TTA Loss: 0.4155â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”[0m 165/203 [2m0:09:53 â€¢ 0:02:06[0m [2;4m0.30it/s[0m  
[2KAttention weights: tensor([[0.6105, 0.3895]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 165/203 [2m0:09:53 â€¢ 0:02:06[0m [2;4m0.30it/s[0m  
[2KAttention weights: tensor([[0.6109, 0.3891]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 165/203 [2m0:09:53 â€¢ 0:02:06[0m [2;4m0.30it/s[0m  
[2KAttention weights: tensor([[0.6117, 0.3883]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 165/203 [2m0:09:53 â€¢ 0:02:06[0m [2;4m0.30it/s[0m  
[2KAttention weights: tensor([[0.6161, 0.3839]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 165/203 [2m0:09:53 â€¢ 0:02:06[0m [2;4m0.30it/s[0m  
[2KAttention weights: tensor([[0.6262, 0.3738]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 165/203 [2m0:09:53 â€¢ 0:02:06[0m [2;4m0.30it/s[0m  
[2KAttention weights: tensor([[0.6423, 0.3577]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 165/203 [2m0:09:53 â€¢ 0:02:06[0m [2;4m0.30it/s[0m  
[2KAttention weights: tensor([[0.6622, 0.3378]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 165/203 [2m0:09:53 â€¢ 0:02:06[0m [2;4m0.30it/s[0m  
[2KAttention weights: tensor([[0.6835, 0.3165]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 165/203 [2m0:09:53 â€¢ 0:02:06[0m [2;4m0.30it/s[0m  
[2KAttention weights: tensor([[0.7101, 0.2899]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 165/203 [2m0:09:53 â€¢ 0:02:06[0m [2;4m0.30it/s[0m  
[2KAttention weights: tensor([[0.5630, 0.4370]], device='cuda:0');98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”[0m 165/203 [2m0:09:53 â€¢ 0:02:06[0m [2;4m0.30it/s[0m  
[2KAttention weights: tensor([[0.7407, 0.2593],â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”[0m 165/203 [2m0:09:53 â€¢ 0:02:06[0m [2;4m0.30it/s[0m  
        [0.3452, 0.6548],
        [0.5565, 0.4435],
        [0.6848, 0.3152],
        [0.6321, 0.3679],
        [0.6048, 0.3952],
        [0.5555, 0.4445],
        [0.6363, 0.3637],
        [0.6560, 0.3440],
[2K        [0.6848, 0.3152]], device='cuda:0')â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”[0m 165/203 [2m0:09:53 â€¢ 0:02:06[0m [2;4m0.30it/s[0m  
[2KAttention weights: tensor([[0.5603, 0.4397],â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”[0m 166/203 [2m0:09:56 â€¢ 0:01:45[0m [2;4m0.36it/s[0m  
        [0.5556, 0.4444],
        [0.5574, 0.4426],
        [0.5584, 0.4416],
        [0.5591, 0.4409],
        [0.5559, 0.4441],
        [0.5549, 0.4451],
        [0.5593, 0.4407],
        [0.5596, 0.4404],
[2K        [0.5590, 0.4410]], device='cuda:0', grad_fn=<SoftmaxBackward0>)mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”[0m 166/203 [2m0:09:56 â€¢ 0:01:45[0m [2;4m0.36it/s[0m  
[2KClass label: TennisSwingâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”[0m 166/203 [2m0:09:56 â€¢ 0:01:45[0m [2;4m0.36it/s[0m  
[2KAttention weights: tensor([[0.6500, 0.3500]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 166/203 [2m0:09:56 â€¢ 0:01:45[0m [2;4m0.36it/s[0m  
[2KStep 0 - TTA Loss: 1.1014â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”[0m 166/203 [2m0:09:56 â€¢ 0:01:45[0m [2;4m0.36it/s[0m  
[2KAttention weights: tensor([[0.6784, 0.3216]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 166/203 [2m0:09:56 â€¢ 0:01:45[0m [2;4m0.36it/s[0m  
[2KAttention weights: tensor([[0.7293, 0.2707]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 166/203 [2m0:09:56 â€¢ 0:01:45[0m [2;4m0.36it/s[0m  
[2KAttention weights: tensor([[0.7881, 0.2119]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 166/203 [2m0:09:56 â€¢ 0:01:45[0m [2;4m0.36it/s[0m  
[2KAttention weights: tensor([[0.8357, 0.1643]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 166/203 [2m0:09:56 â€¢ 0:01:45[0m [2;4m0.36it/s[0m  
[2KAttention weights: tensor([[0.8673, 0.1327]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 166/203 [2m0:09:56 â€¢ 0:01:45[0m [2;4m0.36it/s[0m  
[2KAttention weights: tensor([[0.8852, 0.1148]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 166/203 [2m0:09:56 â€¢ 0:01:45[0m [2;4m0.36it/s[0m  
[2KAttention weights: tensor([[0.8951, 0.1049]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 166/203 [2m0:09:56 â€¢ 0:01:45[0m [2;4m0.36it/s[0m  
[2KAttention weights: tensor([[0.8994, 0.1006]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 166/203 [2m0:09:56 â€¢ 0:01:45[0m [2;4m0.36it/s[0m  
[2KAttention weights: tensor([[0.9046, 0.0954]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 166/203 [2m0:09:56 â€¢ 0:01:45[0m [2;4m0.36it/s[0m  
[2KAttention weights: tensor([[0.5685, 0.4315]], device='cuda:0');98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”[0m 166/203 [2m0:09:56 â€¢ 0:01:45[0m [2;4m0.36it/s[0m  
[2KAttention weights: tensor([[0.8778, 0.1222],â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”[0m 166/203 [2m0:09:56 â€¢ 0:01:45[0m [2;4m0.36it/s[0m  
        [0.6112, 0.3888],
        [0.7225, 0.2775],
        [0.8589, 0.1411],
        [0.8035, 0.1965],
        [0.7987, 0.2013],
        [0.7107, 0.2893],
        [0.7907, 0.2093],
        [0.9061, 0.0939],
[2K        [0.8529, 0.1471]], device='cuda:0')â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”[0m 166/203 [2m0:09:56 â€¢ 0:01:45[0m [2;4m0.36it/s[0m  
[2KAttention weights: tensor([[0.5603, 0.4397],â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”[0m 167/203 [2m0:09:58 â€¢ 0:01:39[0m [2;4m0.37it/s[0m  
        [0.5556, 0.4444],
        [0.5574, 0.4426],
        [0.5585, 0.4415],
        [0.5591, 0.4409],
        [0.5559, 0.4441],
        [0.5549, 0.4451],
        [0.5594, 0.4406],
        [0.5597, 0.4403],
[2K        [0.5590, 0.4410]], device='cuda:0', grad_fn=<SoftmaxBackward0>)mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”[0m 167/203 [2m0:09:58 â€¢ 0:01:39[0m [2;4m0.37it/s[0m  
[2KClass label: BaseballPitchâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”[0m 167/203 [2m0:09:58 â€¢ 0:01:39[0m [2;4m0.37it/s[0m  
[2KAttention weights: tensor([[0.6182, 0.3818]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 167/203 [2m0:09:58 â€¢ 0:01:39[0m [2;4m0.37it/s[0m  
[2KStep 0 - TTA Loss: 0.6382â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”[0m 167/203 [2m0:09:58 â€¢ 0:01:39[0m [2;4m0.37it/s[0m  
[2KAttention weights: tensor([[0.6182, 0.3818]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 167/203 [2m0:09:58 â€¢ 0:01:39[0m [2;4m0.37it/s[0m  
[2KAttention weights: tensor([[0.6219, 0.3781]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 167/203 [2m0:09:58 â€¢ 0:01:39[0m [2;4m0.37it/s[0m  
[2KAttention weights: tensor([[0.6380, 0.3620]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 167/203 [2m0:09:58 â€¢ 0:01:39[0m [2;4m0.37it/s[0m  
[2KAttention weights: tensor([[0.6748, 0.3252]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 167/203 [2m0:09:58 â€¢ 0:01:39[0m [2;4m0.37it/s[0m  
[2KAttention weights: tensor([[0.7355, 0.2645]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 167/203 [2m0:09:58 â€¢ 0:01:39[0m [2;4m0.37it/s[0m  
[2KAttention weights: tensor([[0.8114, 0.1886]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 167/203 [2m0:09:58 â€¢ 0:01:39[0m [2;4m0.37it/s[0m  
[2KAttention weights: tensor([[0.8813, 0.1187]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 167/203 [2m0:09:58 â€¢ 0:01:39[0m [2;4m0.37it/s[0m  
[2KAttention weights: tensor([[0.9302, 0.0698]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 167/203 [2m0:09:58 â€¢ 0:01:39[0m [2;4m0.37it/s[0m  
[2KAttention weights: tensor([[0.9602, 0.0398]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 167/203 [2m0:09:58 â€¢ 0:01:39[0m [2;4m0.37it/s[0m  
[2KAttention weights: tensor([[0.5764, 0.4236]], device='cuda:0');98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”[0m 167/203 [2m0:09:58 â€¢ 0:01:39[0m [2;4m0.37it/s[0m  
[2KAttention weights: tensor([[0.9802, 0.0198],â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”[0m 167/203 [2m0:09:58 â€¢ 0:01:39[0m [2;4m0.37it/s[0m  
        [0.8435, 0.1565],
        [0.8538, 0.1462],
        [0.9574, 0.0426],
        [0.9380, 0.0620],
        [0.9275, 0.0725],
        [0.8773, 0.1227],
        [0.9193, 0.0807],
        [0.9671, 0.0329],
[2K        [0.9572, 0.0428]], device='cuda:0')â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”â”[0m 167/203 [2m0:09:58 â€¢ 0:01:39[0m [2;4m0.37it/s[0m  
[2KAttention weights: tensor([[0.5603, 0.4397],â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”[0m 168/203 [2m0:10:01 â€¢ 0:01:33[0m [2;4m0.38it/s[0m   
        [0.5556, 0.4444],
        [0.5574, 0.4426],
        [0.5585, 0.4415],
        [0.5591, 0.4409],
        [0.5559, 0.4441],
        [0.5549, 0.4451],
        [0.5594, 0.4406],
        [0.5597, 0.4403],
[2K        [0.5590, 0.4410]], device='cuda:0', grad_fn=<SoftmaxBackward0>)0m[38;5;237mâ”â”â”â”â”â”[0m 168/203 [2m0:10:01 â€¢ 0:01:33[0m [2;4m0.38it/s[0m  
[2KClass label: SoccerPenaltyâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”[0m 168/203 [2m0:10:01 â€¢ 0:01:33[0m [2;4m0.38it/s[0m  
[2KAttention weights: tensor([[0.6388, 0.3612]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 168/203 [2m0:10:01 â€¢ 0:01:33[0m [2;4m0.38it/s[0m  
[2KStep 0 - TTA Loss: 0.7655â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”[0m 168/203 [2m0:10:01 â€¢ 0:01:33[0m [2;4m0.38it/s[0m  
[2KAttention weights: tensor([[0.7546, 0.2454]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 168/203 [2m0:10:01 â€¢ 0:01:33[0m [2;4m0.38it/s[0m  
[2KAttention weights: tensor([[0.8634, 0.1366]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 168/203 [2m0:10:01 â€¢ 0:01:33[0m [2;4m0.38it/s[0m  
[2KAttention weights: tensor([[0.9378, 0.0622]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 168/203 [2m0:10:01 â€¢ 0:01:33[0m [2;4m0.38it/s[0m  
[2KAttention weights: tensor([[0.9573, 0.0427]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 168/203 [2m0:10:01 â€¢ 0:01:33[0m [2;4m0.38it/s[0m  
[2KAttention weights: tensor([[0.9724, 0.0276]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 168/203 [2m0:10:01 â€¢ 0:01:33[0m [2;4m0.38it/s[0m  
[2KAttention weights: tensor([[0.9813, 0.0187]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 168/203 [2m0:10:01 â€¢ 0:01:33[0m [2;4m0.38it/s[0m  
[2KAttention weights: tensor([[0.9849, 0.0151]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 168/203 [2m0:10:01 â€¢ 0:01:33[0m [2;4m0.38it/s[0m  
[2KAttention weights: tensor([[0.9868, 0.0132]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 168/203 [2m0:10:01 â€¢ 0:01:33[0m [2;4m0.38it/s[0m  
[2KAttention weights: tensor([[0.9875, 0.0125]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 168/203 [2m0:10:01 â€¢ 0:01:33[0m [2;4m0.38it/s[0m  
[2KAttention weights: tensor([[0.5793, 0.4207]], device='cuda:0')5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”[0m 168/203 [2m0:10:01 â€¢ 0:01:33[0m [2;4m0.38it/s[0m  
[2KAttention weights: tensor([[0.9866, 0.0134],â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”[0m 168/203 [2m0:10:01 â€¢ 0:01:33[0m [2;4m0.38it/s[0m  
        [0.9039, 0.0961],
        [0.8858, 0.1142],
        [0.9678, 0.0322],
        [0.9651, 0.0349],
        [0.9613, 0.0387],
        [0.9350, 0.0650],
        [0.9877, 0.0123],
        [0.9726, 0.0274],
[2K        [0.9718, 0.0282]], device='cuda:0')â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”[0m 168/203 [2m0:10:01 â€¢ 0:01:33[0m [2;4m0.38it/s[0m  
[2KAttention weights: tensor([[0.5604, 0.4396],â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”[0m 169/203 [2m0:10:03 â€¢ 0:01:26[0m [2;4m0.40it/s[0m  
        [0.5557, 0.4443],
        [0.5575, 0.4425],
        [0.5585, 0.4415],
        [0.5592, 0.4408],
        [0.5560, 0.4440],
        [0.5549, 0.4451],
        [0.5594, 0.4406],
        [0.5597, 0.4403],
[2K        [0.5590, 0.4410]], device='cuda:0', grad_fn=<SoftmaxBackward0>)0m[38;5;237mâ”â”â”â”â”â”[0m 169/203 [2m0:10:03 â€¢ 0:01:26[0m [2;4m0.40it/s[0m  
[2KClass label: HammerThrowâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”[0m 169/203 [2m0:10:03 â€¢ 0:01:26[0m [2;4m0.40it/s[0m  
[2KAttention weights: tensor([[0.5887, 0.4113]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 169/203 [2m0:10:03 â€¢ 0:01:26[0m [2;4m0.40it/s[0m  
[2KStep 0 - TTA Loss: 0.3897â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”[0m 169/203 [2m0:10:03 â€¢ 0:01:26[0m [2;4m0.40it/s[0m  
[2KAttention weights: tensor([[0.5887, 0.4113]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 169/203 [2m0:10:03 â€¢ 0:01:26[0m [2;4m0.40it/s[0m  
[2KAttention weights: tensor([[0.5915, 0.4085]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 169/203 [2m0:10:03 â€¢ 0:01:26[0m [2;4m0.40it/s[0m  
[2KAttention weights: tensor([[0.6037, 0.3963]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 169/203 [2m0:10:03 â€¢ 0:01:26[0m [2;4m0.40it/s[0m  
[2KAttention weights: tensor([[0.6312, 0.3688]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 169/203 [2m0:10:03 â€¢ 0:01:26[0m [2;4m0.40it/s[0m  
[2KAttention weights: tensor([[0.6793, 0.3207]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 169/203 [2m0:10:03 â€¢ 0:01:26[0m [2;4m0.40it/s[0m  
[2KAttention weights: tensor([[0.7473, 0.2527]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 169/203 [2m0:10:03 â€¢ 0:01:26[0m [2;4m0.40it/s[0m  
[2KAttention weights: tensor([[0.8233, 0.1767]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 169/203 [2m0:10:03 â€¢ 0:01:26[0m [2;4m0.40it/s[0m  
[2KAttention weights: tensor([[0.8907, 0.1093]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 169/203 [2m0:10:03 â€¢ 0:01:26[0m [2;4m0.40it/s[0m  
[2KAttention weights: tensor([[0.9350, 0.0650]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 169/203 [2m0:10:03 â€¢ 0:01:26[0m [2;4m0.40it/s[0m  
[2KAttention weights: tensor([[0.5747, 0.4253]], device='cuda:0')5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”[0m 169/203 [2m0:10:03 â€¢ 0:01:26[0m [2;4m0.40it/s[0m  
[2KAttention weights: tensor([[0.9487, 0.0513],â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”[0m 169/203 [2m0:10:03 â€¢ 0:01:26[0m [2;4m0.40it/s[0m  
        [0.8393, 0.1607],
        [0.8875, 0.1125],
        [0.9302, 0.0698],
        [0.9612, 0.0388],
        [0.9365, 0.0635],
        [0.9094, 0.0906],
        [0.9482, 0.0518],
        [0.9258, 0.0742],
[2K        [0.9543, 0.0457]], device='cuda:0')â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”[0m 169/203 [2m0:10:03 â€¢ 0:01:26[0m [2;4m0.40it/s[0m  
[2KAttention weights: tensor([[0.5604, 0.4396],â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”[0m 170/203 [2m0:10:07 â€¢ 0:01:38[0m [2;4m0.34it/s[0m  
        [0.5557, 0.4443],
        [0.5575, 0.4425],
        [0.5585, 0.4415],
        [0.5592, 0.4408],
        [0.5560, 0.4440],
        [0.5550, 0.4450],
        [0.5594, 0.4406],
        [0.5598, 0.4402],
[2K        [0.5591, 0.4409]], device='cuda:0', grad_fn=<SoftmaxBackward0>)0m[38;5;237mâ”â”â”â”â”â”[0m 170/203 [2m0:10:07 â€¢ 0:01:38[0m [2;4m0.34it/s[0m  
[2KClass label: HighJumpâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”[0m 170/203 [2m0:10:07 â€¢ 0:01:38[0m [2;4m0.34it/s[0m  
[2KAttention weights: tensor([[0.6026, 0.3974]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 170/203 [2m0:10:07 â€¢ 0:01:38[0m [2;4m0.34it/s[0m  
[2KStep 0 - TTA Loss: 0.7439â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”[0m 170/203 [2m0:10:07 â€¢ 0:01:38[0m [2;4m0.34it/s[0m  
[2KAttention weights: tensor([[0.7117, 0.2883]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 170/203 [2m0:10:07 â€¢ 0:01:38[0m [2;4m0.34it/s[0m  
[2KAttention weights: tensor([[0.8070, 0.1930]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 170/203 [2m0:10:07 â€¢ 0:01:38[0m [2;4m0.34it/s[0m  
[2KAttention weights: tensor([[0.8759, 0.1241]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 170/203 [2m0:10:07 â€¢ 0:01:38[0m [2;4m0.34it/s[0m  
[2KAttention weights: tensor([[0.9232, 0.0768]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 170/203 [2m0:10:07 â€¢ 0:01:38[0m [2;4m0.34it/s[0m  
[2KAttention weights: tensor([[0.9526, 0.0474]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 170/203 [2m0:10:07 â€¢ 0:01:38[0m [2;4m0.34it/s[0m  
[2KAttention weights: tensor([[0.9686, 0.0314]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 170/203 [2m0:10:07 â€¢ 0:01:38[0m [2;4m0.34it/s[0m  
[2KAttention weights: tensor([[0.9777, 0.0223]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 170/203 [2m0:10:07 â€¢ 0:01:38[0m [2;4m0.34it/s[0m  
[2KAttention weights: tensor([[0.9827, 0.0173]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 170/203 [2m0:10:07 â€¢ 0:01:38[0m [2;4m0.34it/s[0m  
[2KAttention weights: tensor([[0.9850, 0.0150]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 170/203 [2m0:10:07 â€¢ 0:01:38[0m [2;4m0.34it/s[0m  
[2KAttention weights: tensor([[0.5764, 0.4236]], device='cuda:0')5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”[0m 170/203 [2m0:10:07 â€¢ 0:01:38[0m [2;4m0.34it/s[0m  
[2KAttention weights: tensor([[0.9753, 0.0247],â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”[0m 170/203 [2m0:10:07 â€¢ 0:01:38[0m [2;4m0.34it/s[0m  
        [0.9024, 0.0976],
        [0.9504, 0.0496],
        [0.9641, 0.0359],
        [0.9847, 0.0153],
        [0.9856, 0.0144],
        [0.9722, 0.0278],
        [0.9744, 0.0256],
        [0.9663, 0.0337],
[2K        [0.9827, 0.0173]], device='cuda:0')â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”â”[0m 170/203 [2m0:10:07 â€¢ 0:01:38[0m [2;4m0.34it/s[0m  
[2KAttention weights: tensor([[0.5604, 0.4396],â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”[0m 171/203 [2m0:10:11 â€¢ 0:01:44[0m [2;4m0.31it/s[0m  
        [0.5557, 0.4443],
        [0.5575, 0.4425],
        [0.5586, 0.4414],
        [0.5592, 0.4408],
        [0.5560, 0.4440],
        [0.5550, 0.4450],
        [0.5595, 0.4405],
        [0.5598, 0.4402],
[2K        [0.5591, 0.4409]], device='cuda:0', grad_fn=<SoftmaxBackward0>)4mâ•¸[0m[38;5;237mâ”â”â”â”â”â”[0m 171/203 [2m0:10:11 â€¢ 0:01:44[0m [2;4m0.31it/s[0m  
[2KClass label: BaseballPitchâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”[0m 171/203 [2m0:10:11 â€¢ 0:01:44[0m [2;4m0.31it/s[0m  
[2KAttention weights: tensor([[0.6161, 0.3839]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 171/203 [2m0:10:11 â€¢ 0:01:44[0m [2;4m0.31it/s[0m  
[2KStep 0 - TTA Loss: 0.9110â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”[0m 171/203 [2m0:10:11 â€¢ 0:01:44[0m [2;4m0.31it/s[0m  
[2KAttention weights: tensor([[0.6161, 0.3839]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 171/203 [2m0:10:11 â€¢ 0:01:44[0m [2;4m0.31it/s[0m  
[2KAttention weights: tensor([[0.6223, 0.3777]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 171/203 [2m0:10:11 â€¢ 0:01:44[0m [2;4m0.31it/s[0m  
[2KAttention weights: tensor([[0.6462, 0.3538]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 171/203 [2m0:10:11 â€¢ 0:01:44[0m [2;4m0.31it/s[0m  
[2KAttention weights: tensor([[0.6966, 0.3034]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 171/203 [2m0:10:11 â€¢ 0:01:44[0m [2;4m0.31it/s[0m  
[2KAttention weights: tensor([[0.7707, 0.2293]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 171/203 [2m0:10:11 â€¢ 0:01:44[0m [2;4m0.31it/s[0m  
[2KAttention weights: tensor([[0.8554, 0.1446]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 171/203 [2m0:10:11 â€¢ 0:01:44[0m [2;4m0.31it/s[0m  
[2KAttention weights: tensor([[0.9311, 0.0689]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 171/203 [2m0:10:11 â€¢ 0:01:44[0m [2;4m0.31it/s[0m  
[2KAttention weights: tensor([[0.9757, 0.0243]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 171/203 [2m0:10:11 â€¢ 0:01:44[0m [2;4m0.31it/s[0m  
[2KAttention weights: tensor([[0.9924, 0.0076]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 171/203 [2m0:10:11 â€¢ 0:01:44[0m [2;4m0.31it/s[0m  
[2KAttention weights: tensor([[0.5846, 0.4154]], device='cuda:0')2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”[0m 171/203 [2m0:10:11 â€¢ 0:01:44[0m [2;4m0.31it/s[0m  
[2KAttention weights: tensor([[0.9955, 0.0045],â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”[0m 171/203 [2m0:10:11 â€¢ 0:01:44[0m [2;4m0.31it/s[0m  
        [0.9349, 0.0651],
        [0.9615, 0.0385],
        [0.9859, 0.0141],
        [0.9907, 0.0093],
        [0.9929, 0.0071],
        [0.9841, 0.0159],
        [0.9826, 0.0174],
        [0.9842, 0.0158],
[2K        [0.9923, 0.0077]], device='cuda:0')â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”[0m 171/203 [2m0:10:11 â€¢ 0:01:44[0m [2;4m0.31it/s[0m  
[2KAttention weights: tensor([[0.5604, 0.4396],â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”[0m 172/203 [2m0:10:12 â€¢ 0:01:23[0m [2;4m0.37it/s[0m  
        [0.5557, 0.4443],
        [0.5575, 0.4425],
        [0.5586, 0.4414],
        [0.5593, 0.4407],
        [0.5561, 0.4439],
        [0.5550, 0.4450],
        [0.5595, 0.4405],
        [0.5598, 0.4402],
[2K        [0.5591, 0.4409]], device='cuda:0', grad_fn=<SoftmaxBackward0>)4mâ•¸[0m[38;5;237mâ”â”â”â”â”â”[0m 172/203 [2m0:10:12 â€¢ 0:01:23[0m [2;4m0.37it/s[0m  
[2KClass label: PoleVaultâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”[0m 172/203 [2m0:10:12 â€¢ 0:01:23[0m [2;4m0.37it/s[0m  
[2KAttention weights: tensor([[0.5474, 0.4526]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 172/203 [2m0:10:12 â€¢ 0:01:23[0m [2;4m0.37it/s[0m  
[2KStep 0 - TTA Loss: 0.7883â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”[0m 172/203 [2m0:10:12 â€¢ 0:01:23[0m [2;4m0.37it/s[0m  
[2KAttention weights: tensor([[0.6892, 0.3108]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 172/203 [2m0:10:12 â€¢ 0:01:23[0m [2;4m0.37it/s[0m  
[2KAttention weights: tensor([[0.8285, 0.1715]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 172/203 [2m0:10:12 â€¢ 0:01:23[0m [2;4m0.37it/s[0m  
[2KAttention weights: tensor([[0.9313, 0.0687]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 172/203 [2m0:10:12 â€¢ 0:01:23[0m [2;4m0.37it/s[0m  
[2KAttention weights: tensor([[0.9816, 0.0184]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 172/203 [2m0:10:12 â€¢ 0:01:23[0m [2;4m0.37it/s[0m  
[2KAttention weights: tensor([[0.9960, 0.0040]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 172/203 [2m0:10:12 â€¢ 0:01:23[0m [2;4m0.37it/s[0m  
[2KAttention weights: tensor([[0.9988, 0.0012]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 172/203 [2m0:10:12 â€¢ 0:01:23[0m [2;4m0.37it/s[0m  
[2KAttention weights: tensor([[9.9941e-01, 5.8513e-04]], device='cuda:0', grad_fn=<SoftmaxBackward0>)m 172/203 [2m0:10:12 â€¢ 0:01:23[0m [2;4m0.37it/s[0m  
[2KAttention weights: tensor([[9.9961e-01, 3.9302e-04]], device='cuda:0', grad_fn=<SoftmaxBackward0>)m 172/203 [2m0:10:12 â€¢ 0:01:23[0m [2;4m0.37it/s[0m  
[2KAttention weights: tensor([[9.9967e-01, 3.3253e-04]], device='cuda:0', grad_fn=<SoftmaxBackward0>)m 172/203 [2m0:10:12 â€¢ 0:01:23[0m [2;4m0.37it/s[0m  
[2KAttention weights: tensor([[0.5989, 0.4011]], device='cuda:0')2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”[0m 172/203 [2m0:10:12 â€¢ 0:01:23[0m [2;4m0.37it/s[0m  
[2KAttention weights: tensor([[9.9689e-01, 3.1100e-03],â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”[0m 172/203 [2m0:10:12 â€¢ 0:01:23[0m [2;4m0.37it/s[0m  
        [9.7595e-01, 2.4054e-02],
        [9.9299e-01, 7.0089e-03],
        [9.9446e-01, 5.5387e-03],
        [9.9841e-01, 1.5901e-03],
        [9.9936e-01, 6.4494e-04],
        [9.9968e-01, 3.1684e-04],
        [9.9629e-01, 3.7063e-03],
        [9.9048e-01, 9.5172e-03],
[2K        [9.9843e-01, 1.5652e-03]], device='cuda:0')â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”â”[0m 172/203 [2m0:10:12 â€¢ 0:01:23[0m [2;4m0.37it/s[0m  
[2KAttention weights: tensor([[0.5603, 0.4397],â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”[0m 173/203 [2m0:10:17 â€¢ 0:01:27[0m [2;4m0.35it/s[0m   
        [0.5557, 0.4443],
        [0.5575, 0.4425],
        [0.5585, 0.4415],
        [0.5592, 0.4408],
        [0.5561, 0.4439],
        [0.5550, 0.4450],
        [0.5594, 0.4406],
        [0.5597, 0.4403],
[2K        [0.5590, 0.4410]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m[38;5;237mâ”â”â”â”â”[0m 173/203 [2m0:10:17 â€¢ 0:01:27[0m [2;4m0.35it/s[0m  
[2KClass label: HammerThrowâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”[0m 173/203 [2m0:10:17 â€¢ 0:01:27[0m [2;4m0.35it/s[0m  
[2KAttention weights: tensor([[0.5867, 0.4133]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 173/203 [2m0:10:17 â€¢ 0:01:27[0m [2;4m0.35it/s[0m  
[2KStep 0 - TTA Loss: 0.5490â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”[0m 173/203 [2m0:10:17 â€¢ 0:01:27[0m [2;4m0.35it/s[0m  
[2KAttention weights: tensor([[0.5867, 0.4133]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 173/203 [2m0:10:17 â€¢ 0:01:27[0m [2;4m0.35it/s[0m  
[2KAttention weights: tensor([[0.5940, 0.4060]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 173/203 [2m0:10:17 â€¢ 0:01:27[0m [2;4m0.35it/s[0m  
[2KAttention weights: tensor([[0.6229, 0.3771]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 173/203 [2m0:10:17 â€¢ 0:01:27[0m [2;4m0.35it/s[0m  
[2KAttention weights: tensor([[0.6841, 0.3159]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 173/203 [2m0:10:17 â€¢ 0:01:27[0m [2;4m0.35it/s[0m  
[2KAttention weights: tensor([[0.7783, 0.2217]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 173/203 [2m0:10:17 â€¢ 0:01:27[0m [2;4m0.35it/s[0m  
[2KAttention weights: tensor([[0.8843, 0.1157]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 173/203 [2m0:10:17 â€¢ 0:01:27[0m [2;4m0.35it/s[0m  
[2KAttention weights: tensor([[0.9630, 0.0370]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 173/203 [2m0:10:17 â€¢ 0:01:27[0m [2;4m0.35it/s[0m  
[2KAttention weights: tensor([[0.9946, 0.0054]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 173/203 [2m0:10:17 â€¢ 0:01:27[0m [2;4m0.35it/s[0m  
[2KAttention weights: tensor([[9.9918e-01, 8.1753e-04]], device='cuda:0', grad_fn=<SoftmaxBackward0>)/203 [2m0:10:17 â€¢ 0:01:27[0m [2;4m0.35it/s[0m  
[2KAttention weights: tensor([[0.5993, 0.4007]], device='cuda:0');5;237mâ•º[0m[38;5;237mâ”â”â”â”â”[0m 173/203 [2m0:10:17 â€¢ 0:01:27[0m [2;4m0.35it/s[0m  
[2KAttention weights: tensor([[9.9876e-01, 1.2424e-03],â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”[0m 173/203 [2m0:10:17 â€¢ 0:01:27[0m [2;4m0.35it/s[0m  
        [9.8024e-01, 1.9757e-02],
        [9.9707e-01, 2.9326e-03],
        [9.9770e-01, 2.3046e-03],
        [9.9980e-01, 2.0283e-04],
        [9.9941e-01, 5.8908e-04],
        [9.9943e-01, 5.7406e-04],
        [9.9749e-01, 2.5076e-03],
        [9.9554e-01, 4.4594e-03],
[2K        [9.9953e-01, 4.7495e-04]], device='cuda:0')â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”[0m 173/203 [2m0:10:17 â€¢ 0:01:27[0m [2;4m0.35it/s[0m  
[2KAttention weights: tensor([[0.5604, 0.4396],â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”[0m 174/203 [2m0:10:19 â€¢ 0:01:26[0m [2;4m0.34it/s[0m  
        [0.5557, 0.4443],
        [0.5575, 0.4425],
        [0.5586, 0.4414],
        [0.5593, 0.4407],
        [0.5561, 0.4439],
        [0.5551, 0.4449],
        [0.5595, 0.4405],
        [0.5598, 0.4402],
[2K        [0.5591, 0.4409]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m[38;5;237mâ”â”â”â”â”[0m 174/203 [2m0:10:19 â€¢ 0:01:26[0m [2;4m0.34it/s[0m  
[2KClass label: TennisSwingâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”[0m 174/203 [2m0:10:19 â€¢ 0:01:26[0m [2;4m0.34it/s[0m  
[2KAttention weights: tensor([[0.6457, 0.3543]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 174/203 [2m0:10:19 â€¢ 0:01:26[0m [2;4m0.34it/s[0m  
[2KStep 0 - TTA Loss: 0.7286â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”[0m 174/203 [2m0:10:19 â€¢ 0:01:26[0m [2;4m0.34it/s[0m  
[2KAttention weights: tensor([[0.7900, 0.2100]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 174/203 [2m0:10:19 â€¢ 0:01:26[0m [2;4m0.34it/s[0m  
[2KAttention weights: tensor([[0.8751, 0.1249]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 174/203 [2m0:10:19 â€¢ 0:01:26[0m [2;4m0.34it/s[0m  
[2KAttention weights: tensor([[0.9156, 0.0844]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 174/203 [2m0:10:19 â€¢ 0:01:26[0m [2;4m0.34it/s[0m  
[2KAttention weights: tensor([[0.9307, 0.0693]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 174/203 [2m0:10:19 â€¢ 0:01:26[0m [2;4m0.34it/s[0m  
[2KAttention weights: tensor([[0.9278, 0.0722]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 174/203 [2m0:10:19 â€¢ 0:01:26[0m [2;4m0.34it/s[0m  
[2KAttention weights: tensor([[0.9165, 0.0835]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 174/203 [2m0:10:19 â€¢ 0:01:26[0m [2;4m0.34it/s[0m  
[2KAttention weights: tensor([[0.9010, 0.0990]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 174/203 [2m0:10:19 â€¢ 0:01:26[0m [2;4m0.34it/s[0m  
[2KAttention weights: tensor([[0.8876, 0.1124]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 174/203 [2m0:10:19 â€¢ 0:01:26[0m [2;4m0.34it/s[0m  
[2KAttention weights: tensor([[0.8793, 0.1207]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 174/203 [2m0:10:19 â€¢ 0:01:26[0m [2;4m0.34it/s[0m  
[2KAttention weights: tensor([[0.5682, 0.4318]], device='cuda:0');5;237mâ•º[0m[38;5;237mâ”â”â”â”â”[0m 174/203 [2m0:10:19 â€¢ 0:01:26[0m [2;4m0.34it/s[0m  
[2KAttention weights: tensor([[0.9714, 0.0286],â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”[0m 174/203 [2m0:10:19 â€¢ 0:01:26[0m [2;4m0.34it/s[0m  
        [0.8681, 0.1319],
        [0.9600, 0.0400],
        [0.9543, 0.0457],
        [0.9920, 0.0080],
        [0.9828, 0.0172],
        [0.9870, 0.0130],
        [0.9672, 0.0328],
        [0.8766, 0.1234],
[2K        [0.9849, 0.0151]], device='cuda:0')â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”[0m 174/203 [2m0:10:19 â€¢ 0:01:26[0m [2;4m0.34it/s[0m  
[2KAttention weights: tensor([[0.5604, 0.4396],â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”[0m 175/203 [2m0:10:24 â€¢ 0:01:25[0m [2;4m0.33it/s[0m  
        [0.5558, 0.4442],
        [0.5576, 0.4424],
        [0.5586, 0.4414],
        [0.5594, 0.4406],
        [0.5562, 0.4438],
        [0.5552, 0.4448],
        [0.5595, 0.4405],
        [0.5598, 0.4402],
[2K        [0.5592, 0.4408]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m[38;5;237mâ”â”â”â”â”[0m 175/203 [2m0:10:24 â€¢ 0:01:25[0m [2;4m0.33it/s[0m  
[2KClass label: BaseballPitchâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”[0m 175/203 [2m0:10:24 â€¢ 0:01:25[0m [2;4m0.33it/s[0m  
[2KAttention weights: tensor([[0.6143, 0.3857]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 175/203 [2m0:10:24 â€¢ 0:01:25[0m [2;4m0.33it/s[0m  
[2KStep 0 - TTA Loss: 0.7397â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”[0m 175/203 [2m0:10:24 â€¢ 0:01:25[0m [2;4m0.33it/s[0m  
[2KAttention weights: tensor([[0.6143, 0.3857]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 175/203 [2m0:10:24 â€¢ 0:01:25[0m [2;4m0.33it/s[0m  
[2KAttention weights: tensor([[0.6148, 0.3852]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 175/203 [2m0:10:24 â€¢ 0:01:25[0m [2;4m0.33it/s[0m  
[2KAttention weights: tensor([[0.6216, 0.3784]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 175/203 [2m0:10:24 â€¢ 0:01:25[0m [2;4m0.33it/s[0m  
[2KAttention weights: tensor([[0.6449, 0.3551]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 175/203 [2m0:10:24 â€¢ 0:01:25[0m [2;4m0.33it/s[0m  
[2KAttention weights: tensor([[0.6960, 0.3040]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 175/203 [2m0:10:24 â€¢ 0:01:25[0m [2;4m0.33it/s[0m  
[2KAttention weights: tensor([[0.7780, 0.2220]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 175/203 [2m0:10:24 â€¢ 0:01:25[0m [2;4m0.33it/s[0m  
[2KAttention weights: tensor([[0.8697, 0.1303]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 175/203 [2m0:10:24 â€¢ 0:01:25[0m [2;4m0.33it/s[0m  
[2KAttention weights: tensor([[0.9309, 0.0691]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 175/203 [2m0:10:24 â€¢ 0:01:25[0m [2;4m0.33it/s[0m  
[2KAttention weights: tensor([[0.9572, 0.0428]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 175/203 [2m0:10:24 â€¢ 0:01:25[0m [2;4m0.33it/s[0m  
[2KAttention weights: tensor([[0.5746, 0.4254]], device='cuda:0');5;237mâ•º[0m[38;5;237mâ”â”â”â”â”[0m 175/203 [2m0:10:24 â€¢ 0:01:25[0m [2;4m0.33it/s[0m  
[2KAttention weights: tensor([[0.9704, 0.0296],â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”[0m 175/203 [2m0:10:24 â€¢ 0:01:25[0m [2;4m0.33it/s[0m  
        [0.7098, 0.2902],
        [0.7655, 0.2345],
        [0.8848, 0.1152],
        [0.9159, 0.0841],
        [0.8673, 0.1327],
        [0.8760, 0.1240],
        [0.8815, 0.1185],
        [0.6610, 0.3390],
[2K        [0.9167, 0.0833]], device='cuda:0')â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”â”[0m 175/203 [2m0:10:24 â€¢ 0:01:25[0m [2;4m0.33it/s[0m  
[2KAttention weights: tensor([[0.5604, 0.4396],â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”[0m 176/203 [2m0:10:26 â€¢ 0:01:20[0m [2;4m0.34it/s[0m  
        [0.5558, 0.4442],
        [0.5576, 0.4424],
        [0.5586, 0.4414],
        [0.5594, 0.4406],
        [0.5562, 0.4438],
        [0.5552, 0.4448],
        [0.5595, 0.4405],
        [0.5598, 0.4402],
[2K        [0.5592, 0.4408]], device='cuda:0', grad_fn=<SoftmaxBackward0>)24mâ•¸[0m[38;5;237mâ”â”â”â”â”[0m 176/203 [2m0:10:26 â€¢ 0:01:20[0m [2;4m0.34it/s[0m  
[2KClass label: BaseballPitchâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”[0m 176/203 [2m0:10:26 â€¢ 0:01:20[0m [2;4m0.34it/s[0m  
[2KAttention weights: tensor([[0.6165, 0.3835]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 176/203 [2m0:10:26 â€¢ 0:01:20[0m [2;4m0.34it/s[0m  
[2KStep 0 - TTA Loss: 0.8253â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”[0m 176/203 [2m0:10:26 â€¢ 0:01:20[0m [2;4m0.34it/s[0m  
[2KAttention weights: tensor([[0.7313, 0.2687]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 176/203 [2m0:10:26 â€¢ 0:01:20[0m [2;4m0.34it/s[0m  
[2KAttention weights: tensor([[0.8406, 0.1594]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 176/203 [2m0:10:26 â€¢ 0:01:20[0m [2;4m0.34it/s[0m  
[2KAttention weights: tensor([[0.9138, 0.0862]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 176/203 [2m0:10:26 â€¢ 0:01:20[0m [2;4m0.34it/s[0m  
[2KAttention weights: tensor([[0.9604, 0.0396]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 176/203 [2m0:10:26 â€¢ 0:01:20[0m [2;4m0.34it/s[0m  
[2KAttention weights: tensor([[0.9784, 0.0216]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 176/203 [2m0:10:26 â€¢ 0:01:20[0m [2;4m0.34it/s[0m  
[2KAttention weights: tensor([[0.9872, 0.0128]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 176/203 [2m0:10:26 â€¢ 0:01:20[0m [2;4m0.34it/s[0m  
[2KAttention weights: tensor([[0.9903, 0.0097]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 176/203 [2m0:10:26 â€¢ 0:01:20[0m [2;4m0.34it/s[0m  
[2KAttention weights: tensor([[0.9912, 0.0088]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 176/203 [2m0:10:26 â€¢ 0:01:20[0m [2;4m0.34it/s[0m  
[2KAttention weights: tensor([[0.9912, 0.0088]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 176/203 [2m0:10:26 â€¢ 0:01:20[0m [2;4m0.34it/s[0m  
[2KAttention weights: tensor([[0.5801, 0.4199]], device='cuda:0');2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”[0m 176/203 [2m0:10:26 â€¢ 0:01:20[0m [2;4m0.34it/s[0m  
[2KAttention weights: tensor([[0.9912, 0.0088],â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”[0m 176/203 [2m0:10:26 â€¢ 0:01:20[0m [2;4m0.34it/s[0m  
        [0.8159, 0.1841],
        [0.8439, 0.1561],
        [0.9536, 0.0464],
        [0.9581, 0.0419],
        [0.9311, 0.0689],
        [0.9207, 0.0793],
        [0.9338, 0.0662],
        [0.8725, 0.1275],
[2K        [0.9639, 0.0361]], device='cuda:0')â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”[0m 176/203 [2m0:10:26 â€¢ 0:01:20[0m [2;4m0.34it/s[0m  
[2KAttention weights: tensor([[0.5605, 0.4395],â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”[0m 177/203 [2m0:10:29 â€¢ 0:01:20[0m [2;4m0.33it/s[0m  
        [0.5558, 0.4442],
        [0.5576, 0.4424],
        [0.5586, 0.4414],
        [0.5594, 0.4406],
        [0.5562, 0.4438],
        [0.5552, 0.4448],
        [0.5595, 0.4405],
        [0.5598, 0.4402],
[2K        [0.5592, 0.4408]], device='cuda:0', grad_fn=<SoftmaxBackward0>)24mâ•¸[0m[38;5;237mâ”â”â”â”â”[0m 177/203 [2m0:10:29 â€¢ 0:01:20[0m [2;4m0.33it/s[0m  
[2KClass label: PoleVaultâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”[0m 177/203 [2m0:10:29 â€¢ 0:01:20[0m [2;4m0.33it/s[0m  
[2KAttention weights: tensor([[0.5538, 0.4462]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 177/203 [2m0:10:29 â€¢ 0:01:20[0m [2;4m0.33it/s[0m  
[2KStep 0 - TTA Loss: 0.6649â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”[0m 177/203 [2m0:10:29 â€¢ 0:01:20[0m [2;4m0.33it/s[0m  
[2KAttention weights: tensor([[0.5538, 0.4462]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 177/203 [2m0:10:29 â€¢ 0:01:20[0m [2;4m0.33it/s[0m  
[2KAttention weights: tensor([[0.5549, 0.4451]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 177/203 [2m0:10:29 â€¢ 0:01:20[0m [2;4m0.33it/s[0m  
[2KAttention weights: tensor([[0.5618, 0.4382]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 177/203 [2m0:10:29 â€¢ 0:01:20[0m [2;4m0.33it/s[0m  
[2KAttention weights: tensor([[0.5827, 0.4173]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 177/203 [2m0:10:29 â€¢ 0:01:20[0m [2;4m0.33it/s[0m  
[2KAttention weights: tensor([[0.6260, 0.3740]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 177/203 [2m0:10:29 â€¢ 0:01:20[0m [2;4m0.33it/s[0m  
[2KAttention weights: tensor([[0.6967, 0.3033]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 177/203 [2m0:10:29 â€¢ 0:01:20[0m [2;4m0.33it/s[0m  
[2KAttention weights: tensor([[0.7903, 0.2097]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 177/203 [2m0:10:29 â€¢ 0:01:20[0m [2;4m0.33it/s[0m  
[2KAttention weights: tensor([[0.8821, 0.1179]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 177/203 [2m0:10:29 â€¢ 0:01:20[0m [2;4m0.33it/s[0m  
[2KAttention weights: tensor([[0.9458, 0.0542]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â”â”â”â”â”[0m 177/203 [2m0:10:29 â€¢ 0:01:20[0m [2;4m0.33it/s[0m  
[2KAttention weights: tensor([[0.5736, 0.4264]], device='cuda:0');2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”[0m 177/203 [2m0:10:29 â€¢ 0:01:20[0m [2;4m0.33it/s[0m  
[2KAttention weights: tensor([[0.8732, 0.1268],â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”[0m 177/203 [2m0:10:29 â€¢ 0:01:20[0m [2;4m0.33it/s[0m  
        [0.8222, 0.1778],
        [0.8922, 0.1078],
        [0.8816, 0.1184],
        [0.9287, 0.0713],
        [0.9545, 0.0455],
        [0.9771, 0.0229],
        [0.9204, 0.0796],
        [0.8356, 0.1644],
[2K        [0.9331, 0.0669]], device='cuda:0')â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”â”[0m 177/203 [2m0:10:29 â€¢ 0:01:20[0m [2;4m0.33it/s[0m  
[2KAttention weights: tensor([[0.5604, 0.4396],â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”[0m 178/203 [2m0:10:32 â€¢ 0:01:22[0m [2;4m0.31it/s[0m   
        [0.5557, 0.4443],
        [0.5576, 0.4424],
        [0.5585, 0.4415],
        [0.5594, 0.4406],
        [0.5562, 0.4438],
        [0.5552, 0.4448],
        [0.5595, 0.4405],
        [0.5597, 0.4403],
[2K        [0.5592, 0.4408]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m[38;5;237mâ”â”â”â”[0m 178/203 [2m0:10:32 â€¢ 0:01:22[0m [2;4m0.31it/s[0m  
[2KClass label: HammerThrowâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”[0m 178/203 [2m0:10:32 â€¢ 0:01:22[0m [2;4m0.31it/s[0m  
[2KAttention weights: tensor([[0.5849, 0.4151]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 178/203 [2m0:10:32 â€¢ 0:01:22[0m [2;4m0.31it/s[0m  
[2KStep 0 - TTA Loss: 0.4874â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”[0m 178/203 [2m0:10:32 â€¢ 0:01:22[0m [2;4m0.31it/s[0m  
[2KAttention weights: tensor([[0.7203, 0.2797]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 178/203 [2m0:10:32 â€¢ 0:01:22[0m [2;4m0.31it/s[0m  
[2KAttention weights: tensor([[0.8283, 0.1717]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 178/203 [2m0:10:32 â€¢ 0:01:22[0m [2;4m0.31it/s[0m  
[2KAttention weights: tensor([[0.9036, 0.0964]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 178/203 [2m0:10:32 â€¢ 0:01:22[0m [2;4m0.31it/s[0m  
[2KAttention weights: tensor([[0.9419, 0.0581]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 178/203 [2m0:10:32 â€¢ 0:01:22[0m [2;4m0.31it/s[0m  
[2KAttention weights: tensor([[0.9600, 0.0400]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 178/203 [2m0:10:32 â€¢ 0:01:22[0m [2;4m0.31it/s[0m  
[2KAttention weights: tensor([[0.9692, 0.0308]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 178/203 [2m0:10:32 â€¢ 0:01:22[0m [2;4m0.31it/s[0m  
[2KAttention weights: tensor([[0.9736, 0.0264]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 178/203 [2m0:10:32 â€¢ 0:01:22[0m [2;4m0.31it/s[0m  
[2KAttention weights: tensor([[0.9760, 0.0240]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 178/203 [2m0:10:32 â€¢ 0:01:22[0m [2;4m0.31it/s[0m  
[2KAttention weights: tensor([[0.9769, 0.0231]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 178/203 [2m0:10:32 â€¢ 0:01:22[0m [2;4m0.31it/s[0m  
[2KAttention weights: tensor([[0.5780, 0.4220]], device='cuda:0')8;5;237mâ•º[0m[38;5;237mâ”â”â”â”[0m 178/203 [2m0:10:32 â€¢ 0:01:22[0m [2;4m0.31it/s[0m  
[2KAttention weights: tensor([[0.9481, 0.0519],â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”[0m 178/203 [2m0:10:32 â€¢ 0:01:22[0m [2;4m0.31it/s[0m  
        [0.8823, 0.1177],
        [0.9460, 0.0540],
        [0.9445, 0.0555],
        [0.9772, 0.0228],
        [0.9804, 0.0196],
        [0.9888, 0.0112],
        [0.9586, 0.0414],
        [0.9167, 0.0833],
[2K        [0.9747, 0.0253]], device='cuda:0')â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”[0m 178/203 [2m0:10:32 â€¢ 0:01:22[0m [2;4m0.31it/s[0m  
[2KAttention weights: tensor([[0.5604, 0.4396],â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”[0m 179/203 [2m0:10:45 â€¢ 0:01:55[0m [2;4m0.21it/s[0m  
        [0.5557, 0.4443],
        [0.5576, 0.4424],
        [0.5585, 0.4415],
        [0.5594, 0.4406],
        [0.5562, 0.4438],
        [0.5552, 0.4448],
        [0.5595, 0.4405],
        [0.5597, 0.4403],
[2K        [0.5592, 0.4408]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m[38;5;237mâ”â”â”â”[0m 179/203 [2m0:10:45 â€¢ 0:01:55[0m [2;4m0.21it/s[0m  
[2KClass label: PoleVaultâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”[0m 179/203 [2m0:10:45 â€¢ 0:01:55[0m [2;4m0.21it/s[0m  
[2KAttention weights: tensor([[0.5475, 0.4525]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 179/203 [2m0:10:45 â€¢ 0:01:55[0m [2;4m0.21it/s[0m  
[2KStep 0 - TTA Loss: 0.4627â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”[0m 179/203 [2m0:10:45 â€¢ 0:01:55[0m [2;4m0.21it/s[0m  
[2KAttention weights: tensor([[0.5475, 0.4525]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 179/203 [2m0:10:45 â€¢ 0:01:55[0m [2;4m0.21it/s[0m  
[2KAttention weights: tensor([[0.5507, 0.4493]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 179/203 [2m0:10:45 â€¢ 0:01:55[0m [2;4m0.21it/s[0m  
[2KAttention weights: tensor([[0.5634, 0.4366]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 179/203 [2m0:10:45 â€¢ 0:01:55[0m [2;4m0.21it/s[0m  
[2KAttention weights: tensor([[0.5913, 0.4087]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 179/203 [2m0:10:45 â€¢ 0:01:55[0m [2;4m0.21it/s[0m  
[2KAttention weights: tensor([[0.6379, 0.3621]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 179/203 [2m0:10:45 â€¢ 0:01:55[0m [2;4m0.21it/s[0m  
[2KAttention weights: tensor([[0.7025, 0.2975]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 179/203 [2m0:10:45 â€¢ 0:01:55[0m [2;4m0.21it/s[0m  
[2KAttention weights: tensor([[0.7735, 0.2265]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 179/203 [2m0:10:45 â€¢ 0:01:55[0m [2;4m0.21it/s[0m  
[2KAttention weights: tensor([[0.8366, 0.1634]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 179/203 [2m0:10:45 â€¢ 0:01:55[0m [2;4m0.21it/s[0m  
[2KAttention weights: tensor([[0.8850, 0.1150]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 179/203 [2m0:10:45 â€¢ 0:01:55[0m [2;4m0.21it/s[0m  
[2KAttention weights: tensor([[0.5683, 0.4317]], device='cuda:0')8;5;237mâ•º[0m[38;5;237mâ”â”â”â”[0m 179/203 [2m0:10:45 â€¢ 0:01:55[0m [2;4m0.21it/s[0m  
[2KAttention weights: tensor([[0.8621, 0.1379],â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”[0m 179/203 [2m0:10:45 â€¢ 0:01:55[0m [2;4m0.21it/s[0m  
        [0.7760, 0.2240],
        [0.8365, 0.1635],
        [0.8567, 0.1433],
        [0.8954, 0.1046],
        [0.9052, 0.0948],
        [0.9206, 0.0794],
        [0.8755, 0.1245],
        [0.8349, 0.1651],
[2K        [0.9015, 0.0985]], device='cuda:0')â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”[0m 179/203 [2m0:10:45 â€¢ 0:01:55[0m [2;4m0.21it/s[0m  
[2KAttention weights: tensor([[0.5604, 0.4396],â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”[0m 180/203 [2m0:10:50 â€¢ 0:02:04[0m [2;4m0.19it/s[0m  
        [0.5557, 0.4443],
        [0.5576, 0.4424],
        [0.5585, 0.4415],
        [0.5594, 0.4406],
        [0.5562, 0.4438],
        [0.5552, 0.4448],
        [0.5595, 0.4405],
        [0.5597, 0.4403],
[2K        [0.5592, 0.4408]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m[38;5;237mâ”â”â”â”[0m 180/203 [2m0:10:50 â€¢ 0:02:04[0m [2;4m0.19it/s[0m  
[2KClass label: CleanAndJerkâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”[0m 180/203 [2m0:10:50 â€¢ 0:02:04[0m [2;4m0.19it/s[0m  
[2KAttention weights: tensor([[0.5669, 0.4331]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 180/203 [2m0:10:50 â€¢ 0:02:04[0m [2;4m0.19it/s[0m  
[2KStep 0 - TTA Loss: 0.4070â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”[0m 180/203 [2m0:10:50 â€¢ 0:02:04[0m [2;4m0.19it/s[0m  
[2KAttention weights: tensor([[0.6524, 0.3476]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 180/203 [2m0:10:50 â€¢ 0:02:04[0m [2;4m0.19it/s[0m  
[2KAttention weights: tensor([[0.7431, 0.2569]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 180/203 [2m0:10:50 â€¢ 0:02:04[0m [2;4m0.19it/s[0m  
[2KAttention weights: tensor([[0.8170, 0.1830]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 180/203 [2m0:10:50 â€¢ 0:02:04[0m [2;4m0.19it/s[0m  
[2KAttention weights: tensor([[0.8636, 0.1364]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 180/203 [2m0:10:50 â€¢ 0:02:04[0m [2;4m0.19it/s[0m  
[2KAttention weights: tensor([[0.8911, 0.1089]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 180/203 [2m0:10:50 â€¢ 0:02:04[0m [2;4m0.19it/s[0m  
[2KAttention weights: tensor([[0.9096, 0.0904]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 180/203 [2m0:10:50 â€¢ 0:02:04[0m [2;4m0.19it/s[0m  
[2KAttention weights: tensor([[0.9232, 0.0768]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 180/203 [2m0:10:50 â€¢ 0:02:04[0m [2;4m0.19it/s[0m  
[2KAttention weights: tensor([[0.9326, 0.0674]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 180/203 [2m0:10:50 â€¢ 0:02:04[0m [2;4m0.19it/s[0m  
[2KAttention weights: tensor([[0.9376, 0.0624]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 180/203 [2m0:10:50 â€¢ 0:02:04[0m [2;4m0.19it/s[0m  
[2KAttention weights: tensor([[0.5716, 0.4284]], device='cuda:0')8;5;237mâ•º[0m[38;5;237mâ”â”â”â”[0m 180/203 [2m0:10:50 â€¢ 0:02:04[0m [2;4m0.19it/s[0m  
[2KAttention weights: tensor([[0.8744, 0.1256],â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”[0m 180/203 [2m0:10:50 â€¢ 0:02:04[0m [2;4m0.19it/s[0m  
        [0.8060, 0.1940],
        [0.9391, 0.0609],
        [0.8838, 0.1162],
        [0.9163, 0.0837],
        [0.9204, 0.0796],
        [0.9223, 0.0777],
        [0.8760, 0.1240],
        [0.8705, 0.1295],
[2K        [0.9210, 0.0790]], device='cuda:0')â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”â”[0m 180/203 [2m0:10:50 â€¢ 0:02:04[0m [2;4m0.19it/s[0m  
[2KAttention weights: tensor([[0.5604, 0.4396],â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”[0m 181/203 [2m0:10:56 â€¢ 0:02:12[0m [2;4m0.17it/s[0m  
        [0.5558, 0.4442],
        [0.5576, 0.4424],
        [0.5585, 0.4415],
        [0.5594, 0.4406],
        [0.5562, 0.4438],
        [0.5553, 0.4447],
        [0.5595, 0.4405],
        [0.5597, 0.4403],
[2K        [0.5592, 0.4408]], device='cuda:0', grad_fn=<SoftmaxBackward0>)224mâ•¸[0m[38;5;237mâ”â”â”â”[0m 181/203 [2m0:10:56 â€¢ 0:02:12[0m [2;4m0.17it/s[0m  
[2KClass label: GolfSwingâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”[0m 181/203 [2m0:10:56 â€¢ 0:02:12[0m [2;4m0.17it/s[0m  
[2KAttention weights: tensor([[0.6272, 0.3728]], device='cuda:0', grad_fn=<SoftmaxBackward0>)mâ”â”â”â”[0m 181/203 [2m0:10:56 â€¢ 0:02:12[0m [2;4m0.17it/s[0m  
[2KStep 0 - TTA Loss: 0.4077â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”[0m 181/203 [2m0:10:56 â€¢ 0:02:12[0m [2;4m0.17it/s[0m  
[2KAttention weights: tensor([[0.6272, 0.3728]], device='cuda:0', grad_fn=<SoftmaxBackward0>)mâ”â”â”â”[0m 181/203 [2m0:10:56 â€¢ 0:02:12[0m [2;4m0.17it/s[0m  
[2KAttention weights: tensor([[0.6303, 0.3697]], device='cuda:0', grad_fn=<SoftmaxBackward0>)mâ”â”â”â”[0m 181/203 [2m0:10:56 â€¢ 0:02:12[0m [2;4m0.17it/s[0m  
[2KAttention weights: tensor([[0.6431, 0.3569]], device='cuda:0', grad_fn=<SoftmaxBackward0>)mâ”â”â”â”[0m 181/203 [2m0:10:56 â€¢ 0:02:12[0m [2;4m0.17it/s[0m  
[2KAttention weights: tensor([[0.6713, 0.3287]], device='cuda:0', grad_fn=<SoftmaxBackward0>)mâ”â”â”â”[0m 181/203 [2m0:10:56 â€¢ 0:02:12[0m [2;4m0.17it/s[0m  
[2KAttention weights: tensor([[0.7180, 0.2820]], device='cuda:0', grad_fn=<SoftmaxBackward0>)mâ”â”â”â”[0m 181/203 [2m0:10:56 â€¢ 0:02:12[0m [2;4m0.17it/s[0m  
[2KAttention weights: tensor([[0.7788, 0.2212]], device='cuda:0', grad_fn=<SoftmaxBackward0>)mâ”â”â”â”[0m 181/203 [2m0:10:56 â€¢ 0:02:12[0m [2;4m0.17it/s[0m  
[2KAttention weights: tensor([[0.8425, 0.1575]], device='cuda:0', grad_fn=<SoftmaxBackward0>)mâ”â”â”â”[0m 181/203 [2m0:10:56 â€¢ 0:02:12[0m [2;4m0.17it/s[0m  
[2KAttention weights: tensor([[0.8954, 0.1046]], device='cuda:0', grad_fn=<SoftmaxBackward0>)mâ”â”â”â”[0m 181/203 [2m0:10:56 â€¢ 0:02:12[0m [2;4m0.17it/s[0m  
[2KAttention weights: tensor([[0.9341, 0.0659]], device='cuda:0', grad_fn=<SoftmaxBackward0>)mâ”â”â”â”[0m 181/203 [2m0:10:56 â€¢ 0:02:12[0m [2;4m0.17it/s[0m  
[2KAttention weights: tensor([[0.5728, 0.4272]], device='cuda:0')8;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”[0m 181/203 [2m0:10:56 â€¢ 0:02:12[0m [2;4m0.17it/s[0m  
[2KAttention weights: tensor([[0.9355, 0.0645],â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”[0m 181/203 [2m0:10:56 â€¢ 0:02:12[0m [2;4m0.17it/s[0m  
        [0.8494, 0.1506],
        [0.9638, 0.0362],
        [0.9628, 0.0372],
        [0.9414, 0.0586],
        [0.9311, 0.0689],
        [0.9107, 0.0893],
        [0.8932, 0.1068],
        [0.9404, 0.0596],
[2K        [0.9520, 0.0480]], device='cuda:0')â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”[0m 181/203 [2m0:10:56 â€¢ 0:02:12[0m [2;4m0.17it/s[0m  
[2KAttention weights: tensor([[0.5604, 0.4396],â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”[0m 182/203 [2m0:10:59 â€¢ 0:02:23[0m [2;4m0.15it/s[0m  
        [0.5558, 0.4442],
        [0.5576, 0.4424],
        [0.5586, 0.4414],
        [0.5594, 0.4406],
        [0.5562, 0.4438],
        [0.5553, 0.4447],
        [0.5595, 0.4405],
        [0.5598, 0.4402],
[2K        [0.5592, 0.4408]], device='cuda:0', grad_fn=<SoftmaxBackward0>)224mâ•¸[0m[38;5;237mâ”â”â”â”[0m 182/203 [2m0:10:59 â€¢ 0:02:23[0m [2;4m0.15it/s[0m  
[2KClass label: CleanAndJerkâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”[0m 182/203 [2m0:10:59 â€¢ 0:02:23[0m [2;4m0.15it/s[0m  
[2KAttention weights: tensor([[0.5713, 0.4287]], device='cuda:0', grad_fn=<SoftmaxBackward0>)mâ”â”â”â”[0m 182/203 [2m0:10:59 â€¢ 0:02:23[0m [2;4m0.15it/s[0m  
[2KStep 0 - TTA Loss: 0.7702â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”[0m 182/203 [2m0:10:59 â€¢ 0:02:23[0m [2;4m0.15it/s[0m  
[2KAttention weights: tensor([[0.7041, 0.2959]], device='cuda:0', grad_fn=<SoftmaxBackward0>)mâ”â”â”â”[0m 182/203 [2m0:10:59 â€¢ 0:02:23[0m [2;4m0.15it/s[0m  
[2KAttention weights: tensor([[0.8066, 0.1934]], device='cuda:0', grad_fn=<SoftmaxBackward0>)mâ”â”â”â”[0m 182/203 [2m0:10:59 â€¢ 0:02:23[0m [2;4m0.15it/s[0m  
[2KAttention weights: tensor([[0.8699, 0.1301]], device='cuda:0', grad_fn=<SoftmaxBackward0>)mâ”â”â”â”[0m 182/203 [2m0:10:59 â€¢ 0:02:23[0m [2;4m0.15it/s[0m  
[2KAttention weights: tensor([[0.9064, 0.0936]], device='cuda:0', grad_fn=<SoftmaxBackward0>)mâ”â”â”â”[0m 182/203 [2m0:10:59 â€¢ 0:02:23[0m [2;4m0.15it/s[0m  
[2KAttention weights: tensor([[0.9270, 0.0730]], device='cuda:0', grad_fn=<SoftmaxBackward0>)mâ”â”â”â”[0m 182/203 [2m0:10:59 â€¢ 0:02:23[0m [2;4m0.15it/s[0m  
[2KAttention weights: tensor([[0.9388, 0.0612]], device='cuda:0', grad_fn=<SoftmaxBackward0>)mâ”â”â”â”[0m 182/203 [2m0:10:59 â€¢ 0:02:23[0m [2;4m0.15it/s[0m  
[2KAttention weights: tensor([[0.9455, 0.0545]], device='cuda:0', grad_fn=<SoftmaxBackward0>)mâ”â”â”â”[0m 182/203 [2m0:10:59 â€¢ 0:02:23[0m [2;4m0.15it/s[0m  
[2KAttention weights: tensor([[0.9500, 0.0500]], device='cuda:0', grad_fn=<SoftmaxBackward0>)mâ”â”â”â”[0m 182/203 [2m0:10:59 â€¢ 0:02:23[0m [2;4m0.15it/s[0m  
[2KAttention weights: tensor([[0.9523, 0.0477]], device='cuda:0', grad_fn=<SoftmaxBackward0>)mâ”â”â”â”[0m 182/203 [2m0:10:59 â€¢ 0:02:23[0m [2;4m0.15it/s[0m  
[2KAttention weights: tensor([[0.5733, 0.4267]], device='cuda:0')8;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”[0m 182/203 [2m0:10:59 â€¢ 0:02:23[0m [2;4m0.15it/s[0m  
[2KAttention weights: tensor([[0.9253, 0.0747],â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”[0m 182/203 [2m0:10:59 â€¢ 0:02:23[0m [2;4m0.15it/s[0m  
        [0.8350, 0.1650],
        [0.9532, 0.0468],
        [0.9560, 0.0440],
        [0.9286, 0.0714],
        [0.9168, 0.0832],
        [0.8916, 0.1084],
        [0.8786, 0.1214],
        [0.9319, 0.0681],
[2K        [0.9425, 0.0575]], device='cuda:0')â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”â”[0m 182/203 [2m0:10:59 â€¢ 0:02:23[0m [2;4m0.15it/s[0m  
[2KAttention weights: tensor([[0.5604, 0.4396],â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”[0m 183/203 [2m0:11:00 â€¢ 0:01:53[0m [2;4m0.18it/s[0m   
        [0.5558, 0.4442],
        [0.5577, 0.4423],
        [0.5586, 0.4414],
        [0.5595, 0.4405],
        [0.5562, 0.4438],
        [0.5553, 0.4447],
        [0.5595, 0.4405],
        [0.5598, 0.4402],
[2K        [0.5592, 0.4408]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â•º[0m[38;5;237mâ”â”â”[0m 183/203 [2m0:11:00 â€¢ 0:01:53[0m [2;4m0.18it/s[0m  
[2KClass label: BaseballPitchâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”[0m 183/203 [2m0:11:00 â€¢ 0:01:53[0m [2;4m0.18it/s[0m  
[2KAttention weights: tensor([[0.6185, 0.3815]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 183/203 [2m0:11:00 â€¢ 0:01:53[0m [2;4m0.18it/s[0m  
[2KStep 0 - TTA Loss: 0.5583â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”[0m 183/203 [2m0:11:00 â€¢ 0:01:53[0m [2;4m0.18it/s[0m  
[2KAttention weights: tensor([[0.6185, 0.3815]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 183/203 [2m0:11:00 â€¢ 0:01:53[0m [2;4m0.18it/s[0m  
[2KAttention weights: tensor([[0.6229, 0.3771]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 183/203 [2m0:11:00 â€¢ 0:01:53[0m [2;4m0.18it/s[0m  
[2KAttention weights: tensor([[0.6430, 0.3570]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 183/203 [2m0:11:00 â€¢ 0:01:53[0m [2;4m0.18it/s[0m  
[2KAttention weights: tensor([[0.6925, 0.3075]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 183/203 [2m0:11:00 â€¢ 0:01:53[0m [2;4m0.18it/s[0m  
[2KAttention weights: tensor([[0.7756, 0.2244]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 183/203 [2m0:11:00 â€¢ 0:01:53[0m [2;4m0.18it/s[0m  
[2KAttention weights: tensor([[0.8763, 0.1237]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 183/203 [2m0:11:00 â€¢ 0:01:53[0m [2;4m0.18it/s[0m  
[2KAttention weights: tensor([[0.9516, 0.0484]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 183/203 [2m0:11:00 â€¢ 0:01:53[0m [2;4m0.18it/s[0m  
[2KAttention weights: tensor([[0.9848, 0.0152]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 183/203 [2m0:11:00 â€¢ 0:01:53[0m [2;4m0.18it/s[0m  
[2KAttention weights: tensor([[0.9943, 0.0057]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 183/203 [2m0:11:00 â€¢ 0:01:53[0m [2;4m0.18it/s[0m  
[2KAttention weights: tensor([[0.5866, 0.4134]], device='cuda:0')38;5;237mâ•º[0m[38;5;237mâ”â”â”[0m 183/203 [2m0:11:00 â€¢ 0:01:53[0m [2;4m0.18it/s[0m  
[2KAttention weights: tensor([[0.9980, 0.0020],â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”[0m 183/203 [2m0:11:00 â€¢ 0:01:53[0m [2;4m0.18it/s[0m  
        [0.9312, 0.0688],
        [0.9708, 0.0292],
        [0.9911, 0.0089],
        [0.9886, 0.0114],
        [0.9819, 0.0181],
        [0.9688, 0.0312],
        [0.9740, 0.0260],
        [0.9848, 0.0152],
[2K        [0.9919, 0.0081]], device='cuda:0')â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”[0m 183/203 [2m0:11:00 â€¢ 0:01:53[0m [2;4m0.18it/s[0m  
[2KAttention weights: tensor([[0.5605, 0.4395],â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”[0m 184/203 [2m0:11:03 â€¢ 0:01:07[0m [2;4m0.29it/s[0m  
        [0.5558, 0.4442],
        [0.5577, 0.4423],
        [0.5586, 0.4414],
        [0.5595, 0.4405],
        [0.5563, 0.4437],
        [0.5553, 0.4447],
        [0.5595, 0.4405],
        [0.5598, 0.4402],
[2K        [0.5593, 0.4407]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â•º[0m[38;5;237mâ”â”â”[0m 184/203 [2m0:11:03 â€¢ 0:01:07[0m [2;4m0.29it/s[0m  
[2KClass label: SoccerPenaltyâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”[0m 184/203 [2m0:11:03 â€¢ 0:01:07[0m [2;4m0.29it/s[0m  
[2KAttention weights: tensor([[0.6416, 0.3584]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 184/203 [2m0:11:03 â€¢ 0:01:07[0m [2;4m0.29it/s[0m  
[2KStep 0 - TTA Loss: 0.5616â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”[0m 184/203 [2m0:11:03 â€¢ 0:01:07[0m [2;4m0.29it/s[0m  
[2KAttention weights: tensor([[0.7713, 0.2287]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 184/203 [2m0:11:03 â€¢ 0:01:07[0m [2;4m0.29it/s[0m  
[2KAttention weights: tensor([[0.8676, 0.1324]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 184/203 [2m0:11:03 â€¢ 0:01:07[0m [2;4m0.29it/s[0m  
[2KAttention weights: tensor([[0.9250, 0.0750]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 184/203 [2m0:11:03 â€¢ 0:01:07[0m [2;4m0.29it/s[0m  
[2KAttention weights: tensor([[0.9500, 0.0500]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 184/203 [2m0:11:03 â€¢ 0:01:07[0m [2;4m0.29it/s[0m  
[2KAttention weights: tensor([[0.9627, 0.0373]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 184/203 [2m0:11:03 â€¢ 0:01:07[0m [2;4m0.29it/s[0m  
[2KAttention weights: tensor([[0.9681, 0.0319]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 184/203 [2m0:11:03 â€¢ 0:01:07[0m [2;4m0.29it/s[0m  
[2KAttention weights: tensor([[0.9694, 0.0306]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 184/203 [2m0:11:03 â€¢ 0:01:07[0m [2;4m0.29it/s[0m  
[2KAttention weights: tensor([[0.9699, 0.0301]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 184/203 [2m0:11:03 â€¢ 0:01:07[0m [2;4m0.29it/s[0m  
[2KAttention weights: tensor([[0.9703, 0.0297]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 184/203 [2m0:11:03 â€¢ 0:01:07[0m [2;4m0.29it/s[0m  
[2KAttention weights: tensor([[0.5755, 0.4245]], device='cuda:0')38;5;237mâ•º[0m[38;5;237mâ”â”â”[0m 184/203 [2m0:11:03 â€¢ 0:01:07[0m [2;4m0.29it/s[0m  
[2KAttention weights: tensor([[0.9924, 0.0076],â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”[0m 184/203 [2m0:11:03 â€¢ 0:01:07[0m [2;4m0.29it/s[0m  
        [0.8997, 0.1003],
        [0.9363, 0.0637],
        [0.9768, 0.0232],
        [0.9729, 0.0271],
        [0.9639, 0.0361],
        [0.9428, 0.0572],
        [0.9704, 0.0296],
        [0.9672, 0.0328],
[2K        [0.9792, 0.0208]], device='cuda:0')â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”[0m 184/203 [2m0:11:03 â€¢ 0:01:07[0m [2;4m0.29it/s[0m  
[2KAttention weights: tensor([[0.5604, 0.4396],â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”[0m 185/203 [2m0:11:04 â€¢ 0:00:58[0m [2;4m0.31it/s[0m  
        [0.5558, 0.4442],
        [0.5577, 0.4423],
        [0.5586, 0.4414],
        [0.5595, 0.4405],
        [0.5563, 0.4437],
        [0.5553, 0.4447],
        [0.5595, 0.4405],
        [0.5598, 0.4402],
[2K        [0.5593, 0.4407]], device='cuda:0', grad_fn=<SoftmaxBackward0>)â•º[0m[38;5;237mâ”â”â”[0m 185/203 [2m0:11:04 â€¢ 0:00:58[0m [2;4m0.31it/s[0m  
[2KClass label: Billiardsâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”[0m 185/203 [2m0:11:04 â€¢ 0:00:58[0m [2;4m0.31it/s[0m  
[2KAttention weights: tensor([[0.5825, 0.4175]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 185/203 [2m0:11:04 â€¢ 0:00:58[0m [2;4m0.31it/s[0m  
[2KStep 0 - TTA Loss: 0.5406â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”[0m 185/203 [2m0:11:04 â€¢ 0:00:58[0m [2;4m0.31it/s[0m  
[2KAttention weights: tensor([[0.5825, 0.4175]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 185/203 [2m0:11:04 â€¢ 0:00:58[0m [2;4m0.31it/s[0m  
[2KAttention weights: tensor([[0.5838, 0.4162]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 185/203 [2m0:11:04 â€¢ 0:00:58[0m [2;4m0.31it/s[0m  
[2KAttention weights: tensor([[0.5905, 0.4095]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 185/203 [2m0:11:04 â€¢ 0:00:58[0m [2;4m0.31it/s[0m  
[2KAttention weights: tensor([[0.6080, 0.3920]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 185/203 [2m0:11:04 â€¢ 0:00:58[0m [2;4m0.31it/s[0m  
[2KAttention weights: tensor([[0.6381, 0.3619]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 185/203 [2m0:11:04 â€¢ 0:00:58[0m [2;4m0.31it/s[0m  
[2KAttention weights: tensor([[0.6816, 0.3184]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 185/203 [2m0:11:04 â€¢ 0:00:58[0m [2;4m0.31it/s[0m  
[2KAttention weights: tensor([[0.7287, 0.2713]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 185/203 [2m0:11:04 â€¢ 0:00:58[0m [2;4m0.31it/s[0m  
[2KAttention weights: tensor([[0.7729, 0.2271]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 185/203 [2m0:11:04 â€¢ 0:00:58[0m [2;4m0.31it/s[0m  
[2KAttention weights: tensor([[0.8244, 0.1756]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 185/203 [2m0:11:04 â€¢ 0:00:58[0m [2;4m0.31it/s[0m  
[2KAttention weights: tensor([[0.5643, 0.4357]], device='cuda:0')38;5;237mâ•º[0m[38;5;237mâ”â”â”[0m 185/203 [2m0:11:04 â€¢ 0:00:58[0m [2;4m0.31it/s[0m  
[2KAttention weights: tensor([[0.8230, 0.1770],â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”[0m 185/203 [2m0:11:04 â€¢ 0:00:58[0m [2;4m0.31it/s[0m  
        [0.8933, 0.1067],
        [0.7339, 0.2661],
        [0.8037, 0.1963],
        [0.7634, 0.2366],
        [0.7648, 0.2352],
        [0.7140, 0.2860],
        [0.7536, 0.2464],
        [0.8205, 0.1795],
[2K        [0.8080, 0.1920]], device='cuda:0')â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”â”[0m 185/203 [2m0:11:04 â€¢ 0:00:58[0m [2;4m0.31it/s[0m  
[2KAttention weights: tensor([[0.5604, 0.4396],â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”[0m 186/203 [2m0:11:05 â€¢ 0:00:49[0m [2;4m0.35it/s[0m  
        [0.5558, 0.4442],
        [0.5577, 0.4423],
        [0.5586, 0.4414],
        [0.5595, 0.4405],
        [0.5563, 0.4437],
        [0.5553, 0.4447],
        [0.5595, 0.4405],
        [0.5598, 0.4402],
[2K        [0.5593, 0.4407]], device='cuda:0', grad_fn=<SoftmaxBackward0>);224mâ•¸[0m[38;5;237mâ”â”â”[0m 186/203 [2m0:11:05 â€¢ 0:00:49[0m [2;4m0.35it/s[0m  
[2KClass label: SoccerPenaltyâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”[0m 186/203 [2m0:11:05 â€¢ 0:00:49[0m [2;4m0.35it/s[0m  
[2KAttention weights: tensor([[0.6379, 0.3621]], device='cuda:0', grad_fn=<SoftmaxBackward0>)7mâ”â”â”[0m 186/203 [2m0:11:05 â€¢ 0:00:49[0m [2;4m0.35it/s[0m  
[2KStep 0 - TTA Loss: 0.5745â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”[0m 186/203 [2m0:11:05 â€¢ 0:00:49[0m [2;4m0.35it/s[0m  
[2KAttention weights: tensor([[0.7171, 0.2829]], device='cuda:0', grad_fn=<SoftmaxBackward0>)7mâ”â”â”[0m 186/203 [2m0:11:05 â€¢ 0:00:49[0m [2;4m0.35it/s[0m  
[2KAttention weights: tensor([[0.8172, 0.1828]], device='cuda:0', grad_fn=<SoftmaxBackward0>)7mâ”â”â”[0m 186/203 [2m0:11:05 â€¢ 0:00:49[0m [2;4m0.35it/s[0m  
[2KAttention weights: tensor([[0.9060, 0.0940]], device='cuda:0', grad_fn=<SoftmaxBackward0>)7mâ”â”â”[0m 186/203 [2m0:11:05 â€¢ 0:00:49[0m [2;4m0.35it/s[0m  
[2KAttention weights: tensor([[0.9621, 0.0379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)7mâ”â”â”[0m 186/203 [2m0:11:05 â€¢ 0:00:49[0m [2;4m0.35it/s[0m  
[2KAttention weights: tensor([[0.9869, 0.0131]], device='cuda:0', grad_fn=<SoftmaxBackward0>)7mâ”â”â”[0m 186/203 [2m0:11:05 â€¢ 0:00:49[0m [2;4m0.35it/s[0m  
[2KAttention weights: tensor([[0.9948, 0.0052]], device='cuda:0', grad_fn=<SoftmaxBackward0>)7mâ”â”â”[0m 186/203 [2m0:11:05 â€¢ 0:00:49[0m [2;4m0.35it/s[0m  
[2KAttention weights: tensor([[0.9973, 0.0027]], device='cuda:0', grad_fn=<SoftmaxBackward0>)7mâ”â”â”[0m 186/203 [2m0:11:05 â€¢ 0:00:49[0m [2;4m0.35it/s[0m  
[2KAttention weights: tensor([[0.9981, 0.0019]], device='cuda:0', grad_fn=<SoftmaxBackward0>)7mâ”â”â”[0m 186/203 [2m0:11:05 â€¢ 0:00:49[0m [2;4m0.35it/s[0m  
[2KAttention weights: tensor([[0.9983, 0.0017]], device='cuda:0', grad_fn=<SoftmaxBackward0>)7mâ”â”â”[0m 186/203 [2m0:11:05 â€¢ 0:00:49[0m [2;4m0.35it/s[0m  
[2KAttention weights: tensor([[0.5911, 0.4089]], device='cuda:0')38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”[0m 186/203 [2m0:11:05 â€¢ 0:00:49[0m [2;4m0.35it/s[0m  
[2KAttention weights: tensor([[0.9762, 0.0238],â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”[0m 186/203 [2m0:11:05 â€¢ 0:00:49[0m [2;4m0.35it/s[0m  
        [0.9879, 0.0121],
        [0.9149, 0.0851],
        [0.9606, 0.0394],
        [0.9717, 0.0283],
        [0.9751, 0.0249],
        [0.9630, 0.0370],
        [0.9984, 0.0016],
        [0.9687, 0.0313],
[2K        [0.9708, 0.0292]], device='cuda:0')â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”[0m 186/203 [2m0:11:05 â€¢ 0:00:49[0m [2;4m0.35it/s[0m  
[2KAttention weights: tensor([[0.5605, 0.4395],â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”[0m 187/203 [2m0:11:07 â€¢ 0:00:44[0m [2;4m0.37it/s[0m  
        [0.5559, 0.4441],
        [0.5577, 0.4423],
        [0.5587, 0.4413],
        [0.5595, 0.4405],
        [0.5563, 0.4437],
        [0.5554, 0.4446],
        [0.5596, 0.4404],
        [0.5598, 0.4402],
[2K        [0.5593, 0.4407]], device='cuda:0', grad_fn=<SoftmaxBackward0>);224mâ•¸[0m[38;5;237mâ”â”â”[0m 187/203 [2m0:11:07 â€¢ 0:00:44[0m [2;4m0.37it/s[0m  
[2KClass label: CleanAndJerkâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”[0m 187/203 [2m0:11:07 â€¢ 0:00:44[0m [2;4m0.37it/s[0m  
[2KAttention weights: tensor([[0.5680, 0.4320]], device='cuda:0', grad_fn=<SoftmaxBackward0>)7mâ”â”â”[0m 187/203 [2m0:11:07 â€¢ 0:00:44[0m [2;4m0.37it/s[0m  
[2KStep 0 - TTA Loss: 0.7651â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”[0m 187/203 [2m0:11:07 â€¢ 0:00:44[0m [2;4m0.37it/s[0m  
[2KAttention weights: tensor([[0.5680, 0.4320]], device='cuda:0', grad_fn=<SoftmaxBackward0>)7mâ”â”â”[0m 187/203 [2m0:11:07 â€¢ 0:00:44[0m [2;4m0.37it/s[0m  
[2KAttention weights: tensor([[0.5702, 0.4298]], device='cuda:0', grad_fn=<SoftmaxBackward0>)7mâ”â”â”[0m 187/203 [2m0:11:07 â€¢ 0:00:44[0m [2;4m0.37it/s[0m  
[2KAttention weights: tensor([[0.5788, 0.4212]], device='cuda:0', grad_fn=<SoftmaxBackward0>)7mâ”â”â”[0m 187/203 [2m0:11:07 â€¢ 0:00:44[0m [2;4m0.37it/s[0m  
[2KAttention weights: tensor([[0.5989, 0.4011]], device='cuda:0', grad_fn=<SoftmaxBackward0>)7mâ”â”â”[0m 187/203 [2m0:11:07 â€¢ 0:00:44[0m [2;4m0.37it/s[0m  
[2KAttention weights: tensor([[0.6304, 0.3696]], device='cuda:0', grad_fn=<SoftmaxBackward0>)7mâ”â”â”[0m 187/203 [2m0:11:07 â€¢ 0:00:44[0m [2;4m0.37it/s[0m  
[2KAttention weights: tensor([[0.6728, 0.3272]], device='cuda:0', grad_fn=<SoftmaxBackward0>)7mâ”â”â”[0m 187/203 [2m0:11:07 â€¢ 0:00:44[0m [2;4m0.37it/s[0m  
[2KAttention weights: tensor([[0.7242, 0.2758]], device='cuda:0', grad_fn=<SoftmaxBackward0>)7mâ”â”â”[0m 187/203 [2m0:11:07 â€¢ 0:00:44[0m [2;4m0.37it/s[0m  
[2KAttention weights: tensor([[0.7786, 0.2214]], device='cuda:0', grad_fn=<SoftmaxBackward0>)7mâ”â”â”[0m 187/203 [2m0:11:07 â€¢ 0:00:44[0m [2;4m0.37it/s[0m  
[2KAttention weights: tensor([[0.8336, 0.1664]], device='cuda:0', grad_fn=<SoftmaxBackward0>)7mâ”â”â”[0m 187/203 [2m0:11:07 â€¢ 0:00:44[0m [2;4m0.37it/s[0m  
[2KAttention weights: tensor([[0.5698, 0.4302]], device='cuda:0')38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”[0m 187/203 [2m0:11:07 â€¢ 0:00:44[0m [2;4m0.37it/s[0m  
[2KAttention weights: tensor([[0.8879, 0.1121],â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”[0m 187/203 [2m0:11:07 â€¢ 0:00:44[0m [2;4m0.37it/s[0m  
        [0.8717, 0.1283],
        [0.8745, 0.1255],
        [0.8738, 0.1262],
        [0.8949, 0.1051],
        [0.9002, 0.0998],
        [0.8689, 0.1311],
        [0.9718, 0.0282],
        [0.8850, 0.1150],
[2K        [0.8984, 0.1016]], device='cuda:0')â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”â”[0m 187/203 [2m0:11:07 â€¢ 0:00:44[0m [2;4m0.37it/s[0m  
[2KAttention weights: tensor([[0.5605, 0.4395],â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”[0m 188/203 [2m0:11:08 â€¢ 0:00:38[0m [2;4m0.40it/s[0m   
        [0.5559, 0.4441],
        [0.5577, 0.4423],
        [0.5587, 0.4413],
        [0.5595, 0.4405],
        [0.5563, 0.4437],
        [0.5554, 0.4446],
        [0.5596, 0.4404],
        [0.5599, 0.4401],
[2K        [0.5593, 0.4407]], device='cuda:0', grad_fn=<SoftmaxBackward0>)mâ•º[0m[38;5;237mâ”â”[0m 188/203 [2m0:11:08 â€¢ 0:00:38[0m [2;4m0.40it/s[0m  
[2KClass label: TennisSwingâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”[0m 188/203 [2m0:11:08 â€¢ 0:00:38[0m [2;4m0.40it/s[0m  
[2KAttention weights: tensor([[0.6459, 0.3541]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 188/203 [2m0:11:08 â€¢ 0:00:38[0m [2;4m0.40it/s[0m  
[2KStep 0 - TTA Loss: 0.6277â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”[0m 188/203 [2m0:11:08 â€¢ 0:00:38[0m [2;4m0.40it/s[0m  
[2KAttention weights: tensor([[0.7243, 0.2757]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 188/203 [2m0:11:08 â€¢ 0:00:38[0m [2;4m0.40it/s[0m  
[2KAttention weights: tensor([[0.8073, 0.1927]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 188/203 [2m0:11:08 â€¢ 0:00:38[0m [2;4m0.40it/s[0m  
[2KAttention weights: tensor([[0.8796, 0.1204]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 188/203 [2m0:11:08 â€¢ 0:00:38[0m [2;4m0.40it/s[0m  
[2KAttention weights: tensor([[0.9318, 0.0682]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 188/203 [2m0:11:08 â€¢ 0:00:38[0m [2;4m0.40it/s[0m  
[2KAttention weights: tensor([[0.9621, 0.0379]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 188/203 [2m0:11:08 â€¢ 0:00:38[0m [2;4m0.40it/s[0m  
[2KAttention weights: tensor([[0.9762, 0.0238]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 188/203 [2m0:11:08 â€¢ 0:00:38[0m [2;4m0.40it/s[0m  
[2KAttention weights: tensor([[0.9818, 0.0182]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 188/203 [2m0:11:08 â€¢ 0:00:38[0m [2;4m0.40it/s[0m  
[2KAttention weights: tensor([[0.9836, 0.0164]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 188/203 [2m0:11:08 â€¢ 0:00:38[0m [2;4m0.40it/s[0m  
[2KAttention weights: tensor([[0.9840, 0.0160]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 188/203 [2m0:11:08 â€¢ 0:00:38[0m [2;4m0.40it/s[0m  
[2KAttention weights: tensor([[0.5816, 0.4184]], device='cuda:0')[38;5;237mâ•º[0m[38;5;237mâ”â”[0m 188/203 [2m0:11:08 â€¢ 0:00:38[0m [2;4m0.40it/s[0m  
[2KAttention weights: tensor([[0.9548, 0.0452],â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”[0m 188/203 [2m0:11:08 â€¢ 0:00:38[0m [2;4m0.40it/s[0m  
        [0.9287, 0.0713],
        [0.9334, 0.0666],
        [0.9580, 0.0420],
        [0.9496, 0.0504],
        [0.9557, 0.0443],
        [0.9125, 0.0875],
        [0.9746, 0.0254],
        [0.9840, 0.0160],
[2K        [0.9614, 0.0386]], device='cuda:0')â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”[0m 188/203 [2m0:11:08 â€¢ 0:00:38[0m [2;4m0.40it/s[0m  
[2KAttention weights: tensor([[0.5605, 0.4395],â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”[0m 189/203 [2m0:11:10 â€¢ 0:00:35[0m [2;4m0.40it/s[0m  
        [0.5559, 0.4441],
        [0.5577, 0.4423],
        [0.5587, 0.4413],
        [0.5595, 0.4405],
        [0.5563, 0.4437],
        [0.5554, 0.4446],
        [0.5596, 0.4404],
        [0.5599, 0.4401],
[2K        [0.5593, 0.4407]], device='cuda:0', grad_fn=<SoftmaxBackward0>)mâ•º[0m[38;5;237mâ”â”[0m 189/203 [2m0:11:10 â€¢ 0:00:35[0m [2;4m0.40it/s[0m  
[2KClass label: GolfSwingâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”[0m 189/203 [2m0:11:10 â€¢ 0:00:35[0m [2;4m0.40it/s[0m  
[2KAttention weights: tensor([[0.6270, 0.3730]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 189/203 [2m0:11:10 â€¢ 0:00:35[0m [2;4m0.40it/s[0m  
[2KStep 0 - TTA Loss: 0.8649â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”[0m 189/203 [2m0:11:10 â€¢ 0:00:35[0m [2;4m0.40it/s[0m  
[2KAttention weights: tensor([[0.6270, 0.3730]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 189/203 [2m0:11:10 â€¢ 0:00:35[0m [2;4m0.40it/s[0m  
[2KAttention weights: tensor([[0.6270, 0.3730]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 189/203 [2m0:11:10 â€¢ 0:00:35[0m [2;4m0.40it/s[0m  
[2KAttention weights: tensor([[0.6269, 0.3731]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 189/203 [2m0:11:10 â€¢ 0:00:35[0m [2;4m0.40it/s[0m  
[2KAttention weights: tensor([[0.6270, 0.3730]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 189/203 [2m0:11:10 â€¢ 0:00:35[0m [2;4m0.40it/s[0m  
[2KAttention weights: tensor([[0.6271, 0.3729]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 189/203 [2m0:11:10 â€¢ 0:00:35[0m [2;4m0.40it/s[0m  
[2KAttention weights: tensor([[0.6285, 0.3715]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 189/203 [2m0:11:10 â€¢ 0:00:35[0m [2;4m0.40it/s[0m  
[2KAttention weights: tensor([[0.6297, 0.3703]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 189/203 [2m0:11:10 â€¢ 0:00:35[0m [2;4m0.40it/s[0m  
[2KAttention weights: tensor([[0.6303, 0.3697]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 189/203 [2m0:11:10 â€¢ 0:00:35[0m [2;4m0.40it/s[0m  
[2KAttention weights: tensor([[0.6294, 0.3706]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 189/203 [2m0:11:10 â€¢ 0:00:35[0m [2;4m0.40it/s[0m  
[2KAttention weights: tensor([[0.5586, 0.4414]], device='cuda:0')[38;5;237mâ•º[0m[38;5;237mâ”â”[0m 189/203 [2m0:11:10 â€¢ 0:00:35[0m [2;4m0.40it/s[0m  
[2KAttention weights: tensor([[0.6177, 0.3823],â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”[0m 189/203 [2m0:11:10 â€¢ 0:00:35[0m [2;4m0.40it/s[0m  
        [0.5973, 0.4027],
        [0.5903, 0.4097],
        [0.6254, 0.3746],
        [0.5989, 0.4011],
        [0.6055, 0.3945],
        [0.5709, 0.4291],
        [0.6885, 0.3115],
        [0.6099, 0.3901],
[2K        [0.6377, 0.3623]], device='cuda:0')â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”[0m 189/203 [2m0:11:10 â€¢ 0:00:35[0m [2;4m0.40it/s[0m  
[2KAttention weights: tensor([[0.5605, 0.4395],â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”[0m 190/203 [2m0:11:12 â€¢ 0:00:32[0m [2;4m0.41it/s[0m  
        [0.5559, 0.4441],
        [0.5577, 0.4423],
        [0.5587, 0.4413],
        [0.5595, 0.4405],
        [0.5563, 0.4437],
        [0.5553, 0.4447],
        [0.5596, 0.4404],
        [0.5598, 0.4402],
[2K        [0.5593, 0.4407]], device='cuda:0', grad_fn=<SoftmaxBackward0>)mâ•º[0m[38;5;237mâ”â”[0m 190/203 [2m0:11:12 â€¢ 0:00:32[0m [2;4m0.41it/s[0m  
[2KClass label: PoleVaultâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”[0m 190/203 [2m0:11:12 â€¢ 0:00:32[0m [2;4m0.41it/s[0m  
[2KAttention weights: tensor([[0.5532, 0.4468]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 190/203 [2m0:11:12 â€¢ 0:00:32[0m [2;4m0.41it/s[0m  
[2KStep 0 - TTA Loss: 0.7277â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”[0m 190/203 [2m0:11:12 â€¢ 0:00:32[0m [2;4m0.41it/s[0m  
[2KAttention weights: tensor([[0.5926, 0.4074]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 190/203 [2m0:11:12 â€¢ 0:00:32[0m [2;4m0.41it/s[0m  
[2KAttention weights: tensor([[0.6620, 0.3380]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 190/203 [2m0:11:12 â€¢ 0:00:32[0m [2;4m0.41it/s[0m  
[2KAttention weights: tensor([[0.7405, 0.2595]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 190/203 [2m0:11:12 â€¢ 0:00:32[0m [2;4m0.41it/s[0m  
[2KAttention weights: tensor([[0.8110, 0.1890]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 190/203 [2m0:11:12 â€¢ 0:00:32[0m [2;4m0.41it/s[0m  
[2KAttention weights: tensor([[0.8620, 0.1380]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 190/203 [2m0:11:12 â€¢ 0:00:32[0m [2;4m0.41it/s[0m  
[2KAttention weights: tensor([[0.8920, 0.1080]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 190/203 [2m0:11:12 â€¢ 0:00:32[0m [2;4m0.41it/s[0m  
[2KAttention weights: tensor([[0.9079, 0.0921]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 190/203 [2m0:11:12 â€¢ 0:00:32[0m [2;4m0.41it/s[0m  
[2KAttention weights: tensor([[0.9154, 0.0846]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 190/203 [2m0:11:12 â€¢ 0:00:32[0m [2;4m0.41it/s[0m  
[2KAttention weights: tensor([[0.9183, 0.0817]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 190/203 [2m0:11:12 â€¢ 0:00:32[0m [2;4m0.41it/s[0m  
[2KAttention weights: tensor([[0.5693, 0.4307]], device='cuda:0')[38;5;237mâ•º[0m[38;5;237mâ”â”[0m 190/203 [2m0:11:12 â€¢ 0:00:32[0m [2;4m0.41it/s[0m  
[2KAttention weights: tensor([[0.8402, 0.1598],â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”[0m 190/203 [2m0:11:12 â€¢ 0:00:32[0m [2;4m0.41it/s[0m  
        [0.7703, 0.2297],
        [0.8205, 0.1795],
        [0.8316, 0.1684],
        [0.8672, 0.1328],
        [0.8945, 0.1055],
        [0.9192, 0.0808],
        [0.8767, 0.1233],
        [0.7999, 0.2001],
[2K        [0.8807, 0.1193]], device='cuda:0')â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”â”[0m 190/203 [2m0:11:12 â€¢ 0:00:32[0m [2;4m0.41it/s[0m  
[2KAttention weights: tensor([[0.5604, 0.4396],â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”[0m 191/203 [2m0:11:26 â€¢ 0:00:36[0m [2;4m0.34it/s[0m  
        [0.5559, 0.4441],
        [0.5577, 0.4423],
        [0.5586, 0.4414],
        [0.5595, 0.4405],
        [0.5563, 0.4437],
        [0.5553, 0.4447],
        [0.5596, 0.4404],
        [0.5598, 0.4402],
[2K        [0.5592, 0.4408]], device='cuda:0', grad_fn=<SoftmaxBackward0>)6;224mâ•¸[0m[38;5;237mâ”â”[0m 191/203 [2m0:11:26 â€¢ 0:00:36[0m [2;4m0.34it/s[0m  
[2KClass label: CleanAndJerkâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”[0m 191/203 [2m0:11:26 â€¢ 0:00:36[0m [2;4m0.34it/s[0m  
[2KAttention weights: tensor([[0.5729, 0.4271]], device='cuda:0', grad_fn=<SoftmaxBackward0>)37mâ”â”[0m 191/203 [2m0:11:26 â€¢ 0:00:36[0m [2;4m0.34it/s[0m  
[2KStep 0 - TTA Loss: 0.7636â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”[0m 191/203 [2m0:11:26 â€¢ 0:00:36[0m [2;4m0.34it/s[0m  
[2KAttention weights: tensor([[0.5729, 0.4271]], device='cuda:0', grad_fn=<SoftmaxBackward0>)37mâ”â”[0m 191/203 [2m0:11:26 â€¢ 0:00:36[0m [2;4m0.34it/s[0m  
[2KAttention weights: tensor([[0.5747, 0.4253]], device='cuda:0', grad_fn=<SoftmaxBackward0>)37mâ”â”[0m 191/203 [2m0:11:26 â€¢ 0:00:36[0m [2;4m0.34it/s[0m  
[2KAttention weights: tensor([[0.5833, 0.4167]], device='cuda:0', grad_fn=<SoftmaxBackward0>)37mâ”â”[0m 191/203 [2m0:11:26 â€¢ 0:00:36[0m [2;4m0.34it/s[0m  
[2KAttention weights: tensor([[0.6046, 0.3954]], device='cuda:0', grad_fn=<SoftmaxBackward0>)37mâ”â”[0m 191/203 [2m0:11:26 â€¢ 0:00:36[0m [2;4m0.34it/s[0m  
[2KAttention weights: tensor([[0.6398, 0.3602]], device='cuda:0', grad_fn=<SoftmaxBackward0>)37mâ”â”[0m 191/203 [2m0:11:26 â€¢ 0:00:36[0m [2;4m0.34it/s[0m  
[2KAttention weights: tensor([[0.6943, 0.3057]], device='cuda:0', grad_fn=<SoftmaxBackward0>)37mâ”â”[0m 191/203 [2m0:11:26 â€¢ 0:00:36[0m [2;4m0.34it/s[0m  
[2KAttention weights: tensor([[0.7577, 0.2423]], device='cuda:0', grad_fn=<SoftmaxBackward0>)37mâ”â”[0m 191/203 [2m0:11:26 â€¢ 0:00:36[0m [2;4m0.34it/s[0m  
[2KAttention weights: tensor([[0.8115, 0.1885]], device='cuda:0', grad_fn=<SoftmaxBackward0>)37mâ”â”[0m 191/203 [2m0:11:26 â€¢ 0:00:36[0m [2;4m0.34it/s[0m  
[2KAttention weights: tensor([[0.8503, 0.1497]], device='cuda:0', grad_fn=<SoftmaxBackward0>)37mâ”â”[0m 191/203 [2m0:11:26 â€¢ 0:00:36[0m [2;4m0.34it/s[0m  
[2KAttention weights: tensor([[0.5655, 0.4345]], device='cuda:0')[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”[0m 191/203 [2m0:11:26 â€¢ 0:00:36[0m [2;4m0.34it/s[0m  
[2KAttention weights: tensor([[0.7864, 0.2136],â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”[0m 191/203 [2m0:11:26 â€¢ 0:00:36[0m [2;4m0.34it/s[0m  
        [0.7326, 0.2674],
        [0.8742, 0.1258],
        [0.8038, 0.1962],
        [0.8224, 0.1776],
        [0.8330, 0.1670],
        [0.8227, 0.1773],
        [0.7983, 0.2017],
        [0.7984, 0.2016],
[2K        [0.8417, 0.1583]], device='cuda:0')â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”[0m 191/203 [2m0:11:26 â€¢ 0:00:36[0m [2;4m0.34it/s[0m  
[2KAttention weights: tensor([[0.5604, 0.4396],â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”[0m 192/203 [2m0:11:29 â€¢ 0:00:33[0m [2;4m0.33it/s[0m  
        [0.5559, 0.4441],
        [0.5577, 0.4423],
        [0.5586, 0.4414],
        [0.5595, 0.4405],
        [0.5563, 0.4437],
        [0.5553, 0.4447],
        [0.5596, 0.4404],
        [0.5598, 0.4402],
[2K        [0.5593, 0.4407]], device='cuda:0', grad_fn=<SoftmaxBackward0>)6;224mâ•¸[0m[38;5;237mâ”â”[0m 192/203 [2m0:11:29 â€¢ 0:00:33[0m [2;4m0.33it/s[0m  
[2KClass label: HighJumpâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”[0m 192/203 [2m0:11:29 â€¢ 0:00:33[0m [2;4m0.33it/s[0m  
[2KAttention weights: tensor([[0.5941, 0.4059]], device='cuda:0', grad_fn=<SoftmaxBackward0>)37mâ”â”[0m 192/203 [2m0:11:29 â€¢ 0:00:33[0m [2;4m0.33it/s[0m  
[2KStep 0 - TTA Loss: 0.7368â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”[0m 192/203 [2m0:11:29 â€¢ 0:00:33[0m [2;4m0.33it/s[0m  
[2KAttention weights: tensor([[0.6617, 0.3383]], device='cuda:0', grad_fn=<SoftmaxBackward0>)37mâ”â”[0m 192/203 [2m0:11:29 â€¢ 0:00:33[0m [2;4m0.33it/s[0m  
[2KAttention weights: tensor([[0.7461, 0.2539]], device='cuda:0', grad_fn=<SoftmaxBackward0>)37mâ”â”[0m 192/203 [2m0:11:29 â€¢ 0:00:33[0m [2;4m0.33it/s[0m  
[2KAttention weights: tensor([[0.8307, 0.1693]], device='cuda:0', grad_fn=<SoftmaxBackward0>)37mâ”â”[0m 192/203 [2m0:11:29 â€¢ 0:00:33[0m [2;4m0.33it/s[0m  
[2KAttention weights: tensor([[0.8883, 0.1117]], device='cuda:0', grad_fn=<SoftmaxBackward0>)37mâ”â”[0m 192/203 [2m0:11:29 â€¢ 0:00:33[0m [2;4m0.33it/s[0m  
[2KAttention weights: tensor([[0.9217, 0.0783]], device='cuda:0', grad_fn=<SoftmaxBackward0>)37mâ”â”[0m 192/203 [2m0:11:29 â€¢ 0:00:33[0m [2;4m0.33it/s[0m  
[2KAttention weights: tensor([[0.9536, 0.0464]], device='cuda:0', grad_fn=<SoftmaxBackward0>)37mâ”â”[0m 192/203 [2m0:11:29 â€¢ 0:00:33[0m [2;4m0.33it/s[0m  
[2KAttention weights: tensor([[0.9716, 0.0284]], device='cuda:0', grad_fn=<SoftmaxBackward0>)37mâ”â”[0m 192/203 [2m0:11:29 â€¢ 0:00:33[0m [2;4m0.33it/s[0m  
[2KAttention weights: tensor([[0.9796, 0.0204]], device='cuda:0', grad_fn=<SoftmaxBackward0>)37mâ”â”[0m 192/203 [2m0:11:29 â€¢ 0:00:33[0m [2;4m0.33it/s[0m  
[2KAttention weights: tensor([[0.9826, 0.0174]], device='cuda:0', grad_fn=<SoftmaxBackward0>)37mâ”â”[0m 192/203 [2m0:11:29 â€¢ 0:00:33[0m [2;4m0.33it/s[0m  
[2KAttention weights: tensor([[0.5785, 0.4215]], device='cuda:0')[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”[0m 192/203 [2m0:11:29 â€¢ 0:00:33[0m [2;4m0.33it/s[0m  
[2KAttention weights: tensor([[0.9480, 0.0520],â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”[0m 192/203 [2m0:11:29 â€¢ 0:00:33[0m [2;4m0.33it/s[0m  
        [0.8836, 0.1164],
        [0.9502, 0.0498],
        [0.9395, 0.0605],
        [0.9660, 0.0340],
        [0.9833, 0.0167],
        [0.9699, 0.0301],
        [0.9515, 0.0485],
        [0.9484, 0.0516],
[2K        [0.9696, 0.0304]], device='cuda:0')â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”â”[0m 192/203 [2m0:11:29 â€¢ 0:00:33[0m [2;4m0.33it/s[0m  
[2KAttention weights: tensor([[0.5604, 0.4396],â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”[0m 193/203 [2m0:11:33 â€¢ 0:00:36[0m [2;4m0.28it/s[0m   
        [0.5559, 0.4441],
        [0.5577, 0.4423],
        [0.5586, 0.4414],
        [0.5595, 0.4405],
        [0.5563, 0.4437],
        [0.5554, 0.4446],
        [0.5596, 0.4404],
        [0.5598, 0.4402],
[2K        [0.5593, 0.4407]], device='cuda:0', grad_fn=<SoftmaxBackward0>)7mâ•º[0m[38;5;237mâ”[0m 193/203 [2m0:11:33 â€¢ 0:00:36[0m [2;4m0.28it/s[0m  
[2KClass label: BaseballPitchâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”[0m 193/203 [2m0:11:33 â€¢ 0:00:36[0m [2;4m0.28it/s[0m  
[2KAttention weights: tensor([[0.6156, 0.3844]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 193/203 [2m0:11:33 â€¢ 0:00:36[0m [2;4m0.28it/s[0m  
[2KStep 0 - TTA Loss: 1.0894â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”[0m 193/203 [2m0:11:33 â€¢ 0:00:36[0m [2;4m0.28it/s[0m  
[2KAttention weights: tensor([[0.6156, 0.3844]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 193/203 [2m0:11:33 â€¢ 0:00:36[0m [2;4m0.28it/s[0m  
[2KAttention weights: tensor([[0.6211, 0.3789]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 193/203 [2m0:11:33 â€¢ 0:00:36[0m [2;4m0.28it/s[0m  
[2KAttention weights: tensor([[0.6415, 0.3585]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 193/203 [2m0:11:33 â€¢ 0:00:36[0m [2;4m0.28it/s[0m  
[2KAttention weights: tensor([[0.6833, 0.3167]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 193/203 [2m0:11:33 â€¢ 0:00:36[0m [2;4m0.28it/s[0m  
[2KAttention weights: tensor([[0.7476, 0.2524]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 193/203 [2m0:11:33 â€¢ 0:00:36[0m [2;4m0.28it/s[0m  
[2KAttention weights: tensor([[0.8226, 0.1774]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 193/203 [2m0:11:33 â€¢ 0:00:36[0m [2;4m0.28it/s[0m  
[2KAttention weights: tensor([[0.8912, 0.1088]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 193/203 [2m0:11:33 â€¢ 0:00:36[0m [2;4m0.28it/s[0m  
[2KAttention weights: tensor([[0.9393, 0.0607]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 193/203 [2m0:11:33 â€¢ 0:00:36[0m [2;4m0.28it/s[0m  
[2KAttention weights: tensor([[0.9642, 0.0358]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 193/203 [2m0:11:33 â€¢ 0:00:36[0m [2;4m0.28it/s[0m  
[2KAttention weights: tensor([[0.5755, 0.4245]], device='cuda:0')[38;5;237mâ•º[0m[38;5;237mâ”[0m 193/203 [2m0:11:33 â€¢ 0:00:36[0m [2;4m0.28it/s[0m  
[2KAttention weights: tensor([[0.9734, 0.0266],â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”[0m 193/203 [2m0:11:33 â€¢ 0:00:36[0m [2;4m0.28it/s[0m  
        [0.8935, 0.1065],
        [0.9405, 0.0595],
        [0.9571, 0.0429],
        [0.9734, 0.0266],
        [0.9857, 0.0143],
        [0.9700, 0.0300],
        [0.9604, 0.0396],
        [0.9622, 0.0378],
[2K        [0.9774, 0.0226]], device='cuda:0')â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”[0m 193/203 [2m0:11:33 â€¢ 0:00:36[0m [2;4m0.28it/s[0m  
[2KAttention weights: tensor([[0.5605, 0.4395],â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”[0m 194/203 [2m0:11:34 â€¢ 0:00:30[0m [2;4m0.31it/s[0m  
        [0.5559, 0.4441],
        [0.5577, 0.4423],
        [0.5587, 0.4413],
        [0.5595, 0.4405],
        [0.5564, 0.4436],
        [0.5554, 0.4446],
        [0.5596, 0.4404],
        [0.5598, 0.4402],
[2K        [0.5593, 0.4407]], device='cuda:0', grad_fn=<SoftmaxBackward0>)7mâ•º[0m[38;5;237mâ”[0m 194/203 [2m0:11:34 â€¢ 0:00:30[0m [2;4m0.31it/s[0m  
[2KClass label: HighJumpâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”[0m 194/203 [2m0:11:34 â€¢ 0:00:30[0m [2;4m0.31it/s[0m  
[2KAttention weights: tensor([[0.5963, 0.4037]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 194/203 [2m0:11:34 â€¢ 0:00:30[0m [2;4m0.31it/s[0m  
[2KStep 0 - TTA Loss: 0.4895â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”[0m 194/203 [2m0:11:34 â€¢ 0:00:30[0m [2;4m0.31it/s[0m  
[2KAttention weights: tensor([[0.7075, 0.2925]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 194/203 [2m0:11:34 â€¢ 0:00:30[0m [2;4m0.31it/s[0m  
[2KAttention weights: tensor([[0.7906, 0.2094]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 194/203 [2m0:11:34 â€¢ 0:00:30[0m [2;4m0.31it/s[0m  
[2KAttention weights: tensor([[0.8456, 0.1544]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 194/203 [2m0:11:34 â€¢ 0:00:30[0m [2;4m0.31it/s[0m  
[2KAttention weights: tensor([[0.8784, 0.1216]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 194/203 [2m0:11:34 â€¢ 0:00:30[0m [2;4m0.31it/s[0m  
[2KAttention weights: tensor([[0.9018, 0.0982]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 194/203 [2m0:11:34 â€¢ 0:00:30[0m [2;4m0.31it/s[0m  
[2KAttention weights: tensor([[0.9206, 0.0794]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 194/203 [2m0:11:34 â€¢ 0:00:30[0m [2;4m0.31it/s[0m  
[2KAttention weights: tensor([[0.9353, 0.0647]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 194/203 [2m0:11:34 â€¢ 0:00:30[0m [2;4m0.31it/s[0m  
[2KAttention weights: tensor([[0.9448, 0.0552]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 194/203 [2m0:11:34 â€¢ 0:00:30[0m [2;4m0.31it/s[0m  
[2KAttention weights: tensor([[0.9495, 0.0505]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 194/203 [2m0:11:34 â€¢ 0:00:30[0m [2;4m0.31it/s[0m  
[2KAttention weights: tensor([[0.5711, 0.4289]], device='cuda:0')[38;5;237mâ•º[0m[38;5;237mâ”[0m 194/203 [2m0:11:34 â€¢ 0:00:30[0m [2;4m0.31it/s[0m  
[2KAttention weights: tensor([[0.8824, 0.1176],â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”[0m 194/203 [2m0:11:34 â€¢ 0:00:30[0m [2;4m0.31it/s[0m  
        [0.8095, 0.1905],
        [0.8736, 0.1264],
        [0.8770, 0.1230],
        [0.9119, 0.0881],
        [0.9509, 0.0491],
        [0.9142, 0.0858],
        [0.8997, 0.1003],
        [0.8994, 0.1006],
[2K        [0.9236, 0.0764]], device='cuda:0')â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”[0m 194/203 [2m0:11:34 â€¢ 0:00:30[0m [2;4m0.31it/s[0m  
[2KAttention weights: tensor([[0.5605, 0.4395],â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”[0m 195/203 [2m0:11:43 â€¢ 0:00:35[0m [2;4m0.24it/s[0m  
        [0.5559, 0.4441],
        [0.5578, 0.4422],
        [0.5587, 0.4413],
        [0.5595, 0.4405],
        [0.5564, 0.4436],
        [0.5554, 0.4446],
        [0.5596, 0.4404],
        [0.5598, 0.4402],
[2K        [0.5593, 0.4407]], device='cuda:0', grad_fn=<SoftmaxBackward0>)7mâ•º[0m[38;5;237mâ”[0m 195/203 [2m0:11:43 â€¢ 0:00:35[0m [2;4m0.24it/s[0m  
[2KClass label: GolfSwingâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”[0m 195/203 [2m0:11:43 â€¢ 0:00:35[0m [2;4m0.24it/s[0m  
[2KAttention weights: tensor([[0.6288, 0.3712]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 195/203 [2m0:11:43 â€¢ 0:00:35[0m [2;4m0.24it/s[0m  
[2KStep 0 - TTA Loss: 0.6325â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”[0m 195/203 [2m0:11:43 â€¢ 0:00:35[0m [2;4m0.24it/s[0m  
[2KAttention weights: tensor([[0.6288, 0.3712]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 195/203 [2m0:11:43 â€¢ 0:00:35[0m [2;4m0.24it/s[0m  
[2KAttention weights: tensor([[0.6325, 0.3675]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 195/203 [2m0:11:43 â€¢ 0:00:35[0m [2;4m0.24it/s[0m  
[2KAttention weights: tensor([[0.6469, 0.3531]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 195/203 [2m0:11:43 â€¢ 0:00:35[0m [2;4m0.24it/s[0m  
[2KAttention weights: tensor([[0.6782, 0.3218]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 195/203 [2m0:11:43 â€¢ 0:00:35[0m [2;4m0.24it/s[0m  
[2KAttention weights: tensor([[0.7294, 0.2706]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 195/203 [2m0:11:43 â€¢ 0:00:35[0m [2;4m0.24it/s[0m  
[2KAttention weights: tensor([[0.7936, 0.2064]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 195/203 [2m0:11:43 â€¢ 0:00:35[0m [2;4m0.24it/s[0m  
[2KAttention weights: tensor([[0.8578, 0.1422]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 195/203 [2m0:11:43 â€¢ 0:00:35[0m [2;4m0.24it/s[0m  
[2KAttention weights: tensor([[0.9019, 0.0981]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 195/203 [2m0:11:43 â€¢ 0:00:35[0m [2;4m0.24it/s[0m  
[2KAttention weights: tensor([[0.9277, 0.0723]], device='cuda:0', grad_fn=<SoftmaxBackward0>)[0m 195/203 [2m0:11:43 â€¢ 0:00:35[0m [2;4m0.24it/s[0m  
[2KAttention weights: tensor([[0.5701, 0.4299]], device='cuda:0')[38;5;237mâ•º[0m[38;5;237mâ”[0m 195/203 [2m0:11:43 â€¢ 0:00:35[0m [2;4m0.24it/s[0m  
[2KAttention weights: tensor([[0.9312, 0.0688],â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”[0m 195/203 [2m0:11:43 â€¢ 0:00:35[0m [2;4m0.24it/s[0m  
        [0.8418, 0.1582],
        [0.8951, 0.1049],
        [0.9363, 0.0637],
        [0.9389, 0.0611],
        [0.9606, 0.0394],
        [0.9301, 0.0699],
        [0.9208, 0.0792],
        [0.9348, 0.0652],
[2K        [0.9495, 0.0505]], device='cuda:0')â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m[38;5;237mâ”[0m 195/203 [2m0:11:43 â€¢ 0:00:35[0m [2;4m0.24it/s[0m  
[2KAttention weights: tensor([[0.5605, 0.4395],â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”[0m 196/203 [2m0:11:46 â€¢ 0:00:29[0m [2;4m0.24it/s[0m  
        [0.5559, 0.4441],
        [0.5578, 0.4422],
        [0.5587, 0.4413],
        [0.5596, 0.4404],
        [0.5564, 0.4436],
        [0.5555, 0.4445],
        [0.5597, 0.4403],
        [0.5598, 0.4402],
[2K        [0.5593, 0.4407]], device='cuda:0', grad_fn=<SoftmaxBackward0>);6;224mâ•¸[0m[38;5;237mâ”[0m 196/203 [2m0:11:46 â€¢ 0:00:29[0m [2;4m0.24it/s[0m  
[2KClass label: GolfSwingâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”[0m 196/203 [2m0:11:46 â€¢ 0:00:29[0m [2;4m0.24it/s[0m  
[2KAttention weights: tensor([[0.6320, 0.3680]], device='cuda:0', grad_fn=<SoftmaxBackward0>)237mâ”[0m 196/203 [2m0:11:46 â€¢ 0:00:29[0m [2;4m0.24it/s[0m  
[2KStep 0 - TTA Loss: 1.2640â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”[0m 196/203 [2m0:11:46 â€¢ 0:00:29[0m [2;4m0.24it/s[0m  
[2KAttention weights: tensor([[0.6663, 0.3337]], device='cuda:0', grad_fn=<SoftmaxBackward0>)237mâ”[0m 196/203 [2m0:11:46 â€¢ 0:00:29[0m [2;4m0.24it/s[0m  
[2KAttention weights: tensor([[0.7027, 0.2973]], device='cuda:0', grad_fn=<SoftmaxBackward0>)237mâ”[0m 196/203 [2m0:11:46 â€¢ 0:00:29[0m [2;4m0.24it/s[0m  
[2KAttention weights: tensor([[0.7383, 0.2617]], device='cuda:0', grad_fn=<SoftmaxBackward0>)237mâ”[0m 196/203 [2m0:11:46 â€¢ 0:00:29[0m [2;4m0.24it/s[0m  
[2KAttention weights: tensor([[0.7656, 0.2344]], device='cuda:0', grad_fn=<SoftmaxBackward0>)237mâ”[0m 196/203 [2m0:11:46 â€¢ 0:00:29[0m [2;4m0.24it/s[0m  
[2KAttention weights: tensor([[0.7857, 0.2143]], device='cuda:0', grad_fn=<SoftmaxBackward0>)237mâ”[0m 196/203 [2m0:11:46 â€¢ 0:00:29[0m [2;4m0.24it/s[0m  
[2KAttention weights: tensor([[0.8021, 0.1979]], device='cuda:0', grad_fn=<SoftmaxBackward0>)237mâ”[0m 196/203 [2m0:11:46 â€¢ 0:00:29[0m [2;4m0.24it/s[0m  
[2KAttention weights: tensor([[0.8156, 0.1844]], device='cuda:0', grad_fn=<SoftmaxBackward0>)237mâ”[0m 196/203 [2m0:11:46 â€¢ 0:00:29[0m [2;4m0.24it/s[0m  
[2KAttention weights: tensor([[0.8236, 0.1764]], device='cuda:0', grad_fn=<SoftmaxBackward0>)237mâ”[0m 196/203 [2m0:11:46 â€¢ 0:00:29[0m [2;4m0.24it/s[0m  
[2KAttention weights: tensor([[0.8270, 0.1730]], device='cuda:0', grad_fn=<SoftmaxBackward0>)237mâ”[0m 196/203 [2m0:11:46 â€¢ 0:00:29[0m [2;4m0.24it/s[0m  
[2KAttention weights: tensor([[0.5634, 0.4366]], device='cuda:0')[38;2;98;6;224mâ•¸[0m[38;5;237mâ”[0m 196/203 [2m0:11:46 â€¢ 0:00:29[0m [2;4m0.24it/s[0m  
[2KAttention weights: tensor([[0.8298, 0.1702],â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”[0m 196/203 [2m0:11:46 â€¢ 0:00:29[0m [2;4m0.24it/s[0m  
        [0.7442, 0.2558],
        [0.7859, 0.2141],
        [0.8281, 0.1719],
        [0.8392, 0.1608],
        [0.8813, 0.1187],
        [0.8252, 0.1748],
        [0.8353, 0.1647],
        [0.8450, 0.1550],
[2K        [0.8638, 0.1362]], device='cuda:0')â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”[0m 196/203 [2m0:11:46 â€¢ 0:00:29[0m [2;4m0.24it/s[0m  
[2KAttention weights: tensor([[0.5605, 0.4395],â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”[0m 197/203 [2m0:11:49 â€¢ 0:00:24[0m [2;4m0.25it/s[0m  
        [0.5559, 0.4441],
        [0.5578, 0.4422],
        [0.5587, 0.4413],
        [0.5595, 0.4405],
        [0.5565, 0.4435],
        [0.5555, 0.4445],
        [0.5596, 0.4404],
        [0.5598, 0.4402],
[2K        [0.5593, 0.4407]], device='cuda:0', grad_fn=<SoftmaxBackward0>);6;224mâ•¸[0m[38;5;237mâ”[0m 197/203 [2m0:11:49 â€¢ 0:00:24[0m [2;4m0.25it/s[0m  
[2KClass label: PoleVaultâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”[0m 197/203 [2m0:11:49 â€¢ 0:00:24[0m [2;4m0.25it/s[0m  
[2KAttention weights: tensor([[0.5498, 0.4502]], device='cuda:0', grad_fn=<SoftmaxBackward0>)237mâ”[0m 197/203 [2m0:11:49 â€¢ 0:00:24[0m [2;4m0.25it/s[0m  
[2KStep 0 - TTA Loss: 1.0065â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”[0m 197/203 [2m0:11:49 â€¢ 0:00:24[0m [2;4m0.25it/s[0m  
[2KAttention weights: tensor([[0.5498, 0.4502]], device='cuda:0', grad_fn=<SoftmaxBackward0>)237mâ”[0m 197/203 [2m0:11:49 â€¢ 0:00:24[0m [2;4m0.25it/s[0m  
[2KAttention weights: tensor([[0.5511, 0.4489]], device='cuda:0', grad_fn=<SoftmaxBackward0>)237mâ”[0m 197/203 [2m0:11:49 â€¢ 0:00:24[0m [2;4m0.25it/s[0m  
[2KAttention weights: tensor([[0.5558, 0.4442]], device='cuda:0', grad_fn=<SoftmaxBackward0>)237mâ”[0m 197/203 [2m0:11:49 â€¢ 0:00:24[0m [2;4m0.25it/s[0m  
[2KAttention weights: tensor([[0.5672, 0.4328]], device='cuda:0', grad_fn=<SoftmaxBackward0>)237mâ”[0m 197/203 [2m0:11:49 â€¢ 0:00:24[0m [2;4m0.25it/s[0m  
[2KAttention weights: tensor([[0.5881, 0.4119]], device='cuda:0', grad_fn=<SoftmaxBackward0>)237mâ”[0m 197/203 [2m0:11:49 â€¢ 0:00:24[0m [2;4m0.25it/s[0m  
[2KAttention weights: tensor([[0.6165, 0.3835]], device='cuda:0', grad_fn=<SoftmaxBackward0>)237mâ”[0m 197/203 [2m0:11:49 â€¢ 0:00:24[0m [2;4m0.25it/s[0m  
[2KAttention weights: tensor([[0.6520, 0.3480]], device='cuda:0', grad_fn=<SoftmaxBackward0>)237mâ”[0m 197/203 [2m0:11:49 â€¢ 0:00:24[0m [2;4m0.25it/s[0m  
[2KAttention weights: tensor([[0.6957, 0.3043]], device='cuda:0', grad_fn=<SoftmaxBackward0>)237mâ”[0m 197/203 [2m0:11:49 â€¢ 0:00:24[0m [2;4m0.25it/s[0m  
[2KAttention weights: tensor([[0.7325, 0.2675]], device='cuda:0', grad_fn=<SoftmaxBackward0>)237mâ”[0m 197/203 [2m0:11:49 â€¢ 0:00:24[0m [2;4m0.25it/s[0m  
[2KAttention weights: tensor([[0.5606, 0.4394]], device='cuda:0')[38;2;98;6;224mâ•¸[0m[38;5;237mâ”[0m 197/203 [2m0:11:49 â€¢ 0:00:24[0m [2;4m0.25it/s[0m  
[2KAttention weights: tensor([[0.7729, 0.2271],â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”[0m 197/203 [2m0:11:49 â€¢ 0:00:24[0m [2;4m0.25it/s[0m  
        [0.6913, 0.3087],
        [0.7161, 0.2839],
        [0.7902, 0.2098],
        [0.7648, 0.2352],
        [0.7843, 0.2157],
        [0.7569, 0.2431],
        [0.7699, 0.2301],
        [0.7785, 0.2215],
[2K        [0.8001, 0.1999]], device='cuda:0')â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m[38;5;237mâ”[0m 197/203 [2m0:11:49 â€¢ 0:00:24[0m [2;4m0.25it/s[0m  
[2KAttention weights: tensor([[0.5605, 0.4395],â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m 198/203 [2m0:11:54 â€¢ 0:00:20[0m [2;4m0.25it/s[0m  4m0.25it/s[0m  
        [0.5559, 0.4441],
        [0.5578, 0.4422],
        [0.5587, 0.4413],
        [0.5596, 0.4404],
        [0.5565, 0.4435],
        [0.5555, 0.4445],
        [0.5596, 0.4403],
        [0.5598, 0.4402],
[2K        [0.5593, 0.4407]], device='cuda:0', grad_fn=<SoftmaxBackward0>)37mâ•º[0m 198/203 [2m0:11:54 â€¢ 0:00:20[0m [2;4m0.25it/s[0m  
[2KClass label: SoccerPenaltyâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m 198/203 [2m0:11:54 â€¢ 0:00:20[0m [2;4m0.25it/s[0m  
[2KAttention weights: tensor([[0.6385, 0.3615]], device='cuda:0', grad_fn=<SoftmaxBackward0>)2m0:11:54 â€¢ 0:00:20[0m [2;4m0.25it/s[0m  
[2KStep 0 - TTA Loss: 0.5424â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m 198/203 [2m0:11:54 â€¢ 0:00:20[0m [2;4m0.25it/s[0m  
[2KAttention weights: tensor([[0.7030, 0.2970]], device='cuda:0', grad_fn=<SoftmaxBackward0>)2m0:11:54 â€¢ 0:00:20[0m [2;4m0.25it/s[0m  
[2KAttention weights: tensor([[0.7935, 0.2065]], device='cuda:0', grad_fn=<SoftmaxBackward0>)2m0:11:54 â€¢ 0:00:20[0m [2;4m0.25it/s[0m  
[2KAttention weights: tensor([[0.8826, 0.1174]], device='cuda:0', grad_fn=<SoftmaxBackward0>)2m0:11:54 â€¢ 0:00:20[0m [2;4m0.25it/s[0m  
[2KAttention weights: tensor([[0.9442, 0.0558]], device='cuda:0', grad_fn=<SoftmaxBackward0>)2m0:11:54 â€¢ 0:00:20[0m [2;4m0.25it/s[0m  
[2KAttention weights: tensor([[0.9743, 0.0257]], device='cuda:0', grad_fn=<SoftmaxBackward0>)2m0:11:54 â€¢ 0:00:20[0m [2;4m0.25it/s[0m  
[2KAttention weights: tensor([[0.9856, 0.0144]], device='cuda:0', grad_fn=<SoftmaxBackward0>)2m0:11:54 â€¢ 0:00:20[0m [2;4m0.25it/s[0m  
[2KAttention weights: tensor([[0.9901, 0.0099]], device='cuda:0', grad_fn=<SoftmaxBackward0>)2m0:11:54 â€¢ 0:00:20[0m [2;4m0.25it/s[0m  
[2KAttention weights: tensor([[0.9919, 0.0081]], device='cuda:0', grad_fn=<SoftmaxBackward0>)2m0:11:54 â€¢ 0:00:20[0m [2;4m0.25it/s[0m  
[2KAttention weights: tensor([[0.9926, 0.0074]], device='cuda:0', grad_fn=<SoftmaxBackward0>)2m0:11:54 â€¢ 0:00:20[0m [2;4m0.25it/s[0m  
[2KAttention weights: tensor([[0.5822, 0.4178]], device='cuda:0')m[38;5;237mâ•º[0m 198/203 [2m0:11:54 â€¢ 0:00:20[0m [2;4m0.25it/s[0m  
[2KAttention weights: tensor([[0.9341, 0.0659],â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m 198/203 [2m0:11:54 â€¢ 0:00:20[0m [2;4m0.25it/s[0m  
        [0.8829, 0.1171],
        [0.8412, 0.1588],
        [0.9160, 0.0840],
        [0.9330, 0.0670],
        [0.9411, 0.0589],
        [0.9224, 0.0776],
        [0.9928, 0.0072],
        [0.9181, 0.0819],
[2K        [0.9327, 0.0673]], device='cuda:0')â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m 198/203 [2m0:11:54 â€¢ 0:00:20[0m [2;4m0.25it/s[0m  
[2KAttention weights: tensor([[0.5605, 0.4395],â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m 199/203 [2m0:11:56 â€¢ 0:00:15[0m [2;4m0.27it/s[0m  
        [0.5560, 0.4440],
        [0.5578, 0.4422],
        [0.5587, 0.4413],
        [0.5596, 0.4404],
        [0.5565, 0.4435],
        [0.5555, 0.4445],
        [0.5597, 0.4403],
        [0.5598, 0.4402],
[2K        [0.5593, 0.4407]], device='cuda:0', grad_fn=<SoftmaxBackward0>)37mâ•º[0m 199/203 [2m0:11:56 â€¢ 0:00:15[0m [2;4m0.27it/s[0m  
[2KClass label: PoleVaultâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m 199/203 [2m0:11:56 â€¢ 0:00:15[0m [2;4m0.27it/s[0m  
[2KAttention weights: tensor([[0.5467, 0.4533]], device='cuda:0', grad_fn=<SoftmaxBackward0>)2m0:11:56 â€¢ 0:00:15[0m [2;4m0.27it/s[0m  
[2KStep 0 - TTA Loss: 0.6069â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m 199/203 [2m0:11:56 â€¢ 0:00:15[0m [2;4m0.27it/s[0m  
[2KAttention weights: tensor([[0.5467, 0.4533]], device='cuda:0', grad_fn=<SoftmaxBackward0>)2m0:11:56 â€¢ 0:00:15[0m [2;4m0.27it/s[0m  
[2KAttention weights: tensor([[0.5493, 0.4507]], device='cuda:0', grad_fn=<SoftmaxBackward0>)2m0:11:56 â€¢ 0:00:15[0m [2;4m0.27it/s[0m  
[2KAttention weights: tensor([[0.5589, 0.4411]], device='cuda:0', grad_fn=<SoftmaxBackward0>)2m0:11:56 â€¢ 0:00:15[0m [2;4m0.27it/s[0m  
[2KAttention weights: tensor([[0.5797, 0.4203]], device='cuda:0', grad_fn=<SoftmaxBackward0>)2m0:11:56 â€¢ 0:00:15[0m [2;4m0.27it/s[0m  
[2KAttention weights: tensor([[0.6142, 0.3858]], device='cuda:0', grad_fn=<SoftmaxBackward0>)2m0:11:56 â€¢ 0:00:15[0m [2;4m0.27it/s[0m  
[2KAttention weights: tensor([[0.6657, 0.3343]], device='cuda:0', grad_fn=<SoftmaxBackward0>)2m0:11:56 â€¢ 0:00:15[0m [2;4m0.27it/s[0m  
[2KAttention weights: tensor([[0.7298, 0.2702]], device='cuda:0', grad_fn=<SoftmaxBackward0>)2m0:11:56 â€¢ 0:00:15[0m [2;4m0.27it/s[0m  
[2KAttention weights: tensor([[0.8049, 0.1951]], device='cuda:0', grad_fn=<SoftmaxBackward0>)2m0:11:56 â€¢ 0:00:15[0m [2;4m0.27it/s[0m  
[2KAttention weights: tensor([[0.8764, 0.1236]], device='cuda:0', grad_fn=<SoftmaxBackward0>)2m0:11:56 â€¢ 0:00:15[0m [2;4m0.27it/s[0m  
[2KAttention weights: tensor([[0.5690, 0.4310]], device='cuda:0')m[38;5;237mâ•º[0m 199/203 [2m0:11:56 â€¢ 0:00:15[0m [2;4m0.27it/s[0m  
[2KAttention weights: tensor([[0.9095, 0.0905],â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m 199/203 [2m0:11:56 â€¢ 0:00:15[0m [2;4m0.27it/s[0m  
        [0.8446, 0.1554],
        [0.8567, 0.1433],
        [0.8955, 0.1045],
        [0.9234, 0.0766],
        [0.9393, 0.0607],
        [0.9469, 0.0531],
        [0.9671, 0.0329],
        [0.8857, 0.1143],
[2K        [0.9283, 0.0717]], device='cuda:0')â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m 199/203 [2m0:11:56 â€¢ 0:00:15[0m [2;4m0.27it/s[0m  
[2KAttention weights: tensor([[0.5605, 0.4395],â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m 200/203 [2m0:12:07 â€¢ 0:00:15[0m [2;4m0.20it/s[0m  
        [0.5560, 0.4440],
        [0.5578, 0.4422],
        [0.5587, 0.4413],
        [0.5596, 0.4404],
        [0.5565, 0.4435],
        [0.5555, 0.4445],
        [0.5597, 0.4403],
        [0.5599, 0.4401],
[2K        [0.5593, 0.4407]], device='cuda:0', grad_fn=<SoftmaxBackward0>)37mâ•º[0m 200/203 [2m0:12:07 â€¢ 0:00:15[0m [2;4m0.20it/s[0m  
[2KClass label: CleanAndJerkâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m 200/203 [2m0:12:07 â€¢ 0:00:15[0m [2;4m0.20it/s[0m  
[2KAttention weights: tensor([[0.5710, 0.4290]], device='cuda:0', grad_fn=<SoftmaxBackward0>)2m0:12:07 â€¢ 0:00:15[0m [2;4m0.20it/s[0m  
[2KStep 0 - TTA Loss: 0.8593â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m 200/203 [2m0:12:07 â€¢ 0:00:15[0m [2;4m0.20it/s[0m  
[2KAttention weights: tensor([[0.6833, 0.3167]], device='cuda:0', grad_fn=<SoftmaxBackward0>)2m0:12:07 â€¢ 0:00:15[0m [2;4m0.20it/s[0m  
[2KAttention weights: tensor([[0.7699, 0.2301]], device='cuda:0', grad_fn=<SoftmaxBackward0>)2m0:12:07 â€¢ 0:00:15[0m [2;4m0.20it/s[0m  
[2KAttention weights: tensor([[0.8304, 0.1696]], device='cuda:0', grad_fn=<SoftmaxBackward0>)2m0:12:07 â€¢ 0:00:15[0m [2;4m0.20it/s[0m  
[2KAttention weights: tensor([[0.8696, 0.1304]], device='cuda:0', grad_fn=<SoftmaxBackward0>)2m0:12:07 â€¢ 0:00:15[0m [2;4m0.20it/s[0m  
[2KAttention weights: tensor([[0.8949, 0.1051]], device='cuda:0', grad_fn=<SoftmaxBackward0>)2m0:12:07 â€¢ 0:00:15[0m [2;4m0.20it/s[0m  
[2KAttention weights: tensor([[0.9075, 0.0925]], device='cuda:0', grad_fn=<SoftmaxBackward0>)2m0:12:07 â€¢ 0:00:15[0m [2;4m0.20it/s[0m  
[2KAttention weights: tensor([[0.9157, 0.0843]], device='cuda:0', grad_fn=<SoftmaxBackward0>)2m0:12:07 â€¢ 0:00:15[0m [2;4m0.20it/s[0m  
[2KAttention weights: tensor([[0.9187, 0.0813]], device='cuda:0', grad_fn=<SoftmaxBackward0>)2m0:12:07 â€¢ 0:00:15[0m [2;4m0.20it/s[0m  
[2KAttention weights: tensor([[0.9190, 0.0810]], device='cuda:0', grad_fn=<SoftmaxBackward0>)2m0:12:07 â€¢ 0:00:15[0m [2;4m0.20it/s[0m  
[2KAttention weights: tensor([[0.5735, 0.4265]], device='cuda:0')m[38;5;237mâ•º[0m 200/203 [2m0:12:07 â€¢ 0:00:15[0m [2;4m0.20it/s[0m  
[2KAttention weights: tensor([[0.9407, 0.0593],â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m 200/203 [2m0:12:07 â€¢ 0:00:15[0m [2;4m0.20it/s[0m  
        [0.8807, 0.1193],
        [0.9192, 0.0808],
        [0.9314, 0.0686],
        [0.9579, 0.0421],
        [0.9700, 0.0300],
        [0.9797, 0.0203],
        [0.9713, 0.0287],
        [0.9148, 0.0852],
[2K        [0.9604, 0.0396]], device='cuda:0')â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;5;237mâ•º[0m 200/203 [2m0:12:07 â€¢ 0:00:15[0m [2;4m0.20it/s[0m  
[2KAttention weights: tensor([[0.5605, 0.4395],â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m 201/203 [2m0:12:08 â€¢ 0:00:09[0m [2;4m0.24it/s[0m  
        [0.5560, 0.4440],
        [0.5578, 0.4422],
        [0.5587, 0.4413],
        [0.5596, 0.4404],
        [0.5565, 0.4435],
        [0.5555, 0.4445],
        [0.5597, 0.4403],
        [0.5599, 0.4401],
[2K        [0.5594, 0.4406]], device='cuda:0', grad_fn=<SoftmaxBackward0>)8;6;224mâ•¸[0m 201/203 [2m0:12:08 â€¢ 0:00:09[0m [2;4m0.24it/s[0m  
[2KClass label: CleanAndJerkâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m 201/203 [2m0:12:08 â€¢ 0:00:09[0m [2;4m0.24it/s[0m  
[2KAttention weights: tensor([[0.5664, 0.4336]], device='cuda:0', grad_fn=<SoftmaxBackward0>)03 [2m0:12:08 â€¢ 0:00:09[0m [2;4m0.24it/s[0m  
[2KStep 0 - TTA Loss: 0.7528â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m 201/203 [2m0:12:08 â€¢ 0:00:09[0m [2;4m0.24it/s[0m  
[2KAttention weights: tensor([[0.5664, 0.4336]], device='cuda:0', grad_fn=<SoftmaxBackward0>)03 [2m0:12:08 â€¢ 0:00:09[0m [2;4m0.24it/s[0m  
[2KAttention weights: tensor([[0.5665, 0.4335]], device='cuda:0', grad_fn=<SoftmaxBackward0>)03 [2m0:12:08 â€¢ 0:00:09[0m [2;4m0.24it/s[0m  
[2KAttention weights: tensor([[0.5670, 0.4330]], device='cuda:0', grad_fn=<SoftmaxBackward0>)03 [2m0:12:08 â€¢ 0:00:09[0m [2;4m0.24it/s[0m  
[2KAttention weights: tensor([[0.5682, 0.4318]], device='cuda:0', grad_fn=<SoftmaxBackward0>)03 [2m0:12:08 â€¢ 0:00:09[0m [2;4m0.24it/s[0m  
[2KAttention weights: tensor([[0.5701, 0.4299]], device='cuda:0', grad_fn=<SoftmaxBackward0>)03 [2m0:12:08 â€¢ 0:00:09[0m [2;4m0.24it/s[0m  
[2KAttention weights: tensor([[0.5730, 0.4270]], device='cuda:0', grad_fn=<SoftmaxBackward0>)03 [2m0:12:08 â€¢ 0:00:09[0m [2;4m0.24it/s[0m  
[2KAttention weights: tensor([[0.5755, 0.4245]], device='cuda:0', grad_fn=<SoftmaxBackward0>)03 [2m0:12:08 â€¢ 0:00:09[0m [2;4m0.24it/s[0m  
[2KAttention weights: tensor([[0.5799, 0.4201]], device='cuda:0', grad_fn=<SoftmaxBackward0>)03 [2m0:12:08 â€¢ 0:00:09[0m [2;4m0.24it/s[0m  
[2KAttention weights: tensor([[0.5847, 0.4153]], device='cuda:0', grad_fn=<SoftmaxBackward0>)03 [2m0:12:08 â€¢ 0:00:09[0m [2;4m0.24it/s[0m  
[2KAttention weights: tensor([[0.5584, 0.4416]], device='cuda:0')m[38;2;98;6;224mâ•¸[0m 201/203 [2m0:12:08 â€¢ 0:00:09[0m [2;4m0.24it/s[0m  
[2KAttention weights: tensor([[0.6892, 0.3108],â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m 201/203 [2m0:12:08 â€¢ 0:00:09[0m [2;4m0.24it/s[0m  
        [0.6327, 0.3673],
        [0.5908, 0.4092],
        [0.6896, 0.3104],
        [0.6683, 0.3317],
        [0.6927, 0.3073],
        [0.6773, 0.3227],
        [0.7403, 0.2597],
        [0.6940, 0.3060],
[2K        [0.7099, 0.2901]], device='cuda:0')â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m 201/203 [2m0:12:08 â€¢ 0:00:09[0m [2;4m0.24it/s[0m  
[2KAttention weights: tensor([[0.5605, 0.4395],â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m 202/203 [2m0:12:10 â€¢ 0:00:04[0m [2;4m0.26it/s[0m  
        [0.5560, 0.4440],
        [0.5578, 0.4422],
        [0.5587, 0.4413],
        [0.5596, 0.4404],
        [0.5565, 0.4435],
        [0.5556, 0.4444],
        [0.5597, 0.4403],
        [0.5599, 0.4401],
[2K        [0.5594, 0.4406]], device='cuda:0', grad_fn=<SoftmaxBackward0>)8;6;224mâ•¸[0m 202/203 [2m0:12:10 â€¢ 0:00:04[0m [2;4m0.26it/s[0m  
[2KClass label: HammerThrowâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m 202/203 [2m0:12:10 â€¢ 0:00:04[0m [2;4m0.26it/s[0m  
[2KAttention weights: tensor([[0.5861, 0.4139]], device='cuda:0', grad_fn=<SoftmaxBackward0>)03 [2m0:12:10 â€¢ 0:00:04[0m [2;4m0.26it/s[0m  
[2KStep 0 - TTA Loss: 0.3727â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m 202/203 [2m0:12:10 â€¢ 0:00:04[0m [2;4m0.26it/s[0m  
[2KAttention weights: tensor([[0.6289, 0.3711]], device='cuda:0', grad_fn=<SoftmaxBackward0>)03 [2m0:12:10 â€¢ 0:00:04[0m [2;4m0.26it/s[0m  
[2KAttention weights: tensor([[0.6888, 0.3112]], device='cuda:0', grad_fn=<SoftmaxBackward0>)03 [2m0:12:10 â€¢ 0:00:04[0m [2;4m0.26it/s[0m  
[2KAttention weights: tensor([[0.7525, 0.2475]], device='cuda:0', grad_fn=<SoftmaxBackward0>)03 [2m0:12:10 â€¢ 0:00:04[0m [2;4m0.26it/s[0m  
[2KAttention weights: tensor([[0.8063, 0.1937]], device='cuda:0', grad_fn=<SoftmaxBackward0>)03 [2m0:12:10 â€¢ 0:00:04[0m [2;4m0.26it/s[0m  
[2KAttention weights: tensor([[0.8423, 0.1577]], device='cuda:0', grad_fn=<SoftmaxBackward0>)03 [2m0:12:10 â€¢ 0:00:04[0m [2;4m0.26it/s[0m  
[2KAttention weights: tensor([[0.8632, 0.1368]], device='cuda:0', grad_fn=<SoftmaxBackward0>)03 [2m0:12:10 â€¢ 0:00:04[0m [2;4m0.26it/s[0m  
[2KAttention weights: tensor([[0.8739, 0.1261]], device='cuda:0', grad_fn=<SoftmaxBackward0>)03 [2m0:12:10 â€¢ 0:00:04[0m [2;4m0.26it/s[0m  
[2KAttention weights: tensor([[0.8788, 0.1212]], device='cuda:0', grad_fn=<SoftmaxBackward0>)03 [2m0:12:10 â€¢ 0:00:04[0m [2;4m0.26it/s[0m  
[2KAttention weights: tensor([[0.8803, 0.1197]], device='cuda:0', grad_fn=<SoftmaxBackward0>)03 [2m0:12:10 â€¢ 0:00:04[0m [2;4m0.26it/s[0m  
[2KAttention weights: tensor([[0.5714, 0.4286]], device='cuda:0')m[38;2;98;6;224mâ•¸[0m 202/203 [2m0:12:10 â€¢ 0:00:04[0m [2;4m0.26it/s[0m  
[2KAttention weights: tensor([[0.8471, 0.1529],â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m 202/203 [2m0:12:10 â€¢ 0:00:04[0m [2;4m0.26it/s[0m  
        [0.7338, 0.2662],
        [0.7799, 0.2201],
        [0.8342, 0.1658],
        [0.8808, 0.1192],
        [0.8508, 0.1492],
        [0.8239, 0.1761],
        [0.8484, 0.1516],
        [0.8261, 0.1739],
[2K        [0.8767, 0.1233]], device='cuda:0')â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[38;2;98;6;224mâ•¸[0m 202/203 [2m0:12:10 â€¢ 0:00:04[0m [2;4m0.26it/s[0m  
[2K                   video-id  t-start  t-end     labelâ”â”â”â”â”â”â”â”â”â”â”[0m 203/203 [2m0:12:14 â€¢ 0:00:00[0m [2;4m0.25it/s[0m  4m0.26it/s[0m  
0  video_validation_0000365     18.1   24.3  HighJump
1  video_validation_0000365     29.6   33.3  HighJump
2  video_validation_0000365     69.7   77.3  HighJump
3  video_validation_0000365     80.8   84.3  HighJump
[2K4  video_validation_0000365    110.4  116.2  HighJumpâ”â”â”â”â”â”â”[0m 203/203 [2m0:12:14 â€¢ 0:00:00[0m [2;4m0.25it/s[0m  
[2K                   video-id     t-start       t-end       score     label[2m0:12:14 â€¢ 0:00:00[0m [2;4m0.25it/s[0m  
0  video_validation_0000365   18.833333   37.666667    2.231281  HighJump
1  video_validation_0000365   66.466667   88.900000   2.4481883  HighJump
2  video_validation_0000365  111.533333  124.066667   2.0611284  HighJump
3  video_validation_0000365  137.800000  156.000000   1.8599951  HighJump
[2K4  video_validation_0000365  156.733333  159.100000  0.71652114  HighJump[2m0:12:14 â€¢ 0:00:00[0m [2;4m0.25it/s[0m  
[2KGround truth labels:  ['HighJump' 'PoleVault' 'TennisSwing' 'GolfSwing' 'HammerThrow'â€¢ 0:00:00[0m [2;4m0.25it/s[0m  
[2K 'Billiards' 'BaseballPitch' 'CleanAndJerk' 'ThrowDiscus' 'SoccerPenalty'][2m0:12:14 â€¢ 0:00:00[0m [2;4m0.25it/s[0m  
[2KPredicted labels:  ['HighJump' 'TennisSwing' 'GolfSwing' 'HammerThrow' 'Billiards'14 â€¢ 0:00:00[0m [2;4m0.25it/s[0m  
[2K 'BaseballPitch' 'CleanAndJerk' 'ThrowDiscus' 'SoccerPenalty' 'PoleVault'][2m0:12:14 â€¢ 0:00:00[0m [2;4m0.25it/s[0m  
[2King [38;2;98;6;224mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 203/203 [2m0:12:14 â€¢ 0:00:00[0m [2;4m0.25it/s[0m  
[2King [38;2;98;6;224mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 203/203 [2m0:12:14 â€¢ 0:00:00[0m [2;4m0.25it/s[0m  
[2KBaseballPitch [11.8, 3.1, 1.1, 0.4, 0.3]â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 203/203 [2m0:12:14 â€¢ 0:00:00[0m [2;4m0.25it/s[0m  
[2King [38;2;98;6;224mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 203/203 [2m0:12:14 â€¢ 0:00:00[0m [2;4m0.25it/s[0m  
[2King [38;2;98;6;224mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 203/203 [2m0:12:14 â€¢ 0:00:00[0m [2;4m0.25it/s[0m  
[2KBilliards [6.8, 4.4, 2.0, 1.0, 0.1]â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 203/203 [2m0:12:14 â€¢ 0:00:00[0m [2;4m0.25it/s[0m  
[2King [38;2;98;6;224mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 203/203 [2m0:12:14 â€¢ 0:00:00[0m [2;4m0.25it/s[0m  
[2King [38;2;98;6;224mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 203/203 [2m0:12:14 â€¢ 0:00:00[0m [2;4m0.25it/s[0m  
[2KCleanAndJerk [37.8, 27.7, 18.0, 8.7, 4.6]â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 203/203 [2m0:12:14 â€¢ 0:00:00[0m [2;4m0.25it/s[0m  
[2King [38;2;98;6;224mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 203/203 [2m0:12:14 â€¢ 0:00:00[0m [2;4m0.25it/s[0m  
[2King [38;2;98;6;224mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 203/203 [2m0:12:14 â€¢ 0:00:00[0m [2;4m0.25it/s[0m  
[2KGolfSwing [18.1, 9.9, 5.8, 1.2, 1.2]â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 203/203 [2m0:12:14 â€¢ 0:00:00[0m [2;4m0.25it/s[0m  
[2King [38;2;98;6;224mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 203/203 [2m0:12:14 â€¢ 0:00:00[0m [2;4m0.25it/s[0m  
[2King [38;2;98;6;224mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 203/203 [2m0:12:14 â€¢ 0:00:00[0m [2;4m0.25it/s[0m  
[2KHammerThrow [39.0, 32.9, 23.7, 17.1, 12.7]â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 203/203 [2m0:12:14 â€¢ 0:00:00[0m [2;4m0.25it/s[0m  
[2King [38;2;98;6;224mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 203/203 [2m0:12:14 â€¢ 0:00:00[0m [2;4m0.25it/s[0m  
[2King [38;2;98;6;224mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 203/203 [2m0:12:14 â€¢ 0:00:00[0m [2;4m0.25it/s[0m  
[2KHighJump [28.4, 15.9, 9.6, 5.6, 2.3]â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 203/203 [2m0:12:14 â€¢ 0:00:00[0m [2;4m0.25it/s[0m  
[2King [38;2;98;6;224mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 203/203 [2m0:12:14 â€¢ 0:00:00[0m [2;4m0.25it/s[0m  
[2King [38;2;98;6;224mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 203/203 [2m0:12:14 â€¢ 0:00:00[0m [2;4m0.25it/s[0m  
[2KPoleVault [48.5, 38.7, 28.2, 21.4, 12.6]â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 203/203 [2m0:12:14 â€¢ 0:00:00[0m [2;4m0.25it/s[0m  
[2King [38;2;98;6;224mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 203/203 [2m0:12:14 â€¢ 0:00:00[0m [2;4m0.25it/s[0m  
[2King [38;2;98;6;224mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 203/203 [2m0:12:14 â€¢ 0:00:00[0m [2;4m0.25it/s[0m  
[2KSoccerPenalty [28.0, 12.7, 8.1, 2.5, 0.9]â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 203/203 [2m0:12:14 â€¢ 0:00:00[0m [2;4m0.25it/s[0m  
[2King [38;2;98;6;224mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 203/203 [2m0:12:14 â€¢ 0:00:00[0m [2;4m0.25it/s[0m  
[2King [38;2;98;6;224mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 203/203 [2m0:12:14 â€¢ 0:00:00[0m [2;4m0.25it/s[0m  
[2KTennisSwing [1.8, 0.8, 0.5, 0.1, 0.0]â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 203/203 [2m0:12:14 â€¢ 0:00:00[0m [2;4m0.25it/s[0m  
[2King [38;2;98;6;224mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 203/203 [2m0:12:14 â€¢ 0:00:00[0m [2;4m0.25it/s[0m  
[2King [38;2;98;6;224mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 203/203 [2m0:12:14 â€¢ 0:00:00[0m [2;4m0.25it/s[0m  
[2KThrowDiscus [6.7, 5.0, 3.6, 3.0, 1.3]â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 203/203 [2m0:12:14 â€¢ 0:00:00[0m [2;4m0.25it/s[0m  
[2King [38;2;98;6;224mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 203/203 [2m0:12:14 â€¢ 0:00:00[0m [2;4m0.25it/s[0m  
[2King [38;2;98;6;224mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 203/203 [2m0:12:14 â€¢ 0:00:00[0m [2;4m0.25it/s[0m  
[2K\begin{tabular}{lrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr
rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr}
\hline
 Class         &     AP@0% &   AP@0% &   AP@0% &   AP@0% &   AP@0% \\
\hline
 BaseballPitch & 11.8      &     3.1 &     1.1 &     0.4 &     0.3 \\
 Billiards     &  6.8      &     4.4 &     2   &     1   &     0.1 \\
 CleanAndJerk  & 37.8      &    27.7 &    18   &     8.7 &     4.6 \\
 GolfSwing     & 18.1      &     9.9 &     5.8 &     1.2 &     1.2 \\
 HammerThrow   & 39        &    32.9 &    23.7 &    17.1 &    12.7 \\
 HighJump      & 28.4      &    15.9 &     9.6 &     5.6 &     2.3 \\
 PoleVault     & 48.5      &    38.7 &    28.2 &    21.4 &    12.6 \\
 SoccerPenalty & 28        &    12.7 &     8.1 &     2.5 &     0.9 \\
 TennisSwing   &  1.8      &     0.8 &     0.5 &     0.1 &     0   \\
 ThrowDiscus   &  6.7      &     5   &     3.6 &     3   &     1.3 \\
 IoU           &  0.231285 &     0   &     0   &     0   &     0   \\
\hline
[2K\end{tabular};6;224mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 203/203 [2m0:12:14 â€¢ 0:00:00[0m [2;4m0.25it/s[0m  
[2K[22.69 15.11 10.06  6.1   3.6 ]â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 203/203 [2m0:12:14 â€¢ 0:00:00[0m [2;4m0.25it/s[0m  
[2KAverage TIOU:  0.010704242421014884â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 203/203 [2m0:12:14 â€¢ 0:00:00[0m [2;4m0.25it/s[0m  
[2Kpreds_tensor: torch.Size([203, 10])â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 203/203 [2m0:12:14 â€¢ 0:00:00[0m [2;4m0.25it/s[0m  
[2KTop-1 accuracy: 0.8522167487684729â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 203/203 [2m0:12:14 â€¢ 0:00:00[0m [2;4m0.25it/s[0m  
[2Kpreds_tensor: torch.Size([203, 10])â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 203/203 [2m0:12:14 â€¢ 0:00:00[0m [2;4m0.25it/s[0m  
[2KTop-3 accuracy: 0.9655172413793104â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 203/203 [2m0:12:14 â€¢ 0:00:00[0m [2;4m0.25it/s[0m  
[2Kpreds_tensor: torch.Size([203, 10])â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 203/203 [2m0:12:14 â€¢ 0:00:00[0m [2;4m0.25it/s[0m  
[2KTop-5 accuracy: 0.9950738916256158â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 203/203 [2m0:12:14 â€¢ 0:00:00[0m [2;4m0.25it/s[0m  
[2Kâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“â”â”â”[0m 203/203 [2m0:12:14 â€¢ 0:00:00[0m [2;4m0.25it/s[0m  
â”ƒ[1m [0m[1m       Test metric       [0m[1m [0mâ”ƒ[1m [0m[1m      DataLoader 0       [0m[1m [0mâ”ƒ
â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©
â”‚[36m [0m[36m          AP_0           [0m[36m [0mâ”‚[35m [0m[35m   22.690000534057617    [0m[35m [0mâ”‚
â”‚[36m [0m[36m         avg_AP          [0m[36m [0mâ”‚[35m [0m[35m    11.51200008392334    [0m[35m [0mâ”‚
â”‚[36m [0m[36m  label top-1 accuracy   [0m[36m [0mâ”‚[35m [0m[35m   0.8522167205810547    [0m[35m [0mâ”‚
â”‚[36m [0m[36m  label top-3 accuracy   [0m[36m [0mâ”‚[35m [0m[35m   0.9655172228813171    [0m[35m [0mâ”‚
â”‚[36m [0m[36m  label top-5 accuracy   [0m[36m [0mâ”‚[35m [0m[35m   0.9950739145278931    [0m[35m [0mâ”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
[2KTesting [38;2;98;6;224mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m 203/203 [2m0:12:14 â€¢ 0:00:00[0m [2;4m0.25it/s[0m
[?25h[[36m2025-02-14 01:21:44,244[0m][[34m__main__[0m][[32mINFO[0m] - Best ckpt path: None[0m
[[36m2025-02-14 01:21:44,256[0m][[34msrc.utils.utils[0m][[32mINFO[0m] - Output dir: /home/def/fewshot/logs/train/runs/2025-02-14_01-09-13[0m
[[36m2025-02-14 01:21:44,257[0m][[34msrc.utils.utils[0m][[32mINFO[0m] - Closing wandb![0m
